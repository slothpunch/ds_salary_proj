Job Title,Salary Estimate,Job Description,Rating,Company Name,Location,Size,Founded,Type of ownership,Industry,Sector,Revenue
Professional Services Consultant,"$48K-$97K
(Glassdoor Est.)","Thycotic, a global leader in IT security, is the fastest growing provider of Privileged Access Management solutions that protect an organization’s most valuable assets from cyber-attacks and insider threats. Our mission is to make self-sufficient security champions, by making security tools people love to use that make privilege management achievable for everyone.

The results show:
--We have over 10,000 customers worldwide ranging from mid-sized organizations to Fortune 100 companies and are adding hundreds of new customers every quarter.
--We are growing at twice the rate of the overall PAM market (50% vs 25%).
-- We are among Inc. 5000 Fastest Growing Companies six years in a row.


Position Summary

The Professional Services (PS) Consultant delivers on pre-paid packaged services including installation, configuration, and customization of Thycotic software and custom engagements that may include scripting (with help from others at Thycotic), API use, and geo-replication. The individual collaborates with other Thycotic staff to ensure that Thycotic software solutions are successfully implemented as the foundation of a strategic Privilege Access Management program. The PS consultant will be involved with advanced troubleshooting and technical escalation management for a client account.

We are open to US location for this role, however it the right candidate must be willing to work EST hours. This position can be based in your remote home office or our DC headquarters. Generally, requires up to 35% travel.
Key Responsibilities
Lead the implementation of the Thycotic solutions in the client’s environment to Best Practices
Collaborate with the Project Management team to help scope engagements for Professional Services
Provide in depth consultative services which include advisement on general security principals, and how to effectively manage a Privileged Account Management project
Prepare and deliver technical presentations explaining products or services to customers and prospective customers
Work with clients to understand the technical architecture of their environments as it relates to the installation, configuration, upgrade, or enhancement of Secret Server
Install, upgrade and/or configure Thycotic software to work within the capabilities of the application for those requirements
Review the configuration decisions that are available to clients and provide guidance on best practices
Produce deliverables for client signoff such as installation plans, configuration plans, documentation on what was installed and configured, the architecture of the resulting environment, and any PowerShell scripts that were used
Build and maintain client relationships to become a trusted advisor
Work efficiently with client’s technical support team to solve client issues

Skills & Requirements
Bachelor’s Degree or higher in a technical field or equivalent experience
4+ years of full-time work experience managing or supporting enterprise systems and/or implementing enterprise-class software solutions – with Privilege Access Management preferred
Windows Server operating system and Active Directory experience
Implementing enterprise-class software dealing with Windows and Active Directory security
SQL Server Implementation (Reporting/Admin) experience
Ability to effectively manage multiple tasks and competing priorities.
Proven ability to effectively engage and work with sales, project managers, technical support, engineering, and other teams within an organization to drive client success.
Excellent verbal and written communication skills.
Working experience or ability to quickly learn all Microsoft workstation and server operating systems from XP to Server 2019
Expertise in TSQL queries and PowerShell is a significant plus
Experience with Thycotic Products a plus
Any Windows or SQL Server certifications a plus
Working experience with cloud deployments on Microsoft Azure a plus

Why Work at Thycotic?

We’re passionate problem-solvers doing our part to make the world a safer place. We invest in people who are smart, self-motivated and collaborative.

What we offer in return is meaningful work, a culture of innovation and great career progression!

Thycotic was named a “Best Places to Work” Award Winner in 2019 and 2020 in recognition of our positive work environment and culture, as reported by employees. A focus on employee advancement and our ethos of respect are just some of the reasons why people love working here!


Thycotic is an Equal Opportunity Employer and does not discriminate on the basis of race, ancestry, national origin, color, religion, gender, age, marital status, sexual orientation, disability, or veteran status.

Upon conditional offer of employment, candidates are required to complete a criminal background check and drug screen per Thycotic employment policy.",4.1,"Thycotic
4.1","Chicago, IL",201 to 500 Employees,1996,Company - Private,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (USD)
Associate Managing Consultant,"$83K-$150K
(Glassdoor Est.)","Business Title
Associate Managing Consultant

27-Jul-2020

Requisition Number
25355BR

Job Description and Requirements
At Synopsys, we’re at the heart of the innovations that change the way we work and play. Self-driving cars. Artificial Intelligence. The cloud. 5G. The Internet of Things. These breakthroughs are ushering in the Era of Smart Everything. And we’re powering it all with the world’s most advanced technologies for chip design and software security. If you share our passion for innovation, we want to meet you.

Our Software Security and Quality business is all about building secure software—faster. That starts with our static analysis, software composition analysis, and dynamic analysis so our customers can build security and quality into the DNA of their code at any stage of the software development lifecycle and across the supply chain. All while minimizing risks and maximizing speed of application development. To find out more about SIG, Synopsys check out https://www.synopsys.com/software-integrity.html.

Associate Managing Consultant

This is a position that requires you have a unique blend of business development, account management, and deep technical knowledge. As Synopsys engages with clients to propose and deliver our software security services and products, you will have direct responsibility for developing strong and lasting relationships with clients. You will also be effectively identifying and selling follow-on work to clients, assisting sales in selling new business to clients, ensuring contracts are properly managed and serving as an effective escalation point for client issues and problems on engagements.

Key Qualifications
Solid experience with software development or software application security
Thorough knowledge of SDLC
Sufficient applications security knowledge to effectively communicate the value of our services to the client and translate that to revenue
Understanding of software development processes, technologies, architectures, and practices, and software risk management
Proven ability to deliver solution strategies and implementations to clients
Understanding and highly effective client interface skills
Demonstrated understanding and ability to manage to Time & Material, Cost Plus, and Fix-Priced engagements
Experience running small consulting/delivery teams and project execution
Ability to create presentations, proposals and SOWs
Written communication skills include: formal documentation, statements of work, proposals, sources sought and request for information responses, white papers, case studies
Expected to manage client profitability and revenue growth.
Willingness to travel (up to 50%)
Education
Bachelor’s Degree in Computer Science, Engineering or equivalent. Master’s Degree preferred

Inclusion and Diversity are important to us. Synopsys considers all applicants for employment without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, military veteran status, or disability.

#LI-DNI

Hiring Location
USA - Illinois - Chicago

Hire Type
Employee

Job Category
Software Security Consulting

Country
United States",4.1,"Synopsys
4.1","Chicago, IL",10000+ Employees,1986,Company - Public,Computer Hardware & Software,Information Technology,$2 to $5 billion (USD)
BI Developer - Jaspersoft,"$81K-$135K
(Glassdoor Est.)","Summary

Using statistical analysis and various data visualization techniques the candidate will collaborate with business users and technical teams across the organization to facilitate data-driven decision making by enabling exploration and analysis of historical and near real-time data access using on premise and cloud-based tools and technologies

Primary Duties and Responsibilities:
To perform this job successfully, an individual must be able to perform each primary duty satisfactorily. You will be part of the Data team, a diverse group of dedicated engineers who are very passionate about data. As the Data team member, you will be responsible for crafting and building large cloud-based data systems that will serve as the backbone for the enterprise data management and analytics capabilities. You will join the core team responsible for the design, development, and implementation. You will work closely with business and technology partners, internal and external. We will define system architecture, technology stack and its tactical implementation. You will help us take on unique technical challenges associated with handling large datasets and managing streaming data in public cloud and hybrid environments, build large and complex data pipelines, integrate data coming from diverse sources in different formats, implement continuous integration/continuous delivery pipelines, automate everything we can get our hands on, and be part of the Enterprise Reporting Platform implementation. You will have a rare and challenging opportunity to apply your technical skills, knowledge and experience, acquire new skills and grow with us.

Supervisory Responsibilities: N/A

Minimum Qualifications :

• BS degree in Computer Science, similar technical field or equivalent experience
• 5+ years of data-centric design, development and architecture experience with primary focus on BI, reporting and analytics solution development
• 3+ years of experience architecting, designing, and developing enterprise wide dashboards and reporting solutions with TIBCO Jaspersoft
• Experience in performance tuning of complex reports and large datasets for optimal performance and maintainability
• Expertise in iReport Designer, creating Ad Hoc reports, Views and Domains
• Experience with common Java application development related technologies – Servlets, XML, JSP, HTML, XHTML, DHTML, CSS, Java script a plus
Ability to design, construct foundation and implement a long-term strategy for Enterprise Reporting platform
Deep knowledge of BI tools, features and functions
Experience with Linux/OSX command line and git
• Understand data models and their relationship to reporting
• Snowflake, Redshift, Postgres MySQL or similar data handling experience
• Experience with rolling out BI platform as a self-service tool for users
• Automation of BI reports distribution in different formats (Excel, PDF)
• Knowledge of best practices in data visualization design and development
• Understand statistical constructs and how to use them in a program
• Strong knowledge of SQL, data warehousing concepts, various data management systems
• Ability to design, construct foundation and implement a long-term strategy for Enterprise Reporting platform
• Ability to interact with business users to identify reporting and data analysis needs
• Experience with Linux/ OSX command line and git
• Scripting knowledge using Shell scripting, Python, or equivalent
• Experience working with Cloud ecosystems (AWS, Azure, GCP)
Understand statistical constructs and how to use them in a program
• Understanding of the software development life cycle (SDLC) in Waterfall, Lean, and Agile work environments
Understand data models and their relationship to reporting
Understanding of financial markets for derivatives and derivatives instruments
• Ability to develop and follow defined processes in structured environment
Excellent communication and presentation skills
• Ability to interact with business users to identify reporting and data analysis needs

Preferred Qualifications:

• Master’s degree or equivalent experience
• Hands-on experience with more than one reporting tools like Tableau, Power BI, Looker or something similar.TIBCO Jaspersoft
• Experience with data wrangling, data virtualization, data curation tools a plus
• Experience with DevOps process (exposure to GitHub, Jenkins or other CI/CD tools)
• Knowledge and experience with Terraform and Ansible
• Financial markets work experience, knowledge of trade and settlement lifecycle

Certificates or Licenses:

• BI tool certification as a plus
• AWS certification as a plus

Step 1
When you find a position you're interested in, click the 'Apply' button. Please complete the application and attach your resume.

Step 2
You will receive an email notification to confirm that we've received your application.

Step 3
If you are called in for an interview, a representative from OCC will contact you to set up a date, time, and location.",2.4,"Options Clearing Corporation
2.4","Chicago, IL",501 to 1000 Employees,1973,Company - Private,Financial Transaction Processing,Finance,$100 to $500 million (USD)
Warehouse Worker - Package Handler,"$10-$16 Per Hour
(Glassdoor Est.)","$14.50/hr. paid weekly for Package Handlers!

Shift: Sunrise/Preload (3:30 AM - 9:30 AM) Twilight (5:00 PM - 10:00 PM)

WAREHOUSE WORKER – PACKAGE HANDLER

Find out what you’ll become as a Package Handler at UPS. In this fast-paced warehouse job, you’ll lift, lower and slide packages up to 70 lbs. You’ll typically work 3 ½ - 4 hour shifts, approximately 17 ½ - 20 hours per week in this part-time or seasonal role. As part of the UPS team, you’ll receive a competitive hourly rate and an attractive benefits package. Take the next step on your career journey as a Package Handler/Warehouse Worker at UPS.

If you’re a student at an approved college, university, trade or technical school, UPS offers an educational assistance program that could provide you with up to $25,000 for tuition, books and fees. If you qualify, you’ll be eligible for the program on your first day of work at UPS.

UPS is an equal opportunity employer. UPS does not discriminate on the basis of race/color/religion/sex/national origin/veteran/disability/age/sexual orientation/gender identity or any other characteristic protected by law",3.5,"UNITED PARCEL SERVICE
3.5","Northbrook, IL",10000+ Employees,1907,Company - Public,Logistics & Supply Chain,Transportation & Logistics,$10+ billion (USD)
Experienced Technician & Experienced Installer In HVAC Field,-1,"IMMEDIATE OPENINGS: *
HVAC* Installer with *experience* in diagnostics, installations, and repair.
Must be great with sheet metal and have a high quality of workmanship.

We do everything from residential change outs to commercial projects.

Positions available for installers and technicians.

2-3 Years HVAC experience. Great customer service skills. Firm command

of residential hot water and steam heating systems.

Illinois driver's License

High school diploma/GED

EPA cerftified

Neatness and good organizational skills

Tools a plus.

MUST PASS BACKGROUND CHECK AND DRUG TESTING

Job Type: Full-time

Pay: $25.00 - $30.00 per hour

Schedule:
Monday to Friday
Supplemental Pay:
Commission pay
COVID-19 considerations:
All employee's must wear masks and gloves provided by the company

Experience:
relevant: 2 years (Required)
Work Location:
Multiple locations
Work Remotely:
No",-1,Giant HVAC,"Chicago, IL",-1,-1,-1,-1,-1,-1
Escrow Closer,"$25K-$53K
(Glassdoor Est.)","Escrow Closer/Title Agent/Escrow Officer*
Fidelity National Title*
Chicago, IL
Job Summary: *
The Escrow Officer is responsible to effectively manage the real estate closing transaction for insuring title insurance. This position requires the Escrow Officer to exercise extreme independent judgment and to possess the knowledge and experience necessary to efficiently handle any situation which may arise during the escrow process.
Job Roles: *
Manage the entire real estate closing process, including compliance with auditing requirements, lender instructions, title requirements, company requirements and other written instructions
Understand the escrow process to determine what steps need to be taken to transfer the title of property pursuant to the conditions called for in the real estate contract and lender instructions
Collaborate with title department to resolve title issues
Prepare all closing documents including the CD necessary to ensure title insurance is issued at closing
Oversee the issuance of checks, bills and statements, receipts, and any other documents needed to ensure customer satisfaction
Secure all documents (corrective and others) that may be required for the issuance of title insurance
Conduct closing with customer, realtor, lenders, and attorneys
Assist customers and clients with closing related questions
Prior to disbursement, confirm all funds are collected, all appropriate documents are checked for accuracy, signatures are collected, and acknowledgements and legal descriptions are correct
Correct all taxes due, HOA dues, and any delinquencies and/or principal and interest
Ensure all payoffs have been collected, mailed, delivered or wired according to instructions
Verify against the CD/Master ALTA statement that all disbursements have been paid correctly
Prior to recording, verify all legal documents for correct acknowledgements, legal, and lien information
Work with escrow assistants in the real estate transaction process
Manage and develop client relationships to ensure future real estate closing transactions
Market new business and make calls on current and prospective clients
Correspond with lenders, builders, real estate agents and attorneys as needed
Perform other duties as assigned by manager
Role Specific Knowledge: *
Familiar with standard concepts, practices, and procedures within the escrow/title industry field.
Good client relations and organizational skills.
Knowledge of SoftPro a plus.
Familiar with APLD, MyDec, Chicago Water and Zoning (preferred but not required).
Ability to read and interpret documents.
Detail-oriented and professional; able to handle confidential information.
Strong communication, both verbal and written.
Ability to deal with multiple types of roles such as real estate sellers, buyers, agents and brokers.
Ability to multi task.
Notary public or be bondable.
Education, Licensure, and Experience: *
Completion of a High School diploma or GED required.
Company provides Continuing Education training.
Job Type: Full-time

Experience:
Escrow Closer/Officer: 2 years (Required)
Residential closing: 3 years (Required)
Education:
High school or equivalent (Required)
Additional Compensation:
Commission
Bonuses
Work Location:
Chicago
Benefits:
Health insurance
Dental insurance
Vision insurance
401K
Employee Stock Purchase
Paid time off
Job Type: Full-time

Benefits:
401(k)
401(k) Matching
Dental Insurance
Disability Insurance
Flexible Spending Account
Health Insurance
Life Insurance
Paid Time Off
Vision Insurance
Experience:
Closing: 1 year (Preferred)",3.1,"Fidelity National Title
3.1","Chicago, IL",51 to 200 Employees,-1,Subsidiary or Business Segment,Insurance Carriers,Insurance,$10 to $25 million (USD)
Automotive Field Sales Representative - Road Warriors Only,"$25K-$58K
(Glassdoor Est.)","If you are truly an automotive-focused road warrior who knows how to close business, Penn Warranty Corp wants to talk with you! Due to anticipated growth in Penn Warranty Corporation's business in the Chicago metro area, we are looking to add a Road Warrior Field Sales Representative to our Midwest Region sales team. The Illinois territory encompasses the entire state of Illinois, with a majority of the business in the Chicago metro area. This is established territory with many working accounts.

Penn Warranty Corporation is a well-respected company, with over 30 years experience in the (VSC) vehicle service contract and ancillary products market to independent and franchise dealerships throughout the United States.

The Dealer Development Manager is a B2B sales position, on-boarding new accounts, servicing existing accounts, training dealers and service centers though daily face to face sale calls within the assigned territory. Developing and managing a weekly pipeline of business that consistently meets budgets and sales goals.
Essential Functions of a Penn Warranty Dealer Development Manager: *
· Creating and executing a sales plan to build revenue

· Getting on the road every morning, prepared to win

· Making sales calls, both cold calls and sales service calls

· Listening to customer needs and selling to those needs and the profile of the dealer

·Understanding and effectively communicating product knowledge to Dealers

.Preparing and making presentations of products and helping dealers select those that are best suited to their needs

· Maintaining and building relationships with dealerships within the assigned territory

· Monitoring competition by gathering information on pricing and products

· Building revenue based on successful execution of a proven sales plan

· Keeping management informed by submitting, via a company-supplied computer, contact reports and e-mails pertaining to activity in the territory

· Assisting with resolving customer issues

· Maintaining an adequate inventory of sales supplies for placement at dealerships

· Participating in trade shows and conventions

· Making 8-12 face-to-face dealer sales and service calls per day
Education and Experience: *
· Experience in business-to-business sales preferred

· Pre-owned Automotive dealership experience preferred but not necessary

· Finance, Insurance, and service contract experience is desirable

· Strong presentation skills

· Proven experience meeting sales goals

· Solid math skills

· Strong computer skills, including familiarity with Microsoft Office Products – Word, Excel and PowerPoint

· Must complete a drug screening and background check upon hire

· Valid Driver’s license, proof of insurance, and reliable transportation
Key Competencies: *
· Sales and results oriented

· Ability to work independently

· Excellent written and verbal communication skills

· Strong Presentation skills

· Solid Client relationships

· Demonstrated Closing skills

· Proven Negotiation skills

· Automotive knowledge

· Multi-tasking

· Organization skills

· Adaptability

The successful candidate must live within the sales territory.

We are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Job Type: Full-time

Pay: $65,000.00 - $75,000.00 per year

Benefits:
401(k)
401(k) Matching
Dental Insurance
Disability Insurance
Flexible Schedule
Flexible Spending Account
Health Insurance
Life Insurance
Paid Time Off
Retirement Plan
Tuition Reimbursement
Vision Insurance
Schedule:
8 Hour Shift
Monday to Friday
Supplemental Pay:
Bonus Pay
Commission Pay
Experience:
auto sales: 2 years (Preferred)
License:
Driver's License (Required)
Work authorization:
United States (Required)
Work Location:
On the road
Paid Training:
Yes
Management:
Ops Manager
Typical start time:
9AM
Typical end time:
6PM
This Company Describes Its Culture as:
Detail-oriented -- quality and precision-focused
Innovative -- innovative and risk-taking
Aggressive -- competitive and growth-oriented
Outcome-oriented -- results-focused with strong performance culture
Stable -- traditional, stable, strong processes
People-oriented -- supportive and fairness-focused
Team-oriented -- cooperative and collaborative
Company's website:
www.PennWarranty.com
Benefit Conditions:
Waiting period may apply
Work Remotely:
Yes",2.9,"Penn Warranty Corp.
2.9","Chicago, IL",51 to 200 Employees,1988,Company - Private,Insurance Carriers,Insurance,Less than $1 million (USD)
FT & PT Package Handler - Warehouse,"$13-$15 Per Hour
(Glassdoor Est.)","FedEx Ground is an essential business that needs people to help us support the economy, handling life-saving medications and other items that keep our communities as prepared as possible during these uncertain times.
FedEx Ground will continue to hire for essential positions like this one.

FedEx Ground is hiring part-time and full-time individuals to load and unload packages in our fast-paced warehouse environment. Part-time employees typically work a 2-4-hour shift per day. Full-time employees work approximately two shifts per day of varying lengths. Package Handlers are responsible for warehouse duties including: the physical loading, unloading and/or sorting of packages of varying sizes and weights by hand, including lifting, pushing, pulling, carrying, scanning, placing packages, as well as physical bending, twisting, kneeling and etc. in a safe and efficient manner. Shifts may vary depending on warehouse package volume and business needs.

Package Handlers will receive a competitive hourly rate and are eligible for an attractive benefits package including medical, dental, vision, vacation, holiday pay, parental leave and tuition assistance after completion of an eligibility period. Flexible schedules are offered at many of our locations and will be discussed during the hiring process.

Individuals who are interested in starting their journey with FedEx Ground must be at least 18 years of age and will be required to watch a virtual job preview before moving forward with the employment application process.

Reasonable accommodations are available for qualified individuals with disabilities throughout the application process.

Address: 920 W Taylor Rd
City: Romeoville
State: Illinois
Zip Code: 60446
Domicile Location: P608
Additional Location Information: ***Up TO 18.50/HR***
DRIVE THRU HIRING EVENT
SEPTEMBER 12, 2020
@ 10AM-2PM

ADDRESS: 920 W TAYLOR ROAD
ROMEOVILLE, IL 60446
Please have application completed*
EEO Statement

FedEx Ground is an equal opportunity / affirmative action employer (Minorities/Females/Disability/Veterans) committed to a diverse workforce",3.3,"FedEx Ground PH US
3.3","Romeoville, IL",10000+ Employees,2000,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,$10+ billion (USD)
Clinical Supervisor/Team Lead: Child and Adolescent PHP/IOP,-1,"\*Clinical Supervisor/Team Lead: Licensed Clinical Therapist

Employment Type: Full time

\*Partial Hospitalization Program/Intensive Outpatient Program

Therapist (LCPC, LCSW, LMFT, PhD, PsyD)

Plena Mind Center, LLC - Northbrook, IL 60062

Exciting opportunity for full-time clinician (40 hours per week: M-F)

Who we are:

Plena Mind Center is a beautiful child and adolescent outpatient PHP/IOP located in a suburban area just north of Chicago. Plena, chosen from the Latin root which translates to “full” in, is at the heart of what we are looking to achieve. We value innovation, whole-child philosophies, and a truly personal approach to ensure our patients and their families can live their lives to the fullest. We are devoted to building a premier pediatric program from the ground up; combining empirically based treatment approaches customized to each patient in a warm and welcoming environment. At Plena, you will experience all the reasons you entered such a rewarding field.

Who we are looking for:

We are seeking an entrepreneurial, motivated clinician interested in joining a compassionate and dynamic multidisciplinary behavioral health team. At Plena Mind Center, we are committed to growing a team dedicated to clinical excellence and professional integrity. We welcome active participation and open collaboration to achieve our goal of becoming leaders in the pediatric PHP/IOP space.

The clinician will be a key member of a multidisciplinary team that provides assessment, conducts treatment planning and treatment intervention (individual, group and family therapy).

The ideal clinician will:

• Possess strong self-motivation.

• Partner with Clinical Manager to ensure all providers on the team are performing at a high level, engaged in their work at Plena Mind Center, and are compliant with standards and evidence-based protocols.

• Provide weekly individual and group supervision.

• Work in collaboration with the senior leadership team towards ongoing development and program expansion.

• Serve as a member of a multidisciplinary team supporting the organization’s treatment program and organizational philosophy (developing a treatment plan according to the team standards).

• Conduct diagnostic assessments for new patients with understanding of DSM criteria.

• Share in providing group, individual, and family therapy; focusing on teaching more adaptive coping skills using cognitive behavioral therapy, insight-oriented therapy, dialectic behavioral therapy, some knowledge of mentalization based therapy preferred, but not required.

• Develop treatment plans and discharge plans tailored to patient’s needs.

• Provide care coordination and disposition planning.

• Assure the deliverance and documentation of quality treatment to patients and their families.

• Intrapersonal skills necessary to maintain a professional demeanour in an emotionally challenging and sometimes stressful environment.

• Asses when abuse is suspected and file mandated reports as indicated by guidelines.

• Provide exceptional dedication to overall patient experience.

• Excel in a fast-paced work environment.

• Recognize appropriate and timely clinical treatment interventions as needed.

• Provide quality customer service, participates in performance improvement efforts, and assumes. responsibility for professional growth and development.

• Knowledge of documenting patient group activity with The Joint Commission standards.

Requirements:

• Active license in Illinois (LSCW, LCPC, LMFT, PsyD, PhD).

• Advanced degree required.

\*This position is 80% direct patient care and 20% administrative (adjustments made as necessary).\*

• Excellent verbal and written communication skills.

• Experience as a therapist delivering individual, family, and group therapy with some knowledge of partial hospitalization program or an intensive outpatient program structure/setting (preferred, but not required).

• Experience with outcome oriented and patient-centered treatment (CBT, DBT, etc).

• Continuous preparedness for Joint Commission and any/all compliance requirements.

• Recognize and lead quality improvement initiatives.

• Familiar with aspects of psychopathology and recognize the appropriate and timely clinical intervention needed.

• Ability to develop rapport with patients and families.

• Able to successfully pass a background and physical exam, including a drug screen.

Compensation will be commensurate with experience. Employment benefits include health insurance, paid time off and holiday pay. 401(k) benefits are not offered at this time, but the potential for profit sharing will be considered based on overall individual and Plena Mind Center performance.

Job Type: Full Time (40 hours/Week)

Education: LCSW, LCPC, LMFT, PhD, PsyD

Required Work Authorization: United States

Plena Mind Center, LLC is an Equal Opportunity Employer

Job Type: Full-time

Experience:
relevant: 3 years (Preferred)
Work Location:
One location
Work Remotely:
No",-1,"Plena Mind Center, LLC","Chicago, IL",-1,-1,-1,-1,-1,-1
Technology Support Specialist,"$32K-$71K
(Glassdoor Est.)","Job Scope:

The Habitat Company is seeking a self-motivated Technology Support Specialist to provide support to our internal teams on a wide range of software and hardware solutions. This position plays a key role in diagnosing, troubleshooting, and resolving helpdesk questions and issues, providing education to end users on functions and features while working with them, and properly escalating potential problems as needed.

Duties and Responsibilities:
Provide daily helpdesk support to our organizational users
Responsible for supporting a wide range of software products including: Microsoft 365, Microsoft Teams, Symantec and Mimecast security solutions, Adobe, Yardi Property management is a plus
Responsible for the review, implementation and upgrade of IT systems and services to ensure organizational objectives are obtained
Microsoft 365 network administration
Citrix and WatchGuard routers
PC’s, laptops, tablets and mobile devices
Networked printers, scanners and copiers
Responsible for maintaining production environments to ensure delivery of IT services
Responsible for evaluating and recommending new or enhanced approaches to deliver IT services
Other duties as assigned
Skills and Qualifications:
Bachelor’s Degree in a Technology or Technology related field
Experience using Microsoft 365, Microsoft Teams and Yardi property management a plus
Self-motivated and Customer service focused
Team oriented and driven
Attention to detail
Creative with solid problem-solving skills
Excellent communication skills
Positive attitude
We operate in an environment where diversity is valued and individual initiative is rewarded. The scale of our portfolio offers challenges and opportunities for individuals who are looking to further their careers with an innovative company. We offer competitive compensation and benefit package along with development and growth opportunities.

The Habitat Company is an EO employer – M/F/Veteran/Disability/Sexual Orientation/Gender Identity",3.1,"The Habitat Company
3.1","Chicago, IL",1001 to 5000 Employees,1971,Company - Private,Real Estate,Real Estate,$2 to $5 billion (USD)
Outside Sales Representative,-1,"Royal Home Flooring is one of the most trusted names when it comes to Flooring in the Chicago-land area. Our Shop-At-Home Flooring Sales Contractors are highly skilled & motivated. With virtually an unlimited income potential based on your performance and backed by our leading management team, your opportunities are endless.
*You will receive Full training that is paid. *
*No Cold Calling*
*Daily Pre-scheduled & Pre-Screened Appointments*
*100% Commission Based*
*1099 Independent Contractor*
*Great Monthly Bonuses *
*Annual Perks & Free Vacation Packages for Top Performing Sales Reps*
Driver’s license, auto insurance, and vehicle required

Job Types: Full-time, Part-time, Contract, Commission

Pay: $500.00 - $3,000.00 per week

Schedule:
Monday to Friday
Weekends
Experience:
Sales: 4 years (Required)
outside sales: 1 year (Preferred)
License:
Driver's License (Required)
Language:
Spanish (Preferred)
Required travel:
75% (Required)
Contract Length:
More than 1 year
Contract Renewal:
Likely
Full Time Opportunity:
Yes
Work Location:
Multiple locations
Fully Remote
On the road
Hours per week:
30-39
Paid Training:
Yes
Management:
Team Lead
Company's website:
www.myroyalflooring.com
Company's Facebook page:
https://www.facebook.com/myroyalflooring/
Work Remotely:
No",5.0,"Royal Home Flooring
5.0","Bridgeview, IL",1 to 50 Employees,-1,Unknown,-1,-1,Less than $1 million (USD)
Mobile Automotive Technician ( Master Tech Needed),-1,"Wrench technicians are self-reliant and true problem-solvers, with extensive knowledge of auto parts, and excited to be in the team of a groundbreaking technology and experience. We want someone that is looking to help create something new and ready for an upgrade from the traditional shop job. Wrench services all makes and models, foreign and domestic, and offers the best customer service in the game. Fleet, diesel, or heavy-duty experience is helpful; automotive experience is required. We hire technicians who are excited to build something phenomenal with us.
Wrench Provides: *
medical, vision, and dental insurance
life insurance
monthly performance bonuses
vehicle/mileage reimbursement
cell phone reimbursement
stock options
paid ASE certification
2 weeks paid vacation
paid holidays
40 hours/week
paid training and uniform provided
overtime pay as available by market
fun company events/culture
Requirements: *
at least 3-5 years automotive mechanic experience
own vehicle and full tool inventory including code-reader or scanner
valid driver's license
current vehicle insurance and registration
desire to work independently
tech savvy and self-starter attitude
strong customer-service mentality
Job Type: Full-time

Pay: $48,000.00 - $68,000.00 per year

Benefits:
401(k)
Dental Insurance
Health Insurance
Life Insurance
Paid Time Off
Parental Leave
Professional Development Assistance
Referral Program
Retirement Plan
Tuition Reimbursement
Vision Insurance
Schedule:
8 Hour Shift
Weekends
Supplemental Pay:
Bonus Pay
COVID-19 considerations:
To keep our employees and customers as safe as possible, we are providing face masks, sanitation solution, and gloves for our technicians.

Experience:
Automotive Technician: 5 years (Preferred)
License:
Driver's License (Required)
Work authorization:
United States (Required)",4.7,"Wrench, Inc.
4.7","Chicago, IL",51 to 200 Employees,2015,Company - Private,Auto Repair & Maintenance,"Construction, Repair & Maintenance",$1 to $5 million (USD)
Manufacturing Sales Representative,-1,"Expert Crane is looking to build our team! We are looking for an energetic, assertive sales performer who is comfortable stepping out of their comfort zone, cold calling, head hunting and developing new business for our Wisconsin and Illinois region. If this is you, contact us today!
Requirements and Responsibilities: *
\*
The OSR is required/expected to solicit new customers and support existing customers by building relationships in the Wisconsin and Illinois Region.
The OSR is required to protect and maintain the morality and ethics that Expert Crane, Inc. has built, stands for and enjoys with their customers.
The OSR is required to protect and maintain the reputation for quality and excellence in overhead crane and hoist design, manufacturing and maintenance services through performance, reliability and integrity.
The OSR is required to represent ECI in a mature and professional manner, utilizing good communication and people skills.
Existing Customers: It is expected that total sales for existing accounts in your territory will increase each year because of the OSR overseeing, educating and up-selling these customers.
New Customers: It is required that sales will increase year to year thru the addition of new accounts due to growth in your territories.
The OSR is expected to identify & aggressively solicit potential customers through market penetration and product implementation for ECI.
a. Sales Meetings: On occasion, ECI management will schedule a sales meeting with the OSR. It is the responsibility of the OSR to attend this meeting and be prepared to give an accurate status of all open quotes and to review weekly reports as ECI management requires.

b. Customer Relations Portal: OSR is to assist in designating a useable tool that will be standardized on for “important note taking” related to customers that is accessible by the sales team and backup staff at ECI.

We offer an excellent benefits package including medical, dental, vision and life insurance! 401(k) with matching, paid holidays and PTO!

Job Type: Full-time

Experience:
Microsoft Office: 3 years (Required)
Industrial Manufacturing Sales: 3 years (Required)
Customer Service: 3 years (Required)
Education:
Associate (Required)
Location:
Chicago, IL (Required)
License:
Driver's License (Required)
Work authorization:
United States (Required)
Required travel:
75% (Required)
Work Location:
On the road
Paid Training:
Yes
Company's website:
www.expertcrane.com
Benefit Conditions:
Waiting period may apply",2.0,"Expert Crane, Inc.
2.0","Chicago, IL",1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,$25 to $50 million (USD)
Infant Teacher in a Reggio-inspired Program,-1,"The Trails School for Early Learning is seeking an Early Childhood Lead Teacher to work with Infants (ages 6 weeks - 15 months) who can passionately support young children’s play, exploration, inquiry, and creative/critical thinking, while working collaboratively to provide the highest quality childcare to our families. The Lead Teacher is also responsible for setting and maintaining the physical environment of the classroom, planning an exciting and dynamic curriculum and working collaboratively with Co-Teachers and coaching Assistant Teachers.

The Trails School is a year-round program with faculty working between the hours of 7:30am-6:00pm. Full-time faculty work 40 hours per week with shifts and breaks coordinated with the Director.
Job Responsibilities*
Model developmentally appropriate and professional early childhood teaching practices and set a positive, fun and collaborative tone for the classroom
Ensure that classroom environment and procedures meet DCFS standards
Communicate effectively and openly with parents, administration and colleagues and develop mutually supportive relationships
Coach Assistant Teacher by providing feedback, delegating responsibilities and supporting Assistant Teacher’s professional growth
Provide nurturing, sensitive and individualized care to children and create an inviting classroom environment (i.e. diaper changing, supporting family style eating, keeping the classroom clean and tidy)
Create an effective environment for learning through daily provocations, invitations and intentional presentation of materials
Collaborate with classroom team to develop large and small group investigations arising out of thoughtful reflection of children’s interest and promote opportunities for creative thinking, skill-building, playful experiences, and meaningful relationships
Advocate for the learning, theories and ideas of young children and yourself as a teacher through documentation, display and presentation in daily photo posts, a weekly blog and in children’s portfolios
Support and model positive discipline
Participate in reflective supervision and incorporate feedback into teaching practice
Demonstrate a working knowledge of child development and developmentally appropriate practice, and take initiative to seek out professional articles and training opportunities to build on knowledge
Participate in all school activities, including professional development, staff meetings and events, social events, special projects, field trips, and class celebrations
_*Employment Qualifications*_
Education: *
Bachelor’s Degree with a minimum of 6 semester credit hours in early childhood education or child development. A Master’s Degree or working toward a Master’s preferred. CPR/First Aid certified. Familiarity with an emergent curriculum and relationship-based early childhood programs is desired. A commitment to securing continuing education related to employment at Trails is required.
Experience: *
A minimum of one year working with young children in a school or child care setting is required.

Job Type: Full-time

Pay: $35,000.00 - $40,000.00 per year

Benefits:
Health Insurance
Paid Time Off
Parental Leave
Retirement Plan
Schedule:
8 Hour Shift
Day shift
Monday to Friday
Experience:
teaching: 1 year (Required)
Education:
Bachelor's (Required)
Work Location:
One location
Company's website:
trailsschool.com
Work Remotely:
No",-1,The Trails School for Early Learning,"Chicago, IL",-1,-1,-1,-1,-1,-1
"Sales Representative (base salary, uncapped commission)",-1,"Advance your career at Liberty Mutual – A Fortune 100 Company!

W2 Opportunity, No Investments.
Company Benefits Available Day one.
+ Industry leading paid Sales Training & Licensing!

Liberty Mutual Insurance helps people preserve and protect what they earn, build, own and cherish. Keeping this promise means we are there when our customers need us most.

We believe that our success is inextricably linked to our employees' satisfaction: satisfaction that they work for an industry leader committed to improving safety, satisfaction that they work for a company that does the right thing, and satisfaction that the company will reward them for their contributions and provide opportunities for personal growth and success. Our employees take pride in knowing that they help people live safer more secure lives every day. This is what drives our success!

Liberty Mutual will take a proactive role in your success as an Experienced Sales Representative by offering industry-leading sales and lead generation training, support and mentoring from the company’s most successful sales professionals and Branch Managers and sponsorship of required licensing exams. As an Experienced Sales Representative, you will build and develop client relationships within local communities to promote Liberty Mutual Insurance products including Auto, Home and Life Insurance. You will leverage our relationships with thousands of Affinity Groups to target customers and build your client base.

First year earnings average is between $70K to $85K – through a combination of base salary, uncapped new business and renewal commissions, and bonus structure.

Responsibilities:
Selling Auto, Home, Life and other insurance and annuity products to individuals within an assigned territory using consultative sales techniques
Identifying prospective customers using established lead methodologies for new business
Counseling and advising prospects and policyholders on matters of insurance coverage that is tailored to their specific situational need
Developing and maintaining business relationships
Making presentations to decision-makers of corporations to establish or maintain an Affinity relationship
Participating in various incentive programs and contests designed to drive sales and exceed production goals
Exceeding sales goals for volume of quality new business quoted and written within company guidelines
Qualifications:
Bachelor's degree or equivalent
Experience in sales or client service environment preferred
Highly effective communication skills - oral, written and group
Demonstrated persuasion and negotiation skills
Strong interpersonal skills to build rapport with prospective and existing customers
Organizational skills and effective time management to succeed in a semi-autonomous, fast-paced environment
Analytical skills to understand complex coverage details and underwriting guidelines
This position requires that incumbents must attain and maintain current state insurance license in property, casualty and life
Benefits:
We value your hard work, integrity and commitment to positive change. In return for your service, it’s our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits

Overview:

At Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.

We’re dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.",3.5,"Liberty Mutual Insurance
3.5","Chicago, IL",10000+ Employees,1912,Company - Private,Insurance Carriers,Insurance,$10+ billion (USD)
Director of Pharmacy,"$86K-$112K
(Glassdoor Est.)","Essential Responsibilities:
Plans and implements procedures in hospital pharmacy according to hospital policies and legal requirements.
Directs pharmacy personnel programs, such as hiring, training, and intern programs.
Confers with computer personnel to develop computer programs for Pharmacy information management systems, patient and department charge systems, and inventory control.
Analyzes records to indicate prescribing trends and excessive usage.
Prepares Pharmacy budget and department reports required by hospital administrators.
Attends staff meetings to advise and inform hospital medical staff of drug applications and characteristics.
Observes Pharmacy personnel at work and develops quality assurance techniques to ensure safe, legal and ethical practices.
Oversees preparation and dispensation of experimental drugs.
Participates in Pharmacy and Therapeutics Committee.
Designs and formulates programs for departmental and housewide continuous quality improvement.
Coordinates departmental continuing education activities.
Participates in interdepartmental communication and information exchange.
Qualifications:
Current State Registered Pharmacist License
Pharmacy Degree from an approved American College of Pharmacology.
Advanced Degree is desired.
Minimum 2 years Pharmacist experience.
One to Two years management experience
Job Type: Full-time

Benefits:
401(k) Matching
Dental Insurance
Health Insurance
Life Insurance
Paid Time Off
Retirement Plan
Vision Insurance
Schedule:
8 Hour Shift
Day shift
Monday to Friday
Experience:
Management: 1 year (Required)
Pharmacist: 2 years (Required)
Education:
Bachelor's (Required)
License:
Licensed Pharmacist (Required)
Registered Pharmacist (Required)
Benefit Conditions:
Only full-time employees eligible
Work Remotely:
No",2.5,"JACKSON PARK HOSPITAL AND MEDICAL CENTER
2.5","Chicago, IL",501 to 1000 Employees,1960,Hospital,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD)
Campaign Jobs Work on behalf of Amnesty USA,-1,"Responsibilities


We are seeking campaign job staff to join our team working on behalf of the nation’s largest human rights organization. Our team members:
Make a Difference on Human Rights and At Work: Campaign jobs staff are on the front lines of the fight against family separation and for human rights globally. On our team, your voice and your ideas matter and make a real difference. Join our team on the ground floor to contribute new ideas, test new methods of fundraising and mobilization, and drive meaningful social change.
Raise Money: Team members are responsible for effectively and efficiently collecting contributions and signing up new members to the nation's largest human rights organization. Donations from members are what allow our partners build the budget and political power to win their campaigns.
Ensure Member Information Security: Ensure that all policies on information security are followed and that members’ information is secure at all times.
Qualifications


More specifically, you:
Have strong communication skills, a good work ethic, and a passion for human rights
Are able to work within a team, receive feedback, and work independently
Previous canvassing, sales, non-profit, customer service, activist job, political campaign experience preferred but not required
Must be willing and able to approach members of the public at their place of residence in a fast paced environment, and cover a large territory each day
Must be able to meet weekly and monthly performance standards
Are comfortable walking for long periods of time
Bilingual is a plus
Growth Opportunities: Grassroots Team is quickly expanding, we are preparing to open more Offices this year. We currently have various leadership positions available with opportunities to advance to field management or director roles, must be geo-flexible.

Pay and Benefits:
$17.00 to $21.00 depending on location, and advancement
Generous performance-based bonuses
Medical coverage (after 90 days)
Paid time off for sick, vacation, and personal leave (after 20 shifts)
Grassroots Team is an equal opportunity employer and encourages applications from people of color, LGBTQIA individuals, women, and individuals with disabilities.

Job Type: Full-time

Pay: $17.00 - $21.00 per hour

Benefits:
401(k)
Dental Insurance
Health Insurance
Paid Time Off
Vision Insurance
Schedule:
Monday to Friday
COVID-19 considerations:

Due to Coronavirus/COVID-19, and recommendations from the Centers for Disease Control and Prevention, Grassroots Team will be conducting interviews over the phone, and video calls. Please submit your application, and we will be in touch about further inte

Experience:
Customer Service: 1 year (Preferred)
Communication Skills: 1 year (Preferred)
Work Location:
Multiple locations
Company's website:
https://www.grassroots.team/
Work Remotely:
No
Pay and Benefits
$17.00 to $21.00 depending on location, level of experience, and advancement
Generous uncapped performance-based bonuses
Medical coverage (after 90 days)
Paid time off for sick, vacation, and personal leave (after 20 shifts)
About Grassroots Team


Grassroots Team is the community mobilization organization for progressive groups like Amnesty International. We raise public consciousness and funds in the fight for immigrant rights, and a healthy environment, and thriving economy that includes everyone.



Grassroots Team is an equal opportunity employer and encourages applications from people of color, LGBTQIA individuals, women, and individuals with disabilities.


Apply To Job",4.2,"Grassroots Team
4.2","Chicago, IL",51 to 200 Employees,2019,Company - Private,Consulting,Business Services,Unknown / Non-Applicable
"IT Analyst - Governance, Risk & Compliance","$49K-$91K
(Glassdoor Est.)","Beam Suntory is Crafting the Spirits that Stir the World. Rooted in two centuries of family heritage, Beam Suntory has evolved into the world's third largest leading premium spirits company ... where each employee is treated like family and trusted with legacy. With our greatest assets - our premium spirits and our people - we're driving growth through impactful marketing, innovation and an entrepreneurial spirit. Beam Suntory is a place where you can come Unleash your Spirit by making an impact each and every day.

IT Analyst - Governance, Risk & Compliance

What makes this a great opportunity?

•Beam Suntory is a leader in the spirits industry with a track record of profitability and growth
•Opportunity to help shape the information security roadmap of the future
•Growth potential beyond this role

Role Responsibilities

Job description

The IT Governance, Risk and Compliance Analyst is a key member of the global information security team who works collaboratively with IT within the overall IT Security function, focusing on IT governance, IT Controls and broadening of the IT Compliance and Risk Management programs.

This position supports the ongoing IT Security risk management program and building out the new IT Compliance function within the Information Technology organization, being primarily focused on design and implementation of controls and compliance activities as part of regularly scheduled processes (e.g., ITGC, system maintenance) and key initiatives (e.g., IT roadmap projects) at the Company. Key responsibilities include:
Contributor to the Beam Suntory IT Governance, Risk and Compliance program
Assist in the development of IT Compliance function with a focus on NIST
Assists with GRC technology administration
Assist in the management of Beam Suntory’s NIST framework program, including coordination of periodic risk assessments, identification of new and changing requirements, and collaboration with Internal and External control owners and Audit teams to ensure appropriate risk coverage
Assist with Identity and Access Management tasks
RESPONSIBILITIES AND DUTIES:
Assist the Beam Suntory IT Security team in monitoring the SOX compliance program. Act as lead for IT on key internal control related matters (Sarbanes Oxley (SOX) compliance, segregation of duties, policies and procedures, the design of controls in systems and processes, and evaluation of risk).
Serve as tower lead for outsourced IAM (Identity and Access Management) for Windows AD and IAM tool, which is performed by an outsourced third party organization. Establish relationship with third party provider, escalate issues with vendor appropriately and work collaboratively with the vendor to resolve IAM issues. Assist with SAP IAM tasks as needed.
Assist in serving as IT Governance, Risk, and Compliance (GRC) analyst and GRC tool administrator. Administer periodic risk assessments, track issues/action plans and drive risk remediation actions to completion. Ensure GRC tool configuration in line with IT Compliance requirements. Perform administrative tasks around IAM review daily processes, reviews of administrative access, service accounts, terminated users, and other required reviews.
Serve as team member during IT projects formed to drive business process and systems enhancements with final word on controls related matters. Develop and proactively enhance IT controls by enhancing and supplementing policy, process, and standard operating procedures.
Support IT Roadmap projects by advising on minimum IT risks founded in NIST, SOX and best practices.
Drive process improvement initiatives across the IT organization.
Qualifications & Experience
Bachelor’s Degree in management information systems (MIS), Accounting, Computer Science or Finance preferred though not required; CISA (or equivalent) preferred; or relevant technical experience
Ideal candidate has worked with a GRC tool, has some experience in IAM (Identity and Access Management) and has worked with business and IT functional areas to develop and implement mitigating controls
Experience with identity and access management (IAM)
Experience performing user administration in Windows Active Directory (AD) or SAP
Experience working with a third-party vendor for IAM a plus
Experience with GRC software (i.e. LogicGate, Archer or similar) a plus
NIST, AD, SAP experience
Relevant experience in IT controls or IT Auditing with some background in segregation of duties or financial controls
Experience of working in a global IT enterprise environment with knowledge of IT controls (change management) and systems audit requirements preferred
Some knowledge of financial/business processes and automated controls a plus with a focus on SAP or ERP financial and production systems experience
SAP or other Experience with Azure, Application Security tools, web-based security tools, SAP Security Vulnerability Management
Strong project management and prioritization skills – ability to multi-task as needed on various projects and initiatives
MS Office software suite knowledge required
At Beam Suntory, people are our number one priority, and we believe our people grow together in diverse and inclusive environments where their unique insights, experiences and backgrounds are valued and respected. Beam Suntory is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, military veteran status and all other characteristics, attributes or choices protected by law. All recruitment and hiring decisions are based on an applicant’s skills and experience.

Nearest Major Market: Chicago

Apply now »",3.6,"Beam Suntory
3.6","Chicago, IL",1001 to 5000 Employees,2014,Company - Private,Food & Beverage Manufacturing,Manufacturing,$2 to $5 billion (USD)
Research Assistant,"$31K-$82K
(Glassdoor Est.)","Research
Assistant

In this role, Research Assistants will utilize
analytical skills in the areas of Economics, Finance, Statistics, Mathematics
and Computer Science to support academic research and policy work by staff
economists. Tasks include quantitative research analyses using economic and
financial data; computer programming; preparation of briefings and educational
outreach materials; and financial and economic database management. The
position requires a two-year commitment and is ideal for students considering
further graduate work, particularly in the fields of economics or finance. The
level of work required is considered entry-level and staff work under direct
supervision. This job has no direct reports. This position is structured as
part of a two-year program.

Principal
Duties and Responsibilities

•Conducts statistical and economic analyses of
current macroeconomic, microeconomic, and regional data, and provides research
support for the economists

•Supports the economists in their basic and
applied research by following instructions to perform tasks including
collecting data, conducting moderately complex statistical analysis, writing
statistical software programs, and organizing the presentation of results.

•Prepares a variety of charts, tables, and
descriptive text for Department management or other staff economists to use in
their briefings of the President and the Board of Directors.

•Researches economic topics for economists'
articles; on some of these occasions, the efforts will be substantial enough to
constitute collaboration with the economists (or department management),
leading to jointly authored articles.

•Recommends, initiates, plans, and executes
research projects under the guidance of manager and department researchers.
Coordinates research projects and directs activities of research assistants and
other staff, as assigned.

•Performs other
duties, as requested

Education and Experience

•Bachelor's degree in Economics, Finance, Business, Mathematics, or related field with emphasis on quantitative and/or analytical skills.

Knowledge and Skills

•Knowledge of and ability to apply economic theory and quantitative analysis techniques under the general supervision of department researchers.

•Ability to use PC and standard software packages, such as but not limited to ArcGIS.

•Ability to use PC statistical programs, such as but not limited to SAS, STATA, and MATLAB to organize data into files and to perform advanced statistical and econometric analyses.
•Strong analytical and problem solving skills.
•Strong organizational and planning skills.
•Strong oral and written communication skills.

Application Requirements

•To be considered, all applications must include a Cover Letter, Resume, Unofficial Transcripts, and Letter of Recommendation.
•Applicants must be U.S. Citizens or hold green cards with the intent to become a U.S. Citizen.

•Please have your Letter of Recommendation submitted to: ResearchAssistantLOR@chi.frb.org

Please have your letter writer include your first and last name in the subject name of their email.

Other Requirements

This position requires access to confidential supervisory information and/or FOMC information, which is limited to ""Protected Individuals"" as defined in the U.S. federal immigration law. Protected Individuals include, but are not limited to, U.S. citizens, U.S. nationals, and U.S. permanent residents who either are not yet eligible to apply for naturalization or who have applied for naturalization within the requisite timeframe. Candidates who are not U.S. citizens or U.S. permanent residents may be eligible for the information access required for this position and sponsorship for a work visa, and subsequently for permanent residence, if they sign a declaration of intent to become a U.S. citizen and meet other eligibility requirements. In addition, all candidates must undergo applicable background checks and comply with all applicable information handling rules, and all non-U.S. citizens must sign a declaration of intent to become a U.S. citizen and pursue a path to citizenship.

As a condition of employment, Federal Reserve Bank of Chicago employees must comply with the Bank’s ethics rules, which generally prohibit employees, their spouses/domestic partners, and minor children from owning securities, such as stock, of banks or savings associations or their affiliates, such as bank holding companies and savings and loan holding companies. If you or your spouse/domestic partner or minor child own such securities, and would not be willing or able to divest them if you accepted an offer of Bank employment, you should raise this issue with the recruiter for this posting, who can provide you contact information for our ethics official if necessary.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex national origin, sexual orientation, age, marital status, disability, gender, gender identity or expression or veteran status.",3.6,"Federal Reserve Bank of Chicago
3.6","Chicago, IL",1001 to 5000 Employees,1914,Government,Federal Agencies,Government,$2 to $5 billion (USD)
2020 - Campus Recruiter,"$52K-$92K
(Glassdoor Est.)","The Campus Recruiter will be responsible for campus recruiting and will also engage in other recruiting initiatives and programs (diversity and international recruiting efforts, summer intern program). Incumbent will coordinate the campus recruiting process - from strategy and planning to implementation and wrap-up – for assigned schools within the region. This person will work closely with assigned School Recruiting Teams of consultants and the NA Recruiting Team.

Job responsibilities



Planning, Organizing and Implementation
Work directly with consultant school teams and Corporate Recruiting to develop and implement schools’ recruiting strategies, including:
Initiate, organize, staff and attend Kearney campus events
Manage interview process
Develop and maintain close working relationships with Universities’ placement offices, serving as the main point of contact for the firm
Attend School Recruiter Forums
Coordinate school-specific cultivation activities
Develop strategies for top talent capture
Monitor competitive trends on campus
Incorporate overall strategy and key messages of firm throughout all school-specific activities to ensure one-firm firm footprint
Relationship Development and Communication
Candidate Interactions
Be fully knowledgeable about Kearney (strategy, work content, organization, philosophy) to represent the firm at all events
Develop relationships with student group leaders
Act as primary HR contact and liaison for candidates
Corporate Recruiting Interactions
Communicate status and progress of recruiting strategy and its execution to school team and leadership on timely basis
Secure and track consultant participation in all events and interviews
Act as link main link between Corporate Recruiting and school teams
Coordinate best practice sharing
Candidate Screening and Tracking
Coordinate candidate screening process for campus candidates
Maintain candidate tracking database for campus candidates
Other
Manage budget for campus recruiting and track expenses
Maintain recruiting calendars
Support Summer Program
Support Corporate Recruiting as needed with national events
Review and analyze recruiting season results
Key Requirements
Bachelor’s
degree or equivalent 4-year degree required
3-7
years work experience, preferably in campus recruiting
Strong
multi-tasking and organizational skills
Stellar interpersonal and communication skills
Motivated team player
Proficiency in Microsoft Office
Some travel required",4.1,"Kearney
4.1","Chicago, IL",1001 to 5000 Employees,1926,Company - Private,Consulting,Business Services,$1 to $2 billion (USD)
Business Development Representative - Entry Level Sales,"$45K-$50K
(Employer Est.)","Business Development Representative Job Description
Sales Empowerment Group (SEG) is looking for recent college graduates who are interested in jump-starting their career as a Business Development Representative. We are looking for motivated, ambitious and talented individuals for a variety of industries including Finance, Marketing, Healthcare, SaaS and the Technology sectors.
The SEG Career Development Platform
SEG Business Development Representatives prospect new business and establish meetings with qualified leads for SEG Clients. The BDRs will go through training and ongoing professional development that will accelerate their careers, meanwhile gaining in-depth knowledge of the industry and client with which they partner. We're looking for people that are excited to develop professionally, but also for people who are passionate about building culture and helping our overall business grow.

Your X Factor!

New-to or a-few-years-into your sales career: Whether you’re fresh out of college or you have a year or two of sales experience under your belt, you are someone who is serious about sales and is ready to develop your career.
Driven and Goal Oriented. You like to get stuff done. You're excited by competition. You're hungry for opportunities. And you're motivated to do your best, each and every day.
You’re Resilient. We know sales can be a really tough job. Sometimes you will hear a lot more ""no's"" than ""yes's."" But this doesn't bother you because the ""yes's"" are what will keep you on the edge of your seat. You're calm, cool, and collected when handling objections and can think on your feet. You're confident in yourself and know how to keep pushing forward. Someone who's comfortable on the phone and leveraging social media
Someone who’s comfortable on the phone and with leveraging social media!As a business development representative, you're going to be on the phone a large portion of each day. We're looking for someone who has stamina and has a natural ease talking to strangers but is also capable of finding ways to interact and engage client prospects with social media and email outreach.
Detailed and Crafty. You're going to be provided leads and contacts, but sometimes you have to think outside of the box to identify the right person to talk to. We're looking for someone who's able to be thorough and detail oriented when it comes to prospecting.
Excited to be a part of a growing team. That’s the reason we’re hiring – We can’t stop growing and we’re looking for folks who want to grow with us!
Life at SEG!
Competitive pay + commission: Commissions are uncapped and bonuses are competitive. We offer full benefits, and a generous base salary increase after your first 6 months.
Opportunity for career growth. We foster career advancement by also helping clients to build the next generation of sales talent. This means that great employees can often get hired into progressive role at the client directly. We call this a promotion as well - since our employees have already proven to be a valuable extension of our client's work family.
Casual dress. Want to wear jeans and a t-shirt to work? Cool. Us too.
Culture! At Sales Empowerment Group, we pride ourselves in our people. Our entire company is a close- knit group.
Ping Pong and Video Game Tournaments. Bring your A game. We’ve had a lot of practice.
It’s Just Lunch! Lunch is on us every other Wednesday.
Health Nuts! Sales Empowerment Group will pay for your membership to the local Planet Fitness Health Club.
Snack Attack. We stock our kitchen with fresh fruit, chips and crackers, and all the cereal your heart desires.
Location, Location, Location. We’re located in the heart of the Loop, which means there are tons of places to gather for happy hour after work. It also means we’re right off of the Red Line (Lake Street stop), the #29 Bus, and the #65 Bus.
Job Type: Full-time
Compensation: Base Salary + Uncapped Commission
OTE | $45,000.00 to $50,000.00 /year",4.3,"Sales Empowerment Group
4.3","Chicago, IL",51 to 200 Employees,2011,Company - Private,Consulting,Business Services,$5 to $10 million (USD)
TechOps Support Specialist,"$34K-$74K
(Glassdoor Est.)","We are seeking an individual to join our team in providing technical support as well as maintaining the technical infrastructure for our organization. This person will work closely with the Technology Operations (TechOps) and Security teams in order to support day-to-day operations, ensure availability of information systems, improve processes, enable users, and promote a secure environment.

You will do well in this role if you love making connections between people and technology. Someone who is “service-minded” is essential, meaning you put people first and proactively identify pain points and figure out how to solve them.

Our Team

This role will be on the internal TechOps team which focuses on supporting, developing, and engaging with employees and technology to create confidence and sustainable uptime within the company’s tech infrastructure. We are primarily a Mac environment with close to 100 employees.

The TechOps team does a wide breadth of types of work. From third-party vendor and SaaS management for the majority of our tech stack to ensuring our hardware devices are fully compliant with security requirements. Wherever we can, we automate repeated logic or at least provide suggestions that reduce the burden of setup through Jamf Pro, Meraki, and Freshservice. The team is also responsible for predicting possible hurdles/outages and following through with creating a solution with documentation, QA testing, and end-user communication.

Responsibilities
Provide hands-on technical support for internal employees -- identify, troubleshoot, and resolve issues for local hardware, software, and networking equipment.
Manage deployment (macOS via Jamf Pro), installation, configuration, and operation of computers, peripheral equipment, and software within established standards and guidelines.
Create and update documentation and communication to team and organization to help assist the adoption of new systems or processes.
Maintain conference room systems and equipment including Zoom rooms
Efficiently onboard and offboard employees while in the office or remote
Demonstrate flexibility in extended hours to meet deadlines whenever necessary.
Qualifications
Hands-on proficiency with MacOS -- Apple applications and hardware
Familiar with Jamf Pro (or similar enterprise-level device management tool) -- configuring new Macs, creating policies, using AutoPkg.
Have a diplomatic and professional attitude -- be sensitive to the TechOps needs of colleagues while regarding other priorities in the job.
Excellent interpersonal skills including oral and written communication with timeliness in mind.
Extraordinary problem solving and critical thinking skills that allow you to work in an efficient manner.
Scripting in Bash and/or Python -- reverse engineering macOS (you read that right!).
Due to COVID-19 and the nature of the role, this position will be a combination of remote and in the office.
Bonus
Knowledge of AWS, cloud computing, and virtualization.
Experience with networking equipment -- Meraki & Cisco firewalls, switches, access points, and routers.
Experience hosting company-wide events’ AV equipment

About Narrative Science

Narrative Science creates software that writes stories from data to drive understanding and results. Powered by artificial intelligence, our technology automatically turns data into easy-to-understand reports, transforms statistics into stories, and converts numbers into knowledge.

Narrative Science works with customers including Deloitte, USAA, Credit Suisse, and members of the U.S. intelligence community, empowering them to understand and act on key business metrics, make better decisions and focus talent on higher-value tasks -- all through the power of data storytelling.

At Narrative Science, we embrace the diverse backgrounds, experiences, and perspectives of our future employees, colleagues, customers, partners, and other stakeholders. We provide equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, age, disability, marital status, citizenship, genetic information, or any other characteristic protected by law.",4.1,"Narrative Science
4.1","Chicago, IL",51 to 200 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable
Marketing Manager,-1,"JOB DESCRIPTON
Work with existing firm management to develop new marketing strategies to both attract and retain new and existing clients
REQUIREMENTS
BA/BS degree or equivalent work experience
Past experience in marketing required
Excellent communicator and creative thinker, with an ability to use data to inform all decisions
Bonus skills: HTML/CSS, Adobe Creative Suite",-1,First America Law,"Chicago, IL",-1,-1,-1,-1,-1,-1
Assistant Property Manager,"$24K-$68K
(Glassdoor Est.)","Position Description and Summary Statement
The Assistant Property Manager provides all administrative support services and reception duties for the Management Office at the Monroe Building. This person will coordinate all tenant requests, vendor ordering, communications, office supply procurement, and serve as the primary point of contact for all customer service-related activities. The Assistant Property Manager, as directed by the Property Manager, will assist in the areas of tenant relations, administrative responsibilities, insurance, maintenance, building operations, and accounting.
Perform duties: (a) in a fiduciary capacity; (b) in a manner consistent with the standards and principles of professional property management practice and care; (c) in compliance with all applicable standards and recommendations of insurance carriers and/or underwriters; and (d) in compliance with all present or future federal, state, local and quasi-governmental laws, ordinances, orders, rules and regulations of governmental authorities having jurisdiction over Owner, Manager and/or the Property. (e) This job description is intended to describe the general nature and work responsibilities of the position. (f) This job description and the duties of this position are subject to change, modification, and addition as deemed necessary by the company. (g) The job responsibilities of this position may include cross-training in other functions to ensure satisfactory operation.

Essential Position Qualifications
Bachelor’s Degree helpful
2-5 years’ experience in property management, as well as significant experience working in an administrative capacity
Excellent written and verbal communication skills
Experienced with customer service
Excellent computer skills, to include experience with Microsoft Office products, Yardi Voyager and Commercial Café
Highly developed organizational skills and attention to detail a requirement
Ability to be on call, including evenings and weekends.
Must possess a positive attitude and the ability to smile under all circumstances.
Participate in training in order to comply with new or existing laws.
Ability to be on-call, including evenings and weekends.
Neat, clean, professional at all times throughout the workday and/or whenever present at the property.
Comply with expectations as demonstrated in the employee handbook.
Demonstrate ability to diffuse and respond to customer concerns to avoid escalation of the problem.
Assigned Responsibilities and Duties
Provide administrative support and reception duties, greet walk-in tenants, visitors, vendors, and contractors; handle their needs or direct them to the appropriate staff.
Answer all incoming telephone calls and handle their needs and questions or direct to the appropriate staff.
Receive and process mail and packages including date stamping and distributing all incoming mail.
Maintain office equipment, levels of office supplies, janitorial supplies and keep the office neat and organized
Maintain all files, including tenant leases, vendor files, service contracts, construction, and other miscellaneous files as directed by the Property Manager.
Assist with the preparation, printing, and distribution of tenant communication, notices, newsletters, website, or e-mails as applicable.
Assist Property Manager with tenant events including, planning, set-up, take-down, tenant notices, etc.
Prepare and distribute new tenant packets, train new tenants on use and access to Commercial Café/work order system,
Visitor Management System, building operations, etc.
Order and coordinate delivery of welcome letter/gifts for tenant anniversaries as directed by the Property Manager.
Track, file and maintain insurance certificates consistent with requirements for all tenants, vendors, tenant’s vendors, contractors and update as required. Send 30 days notices when COIs are set to expire.
Monitor tenant requests through Commercial Café (tenant work-order request system), following up to ensure satisfactory completion of each request and maintain/administer the work-order and leasing portal system. Close and billback tenant work-orders. Prepare quotes for extra tenant services.
Assist Property Manager with abstract tenant leases and enter lease detail into Yardi.
Assist with communication with engineering, security staff, and janitorial, including daily tenant requests, afterhours access, etc.
Ensure orderly loading dock delivery operations are consistent with building rules and regulations.
Maintain updated information in building access control system and administer, distribute/deactivate photo ID access cards as needed.
Promote and foster positive relationships with tenants and owner.
Ensure familiarity with building emergency procedures manual to be able to direct tenants during emergency situations.
Assist with accounting procedures, to include, forwarding invoices to Property Manager for approval, submitting financial information (invoices) to AP department, and following up on past due invoices. Deposit monthly tenant rent payments.
Manage Fitness Center access including Waivers, access key cards and payment. Schedule and manage Fitness Center equipment maintenance and order supplies.
Update tenant emergency and after-hours contact list.
Assistant Property Manager shall operate the Property as a quality business unit and shall, subject to the provision of funds by Owner, perform all acts necessary or desirable for the efficient operation of the Property. In connection with its operation of the Property, Assistant Property Manager shall provide or arrange for the provision to the tenants of those services required to be provided in their respective Leases or required by applicable Laws, those deemed reasonably necessary and appropriate by the Property Manager and such other services as Owner may approve in writing.
Assistant Property Manager shall ensure that the Building, Personal Property, and grounds comprising the Property are at all times well maintained, in good order and repair, in a proper state of cleanliness and in compliance with all Laws. Manager shall make all repairs, alterations, decorations, or replacements (""Repairs"") which shall be reasonably required to preserve, maintain, and keep the Property in first class condition and in compliance with all Laws.
Assistant Property Manager shall perform and carry out all other acts and services which are customary for the management of properties of like size and character or as may be required for the efficient and business-like operation of the Property.
Notify Property Manager if any alterations, additions, or improvements, structural or nonstructural, shall be required in order to cause the Building to be in compliance with applicable Laws. Assistant Property Manager shall promptly forward to Property Manager copies of all communications or notices from any governmental authorities, insurance companies or others regarding any violations of any Laws relating to the Property.
Any other duties assigned by the Property Manager",4.0,"TAWANI Enterprises
4.0","Chicago, IL",51 to 200 Employees,-1,Company - Private,Real Estate,Real Estate,Unknown / Non-Applicable
"Marketing Coordinator, Chicago","$35K-$57K
(Glassdoor Est.)","Marketing Coordinator, Chicago
General Information
Job Title:
Marketing Coordinator
Location:
5515 N. East River Road
Chicago, IL, 60656
United States
Base Pay:
$62000.00 - $72000.00 / Year
Description
The Marketing Coordinator is primarily responsible for working with the marketing/business development team and Regional Manager(s) to produce proposals, prequals, sources sought including, but not limited to, creative/technical writing, etc.

Assigned Responsibilities:
Work with team to manage and produce proposals, prequals (RFPs, RFQs) and presentation submissions
Proposal Manager for RFPs and RFQs
Proposal Manager for Sources Sought
Review specifications and requirements of proposals
Read front end documents
Assist or handle creative and technical writing
Create graphics/charts for proposals
Organize and catalog proposals
Follow up on status of RFQs/RFPs if necessary
Assist with creative ideas to make proposals stand out
Cosential updates with new proposal information
Prepare presentations/materials for meetings and/or interviews
Prepare project award submissions
Produce database reports including FedBiz, BD Opportunity Report, Work in Progress, etc.
Provide research and administrative support to Executive VP and VP BD
Participate in weekly BD meetings
Other duties as assigned
Requirements
Job Knowledge, Skills and Abilities

Exceptional communication and writing skills required. Strong working knowledge of Microsoft Office and In Design software. Familiarity with Cosential database are helpful.

Education and Training

College degree in marketing or communications, and a minimum five (5) years experience in marketing and business development within the construction industry, exceptional follow up and writing skills, familiarity with Microsoft Office, Adobe In Design and Acrobat helpful.

Physical Demands
Involves sitting, walking, stooping, bending, reaching ad lifting.
Can involve lifting and/or moving up to 50 pounds.
Work Environment
Work is performed in the office. Noise levels vary.
General work hours are 8am - 5pm and 5-day work weeks are standard. Note that work hours and workdays may vary (changes, additions, etc.) based on critical work activities.
Summary
We believe that our achievements as a company are a direct result of the dedication and drive of each person who calls him or herself a Paschen employee. That’s why we focus on creating an environment in which our employees can succeed by developing their own unique sets of skills and abilities. If you come to work for us, you can expect to be supported and respected, and to find friendship, satisfying work, and rewarding challenges. But most of all, you can expect to be a valued part of a team where you will work closely with others to find creative solutions, drawing on one another’s strengths and expertise to make Paschen stronger and better.",3.7,"F.H. Paschen
3.7","Chicago, IL",201 to 500 Employees,1975,Company - Private,Construction,"Construction, Repair & Maintenance",$500 million to $1 billion (USD)
Sales Representative,"$51K-$66K
(Employer Est.)","Responsibilities: United Laboratories is seeking an Outside Sales Representative to drive growth
A business-to-business sales representative is providing specialty chemical solutions to municipalities, institutions, schools, medical facilities, manufacturing, and industrial accounts.
United Labs Requirements:
Bachelor’s degree preferred
1-3 years of outside business-to-business sales experience with a record of accomplishment of success preferred
Strong communication skills
Proficiency with computers/tablets
Valid driver’s license and reliable transportation
Ability to pass a background check
Bilingual skills preferred but not required.
United Labs offers you:
Weekly guarantee, plus commission
First Year Average 51k to 66k
Monthly Per Diem Allowance
iPad
Bonus program
Continuous sales and product training
401k, Medical, Dental, and Vision benefits
Customer Service support
Local protected territory - NO OVERNIGHT TRAVEL
Career growth opportunities - we promote from within
Employee-ownership – ESOP stock certificates after one year
https://www.linkedin.com/company/unitedlabsinc
https://www.facebook.com/unitedlabsinc
If you are looking for an opportunity with unlimited earning potential in an industry that is virtually recession-proof, then we would like to speak to you. We are an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status.",3.7,"United Laboratories
3.7","Chicago, IL",201 to 500 Employees,1964,Other Organization,Chemical Manufacturing,Manufacturing,$25 to $50 million (USD)
Patient Representative,"$11-$18 Per Hour
(Glassdoor Est.)","Patient Representative- Chicago, IL

Job Details
Job Location
Orthopedic Building - Chicago, IL
Position Type
Full Time
Summary
It’s the people that make the difference. Are you ready to make your impact?

Midwest Orthopaedics at Rush is nationally recognized as a leader in comprehensive orthopedic services. The Orthopedic Program at Rush University Medical Center is ranked Top 10 in Orthopedics by U.S. News and World Report. Founded in 2003, MOR is comprised of internationally-renowned Orthopedic and Spine surgeons who pioneer the latest advances in technology and surgical techniques to improve the lives and activity levels of patients around the world. MOR doctors are the official team physicians for the Chicago White Sox, Chicago Bulls, Chicago Fire Soccer Club and DePaul University Athletics.

Ready to join in? We are looking for a Patient Representative at our Chicago, IL location.

Responsibilities
Maintains the highest level possible of customer service standards in patient check-in, status update, answering phone calls, etc.
Oversees patient tracking in the Electronic Medical Record while collecting co-pays, and ensuring form completion.
Verifies, updates, and scans new and returning patient information.
Completes the patient check-out process, including collecting any outstanding balances, providing patient with correspondence from practices, and scheduling return appointments.
Maintains a positive demeanor with patients, peers, supervisors, and physicians, especially when receiving feedback or direction.
Direct the flow of patients into the rooms during clinic days.
Measures vital signs, such as blood pressure, weight, and height, and records information on patients' charts.
Ensure rooms are cleaned between patients, as well as cleaned and stocked at the end of the day.
Ability to:
Operate basic office equipment such as a computer, phone and fax machine.
Multi-task and work in a fast-paced environment.
Attention to detail.
Communicate effectively verbally and in writing.
Work and communicate with patients, physicians and staff in all levels of the organization.
Work a flexible schedule to meet the needs of the department.
Education and/or Experience
High school diploma or general education degree (GED)
Minimum of 2 years medical experience.
Our employees make the difference in our patients’ lives, and we value their contributions. Midwest Orthopaedics at Rush offers a comprehensive compensation and benefits package and an opportunity to grow and develop your career with an industry leader. Come see what we’re all about. Equal Opportunity Employer.",3.5,"Midwest Orthopaedics at Rush
3.5","Chicago, IL",201 to 500 Employees,-1,Company - Private,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD)
Project Management Intern- Summer,"$45K-$116K
(Glassdoor Est.)","Location:
Chicago, IL or Barrington, IL

Salary:
Requisition:
0000
Date:
09/01/2020
Description:
Are you looking for a career where you can make a lasting impact?
At Pepper Construction, our work as one of the nation's leading general contractors affects people's lives. From residential high rises to universities, shopping malls to concert halls, hotel rooms to healthcare - we provide shelter, education, entertainment and healing.

What we do transforms neighborhoods, towns, and cities. How we do it has the potential to transform the world.

In everything we do - from how we build buildings to how we build our culture, our team members look beyond the present to consider how the buildings will perform over time and how they will affect the people who occupy these spaces. We do that by introducing carbon draw-down strategies that are proven to lower operating costs, leveraging technology to increase efficiency and sustainability. In doing this, we believe we can improve quality of life through the built world.

This mission can't be achieved in the field alone. Each one of our team members has the opportunity to make an impact and be part of transforming our shared tomorrow.

POSITION SUMMARY

Pepper Construction Company is looking for qualified students, with a passion for learning about the construction industry, to join our summer intern program and experience life as a General Contractor. Throughout the summer, you will be paired with a Project Manager and/or Superintendent and will work directly with many aspects of project management, such as, processing submittals and take-offs, potentially preparing budgets and attending job site / owner meetings. Pepper intends to expose you to real life situations in the field and in the office and will have opportunities to attend training sessions, jobsite tours and safety walks As an intern at Pepper, you will gain hands-on experience with a quality General Contractor.

QUALIFICATIONS
Sophomore, Junior or Senior studying Construction Management or similar discipline.
Good communication skills.
Strong computer skills.
Ability to work individually and as part of a team.
Ability to multi-task.
Pepper Construction Company is an Affirmative Action/ Equal Employment Opportunity employer.",4.0,"Pepper Construction
4.0","Chicago, IL",1001 to 5000 Employees,1927,Company - Private,Construction,"Construction, Repair & Maintenance",$1 to $2 billion (USD)
Part Time Sanitation for Marshmallow Factory,"Employer Provided Salary:
$10-$12 Per Hour","We are looking for a part time evening employee to dust, and clean the floor of a warehouse using an industrial floor scrubber. No experience is necessary.

Hours are 8pm-11pm or 9pm-12am based on production needs.",5.0,"Chicago Vegan Foods
5.0","Addison, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Sanitation/Housekeeping,"$22K-$32K
(Glassdoor Est.)","Sanitation Crew Member in Marshmallow Production Facility
The responsibility of the sanitation crew is to clean and sanitize a food production facility daily after production. Members of this team are critical to the success of the organization so previous sanitation experience is strongly preferred. Members of the team will be asked to fulfill other job requirements not specifically listed as the responsibilities of the sanitation team, at that time, employees will be given sufficient training to safely and effectively complete the required tasks. Typical shift is 8-10 hours. Attention to detail and pride in leaving a clean environment is required.
This job involves: Pushing, pulling, reaching overhead, reaching to the floor, twisting and turning repeatedly over the course of an 8-10 hour shift.
Job Requirements
Flexible schedule.
Must be able to be at work in 30 minutes or less when on call.
Must be able to arrive at work on time as scheduled.
Must be able to lift 60 pounds
Must be at least 18 years of age as a federal requirement to operate a forklift.
Job Type: Full-time
Salary: Starting at $15.00/Hr",5.0,"Chicago Vegan Foods
5.0","Addison, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Interested in our Marketing Team?,"$46K-$91K
(Glassdoor Est.)","ABOUT US

Are you ready to transform an industry? At Centro we are building a comprehensive tech platform that radically increases efficiencies and impact across businesses, teams, and campaigns. Our clients can run all their digital business through Basis, with robust business intelligence, workflow automation, search and social integrations, and the number one rated DSP.
We’re taking the digital advertising world by storm and are proud to be headquartered in the rapidly growing tech hub of Chicago, with offices that span across the United States, Canada, Mexico, and London. Join us in our mission to improve the lives of everyone working in the industry!

ABOUT THE TEAM

This team of highly motivated and innovative thinkers develops internal and external messaging for Centro’s brand and product, Basis. Beyond speaking to specific functionalities, they understand the value of implementing Basis within the ad tech industry and are responsible for communicating those messages throughout the marketplace. Powered by cross-functional collaboration, they go above and beyond by demonstrating how Centro and Basis improve the lives of those working in our industry.

ABOUT THIS OPPORTUNITY

Hi there!
Centro is not actively hiring at the moment, but we’d still love to hear from the talented people who are interested in working at Centro in the future. Please apply here if you’re interested in future opportunities with our Marketing team, and when we have an open role, we’ll contact you if there’s a potential fit!
In the meantime, if you’re interested in learning more about us, take a look at:
Centro’s Manifesto
Centro’s Blog
Video of our CEO and Founder, Shawn Riegsecker
An Overview of Centro’s Culture
A quick tour of Centro’s product, Basis
We look forward to getting through this together and connecting again soon! Stay well!
Centro is an Equal Opportunity Employer. We respect and support an inclusive workplace diverse in thought, perspective and culture. We celebrate all team members regardless of gender/identity, sexual orientation, race or cultural background, religion, physical disability and age. We are better together.",4.0,"Centro
4.0","Chicago, IL",501 to 1000 Employees,2001,Company - Private,Internet,Information Technology,$100 to $500 million (USD)
Implementation Manager,"$36K-$73K
(Glassdoor Est.)","Company Overview

Infutor is the expert in Consumer Identity Management. We are 100% focused on enabling brands to know everything they need to about consumers, to instantly make informed marketing and risk decisions.

Infutors experience linking trusted data sources result in solutions that: Identify, verify and score inbound consumers, on-demand, with as little as a single identifier.
Link customer data, update/add missing identifiers and enhanced attributes.
Enable improved digital marketing performance through higher match rates and complete insights.
Infutor gives brands a secure, privacy compliant foundation to improve inbound engagements and outbound marketing reach, and to minimize fraud and collections risk.
Infutor's headquarters are located in Oakbrook Terrace, IL. with offices in Chicago, IL., Fort Myers, FL., Olathe, KS, and San Rafael de Escazú, Costa Rica.

Infutor is proud to offer an award-winning culture, championed by its diverse group of #expert employees:

#11 of 100 Best Places to Work Overall - Crain's Chicago Business

#7 Best Small Places to Work - Crain's Chicago Business

#5 Best Mid-Sized Place to Work - Builtin Chicago

#20 Best Paying Place to Work - Builtin Chicago

This dynamic, rapidly growing company is seeking a Implementation Manager to join its Implementation team.

Job Summary

The Implementation Manager will work closely with clients and internal stakeholders to ensure every product sold is onboarded by the client as smoothly and pleasantly as possible. Through proactive and effective communication, they will ensure that both new and existing clients are satisfied with their purchase and continue to hold a positive impression of Infutor Data Solutions as a partner.

We are looking for a detail-oriented collaborator who is solution-focused and is always looking for ways to improve processes. The right fit will have a proven track record of successfully onboarding clients in either the data or SAAS industry, preferably with knowledge in API development, batch data appending services or list rental platforms.

They will work closely with the Solutions Engineering, Account Management, Client Success, Data and Product teams to both receive detailed directions on what to implement as well as provide valuable feedback on processes and documentation both from clients and their own personal observation. Diligent note taking is expected of every implementation to allow at a glance knowledge of every implementation performed is available to all stakeholders, from Account Managers to C-Suite executives.

We are looking for someone who is driven to ensure every client partnership gets off on the right foot, ensuring each account that is implemented is in positive standing and likely to renew or expand their product schedule.

Responsibilities and Duties

The Implementation Manager is responsible for assisting clients with getting online with newly purchased products as well as assisting the Account Management team with early client feedback.

As an Implementation Manager, your responsibilities will include, but are not limited to:
Client Onboarding
Enabling product access for new clients and for existing clients who are taking in new products.
Educating clients on the use of processes and procedures patiently and clearly with the aid of company-generated materials.
Monitoring client usage in the early stages of the contract to assist the Account Management team.
Teamwork & Collaboration
Working closely with the Account Management and Client Success teams to give them an understanding of the overall disposition of the account.
Working closely with the Solutions Engineering team to determine the best approaches for product activations based on the parameters used in the preceding evaluations.
Working with the Data Processing team to ensure they have everything they need to deliver on premise files.
Project Management
Establishing an implementation window with the client and working within those parameters.
Notating process milestones to determine baselines for different implementation scenarios.
Logging detailed notes in SalesForce on every implementation
Qualifications and Skills

Requirements:
3+ years proven experience in implementation, client success or a related field.
Ability to thrive in a start-up like environment with a desire to build rather than simply participate.
Exceptional customer orientation and collaboration skills; willingness to go above and beyond to deliver results
Ability to adjust approach to effectively interact with partners at all organizational levels
Ability to confidently make decisions and escalate issues and decisions when appropriate
Excellent organizational skills with strong attention to detail, efficient time management and ability to prioritize work effectively
Ability to effectively handle challenging situations with poise, tact, and patience while demonstrating a sense of urgency
Capacity to anticipate, identify, and solve critical problems
Willingness to travel (limited)
Strong technology skills; PC skills including Word, Excel and PowerPoint are essential.
Preferred:
Bachelors degree in a related field.
API development experience (SOAP, JSON, xml)
Benefits and Perks
OwnershipPerformance Unit Grants
Peer Recognition Awards
Employee Referral Bonus Program
401k with Company Match
Free Access to Office Health Club (Oakbrook & Chicago employees); Discounted gym memberships through BlueCross BlueShield of Illinois
Medical & Prescription Drug Insurance (monthly premiums 100% paid for employee only coverage!)
Dental Insurance (monthly premiums 100% paid for employee only coverage!)
Vision Insurance (monthly premiums 100% paid for employee only coverage!)
Provided at No Cost to Employees: Group Term Life Insurance, Long-Term Disability, and Accidental Death & Personal Loss Insurance
Flexible Spending Accounts for Health Care, Dependent Care, and Commuter Benefits
Identity Protection Insurance
Voluntary Term Life Insurance & Group Universal Life Insurance
Accident & Critical Illness Insurance
Paid Time Off for Vacation, Illness, & Maternity/Paternity Leave
Corporate-sponsored Activities & Events Year Round
Powered by JazzHR",4.7,"Infutor Data Solutions
4.7","Chicago, IL",51 to 200 Employees,2003,Company - Private,Advertising & Marketing,Business Services,$25 to $50 million (USD)
"Data Scientist,Client Analytics","$99K-$162K
(Glassdoor Est.)","Position Summary


Nuveen’s Client Insights & Analytics organization is focused on turbo-charging distribution through digital and analytics capabilities across sales, service, marketing, and product. We are focused on:
establishing a deep understanding of our business and clients through customer research and analytics to redefine the ‘metrics that matter’
building data-driven sales and marketing practices enabled by segmentation and prescriptive modeling to target and serve financial advisors based on their needs and preferences
developing scalable engagement models incorporating digital to enhance our effectiveness, productivity, relevance and return on investment
expanding digital capabilities to deliver a distinctive, omni-channel client experience seamlessly integrating digital and human interactions

The Data Scientist will join Nuveen’s Data Science practice to conduct analysis and build models aligned to our distribution strategy to enhance the effectiveness of client acquisition, development and retention. They will collaborate across the Global Distribution, Product, Marketing, Client Servicing and Technology teams and be a part of Nuveen’s Client Analytics efforts.
Primary Responsibilities
Conduct statistical analysis, build models, and surface insights that enable the client facing organization to make better decisions
Develop models and analyze interaction and transaction data to identify patterns, uncover opportunities, and create executable analytics to drive revenue
Identify and use appropriate investigative and analytical technologies to interpret and verify results
Develop statistical and machine learning techniques to build models that improve how we engage with clients
Apply and learn a wide variety of tools and languages to achieve results (e.g., Python, R, SPSS, Hadoop)
Requires 3 years experience in
advanced analytics, model building and deployment
Hands
on experience designing, building and evaluating practical machine learning
solutions to solve business problems
Advanced degree in relevant field
required (computer science, statistics, applied mathematics)
Experience in normalization of
data, data mining, and tools

Additional Information



Requisition ID: 1728411",3.3,"Nuveen
3.3","Chicago, IL",1001 to 5000 Employees,1898,Company - Private,Investment Banking & Asset Management,Finance,$1 to $2 billion (USD)
Data Scientist,"$82K-$107K
(Glassdoor Est.)","GreenKey is a group of ambitious people working on audacious technology built around solving an important problem: how can voice improve workflows? Over the last five years, we have unlocked the power of voice for the financial industry and are expanding to support critical emergency services functions.

To apply for this position, please email careers@greenkeytech.com with your resume.

We’re Hiring


GreenKey is currently hiring data scientists to lead the development of ground-breaking technologies in the field of speech recognition & natural language processing (NLP) for the financial markets. As a GreenKey Data Scientist, you have influence on our overall NLP strategy by helping define product features, build machine-learning models, drive system architecture decisions, and spearhead industry-best practices. GreenKey Data Scientists have direct lines of communication with clients to have a tight feedback loop between customer problems and machine learning solutions
The ideal candidate is passionate about new opportunities and has a demonstrable track record of success in understanding business problems and crafting mathematical and statistical models to answer them. A commitment to team work and strong communication skills (to both business and technical partners) are core requirements.
What Success Looks Like

In your first 90 days, you will:
Dive into the financial and emergency services domains
Train new ASR and NLP models to structure data from unstructured conversations
Understand the needs of GreenKey’s clients
After six months on the job, you will:
Explore cutting-edge NLP research methods and apply them to client problems
Identify new data sources and algorithms to improve NLP and ASR accuracy
Discover new insights of value to our clients and develop models to extract them
One year in, you will:
Work directly with customers to shape our data strategy
Make an impact on the direction of GreenKey
About GreenKey


GreenKey is a group of engineers, data scientists, finance experts and hard workers building technology. We know that our work gives police officers more time to protect communities, and makes the finance industry more efficient while keeping it honest.

Our users are:
Traders and brokers from the top 15 financial institutions in the world
Police officers and emergency services dispatches in cities across America
Working at GreenKey


We are proud of the culture we’ve created in offices across Chicago, New York and London. Our team is made up of dynamic, humble engineers, data scientists, sales people and business leaders. Our culture is comprised of seven core principles: curiosity, optimism, candor, work ethic, empathy, self awareness and integrity. Success at GreenKey is beyond technical aptitude. Those who demonstrate these values will find themselves surrounded by like-minded individuals ready to tackle challenges together

When you join our team, you can expect: Generous PTO, remote work flexibility, comprehensive insurance, 401k plan with matching",4.3,"Green Key Technologies
4.3","Chicago, IL",1 to 50 Employees,2014,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable
Data & Analytics Consultant,"$86K-$132K
(Glassdoor Est.)","WHO WE LOOK FOR

An SEI Consultant is a master communicator and active listener who understands how to navigate an audience. Self-aware, almost to a fault, SEI consultants keenly understand how to adjust their approach based on the situation. Following a logical, fact-based approach, our consultants possess the superior ability to see correlations others may not, ask the right questions and drive solutions.

As super-connectors, our consultants connect not only people, but data, trends and experiences. Mature, humble, and genuine, SEI Consultants frequently go above and beyond for both their clients and their colleagues. SEI Consultants are ethical and trustworthy individuals who do what they say. SEI Consultants have an insatiable curiosity and love to learn. These individuals are commonly tech savvy and early adopters. Their passion for learning is infectious and excites others.

As every project is different, an SEI Consultant must be adaptable and comfortable with unexpected situations. An SEI Consultant must be at ease with ambiguity because although a client knows that a problem exists – they need SEI to figure it out and drive a solution. SEI Consultants define ambition differently. SEI Consultants are authentic, low-maintenance individuals who like to hang out with colleagues outside of work. Whether it be cooking, traveling, hiking, or volunteering, SEI Consultants enjoy working with genuine, thoughtful folks who want to steer clear of the traditional grind and share the joy of day-to-day life and activities with colleagues, friends and family.

WHAT WE DO

Our consultants work with clients at all levels of the organization, from the C-suite to the shop floor, helping them to deliver on their most strategic initiatives. We’re known for making realistic, data-driven decisions that deliver value in tangible ways to our clients. Our clients ask for us on projects that require a superior combination of technical and business capabilities, people and management skills, and a collaborative mindset. We excel in understanding complex programs and strategic initiatives and breaking them into actionable pieces.

We are actively looking for professionals in the following areas:
Data Strategy and Governance
Database Architecture and Development
Data Analysis
Reporting and Data Visualization
The ideal candidate will:
Have experience understanding and solving real business problems
Solid writing and speaking skills to support data storytelling
Ideal candidates may call themselves Data Engineers, Data Scientists and Analysts and Data Governance professionals. Experience may include but is not limited to the following:
Experience with statistical and mathematical modeling, artificial intelligence and machine learning software and methods
Specialization in architecting enterprise solutions with visualizations and data-discovery tools such as Tableau, QlikView, Spotfire, Amazon Web Services, Cloud, Salesforce
Technical capabilities that include designing scalable data architectures, solution performance tuning, and hardware sizing
Experience and knowledge of programming and scripting languages, such as , Python, Java, C#, PL/SQL, R and SAS
Experience and knowledge of relational and dimensional database structures, theories, principles, and practice used in data warehousing and analytics solutions
Experience managing, populating, and querying database technologies including RDBMS, NOSQL, and big data platforms and experience working with these technologies' ecosystems
QUALIFICATIONS

Required
Demonstrated business and technology acumen
Proven track record of delivering results
Experience working with and/or leading a team
Ability to work independently
Ability to work across industries, roles, functions & technologies
Positive can-do attitude
A curiosity for new technology
Authorization for permanent employment in the United States (this position is not eligible for immigration sponsorship)
Preferred
Bachelor’s degree (Mathematics, Computer Science, or related field preferred)
8+ years professional experience
Consulting experience
Experience across our service offerings",4.6,"SEI
4.6","Chicago, IL",201 to 500 Employees,1992,Company - Private,Consulting,Business Services,$50 to $100 million (USD)
Data Scientist,"$94K-$155K
(Glassdoor Est.)","When you’re the best, we’re the best. We instill an environment where employees feel engaged, satisfied and able to contribute their unique skills and talents. We provide extensive opportunities for personal and professional development, building both employee competence and organizational capability to fuel exceptional performance now and in the future.

Summary:

In this role, you will conduct sophisticated data analysis to help address critical business and member questions, the outputs of which enable members to drive improvements in clinical, operational, and economic outcomes.

Responsibilities:
Provide analysis to identify critical issues/questions around member performance.
Conduct exploratory data analysis from complex, disparate data sources to recognize patterns, and identify member performance improvement opportunities.
Generate hypotheses and analyze data to test and interpret results.
Design and develop data models to predict member outcomes or future impact of key member decisions.
Communicate findings from exploratory and predictive data analysis broadly to team and leaders.
Identify improvement opportunities in reporting and BI tools and collaborate with Products Technology to implement enhancements.
Serve as the resident data expert and share best practices/approaches for statistics, machine learning techniques, data modeling, simulation and advanced mathematics.
Collaborate with key leaders and clinicians to build analytical acumen across all analytic roles in the organization.
Qualifications:
Relevant degree preferred. Advanced degree a plus.
5 or more years of relevant work experience.
Proficient programming experience using SAS/Python/R.
Demonstrated ability to manage large disparate data sets and using quantitative and qualitative analysis.
Experience effectively communicating and presenting data to a variety of audiences required.
Experience working with health care administrative claims data (ICD-10, MS-DRG, CPT/HCPCS) or electronic medical record data tools (Epic Clarity/Caboodle, Cerner CCL-Discern/PowerInsight) strongly preferred.
#LI-DM

Equal Opportunity Employer: Females/Minorities/Veterans/Individuals with Disabilities

The Company is committed to equal employment opportunity to all employees and applicants without regard to race, religion, color, gender identity, ethnicity, age, national origin, sexual orientation, disability status, veteran status or any other category protected by applicable law.",3.7,"Vizient
3.7","Chicago, IL",1001 to 5000 Employees,1977,Company - Private,Health Care Services & Hospitals,Health Care,$500 million to $1 billion (USD)
Data Scientist,"$78K-$110K
(Glassdoor Est.)","Description


Do you want to work at the forefront of artificial intelligence and machine learning? CapaxGlobal has a significant data analytics and management presence across many industries. With that footprint comes massive amounts of data that can inform us about markets and ways to improve our client business practices. This position will be part of the Data Science and Machine Learning team and will bring strong quantitative skills to our data science capabilities. You work in a multidisciplinary team exploring, connecting and mining internal data sources and will develop data models using algorithms for pattern detection and forecasting. In this position you will be managing projects that use advanced analytics techniques, such as optimization, forecasting, machine learning, predictive analytics, and statistical analysis, to develop solutions that help deliver significant value to a variety of Capax’s partners and clients. Candidates will be exposed to a wide spectrum of high visibility projects ranging from sales effectiveness, competitive intelligence, fraud detection, time series forecasting, operational efficiency, sourcing and procurement, supply-chain optimization and financial analysis.
Location: Chicago IL | Philadelphia PA | Remote
Travel: Up to 30%
Responsibilities
Develop and code models by applying algorithms to large structured as well as unstructured data sets for our more complex projects. Develop visualization products to share analysis across a large group of business users.
Design strategies and propose algorithms to analyze and leverage data from existing as well as new data sources.
Continuously seek out industry best practices and develop skills to create new capabilities for data analytics at clients to improve business decisions.
Network with business stakeholders to develop a pipeline of data science projects aligned with business strategies. Translate complex and ambiguous business problems into project charters clearly identifying technical risks and project scope.
Participate on cross-disciplinary project team of database specialists, data scientists, and business subject-matter experts to complete project deliverables.
Qualifications
Bachelor’s degree from an accredited college/university in Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research or related fields.
Master’s degree in data science, applied mathematics, or bioinformatics preferred.
Minimum 6 years relevant work experience (if Bachelor’s degree) or minimum 3 years relevant work experience (if Master’s degree) with a proven track record in driving value in a commercial setting using data science skills.
In-depth knowledge of various modeling algorithms e.g. Linear, GLMs, trees based models, neural networks, clustering, PCA, and time series models.
Proficiency in R (e.g. ggplot2, cluster, dplyr, caret), Python (e.g. pandas, scikit-learn, bokeh, nltk), Spark – MLlib, H20, or other statistical tools.
Minimum 2 years experience working in a data science or machine learning environment.
In-depth knowledge of databases, data modeling, Hadoop, and distributed computing frameworks.
Experience in software development environment, Agile, and code management/versioning (e.g. git).
Strong EDA skills and experience/knowledge.
Ability to understand complex and ambiguous business needs and applying the right tools and approaches.
Collaborative team player.
Excellent communication skills, both written and verbal.
Experience developing and testing machine learning and/or statistical projects.
Strong presentation skills. Ability to present statistical results to lay persons in an easy to understand way.
We are looking for all levels of data science experience, jr through sr.",4.7,"Capax Global
4.7","Chicago, IL",51 to 200 Employees,1998,Subsidiary or Business Segment,IT Services,Information Technology,$25 to $50 million (USD)
Data Scientist,-1,"Title: Data Scientist

Location: Chicago or North NJ (near Newark) (Multiple Openings)

Job Type: Full Time/ Contract to Hire

Salary: Open

Requirements:

• Minimum 5-10 years of hands-on experience with statistical software tools: SQL, R, Python

• 3+ years- experience in business analytics, forecasting or business planning with emphasis on analytical modeling, quantitative reasoning and metrics reporting

• Experience working with large data sets in order to extract business insights or build predictive models

• Proficiency in one or more statistical tools/languages - Python, Scala, R SPSS or SAS and related packages like Pandas, SciPy/Scikit-learn, NumPy etc.

• Good data intuition / analysis skills; sql, plsql knowledge must

• Banking / Financial Sectors (preferred / not a must)

Note: If interested please send your updated resume and include your rate requirement along with your contact details with a suitable time when we can reach you. If you know of anyone in your sphere of contacts, who would be a perfect match for this job then, we would appreciate if you can forward this posting to them with a copy to us.",4.0,"Two95 International Inc.
4.0","Chicago, IL",1 to 50 Employees,-1,Company - Private,Staffing & Outsourcing,Business Services,$1 to $5 million (USD)
Data Scientist,"$81K-$132K
(Glassdoor Est.)","Waystar modernizes the healthcare revenue cycle through innovative, cloud-based technology. We provide the highest-rated client experience to more than 450,000 providers, 22,000 healthcare organizations and 750 health systems and hospitals around the country. Together, our technology, data and client support streamline workflows and improve financials for our clients, so that they can focus on their patients. We are deeply committed to living out our organizational values: honesty; passion; curiosity; fanatical focus; best work, always; making it happen; and joyful, optimistic and fun.

What is the purpose of this position?
We are looking for an experienced Data Scientist, who has previously supported Healthcare software applications. The data scientist role involves solving technical, data-driven Healthcare problems using computer science, mathematical, predictive modeling and statistical methods, & knowledge. This person will interact with teams from Account Management to Application Engineering and R&D, to conduct detailed analysis and experimentation to maximize the utility of predictive modeling, analytic and machine learning across Waystar's product line. The role will focus on extending machine learning, predictive modeling, and analytic components to provide up-to-date intelligence to Healthcare providers maximizing outcomes. An ideal candidate for this position can approach problem-solving challenges independently, has a strong attention to detail, and enjoys working in a fast-paced, collaborative, and team-based environment.

Looking for some details?
Works closely with Application Engineering, Product Management, and Operational teams in designing, experimenting-with, and implementing machine learning and analytical systems applied to design information and user behavior
Works closely with Application Engineering teams to gather and process data, as well as in surfacing various analytically-based features in core products
Works on groundbreaking new applications of machine learning and analytic technology to Healthcare, producing quantitative, justifiable results to guide feature planning
Translates real-world Healthcare problems to mathematical frameworks
Works with Product Management, Marketing, and Sales as needed to promote sales and to incorporate market and customer feedback
Data exploration, hypothesis creation (from business and product goals), testing algorithms, scaling to large data-sets and validating results will be common tasks for this role
Understands, organizes, and communicates root causes of problems and successes succinctly
Do you fit our team?
Complete familiarity with various statistical and machine learning techniques including: classification, regression, dimension reduction, clustering, and various multivariate methods
Complete familiarity with empirical approaches to estimate performance of machine learning models including: hold-out sets, cross-validation, leave-one-out testing
Understanding of orders of algorithms and how they scale
Demonstrated competency in R/Python predictive modeling
Demonstrated competency in RDBMS (e.g. SQL Server)
Ability to code in 1+ general purpose programming language (C#, Java, etc.)
Must be a quick-learner with the ability to multi-task in a fast-paced environment
Outstanding presentation abilities and the ability to communicate with all levels of the Business
Comfortable working in newly-forming, ambiguous areas where learning and adaptability are key skills
Outstanding communication and interpersonal skills
Must possess strong analytical, problem-solving, and writing skills
Proficient in Microsoft Office applications
Detail-oriented
Preferred Skills:
Master of Science degree or higher in the fields of Computer Science, Statistics, or Mathematics is preferred
An aptitude for medical informatics is preferred
In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",3.8,"Waystar
3.8","Chicago, IL",501 to 1000 Employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable
"Data Scientist, People Analytics","$83K-$136K
(Glassdoor Est.)","Job Description


Aon Is Looking For a Data Scientist

As part of an industry-leading team, you will help empower results for our clients, some of the world’s most innovative organizations, by articulating compelling and engaging data-driven stories. The Data Scientist is a highly driven quantitative professional who can help organizations in their data-driven transformation journeys to extract a variety of information and draw deep insights from the data using complex analytical algorithms. Ideally, this position will be located in California, in either the Bay Area, Los Angeles, Denver, or Austin. Alternative U.S. based work arrangements would be considered for qualified candidates.

This role requires a workforce analytics expert with a focus on conducting advanced data analytics. You would run advanced analytics to support external client projects (e.g. pay equity, strategic workforce planning, predictive analytics) as well as streamline internal data acquisition and processing (data cleaning, job matching). Beyond some sales support there will be limited responsibility to acquire new clients or offer new services to existing clients.

Your Impact As the Data Scientist

Job Responsibilities:
Collect, collate and clean data form across the Human Capital Solutions business
Develop codes and processes to simplify data processing and data matching using traditional coding techniques and/or machine learning algorithms
Work with Aon Consultants and participate in client engagements focused on Advanced Business Analytics
Focus on strategy, design and execution of data-centric business problems, and in the process create unique analytical solutions comprising Big Data management supported by advanced analytical techniques (e.g., multiple regression, machine learning, neural networks, etc.)
Generate and test working hypotheses, prepare and analyze historical data, identify patterns from samples for reporting of trends and support Predictive Analytics
Leverage Data Visualization techniques and tools to effectively demonstrate patterns, outliers and exceptional conditions in the data
Work collaboratively with colleagues at Aon to innovate and create compelling data-based stories and experiences
Stay conversant in new analytic technologies, architectures and languages – where necessary – for storing, processing and manipulating data
Develop a flair for the exploratory and experimental side of the role; required to tease out interesting and previously unknown insights in vast pools of data
Communicate complex quantitative analyses in a clear, precise and actionable manner
You Bring Knowledge and Expertise

Required Experience:
Proficient in applying advanced analytical techniques to large and varied data sets, generated and flowing at a rapid rate. Sample techniques include, but are not limited to:
Data visualization (e.g. Tableau)
Proficient in Multiple Regression and other analytical methods such as Cluster Analysis and Neural Networks
Data mining and predictive modelling (e.g. Python, SAS, SPSS, Alteryx, R, MatLab)
Exposure to and general understanding of machine learning and/or natural language processing
Social network analysis and statistical text mining
Planning software coding experience would be a plus – prior exposure working with Anaplan would be another plus
Proficient with programming languages supported by a big data platform, like SAS/SQL, Java, Python, C++, or ECL, etc.
Strong experience of managing and retrieving large scale HR information in one or more industry areas like tech, life sciences, finance, retail, healthcare, telecommunications, etc.
Education and Skills:
Masters/Ph.D. in IO Psychology, Management Sciences, Economics, Statistics, or similar fields and 3-6 years’ experience in a role running quantitative analytics “in the real world”
Creative problem-solving ability, working in ambiguous situations
Flair for storytelling based on actionable insights drawn from raw data
Entrepreneurial and pragmatic mindset
Superior planning and organization skills to work with a high-performing team, handle demanding clients and multitask effectively
High degree of personal motivation and ability to self-manage
We offer you

A competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.

Our Colleague Experience:

From helping clients gain access to capital after natural disasters, to creating access to health care and retirement for millions, Aon colleagues empower results for our clients, communities, and each other every day. They make a difference, work with the best, own their potential, and value one another. This is the Aon Colleague Experience, defining what it means to work at Aon and realizing our vision of empowering human and economic possibility. To learn more visit Aon Colleague Experience.

About Aon:

Aon plc (NYSE:AON) is a leading global professional services firm providing a broad range of risk, retirement and health solutions. Our 50,000 colleagues in 120 countries empower results for clients by using proprietary data and analytics to deliver insights that reduce volatility and improve performance.

By applying for a position with Aon, you understand that, should you be made an offer, it will be contingent on your undergoing and successfully completing a background check consistent with Aon's employment policies. Background checks may include some or all of the following based on the nature of the position: SSN/SIN validation, education verification, employment verification, and criminal check, search against global sanctions and government watch lists, fingerprint verification, credit check, and/or drug test. You will be notified during the hiring process which checks are required by the position.

Aon provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, veteran, marital, or domestic partner status. Aon is committed to a diverse workforce and is an affirmative action employer.

DISCLAIMER:
Nothing in this job description restricts management's right to assign or reassign duties and responsibilities to this job at any time.

2477243",3.6,"Aon
3.6","Chicago, IL",10000+ Employees,1892,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD)
Data Scientist,-1,"Domain Experience:

3+ years-experience in machine learning and predictive analytics

Strong knowledge of statistics and predictive methods such as SEM, multiple and logistic regression, Bayesian modeling, support vector machines, neural net training, tree induction techniques like CHAID, CART, random forest, random tree, etc.

Able to translate complexÂdataÂinto actionable insights and recommendations.

Strong understanding of the Financial Services is required.

Experience with financial models, risk models, marketing cross-sell, up-sell, retention, and customer lifetime value models preferred.

15 years plus Real world experience in monetizing models and making money (Retail or Distribution industry)

Expert in R, Vanatge etc (Sri you know our environment, some one who can coach our team)

Â

Soft Skills:

Multi-tasking and priority setting â ability to effectively manage multiple projects of varying complexity.

Ability to work independently and as part of a team.

Excellent communication skills, both written and verbal.

Technical Skills/Experience:

Experience with statistical modeling

Practical experience in preparingÂdataÂfor machine learning

Practical experience in using and designing regression, SVM, clustering, and other classification models.

Nice to have experience in optimization

Nice to have experience in Spark, Tensorflow, parallel computation

Experience with largeÂdataÂstores, both SQL and noSQL (e.g. Hadoop)

Python, R, Matlab

Node.js, Scala for services, Postgres for theÂdatabase

Kubernetes, for deployment and Devops

AWS for infrastructure, leveraging EC2, S3, SWF, CloudFront, Route53, and much more

Proven capabilities in presenting technical findings to non-technical audiences

Â

Â",4.7,"Unicom Technologies INC
4.7","Chicago, IL",51 to 200 Employees,-1,Company - Private,IT Services,Information Technology,Less than $1 million (USD)
Data Scientist - Life Sciences,"$84K-$92K
(Glassdoor Est.)","Position Description
In this exciting area of research, you will be applying machine learning techniques, with an emphasis on deep learning techniques, to problems in the life sciences with an emphasis on using computational approaches for detecting patterns in a variety of contexts including cancer, brain injury, infectious disease, genome engineering and microbial community datasets. Problems typically involve the construction of computational models for phenotype prediction from data that includes genomic data and other omics data. This role will develop and apply computational models on new experimental data, provide measures of uncertainty, and participate in interdisciplinary discussions aimed at the design of new experiments. You will report on results of research including publishing scholarly papers in scientific journals, give presentations at symposia, conferences, meetings, and seminars. You will also participate in the preparation of reports and proposals required by funding agencies to obtain and continue funding support.

We are seeking outstanding people to join us in the Data Science and Learning Division and the Bioscience Division at all career levels. As a multidisciplinary national laboratory, Argonne offers an exciting campus atmosphere in which to collaborate on interdisciplinary projects developing solutions to complex scientific and engineering problems on the world’s largest parallel supercomputers.

Position Requirements
Minimum bachelor’s degree in Bioinformatics, CS, or Biology
Fluency in scientific programming languages
Experience with bioinformatics analysis techniques and tools
Familiarity working in a Unix environment
Experience on high performance computing platforms and newer GPU systems
Experience processing NGS sequence data, familiarity with bacterial genomics, or demonstrated work in microbiology
Knowledge of artificial intelligence across machine learning, deep learning and statistics
Strong analytical and problem-solving skills
Understanding of computational algorithms to support DNA sequence alignment, small nucleotide polymorphism detection, gene expression quantification and/or small molecule (drug) structure
Experience working on protected health information including electronic health records
Familiarity with regulatory policies and procedures surrounding electronic protected health information required
Ability to write research publications
Considerable collaborative skills, including the ability to interact well with external and internal collaborators
United States citizenship is a requirement on some projects
Ability to think independently and innovatively to develop exceptional technical solutions required
As an equal employment opportunity and affirmative action employer, and in accordance with our core values of impact, safety, respect, integrity and teamwork, Argonne National Laboratory is committed to a diverse and inclusive workplace that fosters collaborative scientific discovery and innovation. In support of this commitment, Argonne encourages minorities, women, veterans and individuals with disabilities to apply for employment. Argonne considers all qualified applicants for employment without regard to age, ancestry, citizenship status, color, disability, gender, gender identity, genetic information, marital status, national origin, pregnancy, race, religion, sexual orientation, veteran status or any other characteristic protected by law.

Argonne employees, and certain guest researchers and contractors, are subject to particular restrictions related to participation in Foreign Government Talent Recruitment Programs, as defined and detailed in United States Department of Energy Order 486.1. You will be asked to disclose any such participation in the application phase for review by Argonne’s Legal Department.
Back to top",4.5,"Argonne National Laboratory
4.5","Lemont, IL",1001 to 5000 Employees,1946,Nonprofit Organization,Federal Agencies,Government,Unknown / Non-Applicable
"Data Scientist, Advanced Analytics","$70K-$116K
(Glassdoor Est.)","GoHealth is looking for a Data Scientist to join its Advanced Analytics and Operations Research team. You will be responsible for using a combination of business intuition and advanced analytic techniques including statistics and optimization to develop models, products and technologies that create value across all aspects of our diverse business. Some current and recent projects include the modeling of customer retention, lifetime values of Medicare Advantage policies and detection of anomalies in commission payments. This role will directly report to our VP of Advanced Analytics.

Due to the unprecedented situation of COVID-19, GoHealth has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities' and the CDC.

Responsibilities:
Understand GoHealth's business processes, including the role each business unit plays in supporting the company's ultimate objectives
Lead quantitative analyses, working with product management, business stakeholders, and data engineers to identify and solve business problems
Provide new and creative insights through a combination of descriptive and diagnostic analytics
Test hypotheses across functions using measurable, statistically-significant methods to evaluate best performing strategies
Stay current with data analytics tools and techniques and methods for data science, statistics and optimization
Skills & Experience:
BS or BA degree in quantitative discipline such as Mathematics, Statistics, Operations Research, Computer Science, Economics or Engineering
Mastery of statistics including regression, estimation and hypothesis testing
Experience with a data and analytics programming language such as Python, R, or MATLAB
Experience with Python packages NumPy, SciPy, pandas and scikit-learn
Familiarity with probabilistic modeling, including Poisson processes and renewal processes
Familiarity with optimization techniques including linear optimization, nonlinear optimization and/or network optimization
SQL experience in writing, editing and modifying complex, efficient SQL scripts
Experience implementing algorithms or models into a product
Experience guiding decision-making in a business context through a combination of descriptive and diagnostic analytics
Proven ability to take insights and turn them into models and products can drive business value
Ability to communicate complex concepts verbally and in writing to colleagues with varying degrees of analytical knowledge and understanding
Experience extracting and standardizing inconsistent data from disparate data sources
Benefits & Perks:
Open vacation policy
401k program with company match
Medical, dental, vision, and life insurance benefits
Flexible spending accounts
Commuter and transit benefits
Professional growth opportunities
Casual dress code
Generous employee referral bonuses
Happy hours, ping-pong tournaments, and more company-sponsored events
Subsidized gym memberships
GoHealth is an Equal Opportunity Employer
*LI-JC1",3.1,"GoHealth
3.1","Chicago, IL",501 to 1000 Employees,2001,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Data Scientist,"$72K-$120K
(Glassdoor Est.)","Logistics done differently.

At XPO Logistics, we believe on-the-job training is the best way to teach individuals about the industry and prepare them for a job within the company. As a Data Scientist, you will evaluate, run discovery, analyze, and improve XPO Logistics pricing products. You will collaborate with a multi-disciplinary team of engineers and operations team members on a wide range of problems. This position will bring scientific rigor and statistical methods to the challenges of product creation, development and improvement with a focus on pricing related products that can include, but is not limited to machine learning algorithms, A/B testing functionalities, etc. You will be comfortable discussing product design and research methodologies with the technology teams, working closely with end users, and presenting findings and proposals to senior leadership. If you’re ready to build a career you can be proud of—we have the opportunity for you to grow with XPO.

Pay, benefits and more.

We are eager to attract the best, so we offer competitive compensation and a generous benefits package, including full health insurance (medical, dental and vision), 401(k), life insurance, disability and more.

What you’ll do on a typical day:
Help shape XPO’s pricing strategies by processing, analyzing and interpreting huge data sets.
Use analytical rigor and statistical methods, mine through data to identify opportunities to improve XPO’s financial performance.
Interview stakeholders to understand business needs and to gather requirements.
Work closely with product managers to build pricing related products including machine learning algorithms.
Present findings and recommendations to senior leadership.
What you need to succeed at XPO:

At a minimum, you’ll need:
Bachelor's degree in Statistics, Computer Science, Engineering, or Mathematics, related quantitative discipline, or equivalent related work or military experience
1-year experience in data science with a focus on pricing analytics, statistical modeling, machine learning, forecasting and optimization.
Advanced experience in Python, and advanced experience in data management systems.
It’d be great if you also have:
PhD in Statistics, Computer Science, Engineering, or Mathematics.
4 years of experience in data science with a focus on pricing analytics, statistical modeling, machine learning, forecasting and optimization.
2 years of customer facing experience
Be part of something big.

XPO is a leading provider of cutting-edge supply chain solutions to the most successful companies in the world. We help our customers manage their goods most efficiently using our technology and services. Our greatest strength is our global team – energetic, innovative people of all experience levels and talents who make XPO a great place to work.

We are proud to be an Equal Opportunity/Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, sex, disability, veteran or other protected status.

XPO adheres to CDC, OSHA and state and local requirements regarding COVID safety. All employees and visitors are expected to comply with XPO policies which are in place to safeguard our employees and customers.

All applicants who receive a conditional offer of employment may be required to take and pass a pre-employment drug test.

The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of personnel so classified. All employees may be required to perform duties outside of their normal responsibilities from time to time, as needed.",3.7,"XPO Logistics
3.7","Chicago, IL",10000+ Employees,2011,Company - Public,Transportation Management,Transportation & Logistics,$10+ billion (USD)
R&D Scientist,-1,"An industry leading pharmaceutical company is looking to add an R&D Scientist to their quickly expanding group. This position has opportunities for upward mobility and involvement with cutting edge drug development research.

Description:
Participate in the research and development efforts for the manufacturing of biopharmaceutical drug products.
Duties will include maintaining equipment logbooks and charts, calibration of equipment, cleaning of lab ware, preparation of buffer solutions, execution of bench scale studies, recording of experiments and results in lab notebook.
Performance of studies will include filtrations, chromatography, ultrafiltration, preparation and submission of samples, organization and presentation of sample data.
Qualifications:
B.S. degree in Chemistry, Biochemistry, or similar training.
1 - 3 years laboratory experience, HPLC preferred
Strong knowledge of protein processing/chromatography is a plus.
Proficient in Microsoft Word, Excel, PowerPoint.",4.3,"Momentum Staffing Group
4.3","Chicago, IL",51 to 200 Employees,2008,Private Practice / Firm,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$1 to $5 million (USD)
Data Scientist,-1,"Job Summary

Perform statistical programming and analysis on datasets. Develop and manage the clinical sub-specialty research datasets. Provide expertise in statistical programming and analytics, advanced database querying, and quality assurance of pre-analysis datasets and post-analysis results reports.
Develop statistical analysis plans (SAPs), including conferring with investigators to finalize SAPs.
Conduct analyses and prepare reports with tabulations and graphical representations using a variety of techniques, ranging from simple data aggregation to more complex methods.
Utilize the multiple clinical specialty research databases to derive the analytical datasets.
Develop standardized database querying and analysis reporting templates to increase efficiency and accuracy of work product.
Develop and implement data quality checks to confirm accuracy and completeness of research analytic datasets (pre-analysis).
Generate quality checks on reports to confirm accuracy and completeness of aggregated results, including cohort comparisons (post-analysis).
Develop and maintain accurate documentation.
Perform other duties as assigned.
Qualifications

Education

Bachelor’s degree in computer science, statistics, data science or other related field is required. Master’s degree is preferred.

Experience

A minimum of 4 years of related work experience in statistical programming, data management, data analysis, and report writing is required. Familiarity with healthcare, clinical databases/registries is preferred.

Essential Skills and Abilities
Excellent knowledge of, and experience in, statistical software (e.g., SPSS, SAS, R)
Proficiency in SQL database skills
Proficiency in Microsoft Office products
Experience with graphical representation of data is desirable
Excellent written and oral communication skills
Excellent organizational, planning, and follow-through capabilities; attention to detail
Ability to multi-task and manage several projects simultaneously
Ability to develop and maintain positive working relationships with co-workers, volunteer leaders, and other organizations; tact, diplomacy, and good judgment
Positive attitude in the workplace
Flexibility and adaptability to changing daily activities and schedules
Ability to travel, as necessary
Ability to participate in evening conference calls, as necessary
Job Type: Full-time

Benefits:
401(k)
Dental Insurance
Health Insurance
Paid Time Off
Schedule:
Monday to Friday",1.0,"The Maxfield Group
1.0","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Data Scientist,"$62K-$104K
(Glassdoor Est.)","Interested in cutting edge Machine Learning techniques in the areas of NLP, Time-Series Forecasting, and Survival Analysis? As a Data Scientist at GoHealth, you will be responsible for working closely with business stakeholders to build end-to-end data science models across all aspects of our diverse business. This includes projects for call-center traffic projection, agent-behavior modeling, and customer retention decay curves.

Due to the unprecedented situation of COVID-19, GoHealth has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities' and the CDC.

Responsibilities:
Lead quantitative analyses with product management, business stakeholders, and data engineers in identifying and solving business problems
Present analytical information in front of large groups of business users
Find innovative ways to combine data that do not naturally mesh together
Stay current with leading edge systems, methods, and best practices for data science and analytics; and successfully introduce technology and process changes across the organization
Drive the collaboration around actual performance and forecasts to directly impact business decisions and actions
Continually find ways to improve how the team operates and delivers results that align with GoHealth's objectives
Skills and Experience:
Master's or PhD in Statistics, Mathematics, Computer Science, or related quantitative field
2+ years of experience demonstrating trajectory of professional growth in software engineering, data science, or data engineering
Proficient in Python and related libraries, such as Pandas, Numpy, Scikit-Learn, TensorFlow, Pytorch
Experience in advanced machine learning topics, including NLP, deep learning, and unsupervised learning
Practical experience in software engineering, and in building and deploying RESTful services
Experience working with Scrum and/or other Agile methodologies, as well as Version control systems such as Git or Bitbucket
Benefits and Perks:
Open vacation policy
401k program with company match
Medical, dental, vision, and life insurance benefits
Flexible spending accounts
Subsidized gym memberships
Commuter and transit benefits
Professional growth opportunities
Casual dress code
Generous employee referral bonuses
Happy hours, ping-pong tournaments, and more company-sponsored events
GoHealth is an Equal Opportunity Employer
*LI-JC1",3.1,"GoHealth
3.1","Chicago, IL",501 to 1000 Employees,2001,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Data Scientist,-1,"Supply Clinic is the online marketplace for healthcare and dental supplies. We’re a two-sided marketplace, helping healthcare offices buy supplies directly from distributors and manufacturers on our platform. We’re a fast-growing digital company disrupting an old-school industry, making waves as we expand in the place of traditional distribution channels. We are growing Data Team, looking to bring a talented Data Scientist on board. If you’re passionate about making a real impact at a young startup company, Supply Clinic may be a great match.

Supply Clinic is looking for a Data Scientist to help drive our Data Team, working closely with multiple team members to collect data, design and run various analyses, and help implement changes based on findings. Short term projects include: analysis of customer sitemap patterns, building product correlation maps, and identifying areas of seller behavior improvement.

Primary Responsibilities:
Using Python and Postgresql (and on occasion Excel) for user-level data analysis
Working with our data warehouse, specifically through MODE and HEAP analytics
Working within the Data Team and alongside development teams to better scale data collection of relevant product and user data points
Assisting in building necessary data infrastructure to continue to expand our analysis capabilities
Required skills:
Experience with statistics and data analysis an absolute must
Experience using both Python and SQL, ideally for data querying and analysis
Fluent with data querying and database maintenance/reference tools and techniques
Must be a creative thinker able to problem-solve to accurately measure and test queries
Experience with stochastic and/or probabilistic modeling a plus
Perks:
Health, dental, and vision insurance
Flexible role in terms of remote work
Office space on Michigan Ave. by the Loop for an easy commute (once we return to the office!)
Amazing, dynamic team (if we do say so ourselves)
Office snacks, coffee, and wide variety of teas, just waiting for our return to the office
Casual, collaborative team environment
Friday happy hours (once we return to the office!)
PLEASE NOTE: While our office is currently open, we greatly limit occupancy at any given time, and by default generally work remotely. We are closely following guidance of health and government officials, and will continue to evolve as new guidance arises. Rest assured, we've implemented procedures to ensure health and safety best practices, and that there is an ample supply of masks and sanitizer available.

We are an equal opportunity employer. We do not discriminate on the basis of race, religion, ethnicity, national origin, citizenship, gender, gender identity, sexual orientation, age, veteran status, disability, genetic information, or any other protected characteristic.

Job Type: Full-time

Pay: $70,000.00 - $90,000.00 per year

Benefits:
Dental insurance
Health insurance
Vision insurance
Schedule:
Monday to Friday
Experience:
SQL: 1 year (Required)
Python: 1 year (Required)
Work authorization:
United States (Required)
Work Remotely:
Yes",5.0,"Supply Clinic
5.0","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Data Scientist,"$75K-$127K
(Glassdoor Est.)","Data Scientist, Chicago, IL

Smarter Thinking. Real Results. Technology consulting has been our story for over 14 years. Companies from all industries partner with us for our innovative mindset to help them digitally transform to create market advantages, become resilient, and prepare for whats next. With us, the possible becomes actual.

We provide strategic and innovative consulting services focused on digital experiences, engineering, automation, data and analytics, and salesforce solutions. Saggezza consultants work as part of a global team, and throughout their tenure, have the opportunity to work on a variety of different projects across various clients and industries. We are chartered to do one thing, and one thing only to bring enabling technology to our clients that allow them to move their business forward.

We are currently looking to hire a Data Scientist to join our team.

What Youll Definitely Need
BA degree in a closely related field with data analysis orientation. Analytical background with a creative approach to problem solving
4+ years experience with Python worked in building analytical solutions using Statistical, Machine Learning, Deep Learning etc. Proficiency with 3rd-party data visualization tools (Tableau, Power BI, etc.)
Good working experience in Data Analysis, Data Wrangling, Data Cleaning and Data Transformation.
Excellent working experience of machine learning on technology stacks such as Python, NumPy, SciPy, Scikit-Learn, Apache Spark and R using libraries such as e1071 and Caret
Excellent fluency in data manipulation tasks using frameworks. such as pandas, plyr, Spark
Good understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, Random Forest etc.
Knowledge of some common data science toolkits, such as Weka, NumPy, MATLAB, etc.
Broad business perspective with the ability to articulate meaningful ROI and financial impacts.
Worked on projects in the Retail, Banking & Finance and Insurance Industries.
Working from Chicago office and requires visits to customer location if needed.
From a cultural perspective, we look for individuals who possess the following qualities that will contribute to our success and the success of our clients:
Entrepreneurial spirit: We seek individuals who enjoy contributing to the growth of an organization and who show commitment to the success of their team.
Problem-solving skills: Individuals at our company have well-honed analytical skills coupled with business acumen to structure problems, deliver solutions, and communicate insights.
Drive: Our team sets ambitious goals and seeks energetic professionals, enjoy a fast pace environment, and thrive in taking on responsibility.
What We Would Love to See
Consultative application of analytic solutions to solve business issues
Able to engage in a consultative manner across multiple levels (c-suite to end user) with a strong executive presence, demonstrating strong
Demonstrated leadership, communication and interpersonal skills: the ability to manage and mentor functional experts and lead cross- functional teams
Dont tick all the boxes? Dont worry about it: we still want to hear from you if you think

youre the right person for the job.

Why Join Our Team?
Diverse culture, experiences, and skills.
Our nurturing and supportive environment fosters collaboration across the entire organization.
We are not hierarchical but operate as a flat surface where every opinion matters, ideas are cultivated and innovation is encouraged.
At Saggezza, we are fortunate to have a strong mentorship program that provides every one of our employees the ability to thrive professionally and personally.
We are only as good as our people. Saggezza, Italian for wisdom, is rooted from the perspective that knowledge is power. We create thought-leaders who are constantly exposed and trained in different technologies in the ever-evolving world of software development.
We welcome innovators with entrepreneurial spirits to grow with our team.
Consulting Magazine - Fastest Growing Firms 2019
Built-In Top Places to Work in Chicago 2020
Best and Brightest Companies in the Nation 2019 and 2020, Best and Brightest Companies in Milwaukee 2020 and Best and Brightest Companies in Chicago 2020
Saggezza is an Equal Employment Opportunity Employer: We believe in treating each employee and applicant for employment fairly and with dignity. We base our employment decisions on merit, experience, and potential, without regard to race, color, national origin, sex, sexual orientation, gender identity, marital status, age, religion, disability, veteran status, or any other characteristic prohibited by federal, state or local law.

Powered by JazzHR",4.2,"Saggezza
4.2","Chicago, IL",501 to 1000 Employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable
Food Scientist,"$44K-$76K
(Glassdoor Est.)","Employee Type:

Full time

Location:

NE Omaha R&D Center

Job Type:

Research and Development

Job Posting Title:

Food Scientist

Job Description:

Under limited supervision, leads the design, planning, validation, and implementation of new products, line extensions, product improvement and technical service for TreeHouse Foods that meet product offering requirements within our Baked Goods Division.

Position Responsibilities:
Under limited supervision, works collaboratively in the execution of development from bench to production scale for new products, product improvements and cost savings projects.
Defines the formulation, nutritional and process parameters needed to develop a product which meets the project objective(s). Understands the impact of these parameters to overall project.
Defines raw material and corresponding process and finished product specifications and set-ups through corresponding systems.
Applies sound scientific methods in all stages of development. Including planning and executing trials, analyzing data and defining solutions to achieve project goals.
Identifies opportunities for competitive market advantage
Provide judgement and experience to assure that an appropriate level of technical knowledge and discipline are being applied and utilized in business decisions
Partner and communicate effectively with cross-functional groups: Marketing, Sales, QA, Procurement, Finance, Operations and Engineering
Ensure the transfer of technology to the operations team when commercializing products. Provide technical oversight of internal and external manufacturing start-ups and ongoing technical service
Contribute significantly and continually to attain results through the generation and application of advanced, specialized knowledge
Generate and support pipeline work to drive cost optimization through formulation and processing efficiencies
Participates in customer presentations and/or preparing product, content for customer meetings
Ensure all activities follow established safety standards, regulatory requirements (FDA, UDSA & Kosher) and Good Manufacturing Procedures (GMP)
Qualifications and Requirements:
Three years’ experience in Food Science Product Development OR No experience required if holding a PhD in Food Science/Engineering or Related Field
Dough and Baked Goods experience preferred
Understanding of ingredient interactions/functionality
Communicate effectively and openly while working in a cross-functional team.
Must be a self-starter, independent, energetic and resourceful
Excellent written and verbal communications skills
Solid Project Management skills and experience
Aptitude for technical leadership and project management
Education: Bachelor’s Degree Required – Type: Food Science/Engineering or Related Field

Preferred Attributes, Qualifications & Working Conditions: Travel - Up to 35%

Disability Assistance
TreeHouse Foods is an Equal Employment Opportunity Employer and offers opportunities to all job seekers, including those with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to disability-accommodations@treehousefoods.com. In your email please include a description of the specific accommodation you are requesting and a description of the position for which you are applying.

EEO Considerations

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, citizenship, disability or protected veteran status.",2.6,"TreeHouse Foods
2.6","Downers Grove, IL",10000+ Employees,2005,Company - Public,Food & Beverage Manufacturing,Manufacturing,$5 to $10 billion (USD)
Data Scientist,"$62K-$103K
(Glassdoor Est.)","Being a Data Scientist at iManage means

You are excited to join forces and collaborate with a multi-disciplinary team of engineers and analysts. You will bring analytical rigor and statistical methods to the challenges of measuring our product quality, improving consumer products and understanding the behavior of end-users.

As a Data Scientist on our team, youll be working on various algorithms and using Natural Language Processing (NLP) methods to work on some of our most interesting problems using expertly curated datasets.

iM Responsible For
Analyzing and modelling structured data using advanced statistical methods, implement algorithms and software needed to perform analyses
Performing machine learning, predictive analytics, optimization, and statistical analysis methods
Using various Natural Language Processing (NLP) methods, to rigorously measure our product quality, improve enterprise products, and understand the behavior of end-users
Structuring and solving problems, conducting and interpreting analysis independently while demonstrating analytical and quantitative skills
Performing explanatory data analyses, generating and testing working hypotheses, preparing and analyzing historical data and identifying patterns
Contributing research, and trying new techniques or experiments to analyze and interpret data from documents using standard statistical tools
iM Qualified Because I have
2-5 years of professional experience working as a Data Scientist
A Masters or PhD (preferred) in Computer Science, Statistics, Mathematics, Engineering, Physics, Operations Research, or related fields
Experience with the theory and practice of standard NLP problems and approaches
An understanding of statistical data analysis such as linear models, multivariate analysis, stochastic models, cross validation, error analysis, statistical tests, and sampling methods
An Ability to implement, maintain, and troubleshoot big data infrastructure
Perform experimentations, draw conclusions and present recommended actions
A passion for learning, connecting and collaborating with others
About iManage

iManage combines artificial intelligence with content and email management to free, secure, and understand information. Over 3000 companies and 1 million users worldwide rely on our market-leading software to share and protect their most valuable data. Our work is not always easy but it is ambitious and rewarding.

So were looking for people who love a challenge. People who are happiest when theyre solving problems and collaborating with the industrys best and brightest. In exchange, well make sure the work you do here is worth doing. Thats the iManage way. Its how we do things that might appear impossible. How we develop our employees strengths and unlock their potential. Its how we find meaning in everything we do.

Whoever you are, whatever you do, however you work. Make it mean something at iManage.

Learn more at: www.imanage.com

Please see our privacy statement for more information on how we handle your personal data: https://imanage.com/privacy-policy/

Powered by JazzHR",4.2,"iManage
4.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (USD)
Data Scientist (Contractor),"$72K-$121K
(Glassdoor Est.)","Marketing

60654

ARYZTA is a global baking company with a Passion for Good Food. We provide our retail and foodservice customers with a portfolio of bakery solutions so they can deliver memorable, delicious food to consumers. With operations in the United States, Canada, South America, Europe, Asia, Australia and New Zealand, ARYZTA has become a global leader in the baked goods industry and one of the largest specialty bakery companies in the world. Our leading bakery brands in North America include La Brea Bakery®, Otis Spunkmeyer®, and Oakrun Farm Bakery®. We have 58 state-of-the-art bakeries and kitchens around the globe, with 20 of those in North America, and are committed to driving innovation, predicting upcoming consumer trends and flavors, and exceeding our customers’ expectations. The Americas team champions the values of Integrity, Ownership, Customer Focus, Creativity and Care to help us deliver on People Safety, Food Safety, Quality and Collaboration.

As a Data Scientist, you will work on the design, development and strategic application of the analytics, machine learning and statistical modeling functions within the marketing team. This position will be responsible for data mining, integration, and preparation for use in advanced analytics to help drive actionable insights for category management, pricing, innovation, portfolio recommendations and other ad hoc needs.

In addition, this position will oversee model integrity and performance while working closely with marketing and sales teams to continuously improve/enhance advanced analytics effectiveness. They will also serve as the business owner for all advanced analytics tools, including their access and application. In this capacity, they will establish structure, methodological approach, and direction on projects, which will bridge the gap between transactional analysis, business research and strategy.

The Data Scientist will report directly to the VP of Marketing and Innovation and work closely with the marketing, Customer and Finance teams.

Key Accountabilities
Work efficiently with client data, retailer data and analytics partners to define, configure, extract, aggregate, package, synthesize, and share data, results, and actionable insight to support business decisions, products and campaigns.
Act as an advertising and retail measurement data subject matter expert
Bring a strong understanding and expert knowledge of the various data sources and methodologies for retail and brand marketing analysis in order to perform analyses and make expert recommendations – retail transaction data, 1st-party CRM data, ad exposure and response data, and 3rd-party data provider attributes (demographics, psychographics, lifestyle segments)
Collaborate with internal and external teams on how to creatively leverage this rich data asset for their respective insight, segmentation, portfolio, measurement, and activation needs
Identify data gaps and advocate for additional data sources to meet unmet marketplace need(s)
Prepare and present compelling analytical presentations and effectively communicate (both in writing and verbally) complex concepts to marketing and business audiences
Provide analytical direction and support for category management customer solutions using store level retailer data to create recommendations on optimal shelf sets including ARYZTA and competitive brands


Skills, Experience & Qualifications
MS or Ph.D. in in Statistics, Mathematics, Data Science, Computer Science or related disciplines preferred
Minimum 5 year’s progressive experience in applied quantitative analysis in CPG, retail, hospitality, supply chain, distribution/transportation or large B2B services or other vertical with a high volume of transactional data highly preferred.
Experience with structured and unstructured data, Nielsen, Techonmic and IRI data is a must.
Experience as a proven leader generating advanced analytics solutions to address business needs with a strong business acumen with proven experience developing analytical models, monitoring them in production, and measuring their business impact.
Experience working with and implementing one or more key technologies / platforms including: Python, R, SQL, SAS, Spark, Hadoop/HDFS, NoSQL databases, Tableau or related technologies, data preparation, model management, machine-generated data visualization platforms, and NLP solutions
Strong written, oral and presentation skills are required.
Demonstrate ability to collaborate and work well cross-functionally.
Desire to work in a fast-paced, entrepreneurial environment
Proficient in MS Office, specifically PowerPoint, Word and Excel


ARYZTA is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.",2.5,"ARYZTA
2.5","Chicago, IL",10000+ Employees,2008,Company - Public,Food & Beverage Manufacturing,Manufacturing,$2 to $5 billion (USD)
Data Scientist - Statistics,"$79K-$127K
(Glassdoor Est.)","Position Overview:

The Soybean Crop Modeling Team at Climate is seeking a highly motivated researcher with demonstrated experience applying advanced statistics and data science methods to develop predictive agronomic models for soy crop systems.
This position is within the science R&D team that uses process, statistical, and machine-learning models, big data, and cloud computing to develop solutions for farmers via digital agriculture. You will work closely with collaborating teams focused on leveraging genetic, environmental and management data to create integrated models that can help farmers better manage key aspects of soybean crop to improve yield outcome.
The role involves working with diverse data sources, and will require the ability to apply statistical and machine learning models to soy crop data. In addition, a strong understanding and ability to communicate limitations and solutions surrounding data quality and/or quantity, as well as methodologies, to an interdisciplinary team of scientists and engineers is key. You will have the opportunity to work with the richest agricultural datasets available in the world to help farmers meet the challenges of feeding a growing population.
What You Will Do:
Explore, munge, and model large and diverse datasets
Design and prototype models using statistical modeling, process modeling, and other techniques such as machine learning
Implement and test algorithms and techniques relevant to achieving project objectives
Analyze and judge the quality of data and work with the data quality team to resolve issues
Work closely with a team of world-class scientists, engineers and mathematicians to deliver impactful scientific research
Select the most appropriate modeling techniques and data visualization for large datasets
Assist with high-level analysis, design, and code reviews
Basic Qualifications:
PhD in Statistics, Biostatistics, Data Science, Applied Mathematics, or another highly quantitative discipline; or Masters degree plus two years of post-graduate experience.
Demonstrated ability to apply advanced statistical methodology and data science solutions to real-world problems
Strong proficiency in Python
Strong analytical and quantitative problem solving ability, with demonstrated ability to build, test, and iterate on a variety of model forms
Demonstrated ability to work in cross-functional environment
Preferred Qualifications:
Applied experience with agricultural science and/or agricultural datasets
At least 1 year of work experience applying statistics and data science to real-world problems
Machine learning experience
Experience in SQL, PySpark, or SparklyR/Spark
Ability to translate complex technical concepts to collaborations, decision makers, and non-technical audiences
Strong drive to learn new topics and skills and to develop innovative products for our customers
Excellent interpersonal and communication skills

What We Offer:
Our teams are composed of industry experts, top scientists, and talented engineers. The environment is extremely engaging and fast-paced, with dozens of specialties coming together to provide the best possible products and experiences for our customers.
We provide competitive salaries and some of the best perks in the industry, including:
Superb medical, dental, vision, life, disability benefits, and a 401k matching program
A stocked kitchen with a large assortment of snacks & drinks to get you through the day
Encouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used
We take part and offer various workshops, conferences, meet-up groups, tech-talks, and hackathons to encourage participation and growth in both community involvement and career development
We also hinge our cultural DNA on these five values:
Inspire one another
Innovate in all we do
Leave a mark on the world
Find the possible in the impossible
Be direct and transparent

Learn more about our team and our mission:
The Climate Corporation - The Technology Behind Making A Difference
https://youtu.be/c5TgbpE9UBI or visit https://climate.com/careers

Climate aims to create a welcoming and collaborative environment for our employees in which a diverse set of perspectives and voices are represented and celebrated.
As part of our dedication to the diversity of our workforce, The Climate Corporation is committed to Equal Employment Opportunity and does not discriminate based on race, religion, color, national origin, ethnicity, gender, sex (including pregnancy), protected veteran status, age, disability, sexual orientation, gender identity, gender expression, or any unlawful criterion existing under applicable federal, state, or local laws. If you need assistance or an accommodation due to a disability, you may contact us at accommodations@climate.com.",3.3,"The Climate Corporation
3.3","Chicago, IL",501 to 1000 Employees,2006,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable
Data Engineer,"$85K-$158K
(Glassdoor Est.)","The Job Details are as follows:

OVERVIEW

We are looking for creative and enthusiastic Data Engineers to join our team in building the best Data Platform on the street. We’re responsible for managing the flow of data into the firm, maintaining the data lake, creating analytics-ready datasets, and building the APIs that make everything accessible to our clients. Our singular goal is to help our investment teams use data to make better investment decisions.

Our analysts and systematic trading teams rely on us to provide analytics-ready datasets. For each dataset we must consider the implications of point in time storage, optimize for our users’ access patterns, and create useful aggregations/slices. Our ideal candidate will have experience with storing, transforming, and modeling big data. In this role, you will:
Develop cloud-first data ingestion processes using Python, SQL, and Spark
Engineer data models and infrastructure for a wide variety of market and alternative datasets
Design and build services and plugins to enhance our Data Acquisition Platform
Maintain alerting systems to ensure smooth day-to-day operations for hundreds of datasets
Author tests to validate data quality and the stability of the platform
Investigate and defuse time-sensitive data incidents
Communicate with data providers to onboard new datasets and troubleshoot technical issues
Evangelize best practices to our partners throughout the firm
Work directly with Analysts, Quants, and Portfolio Managers to understand requirements and provide end-to-end data solutions
WHAT YOU’LL BRING
Bachelors/Masters degree in Computer Science or a related field
Strong analytical, data, and programming skills (Python/SQL/NoSQL)
3+ years of experience with at least one of Spark/Hive/Hadoop
2+ years of experience orchestrating pipelines with a technology like Airflow/Luigi/Oozie/Nifi
Solid understanding of time series data and temporal queries
Ability to understand and contribute to our existing data system software
Aptitude for designing infrastructure, data products, and tools for Data Scientists a plus
Strong oral and written communication skills, most importantly, must be a team player",3.9,"Balyasny Asset Management
3.9","Chicago, IL",501 to 1000 Employees,2001,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable
Enterprise Data Engineer,"$82K-$103K
(Glassdoor Est.)","Our client is searching for an experienced Enterprise Data Engineer to join their team in Chicago. Enterprise Data Engineers build pipelines that support datasets used by all investment teams and strategies across the firm. They manage the firm’s most critical data sets and focus on applying software development best practices to solve complex data challenges. The expectation is that the data engineer has sound programming skills, strong business acumen, and a strong interest in finance.
Responsibilities:
Develop solutions that enable internal analysts to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, bespoke processes), transformations (Python, Perl) and interface (API, schema design, events, etc.)
Build tooling and automation around data pipelines that improve the efficiency, quality and resiliency of the data platform
Partner with internal analysts, quants and data scientists to design, develop, test and deploy solutions that answer fundamental questions about financial markets.
Take on an entrepreneurial mentality by building and selling your own ideas. The company works in an evolving space and they expect you to help design their evolution by challenging the status quo and independently identifying opportunities to improve the entire data organization.

Requirements:
A passion for working with data and developing software to address data processing challenges
Proficiency with Python, C++, Java or equivalent
Proficiency with RDBMS, NoSQL, distributed compute platforms such as Spark, Dask or Hadoop
Prior experience building data pipelines from structured or unstructured data preferably including web crawlers
Prior work developing BI tooling and/or application development for data analytics
Advanced technical communication skills
Working knowledge of statistics, predictive analytics or machine learning techniques
Strong business acumen with prior experience in investment research or direct exposure to product or data science teams AND passionate about using data for investment decisions

If you would like to be considered for the position of Enterprise Data Engineer or wish to discuss the role further then please leave your details below. Your resume will be held in confidence until you connect with a member of our team
Email: info@njf.com or call London (0207 604 4444,) New York (212 400 4845) or Chicago (312 204 72176) to speak to a member of our team. Thank you",4.2,"NJF Global Holdings
4.2","Chicago, IL",51 to 200 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (USD)
Data Scientist (Personal Valuation Team),"$87K-$144K
(Glassdoor Est.)","Company Description

Positioned at Publicis Groupe's core, Conversant is a marketing tech platform that helps brands transform ordinary customer experiences into meaningful, human experiences. The Conversant platform powers a connected suite of products and services called Epsilon PeopleCloud, combining leading-edge identity management, industrial-strength data and technology expertise with big brand acumen gained over five decades of working with the industrys top brands. Our human-powered, data-led marketing delivers unmatched depth, breadth and scale to help brands create exceptional business outcomes. For more information, visit www.epsilon.com. Follow us on Twitter at @EpsilonMktg.

Job Description

External Title: Data Scientist
Internal Title: Decision Science, Scientist

As a Data Scientist in our Decision Sciences R&D organization, yyou will be responsible for researching and building machine learning, natural language processing, and recommender system applications to extend Epsilon CORE Personalization Platform. Epsilon CORE Personalization Platform analyzes anonymized data at Internet scale and evaluates more than one trillion advertising opportunities per month in real-time. You will work on real-world problems as part of our highly collaborative R&D team, and your solutions will directly and rapidly impact our business. This includes analyzing raw source data and derived data, researching and developing models, algorithms, and applications, building tools and analyses for new and existing products and presenting findings.

RESPONSIBILITIES
Develop an understanding of Epsilon CORE Personalization Platform and proprietary datasets
Use your machine learning expertise to research and recommend the best approaches to solving our technology and business problems
Design, implement, and validate your solutions in Apache Spark and Apache Hive using Scala or Python on large state-of-the-art computing clusters.
Work with our Engineering teams to integrate your solutions into Epsilons CORE Personalization Platform
Participate fully in our collaborative approach to research and applications projects
Qualifications
A Ph.D. in Computer Science, Operations Research, Electrical Engineering, Statistics, Mathematics, Physics, Economics, or related scientific discipline
Research experience and coursework in Optimization, Control Theory, Machine Learning, or Simulation
Experience with distributed computing, such as Hadoop, Spark, or related technologies
Familiarity with Scala, Python, SQL, or Java
Strong understanding of modeling and statistical techniques
Desire to work in a highly collaborative environment
ADDITIONAL USEFUL BUT NOT REQUIRED SKILLS
Experience with Recommender Systems, Natural Language Processing, Information Retrieval, Mathematical Optimization, Control Theory, Time-Series Analysis
Additional Information

Great People, Deserve Great Benefits
We know that we have some of the brightest and most talented associates in the world, and we believe in rewarding them accordingly. If you work here, expect competitive pay, comprehensive health coverage, and endless opportunities to advance your career.

Epsilon is an Equal Opportunity Employer. Epsilons policy is not to discriminate against any applicant or employee based on actual or perceived race, age, sex or gender (including pregnancy), marital status, national origin, ancestry, citizenship status, mental or physical disability, religion, creed, color, sexual orientation, gender identity or expression (including transgender status), veteran status, genetic information, or any other characteristic protected by applicable federal, state or local law. Epsilon also prohibits harassment of applicants and employees based on any of these protected categories.

Epsilon will provide accommodations to applicants needing accommodations to complete the application process.

#LI-AL1

REF17386U",3.4,"Epsilon
3.4","Chicago, IL",5001 to 10000 Employees,1969,Subsidiary or Business Segment,Advertising & Marketing,Business Services,$2 to $5 billion (USD)
Principal Geospatial Data Pipelines Architect,"$138K-$219K
(Glassdoor Est.)","Position Overview:


As a senior technical leader in the Data Pipelines engineering organization, you will technically guide a team chartered with ingesting and transforming agronomic data into canonical and post-canonical datasets. You will be accountable for the design and technical stewardship of existing and next-generation large scale data pipelines processing geospatial data acquired from a global farming user base. You will drive pipeline and capability architectures that facilitate the rapid integration of data science based agronomic, data quality, and imagery processing models directly into our data pipelines.

What You Will Do:
Lead technical direction and architectural evolution of our data pipelines and related digital farming platform capabilities.
Partner with other architects and technical leads to collaborate, design and validate appropriate solutions and institute appropriate data governance mechanisms.
Partner with Digital Farming Platform leads to establish and steward a multi-year Data Pipelines technical capabilities roadmap.
Develop cloud-based pipeline architectures that enable massively scalable data processing, while maintaining less than linear operating cost profiles.
Continuously assess next-generation geospatial data and imagery processing techniques to support use cases unique to the agriculture industry.
Work with key leaders and subject matter experts in our Data Science and Product organizations to integrate and enable the latest agronomic data innovations and data quality algorithms.
Evangelize and mentor others on topics such as data governance, data quality, and data management best practices and techniques.
Basic Qualifications:
BS, MS or equivalent in Computer Science or related technical field
10+ years of experience in software or data engineering.
4+ years serving as a lead data or pipeline architect in a large-scale, cloud-based, high-volume data processing organization or business division.
Demonstrated experience writing architectural requirements and systems design documents.
Experience designing and governing scalable cloud-native backend compute capabilities (REST APIs, microservices, distributed computing frameworks, geospatial processing and indexing, messaging frameworks and paradigms, data quality management).
Expertise designing and deploying solutions on at least one cloud-based provider such as AWS, GCP or Azure
Preferred Qualifications:
Excellent written and verbal communication including the presentation of complex engineering designs, concepts, and solutions in a clear and concise manner to technical and non-technical audiences alike
Expertise in processing and aggregating high-volume, geospatially-oriented IoT data
Expertise in imagery processing and feature extraction from satellite and aerial sources
Depth of knowledge in the Data Operations and Data Quality management space
Experience with layered geospatial data structures and data representations
Expertise designing and implementing highly scalable data-intensive distributed computing solutions using modern cloud-native processing frameworks
Experience with Amazon Web Services (EC2, S3, RDS, SQS, etc.) is strongly preferred
Experience with a compiled JVM language, including Scala, is a plus
Working knowledge of open-source and commercial data pipeline tooling (Apache NiFi, Cloudera, etc) strongly preferred
What We Offer:

Our teams are composed of industry experts, top scientists, and talented engineers. The environment is extremely engaging and fast-paced, with dozens of specialties coming together to provide the best possible products and experiences for our customers.

We provide competitive salaries and some of the best perks in the industry, including:
Superb medical, dental, vision, life, disability benefits, and a 401k matching program
A stocked kitchen with a large assortment of snacks & drinks to get you through the day
Encouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used
We take part and offer various workshops, conferences, meet-up groups, tech-talks, and hackathons to encourage participation and growth in both community involvement and career development
We also hinge our cultural DNA on these five values:
Inspire one another
Innovate in all we do
Leave a mark on the world
Find the possible in the impossible
Be direct and transparent
Learn more about our team and our mission:

The Climate Corporation - The Technology Behind Making A Difference
https://youtu.be/c5TgbpE9UBI or visit https://climate.com/careers

Climate aims to create a welcoming and collaborative environment for our employees in which a diverse set of perspectives and voices are represented and celebrated.

As part of our dedication to the diversity of our workforce, The Climate Corporation is committed to Equal Employment Opportunity and does not discriminate based on race, religion, color, national origin, ethnicity, gender, sex (including pregnancy), protected veteran status, age, disability, sexual orientation, gender identity, gender expression, or any unlawful criterion existing under applicable federal, state, or local laws. If you need assistance or an accommodation due to a disability, you may contact us at accommodations@climate.com

#LI-BW1",3.3,"The Climate Corporation
3.3","Chicago, IL",501 to 1000 Employees,2006,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable
Data Scientist,"$79K-$138K
(Glassdoor Est.)","Job Summary
Applies advanced data analysis tools and techniques to provide insights and actionable recommendations for the business. Utilizes complex statistical modeling to make predictions about future outcomes and in multiple scenarios. May explain findings to business audience.

Job Responsibilities
Responsible for applying advanced data analysis tools and techniques to provide insights and actionable recommendations for the business. Utilizes complex statistical modeling to make predictions about future outcomes and in multiple scenarios.
Interprets and applies data in complex analyses, and explains findings to business audiences to improve products and processes.
May support or lead the development of data-related commercial offerings and/or other intellectual property (IP)
Executes statistical and mathematical analyses to support business decision making.
Develops and/or uses algorithms and statistical predictive models and determines analytical approaches and modeling techniques to evaluate scenarios and potential future outcomes.
Applies analytical rigor and statistical methods to analyze large amounts of data, using advanced statistical techniques such as predictive statistical models, customer profiling, segmentation analysis, survey design and analysis, and data mining.
Documents projects including business objectives, data gathering and processing, leading approaches, final algorithm, detailed set of results and analytical metrics.
Develops materials to explain project findings.
Effectively resolves problems and roadblocks as they occur.
Interacts with internal and external peers and/or managers to exchange semi-complex information related to assigned activities.
Prepares and presents interpretation of findings to internal clients.
Walgreens (walgreens.com), one of the nation's largest drugstore chains, is included in the Retail Pharmacy USA Division of Walgreens Boots Alliance, Inc. (Nasdaq: WBA), a global leader in retail and wholesale pharmacy. Walgreens is proud to be a neighborhood health, beauty and retail destination supporting communities across the country, and was named to FORTUNE* magazines 2019 Companies that Change the World list. Approximately 8 million customers interact with Walgreens in stores and online each day. As of August 31, 2019, Walgreens operates 9,277 drugstores with a presence in all 50 states, the District of Columbia, Puerto Rico and the U.S. Virgin Islands, along with its omnichannel business, Walgreens.com. Walgreens also provides specialty pharmacy and mail services and offers in-store clinics and other health care services throughout the United States, most of which are operated by our health care strategic partners.

Basic Qualifications
Bachelor's degree and at least 2 years of experience in quantitative or computational functions; or graduate degree in a quantitative, computational or technical discipline
Knowledge of SQL
Experience in data science, advanced analytics, or statistics. Ability to interrogate data, perform analyses, interpret data, and present to business audiences.
Knowledge of open source data science and statistics packages such as Python, R, Spark, etc.
Experience establishing and maintaining key relationships with internal (peers, business partners and leadership) and external (business community, clients and vendors) within a matrix organization to ensure quality standards for service.
Experience analyzing and reporting data in order to identify issues, trends, or exceptions to drive improvement of results and find solutions.
Willing to travel up to 10% of the time for business purposes (within state and out of state).
Preferred Qualifications
Graduate degree in a quantitative, computational or technical discipline",3.0,"Walgreens
3.0","Chicago, IL",10000+ Employees,1901,Company - Public,Drug & Health Stores,Retail,$10+ billion (USD)
Data Science Intern,-1,"Data Science Intern (Summer 2021)
Location


Chicago

Job Department


Trading

Apply Now

Title: Data Science Intern (Summer 2021)
Location: Chicago
Department: Trading

Data Science Intern (Summer 2021) at Wolverine Trading

If you want to understand the data of modern markets at the deepest level and dive into quantitative trading, the data science research internship is right for you. Wolverine is offering the opportunity to work in a highly collaborative and dynamic environment where you’ll get exposure to our algorithmic trading and execution systems. Data Scientists work with traders and engineers to develop, test, and implement statistical models and algorithmic trading systems that drive every aspect of Wolverine’s business. Wolverine seeks intelligent and creative individuals who will apply their mathematical and programming skills to complex big data and time series problems.

What You’ll Do

As a summer intern, you will work on multiple ML, statistics, and data engineering projects using our cutting-edge cluster computing technology and A/B testing environments. You will perform huge data analysis on our algorithms, and have the opportunity to propose actionable changes to fully automated trading systems. You will gain experience with options pricing and equities trading strategies while learning how we approach significance testing, parameter tuning, outlier analysis, and algorithmic optimizations. Our team oversees thousands of data sources and the algorithms that convert these data into actionable insights for our trading strategies. Wolverine provides classroom education, hands-on training, and mock trading. Wolverine also provides fully furnished apartments that are located close to the office, making your morning commute quick and easy. Additionally, Wolverine will host several social activities throughout the summer to ensure an optimal work-life balance.

What We Look For
Working toward a degree in statistics, computer science, mathematics, or another highly quantitative field and have an expected graduation date between December 2021 and June 2022.
History of academic excellence.
Demonstrated interest in trading, financial markets, and technology, but experience or knowledge of finance not required.
Excellent quantitative and problem-solving skills.
Entrepreneurial and self-motivated.
Strong communication skills.
Desire to work in a team environment.
3-month commitment.
Experience in Python.
Strong background in classical statistics and machine learning preferred.
About Wolverine

Founded in 1994, the Wolverine companies comprise a number of diversified financial institutions specializing in proprietary trading, asset management, order execution services, and technology solutions. We are recognized as a market leader in derivatives valuation, trading, and value-added order execution across global equity, options, and futures markets. With a focus on innovation, achievement, and integrity, we take pride in serving the interests of both our clients and colleagues. The Wolverine companies are headquartered in Chicago with offices in New York and San Francisco and a proprietary trading affiliate office located in London.

Sponsorship is not available for this position.",4.2,"Wolverine Trading
4.2","Chicago, IL",201 to 500 Employees,1994,Company - Private,Investment Banking & Asset Management,Finance,$10 to $25 million (USD)
Data Scientist,"$60K-$102K
(Glassdoor Est.)","Who We Are!

At Maven Wave, an Atos Company, we are relentless in hiring the industrys top talent. Each employee is hand-picked not only for their skills, but for their personality and broad expertise. We are looking for this rare combination of talent that sets us apart in the industry.

Maven Wave helps leading companies make the shift to digital and shorten the fuse to innovation. We combine the expertise of top-tier consulting with the agility of a cutting-edge technology firm. This multidisciplinary blend of skills allows us to create unique digital advantages for our clients. Maven Waves digital solutions are agile, mobile, rooted in analytics, and built in the cloud.


Maven Wave, Google, and YOU: Drive and deliver business results with data-based insights.

We are looking for a Data Scientist who will utilize their analytical, statistical, and programming skills to develop data-driven solutions to complex business challenges.


Your Life As a Maven:
Leverage company data to drive business solutions for enterprise clients using R and Python.
Perform data collection for Data Science operations including Machine Learning.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.
Assess Model accuracy using common metrics (AUC, F1, etc.) and explain the results to client stakeholders.

Your Expertise:
3-5 years of experience manipulating data sets and building statistical models.
Cloud experience in a major platform, such as AWS, GCP, or Azure.
Experience using Data Science languages (R, Python) to manipulate data and draw insights.
Knowledge of a variety of Machine Learning and advanced analytical techniques and their real world advantages/drawbacks.
Familiarity with the following software/tools: Python, C, Java, Jupyter Notebooks, SQL, ML platforms (H2O, DataRobot), distributed data (Map/Reduce, Hadoop), and visualization (Tableau, qlikview)
Must have a Bachelors degree in Computer Science, Technology, Computer Information Systems, Computer Applications, Engineering, or a related field.
Your X-Factor:
Aptitude - You have an innate capacity to transition from project to project without skipping a beat.
Communication - You have excellent written and verbal communication skills for coordination across projects and teams.
Impact - You are a critical thinker with an emphasis on creativity and innovation.
Passion - You have the drive to succeed paired with a continuous hunger to learn.
Leadership - You are trusted, empathetic, accountable, and empower others around you.
Why Were Proud To Be Mavens!
Google Cloud North America Services Partner of the Year 2019, 2018, 2017
#21 Best Workplaces in Chicago, FORTUNE
Great Place To Work Certification, Great Place to Work
Fast Fifty, Crain's Chicago Business
101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR)
Top Google Cloud Partner, Clutch
Fastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine
Top IT Services Companies, Clutch
Google Global Rising Star Partner of the Year
Ready to Learn More?
Digital Transformation at Maven Wave
Check out the Data Team
See what Glassdoor has to say
Real Customer Stories",4.4,"Maven Wave Partners
4.4","Chicago, IL",201 to 500 Employees,2008,Company - Private,Consulting,Business Services,$50 to $100 million (USD)
Data Scientist/Machine Learning Specialist,"$80K-$129K
(Glassdoor Est.)","Driving Infinite Possibilities Within A Diversified, Global Organization


The future is what you make it.

When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers, and doers who make the things that make the future.

That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings smart and safe and even making it possible to breathe on Mars. Working at Honeywell isnt just about developing cool things. Thats why all of our employees enjoy access to dynamic career opportunities across different fields and industries.

Are you ready to help us shape the future? Become a #futureshaper!

An excellent career opportunity is currently available for an Advanced R&D Engineer/Scientist specialized in Data Science/Machine Learning/AI in the Optimization Development group within UOP's Research and Development organization located in Des Plaines, IL. This position affords a unique and visible opportunity to support outcome based digital service models and performance monitoring and optimization solutions for Honeywell UOP customers.

Key Responsibilities:
Develop analytics capabilities to enable upsell opportunities and outcome based business models for Honeywell UOP
Develop analytics tools to identify leading indicators and customer pain points using commercial data and internal domain knowledge
Support infrastructure development to enable next generation digital performance and outcome based service offerings
Collaboration with software development teams to test/implement new software platforms and data analytics tools
Support new tool development to enable productivity improvements for UOPs service organization and transform service into a recurring revenue growth engine
Develop capabilities to enhance first principles models through the use of data science/machine learning algorithms
Author invention disclosures to contribute to the innovation effort at Honeywell UOP
Travel both domestic and internationally approximately 10% annually
YOU MUST HAVE
Bachelor's Degree in Chemical Engineering and 7 years of experience in process systems engineering and machine learning/data science
WE VALUE
PhD in Chemical Engineering highly preferred
Experience with applying machine learning, data science tools and algorithms
Knowledge of optimization theory and experience working with process systems engineering tools and software
Experience with developing and applying reduced order/surrogate models
Knowledge of statistics, parameter estimation, model discrimination and experimental design
Knowledge of chemical engineering fundamentals including fluid flow, heat transfer, mass transfer and reaction engineering
Knowledge of UOP technologies: Refining/Petrochemicals/Gas Processing applications.
Excellent computer programming skills
Strong interpersonal skills and the capability to work effectively across multiple functional departments
Demonstrated ability to work independently with a strong focus on delivering results and identifying alternative solutions when challenges arise
Excellent written and verbal communication skills to ensure all aspects of projects are clearly understood and well documented
Knowledge of Six-Sigma principles and their use in managing risk and uncertainty
Additional Information
JOB ID: req238815
Category: Engineering
Location: 50 E Algonquin Rd,Des Plaines,Illinois,60017-5016,United States
Exempt
Engineering (GLOBAL)

Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, or veteran status.",3.7,"Honeywell
3.7","Des Plaines, IL",10000+ Employees,1885,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD)
Associate Analytical Scientist,-1,"This position is responsible for supporting the development of analytical tests and characterization methods for pharmaceutical formulation, process, and specification development. The Associate Scientist will work with product development team members in support of method development, method transfer, method validation, stability data generation and data summary. This role will also be responsible for drafting test methods, product development SOP’s, and general laboratory maintenance and operation.

Assist in the development of specific and selective chromatographic methods (HPLC, UPLC and other methods for biologics) for use in characterizing prototype pharmaceutical formulations.
Collaborate with Pharmaceutical Development Scientists to design adequate stability/ characterization protocols for new products for toxicology, bioavailability, and early stage clinical support.
Support and oversee Research Associate(s) in the implementation of compendial monographs and procedures (USP, EP, etc.).
Perform duties, as required, for Reference Standard programs, instrument maintenance/ calibration and Stability Programs (internal and external).
Configure and operate laboratory instruments, including HPLC, Karl Fischer Titrator, etc.
Read and record instrument data, tabulate data, and keep detailed laboratory records.
Draft Standard Operating Procedures (SOP’s) for laboratory equipment operation and maintenance.

Bachelor’s degree in a Scientific field with 6-8 years, MS degree with 2-4 years or PhD degree with 0-2 years of industry experiences.
Demonstrated understanding of modern chromatographic methods and theory, especially the chromatographic methods and theory for proteins and Biologics.
Hands on experience and expertise with Mass Spectroscopic instrumentation preferred
Ability to work independently as well as part in a team
Ability to draft routine reports and maintain accurate and detailed records of work performed
Working knowledge of Microsoft Productivity software (Excel, Word, etc.), Agilent ChemStation and common statistical software
Technical/regulatory writing experience preferred
Excellent written and verbal communication skills
Working Conditions
Must be able to stand for extended periods of time.
Must be able to lift 25 lbs. or more.
Adequate vision (corrected or uncorrected) to read fine instruments such as calipers, instrument displays, etc. and perform visual inspection for defects.
Position works with potentially hazardous chemicals and active pharmaceutical ingredients. May require periodic evening and weekend work, as necessary, to meet company deadlines.
Position may include periodic travel (domestic and international).",4.5,"Xeris Pharmaceuticals, Inc.
4.5","Chicago, IL",51 to 200 Employees,-1,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Data Scientist,"$77K-$128K
(Glassdoor Est.)","Job Requirements

Data Scientist: Newark, NJ; Chicago, IL; or Slough, UK

Please note this is a pipeline requisition so responses to your submission may be delayed.

Inspiring the whole Mars business to adopt data driven decision-making by developing advanced analytics methods is huge in your role. How? By mining vast amounts of data from company databases for insights that will help solve business problems and ultimately make Mars more profitable.

Working in a small multidisciplinary team alongside the Global Analytics, Data Engineering, Business Translation and AI teams, you’ll partner with Product Owners to solve problems that real users face using advanced digital techniques. That also means closely collaborating with users from our segments and markets around the world to find the right problems to solve. More than that, you’ll use this direct user exposure to invent true ‘firsts’. That’s new and emerging approaches that Mars, and maybe even the industry, haven’t seen before.

A big part of your role will be choosing the most appropriate technique, based on business need and available data, to develop custom data models and algorithms. As part of that, you’ll also create processes and tools to monitor and analyze model performance and data accuracy. All the time, balancing time to deliver with level of detail and accuracy.

Working with different functional teams, you’ll implement your models and monitor their outcomes – making sure we’re conforming to data security standards at all times. Thinking about the newest technology, you’ll make sure we’re maximizing our efficiency and productivity and provide subject matter expertise across the business whenever it’s needed.

Work Experience

Job Qualifications

· Bachelor’s degree in Analytics or related quantitative fields (statistics, operations research, mathematics, econometrics etc.). An advanced degree is preferred.

· Minimum of 3 years of experience preferred working with modelling techniques and advanced applied skills. For example, significance testing, GLM/Regression, Random Forest, Boosting, Trees, text mining and social network analysis, using tools like Spark, Scala, SAS, R, Python, Bayesia, H2O, Storm, Yarn, and Kafka

· 2-3 years of experience in applied data science role or equivalent. CPG, Telecom or Financial services preferred.

· Experience using key external third-party data sources including Nielsen/ IRI/ Storeviews, Kantar, Homescan Panel, Retail Execution, Shopper card, first party data and consumer surveys

· Experience querying databases (SQL, Hive) and working with big data platforms such as Hadoop ecosystem (Azure), including in-memory solutions (SAP HANA and Apache Spark)

· Working knowledge of data visualization tools such as Tableau, Power BI, D3, ggplot, to deliver output to the broader business community to improve decision making and productivity

· Strong communication and presentation skills",4.0,"Mars
4.0","Chicago, IL",10000+ Employees,1911,Company - Private,Food & Beverage Manufacturing,Manufacturing,$10+ billion (USD)
ASSOCIATE SCIENTIST (NIGHT SHIFT),"$30K-$71K
(Glassdoor Est.)","Job Summary

Responsible for performing routine testing of in-process and finished product samples. Monitors environmental conditions in the production and lab areas. Summarizes environmental monitoring and product test results. Provides project support to Scientist and Lead Scientist. Prepares media and reagents and equipment.

Responsibilities

Generates new standard operating procedures for microbiology test procedures. Keeps others current as assigned.
Performs environmental monitoring for Skan isolators and routine testing of in-process and finished products.
Assists Scientist / Lead Scientist with test method validations and special projects. Carries out special projects independently as required and assigned by supervision.
Assists with plant equipment requalifications as directed.
Monitors and tracks microbiological test results. Must be able to understand and follow company’s good documentation requirements.
Conducts weekly summaries of test results for trend analysis.
Promptly reports data discrepancies and out of limits conditions to supervision. Carries out documentation, investigation, author incident reports, and conducts corrective actions as assigned.
Assists in training new departmental personnel in standard operating procedures.
Keeps supervisory personnel informed of all relevant events impacting the operations and performance of the department.
Maintains knowledge of cGMP’s and GLP’s.
Follow safety requirements, maintain good housekeeping of lab areas, order lab supplies to maintain inventory and prepare test media and reagents as assigned.

Requirements

Bachelor of Science degree in biological sciences with 1-2 years of progressive pharmaceutical lab experience preferred or equivalent education and experience. Excellent verbal and written communication skills are essential. Planning and organizational skills necessary for primary responsibilities. Must successfully execute requirements to achieve ISO 5 environment gown certification as required by supervision.

IND-1

#GD

Additional Information

We offer an excellent salary and benefits package including medical, dental and vision coverage, as well as life insurance, disability, 401K with company match, and wellness program.

Fresenius Kabi is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disabilities, or protected veteran status.",3.4,"Fresenius Kabi
3.4","Melrose Park, IL",10000+ Employees,-1,Subsidiary or Business Segment,Health Care Products Manufacturing,Manufacturing,$5 to $10 billion (USD)
Data Scientist,-1,"The Data Scientist we're looking to hire should love diving into massive data sets, searching for trends and answering questions about what makes the needle move. They will be interested in what makes content go viral and how users interact with social media. The successful candidate will also have a treasure trove of new ideas to help discover and sift through new data points to come up with actionable suggestions for improving the Institute(TM)s work.Overview
The Data Scientist is responsible for extracting, cleaning, and analyzing large datasets, as well as creating custom data sets to be used for research by the Institute. In addition to gathering new data from a variety of sources, the Data Scientist will also be responsible for managing pre existing datasets and ensuring that they are kept up to date.

We seek:
Fluency with databases, scientific computing, predictive modeling and data analysis
A good communicator who can visualize insights
Good statistical skills with strong theoretical fundamentals
A team player
Required Skills

Experience with AWS or other cloud platform
Strong applied statistics skills, such as distributions, statistical testing, regression,
etc.
Good scripting and programming skills
Excellent understanding of machine learning techniques and algorithms
Familiarity with relational, distributed and NoSQL database environments
Strong project management skills and ability to multi-task, set priorities, and follow
through",5.0,"CultureFit Technology Staffing
5.0","Chicago, IL",1 to 50 Employees,1997,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (USD)
Data Scientist II,"$102K-$167K
(Glassdoor Est.)","About The Opportunity


Grubhub is dedicated to connecting hungry diners with our wide network of restaurants across the country. Our innovative technology, easy-to-use platforms and streamlined delivery capabilities make us an industry leader today, and in the future of online food ordering.

We strive to create a workplace that reflects the diversity of our customers and the communities we serve. When you join our team, you become part of a community that works together to innovate, solve problems, take risks, grow, work hard and have a ton of fun in the process!

Why Work For Us

We have a fast-paced environment and that is what our teams thrive on. Grubhub believes in empowering people and offering opportunities for development, as well as professional growth. We value strong, positive relationships in all areas: with each other, our customers and our greater community. Want to be a part of a team of diverse collaborators in an authentically fun culture? If so, we want to talk to you - and hear what’s your favorite restaurant for food delivery!

Grubhub is looking for an innately curious, business-minded, results-oriented Data Scientist to work on our Logistics Data Science team. As part of our Delivery initiative, this team is focused on developing models, algorithms, simulations, and experiments to accelerate and perfect our delivery systems. As a member of this highly collaborative team, you will get to partner with stakeholders all across the business to solve diverse, novel and highly formidable problems. The team’s responsibilities are uniquely broad; they encompass topics such as delivery timing estimation, driver payment strategies, dynamic market balancing and smarter driver dispatching.

A successful candidate is a motivated individual with strong model, algorithm, and software development, and communication skills. They should hold themselves to a high standard for coding best practices and a passion for pushing their team to new heights by designing new tools and evangelizing durable and efficient solutions for deploying large scale machine learning models and algorithms. Ideally, the candidate would strive to remain abreast with related science technologies, show leadership in charting new avenues for automation through data science and the rare ability to appropriately balance short term gains with long term goals.

Some Challenges You’ll Tackle
Build and deploy models and algorithms that intelligently automate a diverse array of services and operations that make Grubhub food delivery possible.
You will constantly pivot between the daily tasks of research, model building and programming to architecting a strategic vision for how our team can automate and optimize Grubhub’s delivery operations.
You will develop and maintain strong relationships with software engineering teams consuming your algorithm and model outputs.
Apply robust and maintainable coding practices to ensure high-quality outputs at all times to our model consumers.
You Should Have


You should have:
Master’s degree in a quantitative or technical field such as Statistics, Mathematics, Physics, Computer Science or Computer Engineering
4 years of industry experience in a data science role or adjacent position
Expert knowledge with Python scripting language and SQL.
Experience with the entire pipeline of deploying machine-learning algorithms including their development, validation, implementation, and production launch.
Demonstrable proficiency in basic statistics, linear algebra, and calculus as they relate to machine learning concepts.
Interest in coding best practices, both in acquiring them, developing them, and evangelizing them to teammates and others.
Strong ability to distill and communicate complex technical concepts and solutions at a level appropriate for the intended audience.
Got These? Even Better:
Ph.D. in aforementioned quantitative or technical field or 6 years of industry directly relevant industry experience.
Past successes processing, analyzing, and modeling GPS data or geotraces.
Experience with big data: extraction, processing, filtering, and presenting large data quantities using cloud technologies like AWS.
Familiarity with utilizing a clustered distributed-data processing tool such as Spark, Dask or Hive.
Expert level knowledge of experimental statistics, research and best practices.
And Of Course, Perks!
Flexible PTO. Grubhub employees are provided a generous amount of time to recharge their batteries.
Health and Wellness. We provide programs that support your overall well-being such as generous medical benefits, employee network groups, company-wide fitness challenges, and a comfortable and casual workplace! We also support our parents by offering 8 weeks of paid parent bonding time, a 4-week returnship program, and 6-8 weeks paid medical leave.
Learning and Career Growth. Your personal and professional development is a priority at Grubhub. From day one, we empower you to lead and be an active participant in your career growth. We provide continuous learning opportunities, training, and coaching and mentorship programs.
MealPerks. Who’s ready for some lunch? We provide our employees with a weekly Grubhub credit to enjoy and support local restaurants. We also offer company-wide meals several times a year to bring our Grubhub family together.
Fun. Every Grubhub office has an employee-led Culture Crew that connects people through fun, meaningful events and initiatives. Some of our popular past events include: Wing-eating contests, Grubtoberfest, 5k Runs, Bring Your Child to Work Day, regular happy hours, and more!
Social Impact. We believe in the importance of serving the communities that support our business. In addition, employees are given paid time off each year to support the causes that are important to them.
Grubhub is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics. The EEO is the Law poster is available here: DOL Poster. If you are applying for a job in the U.S. and need a reasonable accommodation for any part of the employment process, please send an e-mail to TalentAcquisition@grubhub.com and let us know the nature of your request and contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address.

CA Privacy Notice: If you are a resident of the State of California and would like a copy of our CA privacy notice, please email privacy@grubhub.com.",3.9,"GrubHub
3.9","Chicago, IL",1001 to 5000 Employees,2004,Company - Public,Internet,Information Technology,$100 to $500 million (USD)
Environmental Research Scientist,"$55K-$117K
(Glassdoor Est.)","General Statement

Under supervision, carries out applied research projects in relation to wastewater treatment processes, individually or in conjunction with other investigators.

Essential Job Functions

Essential job functions are fundamental, core functions common to positions in a classification. They are not intended to be an exhaustive list of all job duties for any one position in the class. Since class specifications are designed to be descriptive and not restrictive, incumbents may complete one or all of the job duties listed or tasks of similar kind not specifically listed here.
Conducts research assignments on wastewater and sludge processing technology and in the fields of sanitary chemistry, sanitary microbiology, sanitary engineering, wastewater engineering and environmental engineering.
Assists Maintenance and Operations in solving plant problems such as sludge dewatering and odor problems; conducts joint M&R/M&O plant monitoring program.
Assists the Engineering Department through design of treatment processes.
Carries out laboratory, pilot, and field testing procedures.
Assists with various projects carried out by supervisor and outside investigators.

Other Job Functions

Assists in preparing work plans, standard operating procedures, technical manuscripts for publication and interim and final reports on research programs and projects.
Reviews technical documents from other District Departments or outside agencies.
Prepares or participates in seminar and lecture presentations related to research projects
Initiates and processes requisitions and payment forms and other administrative duties.
Assigns, supervises, and reviews the work of subordinates.
Performs other duties as assigned.

Environmental Conditions

May involve exposure to a variety of chemical and biological materials, some of which may be hazardous or toxic. May involve exposure to fumes and noxious odors.

Desirable Knowledge, Skills and Abilities

Considerable knowledge in the principles, practices and techniques of wastewater treatment, including sludge processing.
Considerable knowledge of research methods associated with air, sludge, and water quality monitoring and field and laboratory testing.
Some knowledge of analytical techniques pertaining to wastewater, sludge, and air.
Considerable knowledge of statistical techniques used in analyzing data.
Some knowledge of environmental regulations.
Ability to direct, monitor and participate in the development of research projects.
Ability to communicate effectively, orally and in writing.

Minimum Qualification Requirements

A master's degree in water resources sciences, environmental sciences, environmental engineering or sanitary engineering from an accredited college or university.

Promotional Requirement

Possession of a master’s degree in water resources sciences, environmental sciences, environmental engineering or sanitary engineering.
One year of service with the District as a Senior Laboratory Technician or Senior Environmental Research Technician.
Civil service status in one of the foregoing classifications.",4.1,"MWRD of Greater Chicago
4.1","Chicago, IL",1001 to 5000 Employees,-1,Government,Federal Agencies,Government,Less than $1 million (USD)
Product Data Scientist,"$51K-$90K
(Glassdoor Est.)","Who We Are

We reward shoppers for digitizing their shopping experience. Our mission is to delight the world's shoppers with a free smartphone app that's easy, smart, and fun.

Why Join the Fetch Family?

We make it better for users even when that's difficult for us.
We empower people with information and trust.
We challenge ideas - not people.
We think bigger and keep building.
We find ways to bring the fun to Fetch!

We're committed to building an empowered and inclusive community of innovative and passionate people. As a growing organization, we need team players who can go above and beyond their individual responsibilities to help our company build towards its vision. If you are a creative, hard-working, and fun-seeking person interested in working with a close-knit group of highly talented people, this is the right place for you.

Fetch Rewards is an equal employment opportunity employer.

The Role!

The Data Science & Analytics team embodies these values and works with a laser focused objective to enable data driven decision making for both internal stakeholders and external partners. We are looking for a Product Data Scientist to contribute to this vision and reap the rewards of joining an exciting company in the high growth phase.

You will create analytical solutions that help Fetch teams leverage and monetize actionable insights from our unique data. This is a challenging and high visibility position, responsible for creating these solutions as well as influencing technical direction. Success in this role requires the ability to take on challenging problems and design & develop an amazing solution with little to no assistance.

You possess:
Ability to create SQL/Python programming modules for custom insights required by our Product Teams. Leverage statistical analysis to understand what is ""acceptable"" versus ""outliers"".
Ability to successfully collaborate with both business users and engineers for effective analytical solution development and deployment. Create automated KPI dashboards and monitoring reports.
Passion to drive actionable insights from product usage and other relevant data to measure success of experiments, diagnosis of issues, understanding of general consumer behavior.
Ability to present insights to business stakeholders through Tableau / Powerpoint / Excel in a compelling manner.
Knack for conducting the apt Data Exploration needed to enhance the cleanliness and effectiveness of our data sources.
Discipline to create well documented coding and analytics packets to ensure reusability as the team expands.
Master's in Statistics, Mathematics, Computer Science or any other Quantitative field.
Bonus points for:
Experience in analytics at app-based / Consumer Tech companies.
Good grasp of machine learning techniques, and their application in the real world.
Familiarity with Big Data frameworks like Snowflake, Spark and AWS services.
Familiarity with Tableau or any other visualization tools.
Effective communication, ability to translate and explain technical issues to non-technical team members.
Love of Dogs! . . . Or just tolerance. We're a very canine-friendly workplace.",4.9,"Fetch Rewards
4.9","Chicago, IL",51 to 200 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable
Polymer Characterization Scientist,"$18K-$79K
(Glassdoor Est.)","A trusted partner at nearly three million commercial customer locations, Ecolab (ECL) is the global leader in water, hygiene and infection prevention solutions and services. With annual sales of $13 billion and more than 45,000 associates, Ecolab delivers comprehensive solutions, data-driven insights and personalized service to advance food safety, maintain clean and safe environments, optimize water and energy use, and improve operational efficiencies and sustainability for customers in the food, healthcare, hospitality and industrial markets in more than 170 countries around the world.

Ecolab is seeking a Polymer Characterization Scientist to develop and advance technical platforms satisfying both business and customer needs. In this role, you will be responsible for performing and leading research, development and problem-solving projects to enable new product and platform development. You will work closely with anchor and divisional RD&E teams to design, execute and communicate results. We are seeking candidates who have strong collaboration and teamwork skills, are self-motivated, have good communication skills, are creative problem solvers, and possess strong observation and perception skills.

Whats in it For You:
The opportunity to take on some of the worlds most meaningful challenges, helping customers achieve clean water, safe food, abundant energy and healthy environments
The ability to make an impact and shape your career with a company that is passionate about growth
The support of an organization that believes it is vital to include and engage diverse people, perspectives and ideas to achieve our best
What You Will Do:
Develop and transfer phase 0-1 chemistry and formulation concepts
Collaborate with anchor and divisional research scientists/RD&E leaders on new development projects and platforms
Conduct synthetic polymer characterizations through, for example, molecular weight measurements using Size Exclusion Chromatography-Multi Angle Light Scattering (SEC-MALS) techniques
Develop organic and aqueous phase SEC methods
Perform Thermogravimetric Analysis (TGA) and Differential Scanning Calorimetry (DSC) analysis of products and product blends
Collaborate with other researchers to design and ultimately provide the most complete product analysis
Actively engage in development of new platforms that meet strategic business needs
Interpret experimental data and communicate results clearly to peers and project teams in written reports and oral presentations
Provide consulting on experimental design, mentoring, and work direction for junior lab scientists
Maintain employee safety standards, including 6S lab standards
Minimum Qualifications:
Bachelors degree in Chemistry or related discipline and 5 years of R&D experience; Masters Degree and 3 years of R&D experience; or Ph.D. and 1 year of R&D experience
Experience working with fundamental physical/chemical properties and structural activity relationships
Experience conducting synthetic polymer characterizations through, for example, molecular weight measurements using Size Exclusion Chromatography-Multi Angle Light Scattering (SEC-MALS) techniques
Experience developing organic and aqueous phase SEC methods
Experience performing Thermogravimetric Analysis (TGA), Differential Scanning Calorimetry (DSC), and rheological analysis of products and product blends
Preferred Qualifications:
Method development experience with water soluble polymer characterization techniques like SEC/GPC, SEC-MALS and viscometry
Demonstrated record of applying polymer characterization techniques to a wide variety of problems
Fundamental understanding of polymerization processes and formulation
Working knowledge of statistics
Strong problem-solving skills
Strong oral and written communication skills
Our Commitment to Diversity and Inclusion

At Ecolab, we believe the best teams are diverse and inclusive, and we are on a journey to create a workplace where every associate can grow and achieve their best. We are committed to fair and equal treatment of associates and applicants. We recruit, hire, promote, transfer and provide opportunities for advancement on the basis of individual qualifications and job performance. In all matters affecting employment, compensation, benefits, working conditions, and opportunities for advancement, we will not discriminate against any associate or applicant for employment because of race, religion, color, creed, national origin, citizenship status, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran.

In addition, we are committed to furthering the principles of Equal Employment Opportunity (EEO) through Affirmative Action (AA). Our goal is to fully utilize minority, female, disabled and covered veteran individuals at all levels of the workforce. Ecolab is a place where you can grow your career, own your future and impact what matters.

We will consider for employment all qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local laws, including the City of Los Angeles Fair Chance Initiative for Hiring Ordinance and the San Francisco Fair Chance Ordinance.",3.6,"Ecolab
3.6","Naperville, IL",10000+ Employees,1923,Company - Public,Chemical Manufacturing,Manufacturing,$10+ billion (USD)
"Senior Data Scientist, Ad Intelligence",-1,"Who We Are

Sensor Tower is the leading solution for mobile marketers, app developers, and industry analysts who demand superior competitive insights into the mobile market economy.

We serve independent and Fortune 500 customers alike, spanning the mobile games, travel & hospitality, music, finance, and broadcast entertainment markets. Our suite of products consist of free, “SMB”, and Enterprise-tiered solutions including Store Intelligence, Usage Intelligence, Ad Intelligence, and App Intelligence.

We are a privately held company headquartered in San Francisco and was a member of AngelPad’s startup incubator program in 2013. Our insights are cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.

Role Summary

As a Senior Data Scientist, Ad Intelligence, you will be the expert of all things related to mobile advertising. You will leverage your mobile advertising and mobile industry knowledge to drive strategies to improve the accuracy and offerings of our Ad Intelligence solution. This solution allows one to uncover insights like which app publishers are advertising the most on mobile app campaigns, which creatives are performing best across certain ad networks, and which ad network a publisher is marketing on the most.

The Ad Intelligence solution presents complex challenges involving large-scale data (>140 billion data records) and high load on a daily basis. To learn more about one of these challenges, here's a link to our blog post describing how to speed up the backend with graph theory. You can read more about our industry-leading solution here.
Requirements
2+ years of experience in a technical role within the mobile advertising space (i.e. experience at mobile attribution companies, mobile ad networks, mobile ad agencies)
Master's degree or above in mathematics, statistics, or computer science
4+ years applied experience in business intelligence, data mining, analytics, or statistical modeling in technology or mobile industries
A passion for data analysis and presentation of data insights
Ability to communicate effectively with technical developers and non-technical marketing business partners
Extensive programming experience (Python, Ruby or a similar language)
Moderate experience implementing machine learning algorithms
Good working knowledge of MongoDB or similar DB technologies
Strong proficiency with one or more statistical visualization or graphing toolkits (MS Excel, a Javascript framework like Highcharts or Tableau)
Extra Credit!
Enjoy working in small, fast-paced teams where you can take initiative and accountability, and generate results every day
Detail-oriented, organized, and focused on delighting customers

Why Join Sensor Tower?
We were named one of the 50 Tech Companies to Know in 2020 by BuiltIn
After seven years of building Sensor Tower off of $1MM (Seed, 2013), we're excited to announce our $45MM growth investment. Read more about it here, in the words of our co-founders.
We have a birds-eye view of the entire mobile app ecosystem, and we keep our teams constantly abreast of the latest mobile app trends, news, and best practices.
You align with our Core Values: Customer-Focused, Innovative, Continuously Learning, Action-Oriented, Respectful, Data & Metrics-Driven.
We grant options to all of our employees because we recognize that everybody plays an integral role in our success; thus all employees should be invested in Sensor Tower (both figuratively and literally).
We offer unlimited PTO, Health and Wellness stipends, flexible work hours, 401K, team trips (white water rafting, Hawaii, and weekend Tahoe mansion trips to name a few), and more
Covid-19 Specific benefits: Stipend to set up your home office and/or gym, WiFi stipend, daily UberEats delivery stipend, and virtual team events
For more information about our Engineering team and what it is like working with them please visit our team page here.

Sensor Tower is proud to be an equal opportunity workplace.

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

If you have a disability or special need that requires accommodation, please let us know.",4.6,"Sensor Tower
4.6","Chicago, IL",1 to 50 Employees,-1,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable
"Director, Data Science","$139K-$220K
(Glassdoor Est.)","Reporting to the Sr. Director, Analytics & Data, the Director of Data Science will direct the selection, planning and completion of all data science opportunities that involve high impact, customer-affecting tactics and strategies working in partnership with various functional and business partners.

The decisions made by this position have a profound impact on the organization through the development of analytical work that influences overall company direct marketing, catalog, eCommerce, branch, and sales force strategies and enhances the success of tactical initiatives. The role is critical to company’s continued transformation to an increasingly digital and data-driven organization.

Principal Duties & Responsibilities:
Work with internal senior leaders and business partners to identify key areas for Data Science to impact customer experience and demand generation across domains that include sales force, marketing and website
Create and align on a roadmap to execute against the priorities
Research and recommend data science solutions for improved effectiveness and delivery of demand generation initiatives
Direct the design, development, and delivery of data science initiatives across the organization
Partner with internal senior leaders to ensure these business initiatives are executed with optimal chance of success and adoption
Direct, coach, and mentor a growing talented team of data scientists, while creating an inclusive environment
Provide thought leadership around the data and computing environment necessary for optimal success
Appropriately communicate and represent the work performed by the team to senior leadership within the company
Preferred Education & Experience:
Bachelor’s degree in statistics, economics, mathematics, or related field. Master’s in statistics, economics, data science, or analytics preferred
10+ years equivalent work experience required.
Experience directing a Data Science program in a company, that includes demonstrable impact via development and implementation of Data Science based products and product roadmaps
Experience with linear regression, logistic regression, cluster analysis, time series analysis, and machine learning/ AI techniques
Experience with SAS, R, Python, and SQL
Knowledge of artificial intelligence systems, including image recognition
Ability to assume high exposure responsibilities and interact with senior leadership
Strong business acumen and a strategic mindset
Excellent and proven communication skills
Ability to establish and sustain strong business relationships and effectively prioritize business needs
Grainger is an Equal Opportunity Workplace and an Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.

#dice

Apply Now",3.7,"Grainger
3.7","Lake Forest, IL",10000+ Employees,1927,Company - Public,Wholesale,Business Services,$10+ billion (USD)
Data Scientist 2 - Styling/Trunks Data Science & Analytics,"$75K-$123K
(Glassdoor Est.)","Job Description


Data Scientist 2 - Styling/Trunks Data Science & Analytics

Join a high impact, customer-obsessed data science and analytics team!

Nordstrom is a specialty retailer offering the very best in fashion and customer service since 1901. We live by five simple values that guide how we work together day-to-day and how we deliver analytics & data science products. We are customer-obsessed, owners at heart, curious and ever-changing, we extend ourselves to our peers and our customers, and we’re here to win! We're proud to be named to Fortune™ magazine's list of '100 Best Companies to Work For.' We believe this recognition comes from our desire to empower our employees to set their sights high and deliver exceptional service to customers. At Nordstrom, we apply Data Science across a complex and rapidly evolving retail landscape to develop innovative data products, new business processes and improve the customer experience in our stores and online. Our data science teams are composed of interdisciplinary contributors with a broad scope who work in an energizing and collaborative atmosphere.

The Styling Data Science & Analytics team is on a mission to reinvent digital styling experiences through the power of data and artificial intelligence. We are working on exciting, cutting edge and impactful opportunities, such as: building advanced recommendation systems, making sense of text data via natural language processing, extracting valuable insights from images via computer vision algorithms and develop analytics solutions that enable the business to make data-driven decisions.

The ideal candidate is a creative self-starter and strong technical contributor who is always looking for new opportunities to solve business problems with data-driven tools. We welcome your curiosity about the business, your passion to unlock rich, nuanced insights from complicated data and the desire to communicate those insights in a way that drives positive business outcomes.

We are committed to building teams that reflect the diversity of our customers and active inclusion is core to how Nordstrom wins. We’re an equal opportunity employer and encourage individuals from underrepresented backgrounds to apply.

If the idea to make a difference in this vibrant intersection of fashion, data science, and technology excites you, join our world-class data science team!

What you'll do

Technical Excellence
Track record of delivering end-to-end data science products, i.e. ability to work across the product lifecycle from research and discovery to operationalization and production.
You are familiar with the entire end-to-end ML pipeline, including a wide range of the families of techniques for each step of the ML product development.
Strong Python skills and proficiency in at least one machine learning framework and common data science libraries (e.g., spark, scikit-learn, pandas, numpy, tensorflow, pytorch, keras, theano, seaborn, matplotlib, etc.)
Good software engineering best practices, including story estimation, test driven development, code review, and version control with git.
Own medium machine learning projects driving technical decisions and making informed trade-offs that balance quick wins with long term robust solutions with minimal supervision
Your passion for machine learning, curiosity, problem solving, and innovation empower you to stay up-to-date with research and to prototype new ideas quickly
Relationships and communication
Engage with Data Science & Analytics program management and stakeholders to frame, structure and prioritize business problems where projects or tools can have the biggest impact.
Collaborate with a cross-functional agile team spanning product management, engineering, user research and design to build innovative product solutions.
Work closely with data engineering partners to leverage and improve our Machine Learning infrastructure.
Influence the product strategy by uncovering business opportunities.
Comfort and aptitude for regularly presenting progress, insights and recommendations to stakeholders and senior leadership.
Strong technical writer and documenter.
Good Python skills including proficiency with popular data science libraries (e.g., scikit-learn, pandas, numpy, etc.) and visualization libraries (e.g., seaborn, ggplot, Altair, Plotly, etc.).
Familiarity with more specialized libraries/frameworks (e.g., tensorflow, scrapy, etc.) is a plus.
What your background may look like
2+ years of relevant hands-on industry experience with track record of building successful end-to-end data product
Degree in a quantitative field (or equivalent experience). MS preferred. PhD is a plus.
Experience with SQL and NoSQL data environments and tools such as Hadoop, Spark, DynamoDB is a plus.
Experience with Amazon Web Services ecosystem is a plus.
Excellent written and verbal communication skills
A few of our perks
Tremendous opportunity to work on some of the most exciting machine learning problems and learn from a large team of data science experts
Career advancement opportunities and annual stipend for continuous education
Lunch and learns
Hackathon days
State of the art workplace environment in the popular Chicago River North neighborhood. Social environment with built-in bars, a rooftop view, and our very own coffee shop!
Comprehensive health coverage, competitive salary, 401(k) match
Nordstrom discount
A company culture like you’ve never experienced

We’ve got you covered…

Our employees are our most important asset and that’s reflected in our benefits. Nordstrom is proud to offer a variety of benefits to support employees and their families, including:
Medical/Vision, Dental, Retirement and Paid Time Away
Life Insurance and Disability
Merchandise Discount and EAP Resources
A few more important points...

The job posting highlights the most critical responsibilities and requirements of the job. It’s not all-inclusive. There may be additional duties, responsibilities and qualifications for this job.

Nordstrom will consider qualified applicants with criminal histories in a manner consistent with all legal requirements.

Applicants with disabilities who require assistance or accommodation should contact the nearest Nordstrom location, which can be identified at www.nordstrom.com.

Nordstrom Careers Privacy Policy: https://careers.nordstrom.com/#/contact-us/privacy

© 2020 Nordstrom, Inc.

Current Nordstrom employees: To apply, log into Workday, click the Careers button and then click Find Jobs.",3.7,"Nordstrom
3.7","Chicago, IL",10000+ Employees,1901,Company - Public,"Department, Clothing, & Shoe Stores",Retail,$10+ billion (USD)
Data Scientist,"$79K-$106K
(Glassdoor Est.)","What’s significantly better than working on a typical data science team? How about working on a data science team in which you’re directly making an impact in the revolutionary field of artificial intelligence even as an entry level team member? (well, statistically significant that is). Pardon the pun, but at Spectrum we’re certain that our team is pumped up to work not only with like-minded data-savvy and fun loving professionals, but also to work with cutting edge new tools like our predictive, artificially intelligent proprietary software. So, if your confident that you want to make a direct impact in your next job today, then please keep on reading.

Responsibilities

Beyond working with state of the art technology you will have many different fantastic projects to work on as a Data Scientist at Spectrum. Here are just a few different responsibilities you can expect off the bat:
Work with IT teams, management and/or data scientists to determine organizational goals
Mine data from primary and secondary sources
Clean and prune data to discard irrelevant information
Analyze and interpret results using standard statistical tools and techniques
Pinpoint trends, correlations and patterns in complicated data sets
Identify new opportunities for process improvement
Provide concise data reports and clear data visualizations for management
Some Characteristics That Define You

We understand that as a Data Scientist for Spectrum, you have many different professional goals and personal interests. As such here are just a few different things that typically define our team members on the Data Science team:
Analytical. In order to solve problems and build innovative new digital marketing campaigns, it is essential that you know how to take an idea and analyze it from all of its angles.
Patient. As a data scientist, you know that you work with extremely large data sets on a daily basis. As such we are looking for someone who is not only meticulous, but patient enough to sit and sift through that data in a thorough way.
Creative. Beyond just analyzing data sets, you are an explorer and a puzzle solver. Pulling insights out of your data and understanding how those insights can better shape our tools is something that you live to do.
Student. More so than most industries, the field of data science is always changing and evolving. As such, you are always looking to learn new things and gain new skills.
Business-Savvy. Beyond the wicked data science skills you bring to the table, we also want you to consider the business implications of our data tools. From the ways our team will use them to how our customers will use them, we always want you to keep the user and the business application in mind.
Required Skills and Experience

On top of the many intangible skills you bring to the table, there are many skills that can help improve the efficiency and success of your work at Spectrum. Here are a few of those required skills and experience that you will come in with as a Data Scientist on our team:
A bachelor’s degree/pursuing a bachelor's degree in computer science, mathematics, statistics, information systems, or a related field
Experience with statistical modeling
Fundamental knowledge of R and/or SAS languages
Experience with SQL databases and database querying languages
Experience with data mining and data cleaning
Experience with data visualization and reporting techniques
Written and verbal expression
Benefits

As a Data Scientist at Spectrum there are a ton of fantastic perks and benefits that come along with your work. Here are just a few of the benefits you can expect when joining the Spectrum family:
Comprehensive medical & dental insurance
Retirement planning & company matching
Generous PTO, including sick days & holidays
A state-of-the-art office environment
Nintendo Switch in-office gaming such as FIFA, Arms, Mario Kart, and Rocket League
Year-round gym memberships
Paid continuing education
Casual dress code
Flexible scheduling
Free-Lunch-Friday
Company sponsored parties and group activities outside of the office",3.5,"Spectrum Communications and Consulting
3.5","Chicago, IL",51 to 200 Employees,1992,Company - Private,Advertising & Marketing,Business Services,$10 to $25 million (USD)
"Applied Data Scientist, Nonprofit","$61K-$102K
(Glassdoor Est.)","What we do

At Civis, we take a science-first approach to solving problems. With a blend of proprietary technology and statistical advisory services, we help public and private sector organizations find, understand and connect with the people they care about, so they can stop guessing and start using mathematical proof to guide decisions. We know others use ""data science"" and ""analytics"" as buzzwords, but at Civis we don't stand for fluff, and we will always deliver scalable products and technologies — not PowerPoints — to drive your business forward. Learn more about Civis at www.civisanalytics.com.

Our mission

Our mission is to bring objective, data-driven truth to organizational decision-making – all the way from the boardroom to the world's largest social causes.

What we are looking for

Are you interested in using data science to solve new and challenging problems in innovative ways — like helping an environmental advocacy organization engage new supporters or an anti-poverty non-profit sign people up for services? Civis Analytics is looking for an Applied Data Scientist to join our Nonprofit Applied Data Science practice and help us solve some of the most challenging and interesting questions facing businesses today. You can read about some of our recent work to combat poverty in New York City with the Robin Hood Foundation and to engage new arts audiences with the Lyric Opera of Chicago.

The Applied Data Science (ADS) team is the solutions and advisory arm of Civis Analytics and works closely with organizations to help solve their toughest challenges with data science. This role of Applied Data Scientist will support clients in our nonprofit verticals specifically and report to an Applied Data Science Manager.

Responsibilities
An Applied Data Scientist is responsible for the end-to-end execution of client engagements utilizing data science, which includes:
Unifying large 1st- and 3rd-party datasets and building predictive models
Deriving clear, actionable, and timely insights from analyses
Creating client-ready materials and solutions for stakeholders of varying technical experience or familiarity with methods
Working with cross-functional teams of data scientists and software engineers where necessary to create and implement solutions
Other job responsibilities of an Applied Data Scientist include:
Creatively identifying opportunities in the solution delivery process for scalable applications, and collaborating with other teams to further construct these tools
Maintaining a continuous and independent education of cutting-edge statistical techniques and programming languages
Travel requirements: <5>
Qualifications
Bachelor's degree in an analytical subject (statistics, math, economics, physics, engineering, business, political or social science, computer science, etc.)
Proven affinity for and experience working with large or messy data sets
SQL experience a plus
Experience with statistical programming languages (R, Python, etc.) and proven ability to work pragmatically with statistical concepts
Experience with presentation or data visualization software, such as Microsoft PPT, Tableau, Shiny, etc.
Excellent interpersonal and communication skills
US work authorization
Preferred Qualifications
Practical understanding of and experience with predictive analytics, machine learning, and/or causal inference
Familiarity with software development tools and practices (Git, code review, etc.)
Who we are

At Civis, we have opportunities for applicants who are newcomers, seasoned professionals, and anywhere in between. Our teams are energized by complex challenges and value diversity of thought. Opportunities to stand out and inspire happen daily and we trust and encourage you to act on your ideas – no matter how big they are. We offer you the tools and community you need to do your best work. Each of us is committed to holding ourselves accountable for results, challenging the status quo and finding new ways to grow our company and each other.

Why join our team?
The opportunity to be part of a growing tech startup focused on solving interesting and meaningful problems, invested in internal promotion, and committed to fostering a diverse, equal and inclusive workplace.
Competitive benefits, including unlimited PTO, 401K match with immediate vesting, health, dental, and vision benefits, fully paid parental leave, breastfeeding support including breastmilk shipping services for traveling moms, commuter benefits, wellness initiatives including weekly group meditations, monthly on-site massage therapy, and pet insurance.
To support employees in our now fully remote work environment, we also have expanded our virtual journal and book clubs, Donut Pals (organized virtual coffee meet-ups), Lightning Talks (5-minute presentations on anything you'd like), Lunch-and-Learns, and HR Open Discussions (bi-weekly meet-up where we discuss ideas and topics of the day in a casual format). We are also able to support and accommodate flexible work from home schedules to help employees juggle responsibilities at home.
Civis Analytics embraces the individuality of our employees and we celebrate each other's differences. Our products, services, and culture benefit from and thrive on the unique perspectives brought by each person in our community. We're proud to be an equal opportunity workplace, and we are committed to equal employment opportunity regardless of race, age, sex, color, ancestry, religion, national origin, sexual orientation, gender identity, citizenship, marital status, disability, or Veteran status. If you have a disability or special need that requires accommodation, please contact internalrecruiting@civisanalytics.com

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States.

EEO IS THE LAW

EEO Supplement

Pay Transparency",3.2,"Civis Analytics
3.2","Chicago, IL",51 to 200 Employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,$25 to $50 million (USD)
Statistician (Data Scientist) *12 month Roster* *Direct Hire*,"$71K-$119K
(Glassdoor Est.)","The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.",3.6,"Internal Revenue Service
3.6","Chicago, IL",10000+ Employees,1862,Government,Federal Agencies,Government,Less than $1 million (USD)
Data Scientist (Decision Science Identity Team),"$87K-$144K
(Glassdoor Est.)","Company Description

Positioned at Publicis Groupe's core, Conversant is a marketing tech platform that helps brands transform ordinary customer experiences into meaningful, human experiences. The Conversant platform powers a connected suite of products and services called Epsilon PeopleCloud, combining leading-edge identity management, industrial-strength data and technology expertise with big brand acumen gained over five decades of working with the industrys top brands. Our human-powered, data-led marketing delivers unmatched depth, breadth and scale to help brands create exceptional business outcomes. For more information, visit www.epsilon.com. Follow us on Twitter at @EpsilonMktg.

Job Description

External Title: Data Scientist
Internal Title: Decision Sciences, Scientist

In this role, you will research and develop enhancements to Epsilons CORE Personalization Platform to continually increase the capabilities of Epsilons digital marketing businesses.

The Decision Sciences group is a collaborative, multi-disciplinary R&D team combining data science, machine learning, AI, computer science, and more. Our colleagues love the fast-paced, dynamic work environment, the speed with which we translate research to business impact, the opportunity to continually learn new knowledge and skills, the internal research seminars, the external training opportunities, and the excellent work-life balance our culture promotes.

We prioritize talent and potential over having closely similar prior experience. If using internet scale data to drive business impact excites you, we want to talk to you.

RESPONSIBILITIES
Conduct projects from early stage research through development, in consultation with stakeholders
Use your expertise in data science, machine learning, and/or computer science to research and recommend solutions to our technology and business problems
Provide technology leadership to yield innovative differentiating solutions
Implement and optimize state of the art algorithms in distributed environments
Participate fully in our collaborative approach to research and applications projects
Develop an understanding of Conversants personalization platform and proprietary datasets
Qualifications
Ph.D in a computational, mathematical, engineering, or scientific field
Research experience in a computational area such as data science, computer science, machine learning, artificial intelligence, statistics, or graph algorithms.
Fluency in programming
Analytic and modeling skills; proficient at conceptualizing, implementing, and evaluating accurate and scalable solutions to business problems
Verbal and written communication skills, including the ability to summarize technically complex information for a non-technical audience
ADDITIONAL DESIRABLE BUT NOT REQUIRED SKILLS
Experience with distributed computing
Demonstrated proficiency working with business and technical teams to integrate algorithms into product platforms on large data sets
Additional Information

Great People, Deserve Great Benefits
We know that we have some of the brightest and most talented associates in the world, and we believe in rewarding them accordingly. If you work here, expect competitive pay, comprehensive health coverage, and endless opportunities to advance your career.

Epsilon is an Equal Opportunity Employer. Epsilons policy is not to discriminate against any applicant or employee based on actual or perceived race, age, sex or gender (including pregnancy), marital status, national origin, ancestry, citizenship status, mental or physical disability, religion, creed, color, sexual orientation, gender identity or expression (including transgender status), veteran status, genetic information, or any other characteristic protected by applicable federal, state or local law. Epsilon also prohibits harassment of applicants and employees based on any of these protected categories.

Epsilon will provide accommodations to applicants needing accommodations to complete the application process.

#LI-AL1

REF17386U",3.4,"Epsilon
3.4","Chicago, IL",5001 to 10000 Employees,1969,Subsidiary or Business Segment,Advertising & Marketing,Business Services,$2 to $5 billion (USD)
Data Scientist Advanced Analytics,-1,"Location: remote from Chicago

Who is FNA?

FNA is a fast-growing, deep technology analytics company and leader in Supervisory Technology (SupTech) and Regulatory Technology (RegTech). The FNA Platform allows analysts and data scientists to map and monitor complex financial networks and to simulate operational and financial risks. FNAs clients include the worlds largest central banks, financial market infrastructures, leading financial institutions and government agencies

Make an impact on the global stage!

Apply your curiosity of machine learning and network science for the betterment of all and help us make the financial system safer and more efficient. Youll help the world's largest and most influential financial institutions by delivering solutions to some of their topmost predicaments. Join a selective team of brilliant data scientists who challenge the status quo daily and are quietly pushing forward the bleeding edge of analytics with our advanced graphing platform.

Were looking for Data Scientists who enjoy autonomy and working remotely with some travel to interface with clients for implementations, training and use case exploration. You consider Advanced Analytics, Machine Learning, Artificial Intelligence, Big Data, Business Intelligence, and Data Visualization your playground. You have hands-on experience delivering successful projects and solutions to customers In-Cloud and On-premise installations. This role will be an integral part of the Data Science team, working to accelerate the development of our software capabilities while implementing and delivering successful solutions for globally important institutions in North and South America.

What are the benefits of joining FNA?
Contributing to FNAs mission of making our global financial system safer and more efficient
Opportunity to expand your career with additional duties and job titles as the company grows
Being part of a high-growth technology company developing and implementing the next generation of analytics solutions that is changing how businesses analyze their data
Being part of a team of collaborative, brilliant, passionate, hard-working & humble colleagues who embrace working from anywhere there is a solid internet connection
Entrepreneurial spirit at every level of the company
Fully supportive of your personal and professional growth with a £1k/yr annual stipend for continuing education
Twice per year company trips to very cool locations for all team off-sites
You will own projects from end to end, stamp your name to important work and document use cases in technical reports, white papers, etc.
Publish! Publish papers stemming from your projects at FNA
Key Areas of Responsibility:
Using the FNA platform and scripting language, identify hidden behavioural patterns and interconnections in large datasets, helping to create breakthrough solutions, performing exploratory and targeted data analyses as part of quantitative services engagements or proof of concepts. This will be achieved both remotely and on-site with clients
With time, the Data Scientist will be customer facing to develop and present customer specific use cases clearly and concisely, communicate analyses, recommendations, status and results to existing customers and prospects at business management and executive level
You will be heavily involved in the research and development of new use-cases, either as part of our product road-map or based on specific customer requirements
Partner with cross-functional teams to solve business problems at scale and identify trends/opportunities for the customers
Customer Excellence - Effectively help to resolve relevant customer support requests in a professional and timely manner
Required profile:
The right candidates will have experience and knowledge of Machine Learning concepts and will be allowed the freedom to explore new concepts to help develop future products
Youve executed in highly complex situations, delivered measurable business value, and exhibit strategic business acumen
Must have 2+ years commercial experience as a Data Scientist
2+ years experience with machine learning and predictive modeling within large datasets
2+ years experience with R/Python/MatLab/SQL or similar
Experience on projects applying network science/graph analytics
The right candidate will be naturally inquisitive, analytical and have good attention to detail. You should have the ability to communicate technical findings to non-technical personnel and not be afraid to present creative, data-driven ideas to stakeholders
Passion and curiosity for what is happening within RegTech/FinTech/SupTech, Big Data, Graph Databases, Data Analysis and especially Graph Analytics
You like to get things done with speed and efficiency
Business level written and spoken English is a minimum
Ability to travel approximately 25% of the time (Domestic and International)
Nice To Haves:
MS or PhD level qualification in mathematics, statistics, physics, engineering or related applied quantitative field
Bi-lingual business-level language capability
Powered by JazzHR",-1,FNA,"Chicago, IL",Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD)
Data Scientist,"$72K-$116K
(Glassdoor Est.)","Vistex is an SAP software solutions extensions partner serving businesses of all sizes worldwide across a spectrum of industries by managing their master data, contracts, pricing, rebates and incentive programs. Our solutions provide unprecedented visibility into the breadth and depth of go-to-market programs and enable businesses with insightful information that drive revenue, control costs and increase margins. Our deep industry expertise coupled with in-house implementation, delivery and training services makes Vistex a full solutions resource and consultancy.
The Data Scientist, a member of our Data Science Team, will have a great opportunity to enhance and innovate the advanced analytics supporting all go-to-market-strategies in a business-to-business context and help our clients better understand how they bring value to their clients.
The charter of Vistex data science team is to continuously and pro-actively add more intelligence to the go-to-market functionality that Vistex delivers to their customers. To achieve this, the data science team leverages deep expertise in data-driven science as well as acumen in business-to-business commerce. This data-driven science includes broad areas of mathematics, statistics, econometrics, operations research and computer science, in domains such as machine learning, cluster analysis, data mining, and mathematical programming.

Conducting independent data science projects with customers, geared at solving a specific business problem
Exploring and validating new techniques to be incorporated into price segmentations, price optimization, and demand modeling
Conducting data science projects geared at configuring the Vistex solutions to maximize value for our customers
Generalize these opportunities into product modules that are valuable across multiple industries
Define reliable, controlled, automated analytical processes
Execute analytical work such as segmentation, forecasting, and mathematical programming
Conduct effective and efficient proof of concept and proof of value projects
Support the development, implementation and on-going use of analytical applications and models.
Travel to client sites as necessary

Requires a graduate degree in a quantitative science, such as (but not limited to) data science, mathematics, statistics, econometrics, operations research or computer science, and a genuine interest in the business impact of the application of advanced analytics.
Minimum of 5 years of experience in the use of analytical techniques, working with real data, with solid communication skills and a relevant combination of education, experience and skills
Analytical coding languages such as SAS, Python and/or R
Experience with C/C++ is a bonus
Machine Learning, Mathematical Programming,Econometrics, Simulation
Google Cloud Analytics is a great plus
Practical knowledge of go-to-market strategies, marketing measurement and channels of distribution, and a
Keen ability to work collaboratively across the organization.
About us: The Vistex platform helps businesses finally get control of all their different promotions, rebates, SPAs, discounts, and other incentives. With so many programs across so many partner relationships, it can be impossible to see where all the money is going, let alone how much difference it’s actually making to revenue. With Vistex, business leaders can see the numbers, see what really works, and see what to do next – so they can make sure every dollar they spend really is driving more growth, not just more costs. It’s why global enterprises ranging from Coca-Cola to Sony to Grainger rely on Vistex every day. Vistex | Now it all adds up.™",3.6,"Vistex, Inc.
3.6","Hoffman Estates, IL",1001 to 5000 Employees,1999,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (USD)
Postgres DBA/Data Engineer,-1,"NOTE: ONLY CANDIDATES CURRENTLY LIVING IN THE CHICAGO METRO AREA WILL BE CONSIDERED

Database Engineer/Administrator

Overview:

As a database administrator, youre ready to expand your knowledge and best practice experience through an established software development methodology and database best-practices. We employ technology that connects patients and physicians and fosters a patient experience that is unrivaled in the industry, and we seek a meticulous database administrator that will ensure our product continues to ship with high quality data and reporting abilities. This role will report directly to the Vice President of Technology. Primary duties will include data design in our proprietary application and building ETL connections to third party systems (CRM, Billing, etc.) and export to a centralized data store for analytics. This role is for a highly driven individual that can fit well in a diverse team, filling a key role in the technology team.

Expectations:
Architect data structures; set and monitor standards.
Great time management and self-direction and able to work independently while contributing on team efforts with clear communication
Can scope, estimate, develop, document, and test data/database/dataset functionality
Incorporate disparate data sources into a database/data lake for consumption via analytics tools such as Tableau or Looker
Ability to work with technical team to resolve data discrepancies, and work within project management tool like Jira to track work items and defects
Design, create, modify and review database objects (tables, views, indexes, keys, stored procedures, functions, DB links, etc.) to support development projects.
Troubleshoot production issues related to data and SQL code
Coordinate with VP of technology to manage projects/priorities
Required Technical Skills:
3+ years of practical experience building and supporting Postgres databases
Expert understanding of SQL including stored procedures and functions, permissions, bulk load/export
Insistence on DRY methodology
Understanding of normalization and its tradeoffs
Documentation experience for both engineering and cross functional documentation
Ability to manage, describe maintain and document disparate data flows and sources
Experience automating and routine tasks and processes
Preferred Skills:
Familiarity with HIPAA compliance requirements
Coding and scripting experience using Python
Experience using an ORM such as Django ORM or SqlAlchemy
Experience with data operations tools (Keboola and Snowflake)",4.6,"First Stop Health
4.6","Chicago, IL",1 to 50 Employees,2011,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
"Data Scientist - Health Outcomes, Advisor","$76K-$127K
(Glassdoor Est.)","Job Description
If you are passionate about making a difference in the work you do, being recognized for your talent and expertise in solving complex and challenging analytical/data problems while contributing to the success of key strategic initiatives, consider growing your career with a Fortune 10 healthcare leader! As a member of the Enterprise Analytics organization you will be responsible for the leadership and coordination of critical cross-functional analytic initiatives aimed at driving best-in-class analytic solutions to improve medication adherence. You will be responsible for designing and leading implementation of analytic solutions, including predictive modeling and machine learning, data visualization and insight tools development, and data infrastructure improvements aimed at improving the medication adherence of the patients CVS Health serves. You will collaborate with analytic partners and business partners from product, marketing, IT, data strategy, and predictive analytics to develop effective solutions for our partners.

The essential roles and responsibilities of the role are:
Collaborating with key internal and external stakeholders to gather and analyze needs and requirements to design and implement robust analytic solutions to support the identified needs;
Developing and executing strategic plans to use advanced analytics in conjunction with patient interventions to improve medication adherence outcomes;
Leveraging pharmacy and medical claims data as well as identifying and utilizing other data sources (EMR, lab results, clinical data and notes, consumer purchasing data, digital engagement data, etc.) to provide actionable, relevant, and timely analytic insight;
Accessing, manipulating, analyzing, and visualizing data from large databases using a variety of tools and techniques, such SQL, Python, R, SAS, and/or Tableau;
Conducting analyses of the data, ranging from descriptive data exploration to advanced statistical modeling;
Designing experiments to perform A/B testing and establishing specifications to develop an automated system of measurement;
Assessing existing available data, identifying data gaps, and collaborating with the data strategy team, IT, business partners, and outside vendors to develop approaches to closing the data gaps;
Collaborating with business and analytic resources across multiple teams in a matrix organization to accomplish project goals;
Constructing persuasive presentations and gaining consensus among a diverse group of individuals;
Constructing and delivering written reports of the analytic findings in a variety of formats (reports, PPT, including visualization of data and findings), formulating recommendations, and effectively presenting the results to potential non-analytic audiences;
Communicating complex technical subjects to technical and non-technical audiences.
Required Qualifications
Problem solving skills and experience constructing analytic solutions to business problems;
Developing innovative analytic approaches leveraging available internal and external data sources;
Experience interacting with and influencing decision-making by business audiences;
Solid understanding and hands-on experience with a variety of analytic processes and techniques, including health economics outcomes research, experiment design, development of measurement methodologies, hypothesis testing, statistical significance testing, modeling, and machine learning;
Ability to quickly develop knowledge and understanding of new domains and underlying data sources;
Solid understanding and hands-on experience working with large data sources, particularly pharmacy or medical claims and clinical program data, focusing on efficient data extraction from large databases, data manipulation, and insight generation;
Solid understanding and hands-on experience with SAS, SQL, Python, R, Tableau and/or other data, statistical, and data visualization tools and techniques, and ability to investigate and adapt emerging analytic tools and solutions into the analytic standard operating procedures;
Understanding of the healthcare administration landscape and CVS Health business model, including patient and payer concerns, as well as the operational considerations in support of the business objectives;
Excellent written and oral communication skills, including conveying analytic concepts and findings to executive and non-technical audiences with the goal of obtaining feedback and defining next steps to make the analytic insights actionable.
Preferred Qualifications
Experience working with business partners in product, IT, and marketing
Experience with campaign design and consumer market research, such as survey design, implementing large-scale campaigns, and performing A/B testing;
Experience applying behavioral economic concepts to drive behavior change;
Developing roadmaps, business cases, and project plans;
Managing projects and processes, including coordinating activates across diverse departments and ensuring that contributions across different teams are aligned and integrated as part of overall delivery;
Experience developing methodology to measure program and intervention outcomes;
Experience with programs and interventions that drive medication adherence;
Experience conducting data analysis in a healthcare setting;
Working knowledge of healthcare industry products/services and operations
Education
PhD in Statistics, Computer Science, Mathematics, Economics, Biophysics or directly related fields.
Will also consider candidates with a Masters degree in these fields, plus 2+ years of relevant post graduate professional paid work experience with an outstanding track record of developing and deploying advanced quantitative analytics to support business objectives.
Business Overview
At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.",2.9,"CVS Health
2.9","Northbrook, IL",10000+ Employees,1963,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
Data Scientist,"$55K-$91K
(Glassdoor Est.)","Careers | UL | Data Scientist in Northbrook, Illinois | Careers at United States - Northbrook
Please Enable Cookies to Continue

Please enable cookies in your browser to experience all the personalized features of this site, including the ability to apply for a job.

Welcome page

Returning Candidate?

Log back in!


Data Scientist

Location

US-IL-Northbrook

Job ID

2020-17946

# of Openings

1

Job Category

Information Technology



What you’ll learn & achieve:



Use advanced mathematical and statistical concepts and theories to collect and analyze data and construct solutions to complex business problems. Identify what data is available and relevant, including internal and external data sources, leveraging new data collection processes such as sensors, open data, and social media feeds. Perform advanced statistical analysis on experimental or business data to identify, validate and quantify trends or patterns. Design experiments, test hypotheses, and build models to explore complex business and safety science systems. Construct advanced predictive models, algorithms and probability engines to support data analysis or product functions. Write methodology, analysis and data insights for research papers, proposals and presentations. Synthesize all aspects of a data science project to lead non-technical audiences through the goals, methods and implications of the project. Leverage knowledge in machine learning, natural language processing, mathematical and statistical analyses, and technologies such as R, MongoDB, Elastic Search and open source analysis tools. Work with business leaders and researchers to suggest other projects and initiatives that will advance the organizations goals. *This position qualifies for Underwriters Laboratories Inc.’s employee referral policy program.



What makes you a great fit:



Master’s degree in data science, predictive analytics, mathematics or statistics and 3 years of experience in data analytics or data science.

Must have work experience with each of the following: 1.) predictive modeling using machine learning including neural networks Bayesian, k-means and related algorithms; 2.) implement natural language processing algorithms to detect patterns in large volumes of unstructured data using BERT, Spark, scikit learn, NLTK and SpaCy; 3.) conduct mathematical and statistical analyses to uncover relationships between variables using R, multivariate, logistic and other regression methods; and 4.) aggregate, prepare and pre-process large volumes of unrelated data for use in Data Lakes that implement MongoDB, Elastic Search and open source analysis tools.



What you’ll experience working at UL:



.

Options

Apply for this job onlineApply
Share
Email this job to a friendRefer

Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.

Share on your newsfeed


Connect With Us!

Not ready to apply? Connect with us for general consideration.

EEO is the Law
E-Verify Poster (English)
Right to Work Poster (English)

UL is committed to hiring and retaining a qualified diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class U.S. Citizenship is required for most positions.

If you experience technical difficulties during the application process, please click here

Software Powered by iCIMS
www.icims.com",3.5,"Underwriters Laboratories
3.5","Northbrook, IL",10000+ Employees,1894,Company - Private,Consulting,Business Services,$2 to $5 billion (USD)
Senior Data Scientist,"$136K-$227K
(Glassdoor Est.)","Job Title: Senior Data Scientist

Job Location: Chicago, IL

Company Overview

We are a fast growing, cyber security company based in Chicago, IL. We gather cyber intelligence from hundreds of places around the world and process billions of records a day to provide data security to our clients who rely on us for next generation cyber threat protection and enterprise data security.

Position Description

The 5thColumn Data Scientist / Data Analyst to support our clients to help deploy Data Lake solutions internally for 5thColumn based in Chicago. This critical role is in support of clients various teams across the company to identify and solve business challenges utilizing large structured, semi-structured, and unstructured data in a distributed processing environment.

The Data Scientist / Data Analyst role will be directly responsible for the successful support and operations of our customers data lake strategy. Communication with customers, vendors and co-workers in a clear and professional manner is an absolute must.

Work will often require direct interaction with team members without direct supervision. You must be able to think on your feet, communicate constantly and professionally, and above all else meet the expectations of our clients.

The ideal candidate will have a passion for technology with good understanding of their applicability to business, a relentless focus on the customer experience and an ability to multitask, assimilate data, make decisions and prioritize complex work while paying attention to the details.

Responsibilities Include:
Develop statistical models to across multiple industries including medical, insurance, and security data but not limited to. Assist in developing internal tools for data analysis against the data lake.
Executes on modeling/machine learning projects effectively
Communicates findings to team and leadership ensure models are well understood and incorporated into business processes
Leverages research and applies state-of-the-art techniques to inform recommendations and decisions.
Works across the enterprise to identify and incubate business use cases.
Manage analytical modeling projects from beginning to end: data selection, cleaning and transformation; model development, implementation and interpretation; and insight application
Find innovative ways to search for meaningful patterns, trends, and relationships amongst large amounts of data and to identify the success measures, analyses and reporting processes that lead to actionable findings
Synthesize complex qualitative and quantitative data to form clear, well-supported, data-driven recommendations for non-technical audiences and present results to internal stakeholders
Work with stakeholders to understand business objectives; translate objectives to define KPIs and goals at the business and campaign level around various products
Advance analytics maturity within the firm by counseling stakeholders on how to extract value from data and make data-driven decisions to improve marketing activities
Required Skills:
5+ years of experience in Information Technology in managing implementing and supporting Data Warehousing as an ETL developer/lead
3 + years in leading ETL programs handling from the beginning of the design and development for complex projects.
Experience in applying analytical models for solving business problems in Networking and Security industry
Ability to work with NoSQL data stores (Cassandra, MongoDB, DynamoDB, etc)
Proficient in using query languages such as SQL, Hive, Pig etc
Experience with large scale data storage and processing frameworks (e.g., Hadoop, MySQL, Big Table, MapReduce, SAS, AWS Kinesis, AWS Firehose, but not limited too)
Large-scale, distributed systems design and development
Worked on scaling, performance and scheduling and ETL techniques
Knowing how to develop in the following programing languages: Python, C, C++, Java, Ruby on Rails
Implemented data warehouse solution which leveraged ETL jobs from multiple data sources.
Informatica (ETL), and Tableau/Kibana (interactive data visualization) experience is a plus or equivalent tool sets.
Qualifications:
Total 7 to 10 years of experience and minimum 5 years of experience as a data scientist, data analyst, business intelligence analyst, or equivalent roles
University degree in Computer Science, Math, Quantitative Methods, Bayesian statistics, or related fields
Experience developing machine vision, machine learning, or artificial intelligence algorithms/models with state of the art deep learning frameworks
A graduate degree in a field such as math, computer science, statistics, engineering or machine learning, or equivalent experience.
Seasoned Technical Veteran with 5+ years as a data scientist.
Strong knowledge of data analytics and business intelligence visualization tools (e.g., Kibana,Tableau, Qlikview, PowerBI, Domo); Kibana is preferred
Demonstrated skills in coding. Software development experience a plus.
Data mining and data analysis skills with the ability to clearly present complex information in a simple manner, discern business meaning and recommended actions to stakeholders
Knowledge of the theory and practice of machine vision and deep-learning techniques
Ability to develop new concepts and stay current with academic research.
Ability to summarize research and analysis for audiences with varying levels of expertise.
Bachelors degree or equivalent experience desirable.
Experience mentoring and developing team members of 10+ people
Vision beyond horizon to establish frameworks and standard building blocks of a future focused team and to help each team member grow.
Ability to champion ambiguous scenarios and challenges
High degree of comfort and ease with ambiguity and uncertainty
Passion for understanding clients vision and business goals
Driven to help organizations innovate via digital products
Natural sense of leadership and ownership - both in project delivery and business development settings
Problem-solver, curious, hands-on mentality
5thColumn LLC is an Equal Employment Opportunity employer. 5thColumn conducts all employment-related activities without regard to race, religion, color, national origin, age, sex, martial status, sexual orientation, disability, citizenship status, genetics, or status as a Vietnam-era special disabled and other covered veteran status, or any other characteristics protected by law. 5thColumn LLC participates in E-Verify and will confirm work authorization for candidates residing in the United States.

Powered by JazzHR",3.8,"5thColumn
3.8","Chicago, IL",1 to 50 Employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable
Data Scientist Consultant,"$83K-$98K
(Glassdoor Est.)","Chicago Data Scientist

The AI & Analytics practice group at Capgemini is expanding its footprint… rapidly. As part of the fastest growing digital practice within Capgemini, we work with the latest advanced analytics, machine learning, and big data technologies to extract meaning and value from data in a number of different industries, including Media & Entertainment, High Tech, Automotive, Consumer Products & Retail, Industrial Products, Manufacturing, Telecom, Aerospace & Defense, and Energy & Utilities.

The AI & Analytics group is the fastest growing digital practice at Capgemini demanding agile innovation. As part of the AI & Analytics group, you will work in a collaborative environment with internal and client resources to understand key business goals, build solutions, and present findings to client executives while solving real-world problems. If you are passionate about solving problems in the realm of cognitive computing, big data, and machine learning while utilizing business acumen, statistical understanding, and technical know-how, the AI & Analytics practice group at Capgemini is the best place to grow your career.

Role & Responsibilities:


Work in a collaborative environment with global teams to drive client engagements in a broad range of industries to design and build scalable AI and Machine Learning solutions to solve business problems and create value by leveraging client data

Work with team to quickly understand client needs, develop solutions, and collaboratively present findings to client executives

Collaborate with team to provide data-driven recommendations and solutions to clients by clearly articulating complex technical concepts through generation and delivery of presentations

Analyze and model both structured and unstructured data to generate value

Use industry expertise and data science experience to uncover new opportunities with clients’ data

Perform EDA and feature engineering to both inform the development of statistical models and generate improve model performance and flexibility
Candidates should be flexible / willing to work across this delivery landscape which includes and not limited to Agile Applications Development, Support and Deployment.

Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.

(Includes Data Modeler, Data Miner.) Responsible for importing, cleaning, transforming, validating and modeling data with the purpose of understanding and drawing conclusions from data (may be presented in charts, graphs, and/or tables). Also, design and develop relational databases for collecting and storing data and build and design data input and data collection mechanisms.

Required Skills and Experience:

You are responsible for data related activities such as data extraction, profiling, cleansing, de-duplication, standardization, conversion, transformation and loading, data mining, warehousing, archiving and reporting. Responsible for all activities required to ensure optimum performance and data integrity of databases in production environments, in line with the requirements. Responsible for providing support of server based databases in development and test environments including database software installation, database creation, performance and capacity design, backup and recovery design, security design, providing Analytical feedback as appropriate.

Qualifications


1 -2 years industry experience, with work in a quant or data scientist field preferred

Master’s degree or PhD in Computer Science, Statistics, Economics, Mathematics, or other closely related field

Excellent team-oriented and interpersonal skills, with a strong interest for consulting

Outstanding communication skills with the ability to clearly articulate findings and present solutions to business partners

Preferred Qualifications


Experience with one or two of the following: Deep Learning methods, NLP, computer vision, sentiment analysis, topic modeling and graph theory and databases

Experience with common data science tools such as Python, R, PyTorch, TensorFlow, Keras, NLTK, Spacy, or Neo4j, and a good understanding of modelling platforms (Azure AutoML, SageMaker, DataBricks, DataRobot and H2O.ai)

Experience working with big data distributed programming languages, and ecosystems: Spark, Hadoop, MapReduce, Pig, Kafka

Familiarity with Cloud-based environments such as AWS (S3/EC2), Azure, Google Cloud

Knowledge of other coding languages such as Java, Matlab, SAS, C

Experience with building and deploying predictive and prescriptive analytics modelss Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Click the following link for more information on your rights as an Applicant : http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law
About Capgemini
A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.

Visit us at www.capgemini.com. People matter, results count.",3.8,"Capgemini
3.8","Chicago, IL",10000+ Employees,1967,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (USD)
Actuary/Data Scientist,"$67K-$112K
(Glassdoor Est.)","Duties
Help Help
Duties
Summary
This position is located in the Railroad Retirement Board's Bureau of the Actuary and Research. The incumbent will be responsible for assisting in the activities of the financial interchange (FI) division, which is a multibillion dollar project mandated by the Railroad Retirement Act (RRA).

This job announcement may be used to fill one or more vacancies.
Learn more about this agency
Responsibilities
As a Actuary/Data Scientist, you will:
Provide technical advice and assist in reviewing the accuracy of calculations for inclusion in the annual FI determinations as specified by law.
Independently plan and develop complex actuarial and statistical programs involving mainframe and personal computer applications.
As an expert subject matter analyst, work closely with the bureau's computer specialists and other staff in the development of computer programs for the processing of data.
Conduct individual research in the fields of social insurance, private insurance, and pensions, and makes comparisons between the railroad retirement program and similar programs for workers in other industries.
Compose a variety of technical publications, memoranda, etc., pertaining to aspects of the FI.
Prepare data processing requests for program changes, review documentation, prepare test data, and review test output.
Work with reviewers and auditors from the Social Security Administration (SSA), the Centers for Medicare and Medicaid Services (CMS), Government Accountability Office (GAO), and Office of the Inspector General (OIG) to coordinate case reviews and audit issues.
Utilize SAS, R, and Microsoft Office software packages to accomplish a variety of work assignments.
This work requires a professional actuary or data scientist.
Travel Required
Not required
Supervisory status
No
Promotion Potential
14
Job family (Series)
1510 Actuarial Science
1530 Statistics
Similar jobs
Actuaries
Actuaries, Health
Actuaries, Insurance
Health Actuaries
Insurance Actuaries
Mathematical Statisticians
Requirements
Help Help
Requirements
Conditions of Employment
Must be a U.S. Citizen
Males born after 12/31/59 must be registered for Selective Service
Suitable for Federal employment, determined by a background investigation
May be required to successfully complete a probationary period
Qualifications
In order to qualify, you must meet the education and experience requirements described below:

Basic Education Requirements for Series 1510 (Actuary):

A. A bachelor's degree that included courses in actuarial science, mathematics, relevant statistics, business, finance, economics, insurance, or computer science totaling at least 24 semester hours. This course work must have included a minimum of 12 semester hours of mathematics that included differential and integral calculus and one or more courses in mathematics for which these calculus courses were prerequisites.

OR

B. A combination of education and experience that includes both of the following requirements:
Technical work experience in actuarial support work or in mathematics; and
Completion of a minimum of 24 semester hours of courses in actuarial science, mathematics, relevant statistics, business, finance, economics, insurance, or computer science at a four year college or university. This course work must have included a minimum of 12 semester hours of mathematics that included differential and integral calculus and one or more courses in mathematics for which these calculus courses were prerequisites.
Basic Education Requirements for Series 1530 (Statistician):

A. Successful completion of a full 4-year course of study in an accredited college or university leading to a bachelor's or higher degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing.

OR

B. Combination of education and experience -- courses as shown in A above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.

In addition to the Basic Requirements listed above, applicants must also have the following specialized experience:

At the GS-14 level for both series, applicants must have one year of specialized experience at or equivalent to at least the GS-13 grade level in the Federal service.

Specialized experience is defined as experience performing a wide range of professional actuarial and/or statistical functions which included applying actuarial and/or statistical principles and techniques in the analysis, evaluation, and projection of data with an emphasis on complex retirement and pension plans or other similar employee benefit programs.

You MUST provide transcripts or other documentation to support your educational claims.Official or unofficial transcripts are acceptable. All materials must be submitted by the closing date of the announcement. Official transcripts will be required if selected.

Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional, philanthropic, religious, spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.

Only experience obtained by the closing date of this announcement will be considered.
Education
See Basic Education Requirements above.
Additional information
INTERAGENCY CAREER TRANSITION ASSISTANCE PLAN (ICTAP):
ICTAP provides eligible displaced Federal competitive service employees with selection priority for competitive service vacancies. You must be determined to be well-qualified for the vacancy to be eligible for special selection priority. After submission of an acceptable application which meets ICTAP eligibility, you will be determined to be well-qualified for a vacancy if your rating places you in the best qualified category.
ICTAP eligibles must submit proof of eligibility for special selection priority, such as: a separation notice; an agency certification that you cannot be placed after injury compensation has been terminated; an OPM notification that your disability annuity has been terminated; or a Military Department or National Guard Bureau notification that you are retired under 5 U.S.C. 8337(h) or 8456. You must also submit a ""Notice of Personnel Action"" (SF-50) notating your current position, grade level, and duty location, and a copy of your most recent Performance Rating. Click here for more information on ICTAP.

If you are a male applicant who was born after 12/31/59 you are required to register under the Military Selective Service Act; the Defense Authorization Act of 1986 requires that you be registered or you are not eligible for appointment in this agency.

If you are unable to apply online or need to fax a document you do not have in electronic form, view the following link for information regarding an Alternate Application.
Read more
How You Will Be Evaluated
You will be evaluated for this job based on how well you meet the qualifications above.
This position will be filled using direct hire procedures. You will be evaluated for this job based on how well you meet the qualifications above. Traditional rating and ranking of applications does not apply to this vacancy. Applications will be evaluated against the basic qualifications. Qualified candidates will be referred for consideration in accordance with the Office of Personnel Management direct hire guidelines. Veterans' preference does not apply to direct hire recruitment procedures.
Read more
Background checks and security clearance
Security clearance
Not Required
Drug test required
No
Required Documents
Help Help
Required Documents
To apply for this position, you must provide a complete Application Package which includes:
Resume showing work schedule, hours worked per week, dates of employment and duties performed.
Transcripts: You must submit transcripts. Original transcripts will be required if selected.
Interagency Career Transition Assistance Plan (ICTAP) documentation: If you are eligible under ICTAP, you must submit all required materials verifying your eligibility as listed in ""Other Information.""
Benefits
Help Help
Benefits
A career with the U.S. Government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Learn more about federal benefits.
Review our benefits
Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time, or intermittent. Contact the hiring agency for more information on the specific benefits offered.
How to Apply
Help Help
How to Apply
Please read the entire announcement and all the instructions before you begin an application. To apply for this position, you must complete the initial online application, to include submission of the required documentation specified in the Required Documents section. The complete application package must be submitted by 11:59 PM (ET) on the closing date of the announcement to receive consideration. The application process is as follows:

If you have not already, create a login.gov account:
Enter an email address during the account set up - use the same email address you use for USAJOBS (your primary or secondary email address).
Create a new password.
Have a working phone number (mobile or landline) near you - login.gov will send you a security code.
Finish setting up your login.gov account.
Once you've finished setting up your login.gov account, you'll go back to USAJOBS to finish the process. Double check your USAJOBS Profile to make sure all of your information is accurate.
Note: We recommend you don't use a .gov, .mil or .edu email address. Instead, you should use a personal (non-government) email address when you create your login.gov account.

You also cannot use an email address you share with someone else.

** For any issues signing into login.gov, go to https://login.gov/contact/

Once you have a login.gov account:
You need to use your login.gov email address, password and security code every time you want to sign into USAJOBS.
Follow the prompts in USAJOBS to take the online questionnaire, and submit the required documents. See Required Documents section for more details.
Click the Submit Application button prior to 11:59PM (ET) on the announcement closing date.
To update your application, including supporting documentation, at any time during the announcement open period by returning to your USAJOBS account. There you will find a record of your application, the application status, and an option to Update Application. This option will no longer be available once the announcement has closed.

To verify the status of your application both during and after the announcement open period, log into your USAJOBS account. All of your applications will appear on the Welcome page. The application record in your USAJOBS account provides an Additional Application Information page that provides information regarding the documentation you submitted and any correspondence we have sent related to this application. The Application Status will appear along with the date your application was last updated. For information on what each Application Status means, visit: https://www.usajobs.gov/Help/how-to/application/status/.
Read more
Agency contact information
RRB Human Resources RRB Human Resources
Phone
(312) 751-4580
Email
recruit@rrb.gov
Address
Railroad Retirement Board
844 N Rush St
Chicago, IL 60611
US
Learn more about this agency
Next steps
Once your online application is submitted you will receive a confirmation notification by email. After a review of your complete application is made, you will be notified of your rating and possible referral to the hiring official. If further evaluation or interviews are required you will be contacted.
Fair & Transparent
Fair & Transparent
The Federal hiring process is setup to be fair and transparent. Please read the following guidance.
Equal Employment Opportunity Policy
The United States Government does not discriminate in employment on the basis of race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service, or other non-merit factor.
Equal Employment Opportunity (EEO) for federal employees & job applicants
Read more
Reasonable Accommodation Policy
Federal agencies must provide reasonable accommodation to applicants with disabilities where appropriate. Applicants requiring reasonable accommodation for any part of the application process should follow the instructions in the job opportunity announcement. For any part of the remaining hiring process, applicants should contact the hiring agency directly. Determinations on requests for reasonable accommodation will be made on a case-by-case basis.
A reasonable accommodation is any change to a job, the work environment, or the way things are usually done that enables an individual with a disability to apply for a job, perform job duties or receive equal access to job benefits.
Under the Rehabilitation Act of 1973, federal agencies must provide reasonable accommodations when:
An applicant with a disability needs an accommodation to have an equal opportunity to apply for a job.
An employee with a disability needs an accommodation to perform the essential job duties or to gain access to the workplace.
An employee with a disability needs an accommodation to receive equal access to benefits, such as details, training, and office-sponsored events.
You can request a reasonable accommodation at any time during the application or hiring process or while on the job. Requests are considered on a case-by-case basis.
Learn more about disability employment and reasonable accommodations or how to contact an agency.
Read more
Legal and regulatory guidance
Financial suitability
Social security number request
Privacy Act
Signature and false statements
Selective Service
New employee probationary period
This job originated on www.usajobs.gov. For the full announcement and to apply, visit www.usajobs.gov/GetJob/ViewDetails/576375900. Only resumes submitted according to the instructions on the job announcement listed at www.usajobs.gov will be considered.",3.0,"Social Security Administration
3.0","Chicago, IL",10000+ Employees,1937,Government,Federal Agencies,Government,Less than $1 million (USD)
Data Scientist,-1,"Data Scientist
If you are a Senior Data Scientist with experience, please read on!

Based in Chicago, IL, we are a first-class management consulting provider in financial planning; performance improvement; partnerships, mergers, and acquisitions; and treasury and capital markets.

Currently we are looking to bring on a Senior Data Scientist to help us in efforts to transform data into insight to help our company advance a variety of our practices.

What You Will Be Doing
Oversees development and delivery of analytic models using big data management, algorithm design, statistical analysis, machine learning and more.
Translate understanding of the business problems and turn them into mathematical representations and technical specifications.
Ensures overall quality of the data and solutions throughout the analytic process.
Create prototypes of new functionalities and schemes to visualize data.
Research and develop measures.
Evaluate and improve functionality of data.
Interpret results and communicate them to technical and non-technical audiences.
Generates and pursue research questions with business value.
Conduct literature search and review to support new functionality and solutions for clients.

What You Need for this Position
Data Science
Data Mining
Machine Learning
Big Data Analytics
What's In It for You
Best in class Medical, Dental and Vision
401(k) and Roth 401(k) w/ match
Generous PTO and vacation
Educational resources

So, if you are a Senior Data Scientist with experience, please apply today!
Applicants must be authorized to work in the U.S.

CyberCoders, Inc is proud to be an Equal Opportunity Employer
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",4.2,"CyberCoders
4.2","Chicago, IL",201 to 500 Employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Informatics Scientist - Cardiology AI,"$65K-$114K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

Tempus Insights is our business to develop, validate and launch new predictive tests, in oncology, cardiology and new disease areas, by leveraging our clinical + molecular + imaging data to provide novel insights to clinicians and patients.

We are seeking a highly motivated and capable informatics scientist with extensive experience and interest in healthcare statistical analysis to join our team and lead our efforts to secure regulatory approval for novel AI algorithms in cardiology. This position requires experience with algorithm validation, statistical analysis, scientific writing and algorithm validation. Top candidates will also have experience with cardiology.

Duties and Responsibilities:
Lead efforts to validate predictive algorithms in cardiology and submit those AI algorithms to the FDA
Design, develop and document statistical analyses for AI algorithms to ultimately submit those algorithms for FDA approval
Collaborate with scientists, and clinicians to design and perform analyses on cardiology clinical, imaging and molecular data in order to improve quality of care.
Work in interdisciplinary groups of scientists, engineers, and product developers to translate research into clinically actionable insights for doctors and patients.
Produce high quality and detailed documentation for all projects.
Develop and implement rigorous testing and validation infrastructure to support the use of predictive algorithms in clinical care.
Required Experience:
Ph.D. or Masters in Biostatistics, Statistics, Epidemiology or a related field
Computational skills using Python and R.
Understanding of FDA validation protocols and how to bring scientific ideas to market
Ideal candidates will possess:
2-5 years experience working with healthcare algorithms to improve patient care
Self-driven and works well in interdisciplinary teams
Background in predictive or prognostic algorithm development
Strong background in the development of statistical models",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Data Engineer – Full-Time,"$81K-$100K
(Glassdoor Est.)","Job Description

Data Engineers are tasked with building and maintaining our bespoke enterprise data pipelines. They take ownership of our data pipelines, starting with how we ingest data from the outside world, to transforming that information into actionable insights, to ultimately designing the interfaces and APIs that our analysts and quants use to monetize that information. Throughout that process our data engineers work side-by-side with investment professionals and data scientists to design systems that are solving our must challenging problems and answering the most difficult questions in the hedge fund industry.

Key Responsibilities:


· Develop solutions that enable internal analysts to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, bespoke processes), transformations (Python, Perl) and interface (API, schema design, events, etc.)

· Build tooling and automation around data pipelines that improve the efficiency, quality and resiliency of our data platform

· Partner with internal analysts, quants and data scientists to design, develop, test and deploy solutions that answer fundamental questions about financial markets.

· Take on an entrepreneurial mentality by building and selling your own ideas. We work in an evolving space and we expect you to help design our evolution by challenging the status quo and independently identifying opportunities to improve the entire data organization.

Required Skills

· A deep passion for working with data and developing software to address data processing challenges

· Bachelor’s, Master’s or PhD degree in Computer Science or equivalent experience

·Proficiency within one or more programming languages like Java, Python, Perl or JavaScript.

· Proficiency with RDBMS, or NoSQL

· Experience with some of the following areas: Distributed Computing, Natural Language Processing, Machine Learning or Software Architecture

· Experience with any of the following systems: Apache Airflow, AWS/GCP/Azure, Jupyter, Kafka, Docker, Nomad/Kubernetes

· Strong written and verbal communications skills

· Ability to manage multiple tasks and thrive in a fast-paced team environment

About Citadel


Citadel is a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For a quarter of a century, Citadel’s hedge funds have delivered meaningful and measurable results to top-tier investors around the world, including sovereign wealth funds, public institutions, corporate pensions, endowments and foundations.

With an unparalleled ability to identify and execute on great ideas, Citadel’s team of more than 675 investment professionals, operating from offices including Chicago, New York, San Francisco, London, Hong Kong and Shanghai, deploy capital across all major asset classes, in all major financial markets.

Apply Now",3.9,"Citadel
3.9","Chicago, IL",1001 to 5000 Employees,1990,Company - Private,-1,-1,$50 to $100 million (USD)
"Data Scientist, Data Science & Analytics","$72K-$121K
(Glassdoor Est.)","Company Description

With over 20 years of experience, CJ Affiliate is the most trusted and established name in affiliate marketing. As a performance-based marketing channel, we help advertisers acquire new customers and increase sales to current customers, while facilitating compensation to publishers for every action they drive. We reach billions of consumers by creating fair, transparent, and successful partnerships between advertisers and publishers.

We take just as much pride in our innovative technology and comprehensive data as we do in the expertise and dedication of our people. Our collaborative teams are equipped with advanced tools, training, and career development opportunities in order to provide our clients with cutting edge solutions, strategies, and support that drive meaningful results.

Under Publicis Groupe’s solution hub Publicis Media, CJ Affiliate has the resources and commitment to offer a truly customer-centric approach to affiliate marketing across our 14 offices worldwide. Above all else, our greatest asset has always been our people, and we are honored that that some of the best and brightest in the industry choose to call us home. We hope you will, too.

Job Description

CJ's Data Scientist is on the Data Science team and works closely with Client Development, Product Management, and other internal teams to solve business problems. The Data Scientist consults with clients and internal teams to define, design, and support the implementation of data solutions to solve those business problems. A strong candidate will have a passion for deriving actionable insight from complex data, working directly with stakeholders to define business problems, and developing informative and interactive data visualizations. An excellent candidate will combine this passion with an understanding of marketing channels and how to evaluate their performance.

Do these things interest you? You will:
Collaborate with internal stakeholders to find the root of a problem and develop well defined data problems
Develop new data solutions and insights via an end to end process from problem definition, data acquisition, data processing/cleaning, analytics/insights, deliverable development, and quality control (QA/QC)
Acquire data from a variety of different data sources utilizing Spark, Python, SQL, R, or similar
Appropriately account for the timeliness, quality and accuracy of all assignments
Manage multiple projects concurrently
Present technical solutions to internal stakeholders in a formal setting, effectively communicating key concepts and functionalities
Effectively manage client expectations via direct and frequent communication with high quality results
Develop front end deliverable solutions for stakeholders utilizing BI tools such as Tableau, Cognos, Excel, or similar
Gain mastery over business problems, and proactively suggest new analyses and approaches
Qualifications

Minimum Qualifications:
Bachelor’s degree in a quantitative discipline (e.g., data science, statistics, economics, mathematics) or significant relevant coursework/experience
2-4 years’ professional experience with data analysis and business intelligence
Demonstrated ability to improve performance by deriving actionable insight from complex datasets
Experience using SQL on large datasets (or related environments like SAS, Spark, Hadoop, Python, etc.)
Strong technical skills and analytic thought process with excellent attention to detail
Experience creating functional and clean data visualizations
Expertise with Microsoft Office products; including Excel, PowerPoint, and Outlook
Effective organization and time management skills
Strong critical thinking and problem-solving skills
Excellent verbal and written communication skills
Self-motivator and collaborative team player with strong interpersonal skills
Desirable Qualifications:
Advanced degree (MS/PhD) in Statistics, Economics or other quantitative discipline
Ability to program in newer and emerging languages; working knowledge of Spark/Python and other big data technologies
Additional Information

Why CJ Affiliate?

CJ Affiliate is the leader in Affiliate Marketing. We take pride in our innovative technology, comprehensive data solutions and our people. We equip our teams with advanced tools, training and career development opportunities all to provide cutting edge solutions, strategies and support to deliver high quality results for our clients. We work in an energetic, results-oriented, collaborative, team environment that recognizes exceptional performance. As we evolve and grow as a business, so do you.

Conditions of Employment

All job offers are contingent upon successful completion of certain background checks which unless prohibited by applicable law may include criminal history checks, employment verification, education verification, drug screens, credit checks, DMV checks (for driving positions only) and fingerprinting.

Great People, Deserve Great Benefits

We know that we have some of the brightest and most talented associates in the world, and we believe in rewarding them accordingly. If you work here, expect competitive pay, comprehensive health coverage, and endless opportunities to advance your career.",3.3,"CJ Affiliate
3.3","Chicago, IL",201 to 500 Employees,1998,Subsidiary or Business Segment,Advertising & Marketing,Business Services,Unknown / Non-Applicable
Senior Data Scientist - Nationwide Opportunities,"$112K-$153K
(Glassdoor Est.)","Want to help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI) and Machine Learning (ML)? Excited by using massive amounts of disparate data to develop ML models? Eager to learn to apply ML to a diverse array of enterprise use cases? Thrilled to be a part of Amazon who has been pioneering and shaping the worlds AI/ML technology for decades?

At Amazon Web Services (AWS), we are helping large enterprises build ML models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. AWS Professional Services works together with AWS customers to address their business needs using AI solutions.

AWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML models, wed like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers. A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions.

This is a customer-facing role and you will be required to travel to client locations and deliver professional services as needed.

Major responsibilities include:
· Assist customers by being able to deliver a ML project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models with concept-drift monitoring and retraining to deliver business impact to the organization
· Use AWS AI services (e.g., Personalize), ML platforms (SageMaker), and frameworks (e.g., MXNet, TensorFlow, PyTorch, SparkML, scikit-learn) to help our customers build ML models
· Research and implement novel ML approaches, including hardware optimizations on platforms such as AWS Inferentia
· Work with our other Professional Services consultants (Big Data, IoT, HPC) to analyze, extract, normalize, and label relevant data, and with our Professional Services engineers to operationalize customers models after they are prototyped

Basic Qualifications

· Bachelors degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent professional or military experience
· Experience with ML fields, e.g., natural language processing, computer vision, statistical learning theory
· 6+ years of industry experience in predictive modeling, data science, and analysis
· Experience in an ML engineer or data scientist role building ML models
· Experience writing code in Python, R, Scala, Java, C++ with documentation for reproducibility
· Experience handling terabyte size datasets, diving into data to discover hidden patterns, using data visualization tools, writing SQL, and working with GPUs to develop models
· Experience writing and speaking about technical concepts to business, technical, and lay audiences and giving data-driven presentations

Preferred Qualifications

· Maters degree of PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
· Ability to develop strategic, baselined, data modeling processes; ability to accurately determine cause-and-effect relationships.
· Publications or presentations in recognized ML journals or conferences
· Deep technical skills, consulting experience, and business savvy to interface with all levels and disciplines within our customers organization
· Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.",3.9,"Amazon
3.9","Chicago, IL",10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD)
Wetlands Scientist,"$29K-$45K
(Glassdoor Est.)","Description

Burns & McDonnell's regional operation in Chicago is looking for a Wetlands Scientist to perform wetland assessments and delineations, vegetative studies, wetland mitigation monitoring, and soil sampling for large construction projects in a variety of locations. (This individual can sit in either the Downers Grove or downtown offices.) Burns & McDonnell is a 100% employee-owned firm ranked on FORTUNE's List of 100 Best Companies to Work For and voted as a Best Place to Work in numerous cities across the United States.

This position can sit in either the Downers Grove or downtown Chicago offices.

The Wetlands Scientist will work within our Environmental Services Global Practice and perform the following duties:

Assist in conducting wetland assessments and delineations with strict adherence to federal and state environmental regulations.
Assist in conducting and filing annual wetland mitigation monitoring and post construction compliance inspections.
Assist in conducting and filing field investigations such as habitat evaluations, endangered plant identification and surveys and soil sampling and classification.
Assist in researching and preparing environmental assessments and permitting documents.
Assist with compiling and analyzing field data to compose technical reports.
Assist with preparing and presenting results from field investigations to project managers.
Assist in gathering data and preparing applications for various regulatory approvals.
Assist with collecting and analyzing Geographic Information Systems (GIS) data and data recording using a Global Positioning System (GPS).
Ensure compliance with company and site safety policies.
Other duties as assigned.
Qualifications
Bachelor's degree in Biology, Environmental Science, Botany, Soil Science or a related field from an accredited program required. Minimum of a 3.0 GPA strongly preferred.
Minimum of 2 years of applicable professional experience conducting wetland assessments and delineations, conducting and filing wetland mitigation and post-construction inspections, analyzing GIS data, preparing environmental assessments and permitting documents, conducting field investigations and associated work is highly preferred.
Completion of a master's degree in a related field may be substituted for one year of experience.
Previous consulting experience is a plus.
Basic knowledge of wetlands and aquatic resources.
Basic knowledge of Section 404, 401 and Section 10 permitting requirements.
Basic knowledge of the regulatory agencies that govern wetland resources.
Basic knowledge of erosion control and site restoration practices.
Demonstrated proficiency operating GPS and GIS equipment and support software.
Ability to clearly communicate both verbal and written technical information.
Ability to work under pressure and meet tight deadlines.
Must be proficient in the use of computer software (i.e., Microsoft Word, Excel, PowerPoint).
Valid driver's license required. In addition, must meet standards to qualify for and maintain the Company's vehicle driving privileges as outlined in the Company's Motor Vehicle Safety Policy
EEO/Minorities/Females/Disabled/Veterans

Job Environmental

Primary Location US-IL-Downers Grove

Other Locations US-IL-Chicago

Travel: Yes, 50 % of the Time

Req ID: 201051

#LI-JJ #ENS",3.8,"Burns & McDonnell
3.8","Chicago, IL",5001 to 10000 Employees,1898,Company - Private,Architectural & Engineering Services,Business Services,$2 to $5 billion (USD)
Sr Data Scientist (Strategy & Support) - ComEd,"$101K-$166K
(Glassdoor Est.)","Sr Data Scientist (Strategy & Support) - ComEd - (226627)
Description


At Exelon, we've got a place for you!

Join the nation's leading competitive energy provider, with one of the largest electricity generation portfolios and retail customer bases in the country. You will be part of a family of companies that strives for the highest standards of power generation, competitive energy sales, and energy delivery. Our team of outstanding professionals is focused on performance, thought leadership, innovation, and the power of ideas that come from a diverse and inclusive workforce.

Exelon will provide you the tools and resources you need to design, build and enhance a successful career. We are also dedicated to motivating the success of our employees through competitive base salary, incentives, and health and retirement benefits.

Join Exelon and share your passion at a forward-thinking Fortune 100 company. Establish yourself in a place where you can truly shine and create a brighter, more sustainable tomorrow. Energize your career at Exelon!

PRIMARY PURPOSE OF POSITION
Apply the scientific method to extract knowledge and insights from data, which may take the form of time-series (smart-meters, smart-grid, and other IoT), structured (relational data stores), and unstructured (text and multi-media) data sets.

Closely collaborate with various internal stakeholders, information architects, data engineers, project/program managers, and other teams to turn data into critical information to inform decision making. This requires understanding business needs, providing and receiving regular feedback, and planning the proper transfer of developed solutions. Mine big and small data for insights, using advanced statistic and machine learning methods. Validate findings with the business by sharing analysis outputs in a way that can be understood by business stakeholders.

Become a subject matter expert in the areas of artificial intelligence, machine learning, feature engineering, data mining, and data manipulation/storage. Demonstrate commitment to continuous learning and professional development in technical subject matter. Share knowledge with team members, and business stakeholders, and IT partners.

Collect, cleanse, standardize and analyze data from a variety of internal and external sources. Produce novel insights to help inform business actions using statistical modeling and machine learning techniques on complex data-sets on the order of several terabytes or petabytes.

Position may be required to work extended hours, including 24 x 7 coverage during storms or other energy delivery emergencies.

PRIMARY DUTIES AND ACCOUNTABILITIES
Develop key predictive models that lead to delivering a premier customer experience, operating performance improvement, and increased safety best practices. Develop and recommend data sampling techniques, data collections, and data cleaning specifications and approaches. Apply missing data treatments as needed.
Analyze data using advanced analytics techniques in support of process improvement efforts using modern analytics frameworks, including – but not limited to – Python, R, Scala, or equivalent; Spark, Hadoop file system and others
Access and analyze data sourced from various Company systems of record. Support the development of strategic business, marketing, and program implementation plans.
Access and enrich data warehouses across multiple Company departments. Build, modify, monitor and maintain high-performance computing systems.
Provide expert data and analytics support to multiple business units
Works with stakeholders and subject matter experts to understand business needs, goals and objectives. Work closely with business, engineering, and technology teams to develop solution to data-intensive business problems and translates them into data science projects. Collaborate with other analytic teams across Exelon on big data analytics techniques and tools to improve analytical capabilities.

Qualifications
MINIMUM QUALIFICATIONS
Education: Bachelor’s degree in a Quantitative discipline. Ex: Applied Mathematics, Computer Science, Finance, Operations Research, Physics, Statistics, or related field
Experience: Between 5-8 years of relevant experience developing hypotheses, applying machine learning algorithms, validating results to analyze multi-terabyte datasets and extracting actionable insights is required. Previous research or professional experience applying advanced analytic techniques to large, complex datasets.
Analytical Abilities: Strong knowledge in at least two of the following areas: machine learning, artificial intelligence, statistical modeling, data mining, information retrieval, or data visualization.
Technical Knowledge: Proven experience in developing and deploying predictive analytics projects using one or more leading languages (Python, R, Scala, etc.). Experience working within an open source environment and Unix-based OS.
Communication Skills: Ability to translate data analysis and findings into coherent conclusions and actionable recommendations to business partners, practice leaders, and executives. Strong oral and written communication skills.
PREFERRED QUALIFICATIONS
Education: Masters, or PhD in a Quantitative discipline. Ex: Applied Mathematics, Computer Science, Finance, Ops Research, Physics, Statistics, or related field
Experience: Prior exposure to data structures pertaining to smart-meters, billing, or outage management systems. Prior exposure to the utilities or broader energy sector. Prior exposure to the full spectrum of data science lifecycle, including data acquisition, maintenance, processing, analysis, and communication.
Analytic Abilities: Solid understanding of relevant theories in machine learning, statistics, probability theory, data structures and algorithms, optimization, etc.
Technical Knowledge: Expert level coding skills (Python, R, Scala, SQL, etc), and experience developing in a Unix environment. Proficiency in database management and large datasets: create, edit, update, join, append and query data from columnar and big data platforms.
Communication Skills: Ability to translate executive and analytics leaders’ vision and guidance into methods and analytics. Strong time management and presentation skills.
POSITION SCOPE
Support business unit strategic planning while providing a strategic view on machine learning technologies.
Advice and counsel key stakeholders on machine learning findings and recommend courses of action that redirect resources to improve operational performance or assist with overall emerging business issues.
Provide key stakeholders with machine learning analyses that best positions the company going forward.
Educate key stakeholders on the organizations advance analytics capabilities through internal presentations, training workshops, and publications.
Exelon is proud to be an equal opportunity employer and employees or applicants will receive consideration for employment without regard to: age, color, disability, gender, national origin, race, religion, sexual orientation, gender identity, protected veteran status, or any other classification protected by federal, state, or local law.

VEVRAA Federal Contractor

EEO is the Law Poster
Primary Location
: US-IL-OAK BROOK
Work Locations
:
ComEd Commercial Center
1919 SWIFT DR # 622
OAK BROOK 60523
Job
: Customer Service
Organization
: ComEd
Schedule
: Full-time
Employee Status
: Regular
Job Posting
: Sep 4, 2020, 12:30:20 PM
Unposting Date
: Ongoing",3.9,"Exelon
3.9","Oak Brook, IL",10000+ Employees,2000,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$10+ billion (USD)
Statistician / Data Scientist - Validate Health,-1,"Interested in being part of a small founding team, so you can see your direct impact on improving the healthcare industry? Want to be one of the rockstars building an innovative product from the ground up?

COMPANY

Validate Health is an early stage healthcare analytics company on a mission to improve accessibility to healthcare and industry transition to value based care. Validate was founded by a prominent healthcare actuary advising on matters of health economics policy and the entrepreneur-in-residence at the U.S. Department of Health & Human Services. Validate is building its analytics platform that encompasses the accumulated wisdom of its experts and clients, in order to empower medical organizations to manage their financial risk, while improving the clinical outcomes of their patients. We're looking for talented and driven contributors to join our team and be a part of this important moment in the healthcare industry.

JOB DESCRIPTION

As a Junior Statistician / Actuary you would be at the forefront of enabling new value based healthcare models and deliver constantly evolving analytics services to the industry. You’ll have an excellent opportunity for professional growth in the fields of healthcare economics, quantitative analytics and related technologies.

▪ Perform in scenario modeling, forecasting and simulations on large datasets. Work on challenging problems in pricing, reserving and risk quantifications of commercial and government value based healthcare models.

▪ Learn and apply rules and regulation around government healthcare programs, like Medicare and Medicaid. Learn and apply models for commercial programs and contracts.

▪ Use modern programming languages (such as R, Python, SAS, SQL) to work with large datasets to automate regulatory, economic and actuarial modeling. Gather and analyze large medical claims, public health datasets and financial data.

▪ Participate in implementation, maintenance and analysis of models, forecasts, studies and systems which use actuarial principles for the purposes of pricing, underwriting, statistics, reserving and forecasting.

▪ Develop written and oral presentations that provide basic information for decision making. Participate in defining features and capabilities of analytical products.

▪ Continuously learn by experimenting with statistical models and investigating scalable data science technologies.

Requirements

REQUIREMENTS

The ideal candidate would have:

▪ BS or MS in Statistics from a top 20 university statistics program.

▪ History of exceptional academic accomplishments or a portfolio of projects in statistics and relevant technologies.

▪ Desire to be an expert in healthcare economics and passionate about making an impact in this field.

▪ Must be willing to try a fun ""challenge"" early in the interview process to help us understand your level of proficiency. We give you a handful of the problems like those we enjoy solving every day. It may cover statistics, actuarial topics (if relevant) and related technologies (such as Python, R and SQL).

PREFERENCE given to candidates who are:

▪ Interested in pursuing actuarial accreditation.

▪ Located in Chicago or eventually interested in relocating to Chicago. But not a requirement for the right candidate.

TO APPLY

(Currently accepting only alumni and upcoming Spring 2020 graduates.)

Send in your latest resume to careers+1871@ValidateHealth.com. Write a note explaining what makes you particularly interested in Validate and this position specifically. Feel free to include any links that you feel speak to who you are and your capabilities, such as to LinkedIn, GitHub, publications, blog or portfolio. Specify when you’re available to start work and any visa sponsorship requirements. Indicate that you’re willing to take an aptitude test. Add “Statistician/Actuary via 1871” to the subject line.

Benefits

Fun team environment and gratifying work. Remote work friendly and no travel. Stock options.",-1,1871 Member Companies,"Chicago, IL",-1,-1,-1,-1,-1,-1
Sr Data Scientist (Strategy & Support) - ComEd,"$101K-$166K
(Glassdoor Est.)","Sr Data Scientist (Strategy & Support) - ComEd - (226627)
Description


At Exelon, we've got a place for you!

Join the nation's leading competitive energy provider, with one of the largest electricity generation portfolios and retail customer bases in the country. You will be part of a family of companies that strives for the highest standards of power generation, competitive energy sales, and energy delivery. Our team of outstanding professionals is focused on performance, thought leadership, innovation, and the power of ideas that come from a diverse and inclusive workforce.

Exelon will provide you the tools and resources you need to design, build and enhance a successful career. We are also dedicated to motivating the success of our employees through competitive base salary, incentives, and health and retirement benefits.

Join Exelon and share your passion at a forward-thinking Fortune 100 company. Establish yourself in a place where you can truly shine and create a brighter, more sustainable tomorrow. Energize your career at Exelon!

PRIMARY PURPOSE OF POSITION
Apply the scientific method to extract knowledge and insights from data, which may take the form of time-series (smart-meters, smart-grid, and other IoT), structured (relational data stores), and unstructured (text and multi-media) data sets.

Closely collaborate with various internal stakeholders, information architects, data engineers, project/program managers, and other teams to turn data into critical information to inform decision making. This requires understanding business needs, providing and receiving regular feedback, and planning the proper transfer of developed solutions. Mine big and small data for insights, using advanced statistic and machine learning methods. Validate findings with the business by sharing analysis outputs in a way that can be understood by business stakeholders.

Become a subject matter expert in the areas of artificial intelligence, machine learning, feature engineering, data mining, and data manipulation/storage. Demonstrate commitment to continuous learning and professional development in technical subject matter. Share knowledge with team members, and business stakeholders, and IT partners.

Collect, cleanse, standardize and analyze data from a variety of internal and external sources. Produce novel insights to help inform business actions using statistical modeling and machine learning techniques on complex data-sets on the order of several terabytes or petabytes.

Position may be required to work extended hours, including 24 x 7 coverage during storms or other energy delivery emergencies.

PRIMARY DUTIES AND ACCOUNTABILITIES
Develop key predictive models that lead to delivering a premier customer experience, operating performance improvement, and increased safety best practices. Develop and recommend data sampling techniques, data collections, and data cleaning specifications and approaches. Apply missing data treatments as needed.
Analyze data using advanced analytics techniques in support of process improvement efforts using modern analytics frameworks, including – but not limited to – Python, R, Scala, or equivalent; Spark, Hadoop file system and others
Access and analyze data sourced from various Company systems of record. Support the development of strategic business, marketing, and program implementation plans.
Access and enrich data warehouses across multiple Company departments. Build, modify, monitor and maintain high-performance computing systems.
Provide expert data and analytics support to multiple business units
Works with stakeholders and subject matter experts to understand business needs, goals and objectives. Work closely with business, engineering, and technology teams to develop solution to data-intensive business problems and translates them into data science projects. Collaborate with other analytic teams across Exelon on big data analytics techniques and tools to improve analytical capabilities.

Qualifications
MINIMUM QUALIFICATIONS
Education: Bachelor’s degree in a Quantitative discipline. Ex: Applied Mathematics, Computer Science, Finance, Operations Research, Physics, Statistics, or related field
Experience: Between 5-8 years of relevant experience developing hypotheses, applying machine learning algorithms, validating results to analyze multi-terabyte datasets and extracting actionable insights is required. Previous research or professional experience applying advanced analytic techniques to large, complex datasets.
Analytical Abilities: Strong knowledge in at least two of the following areas: machine learning, artificial intelligence, statistical modeling, data mining, information retrieval, or data visualization.
Technical Knowledge: Proven experience in developing and deploying predictive analytics projects using one or more leading languages (Python, R, Scala, etc.). Experience working within an open source environment and Unix-based OS.
Communication Skills: Ability to translate data analysis and findings into coherent conclusions and actionable recommendations to business partners, practice leaders, and executives. Strong oral and written communication skills.
PREFERRED QUALIFICATIONS
Education: Masters, or PhD in a Quantitative discipline. Ex: Applied Mathematics, Computer Science, Finance, Ops Research, Physics, Statistics, or related field
Experience: Prior exposure to data structures pertaining to smart-meters, billing, or outage management systems. Prior exposure to the utilities or broader energy sector. Prior exposure to the full spectrum of data science lifecycle, including data acquisition, maintenance, processing, analysis, and communication.
Analytic Abilities: Solid understanding of relevant theories in machine learning, statistics, probability theory, data structures and algorithms, optimization, etc.
Technical Knowledge: Expert level coding skills (Python, R, Scala, SQL, etc), and experience developing in a Unix environment. Proficiency in database management and large datasets: create, edit, update, join, append and query data from columnar and big data platforms.
Communication Skills: Ability to translate executive and analytics leaders’ vision and guidance into methods and analytics. Strong time management and presentation skills.
POSITION SCOPE
Support business unit strategic planning while providing a strategic view on machine learning technologies.
Advice and counsel key stakeholders on machine learning findings and recommend courses of action that redirect resources to improve operational performance or assist with overall emerging business issues.
Provide key stakeholders with machine learning analyses that best positions the company going forward.
Educate key stakeholders on the organizations advance analytics capabilities through internal presentations, training workshops, and publications.
Exelon is proud to be an equal opportunity employer and employees or applicants will receive consideration for employment without regard to: age, color, disability, gender, national origin, race, religion, sexual orientation, gender identity, protected veteran status, or any other classification protected by federal, state, or local law.

VEVRAA Federal Contractor

EEO is the Law Poster
Primary Location
: US-IL-OAK BROOK
Work Locations
:
ComEd Commercial Center
1919 SWIFT DR # 622
OAK BROOK 60523
Job
: Customer Service
Organization
: ComEd
Schedule
: Full-time
Employee Status
: Regular
Job Posting
: Sep 4, 2020, 12:30:20 PM
Unposting Date
: Ongoing",3.9,"Exelon
3.9","Oak Brook, IL",10000+ Employees,2000,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$10+ billion (USD)
Data Scientist,-1,"Data Scientist Opportunity in Chicago, IL!
W-2 Contract-to-Hire/Temp-to-Perm Position
$55/hour MAX
ACTIVE SECRET CLEARANCE REQUIRED

USPRO has partnered with our client in their search for a Data Scientist with an active secret clearance. This position will be remote to start, but will eventually transition to an office position in Chicago.

Overview:
Leverage your “science first” mentality, curiosity, deep technical expertise, and problem-solving skills to explore, discover, and predict patterns and insights within complex data sets.
This includes enabling government to capitalize on the value proposition of advanced analytics, and the derivation of clear narratives that help our clients understand their data and how those insights address their research questions.
Responsibilities:
Use analytical and statistical tools to evaluate data and aid in decision making.
Manipulate / create social media analytics and data to strengthen marketing campaign effectiveness
Manipulate common data formats, including comma-delimited, text files, and JSON.
Transform data and analysis into informative visualizations and interactive dashboards using open-source and commercially available tools.
Work with clients to prioritize research and modeling initiatives
Derive insights and analytic narratives from data and visualizations for effective storytelling and clear communication in response to client research questions.
Support the development of a mature analytics function informed by industry best practices
Work in a fast-paced, solutions-oriented, and collaborative environment focused on client deliverables, analysis, and reporting

Qualifications:
Degree (Master’s required) in science, technology, engineering, mathematics, computer science, economics, or other related business or technical discipline is required
Extensive experience in social media analytics and marketing campaign effectiveness.
Experience in Salesforce, Sprinklr, and Adobe Analytics - marketing analytics background
Experience working with tools, including object-oriented programming (Python, Java), computational analysis tools (R, MATLAB), and associated data science libraries (scikit-learn)
Significant experience in the AI/ML lifecycle, from ideation and solution concept development, to rapid prototyping and validation in operational environments, and importantly, in the sustainment of AI/ML solutions for CI/CD.
Significant experience and knowledge of best practices in the practical application and execution of AI/ML in operational environments.
Ability to frame and scale data problems to analyze, visualize, and find data solutions, and translate customer qualitative requirements into quantitative and technical approaches
Experience creating meaningful data visualizations and interactive dashboards using platforms such as Tableau, Qlik, Power BI, RShiny, plotly, and d3.js to communicate findings and relate them back to how your insights create business impact
Working knowledge of databases and SQL; preferred qualifications include linking analytic and data visualization products to database connections
At least 5+ years of experience in the field
DoD Secret clearance required
Superior communication skills, both oral and written
Preferred experience in the following areas:
DoD experience is preferred, in particular with human capital data and workforce analytics.
Data science methods related to data architecture, data munging, data and feature engineering, and predictive analytics
Knowledge of AI/ML SaaS platforms (e.g., DataRobot, H2O DriverlessAI)
Unstructured text and natural language processingo Computational tools such as R, Python, SAS, SQL, and MATLABo Anaconda, IBM Blue, and Oracle Big Data to analyze large data sets and develop automated analytics in making sense of data affecting DoD operations
Developing machine learning, data mining, statistical network, natural language processing, text analytics, and graph-based algorithms to analyze massive data setso Supervising algorithm implementation in on-premise and cloud-based computing environments
Developing software to generate reports and visualizations that summarize data sets and provide data-driven insights
Developing and implementing statistical, machine learning, and heuristic techniques to create descriptive, predictive, and prescriptive analytics as well as to develop statistical tests to make data-driven recommendations and decisions",3.8,"USPRO
3.8","Chicago, IL",201 to 500 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
"ADAS Data Scientist(Relocation to Phoenix, AZ)","$91K-$152K
(Glassdoor Est.)","Description

The ADAS team is currently seeking a data scientist to play a critical role in enabling Nikola vehicles with the most high tech ADAS and Autonomous features.

Come work in a field where the technology is changing daily, but will also forever change the world as we know it. Come get to know a team who are daily learning, discovering, and developing the technology that everyone will know by name in 5-7 years from now.

Our ideal candidate will learn quickly, be passionate about automated vehicle technology, and strive for perfecting the safest and most advanced vehicle on the market.

What you’ll be building:
Design a data processing pipeline for vehicle data and machine learning.
Develop stunning visualization for users to quickly understand the problems and metrics.
Custom data analysis tasks from truck and field data.
Be able to take your data and insights gained, to develop stories to bring the data to life.
What you “must” already bring to the table:
At least a 4-year career as a data scientist professional, in a start-up, rapid growing or fast paced environment.
BS, MS preferred, in CS, Machine Learning, Statistics, Math, Ops Research or related discipline.
Strong programming proficiency in: Python, C++ Scala, Spark, Jupyter, Zephyr.
Database knowledge of: Postgres, SQL, mongoDB, etc.
Experience with Cloud platforms (AWS, Kubernetes, Docker, etc.)
Complimentary skills:
Automotive or a related industry
Functional Safety, ISO26262
C programming
This position is not eligible for CPT or OPT.",4.7,"Nikola Motor Company
4.7","Chicago, IL",201 to 500 Employees,2014,Company - Public,Transportation Equipment Manufacturing,Manufacturing,Less than $1 million (USD)
Senior Data Scientist,"$63K-$111K
(Glassdoor Est.)","Who We Are:

We reward shoppers for digitizing their shopping experience.
Our mission is to delight the world's shoppers with a free smartphone app that is easy, smart and fun.

Why Join the Fetch Family?

We make it better for users even when that's difficult for us
We empower people with information and trust
We challenge ideas, not people
We think bigger and keep building
We find ways to bring the fun to Fetch!

We're committed to building an empowered and inclusive community of innovative and passionate people. As a growing organization, we need team players who can go above and beyond their individual responsibilities to help our company build towards its vision. If you are a creative, hard-working, and fun-seeking person interested in working with a close-knit group of highly talented people, this is the right place for you.

Fetch Rewards is an equal employment opportunity employer.

The Role!

The Data Science & Analytics team embodies these values and works with a laser focused objective to enable data driven decision making for both internal stakeholders and external partners. We are looking for a Senior Data Scientist to contribute to this vision and reap the rewards of joining an exciting company in the high growth phase.

You will create analytical solutions and machine learning models that help Fetch teams leverage and monetize actionable insights from our unique data. This is a challenging and high visibility position, responsible for creating these solutions as well as guiding technical direction. Success in this role requires the ability to take on challenging problems and design & develop an amazing solution with little to no assistance.

You possess:
Entrepreneurial and big-picture bend of mind for applications of machine learning in a consumer tech world like ours
Hands-on experience in developing / deploying machine learning models that are tied to business value
Ability to create SQL/Python programming modules for custom insights required by our clients. Leverage statistical analysis to understand what is ""acceptable"" versus ""outliers"".
Ability to successfully collaborate with both business users and engineers for effective analytical solution development and deployment
Passion to drive actionable insights from data and present them to external and internal clients through Tableau / Powerpoint / Excel in a compelling manner.
Knack for conducting the apt Data Exploration needed to enhance the cleanliness and effectiveness of our data sources.
Discipline to create well documented coding and analytics packets to ensure reusability as the team expands.
Master's or PhD in Statistics, Mathematics, Computer Science or any other Quantitative field
5+ years of work experience in data science
Bonus points for:
Experience in CPG/Retail domain and/or analytics at app-based B2C companies
Familiarity with Big Data frameworks like Snowflake, Spark and AWS services
Familiarity with Tableau or any other visualization tools
Effective communication, ability to translate and explain technical issues to non-technical team members
Love of Dogs! . . . Or just tolerance. We're a very canine-friendly workplace",4.9,"Fetch Rewards
4.9","Chicago, IL",51 to 200 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable
"Data Scientist, Analytics Advisor","$86K-$141K
(Glassdoor Est.)","Job Description
If you are passionate about making a difference in the work you do, being recognized for your talent and expertise in solving complex and challenging analytical/data problems while contributing to the success of key strategic initiatives, consider growing your career with a Fortune 10 healthcare leader! You will be responsible for designing and leading implementation of analytic solutions, including predictive modeling and machine learning, data visualization and insight tools development, and data infrastructure improvements aimed at improving the clinical and cost outcomes of the patients CVS Health serves. You will collaborate with analytic partners and business partners from product, marketing, medical affairs, IT, data strategy to develop effective solutions for our partners. The essential roles and responsibilities of the role are:
Collaborating with key internal and external stakeholders to gather and analyze needs and requirements to design and implement robust analytic solutions to support the identified needs;
Developing and executing strategic plans to use advanced analytics in conjunction with patient and provider interventions to improve clinical and cost outcomes;
Leveraging pharmacy and medical claims data as well as identifying and utilizing other data sources (EMR, lab results, clinical data and notes, consumer purchasing data, digital engagement data, etc.) to provide actionable, relevant, and timely analytic insight;
Accessing, manipulating, analyzing, and visualizing data from large databases using a variety of tools and techniques, such SQL, Python, R, and/or Tableau;
Conducting analyses of the data, ranging from descriptive data exploration to advanced statistical modeling;
Assessing existing available data, identifying data gaps, and collaborating with the data strategy team, IT, business partners, and outside vendors to develop approaches to closing the data gaps;
Collaborating with business and analytic resources across multiple teams in a matrix organization to accomplish project goals;
Constructing persuasive presentations and gaining consensus among a diverse group of individuals;
Constructing and delivering written reports of the analytic findings in a variety of formats (reports, PPT, including visualization of data and findings), formulating recommendations, and effectively presenting the results to potential non-analytic audiences;
Communicating complex technical subjects to technical and non-technical audiences.
Required Qualifications
Problem solving skills and experience constructing analytic solutions to business problems;
Developing innovative analytic approaches leveraging available internal and external data sources;
Experience interacting with and influencing decision-making by business audiences;
Solid understanding and hands-on experience with a variety of analytic processes and techniques, including health economics outcomes research, experiment design, development of measurement methodologies, hypothesis testing, statistical significance testing, modeling, and machine learning;
Ability to quickly develop knowledge and understanding of new domains and underlying data sources;
Solid understanding and hands-on experience working with large data sources, particularly pharmacy or medical claims and clinical program data, focusing on efficient data extraction from large databases, data manipulation, and insight generation;
Solid understanding and hands-on experience with SQL, Python, R, Tableau and/or other data, statistical, and data visualization tools and techniques, and ability to investigate and adapt emerging analytic tools and solutions into the analytic standard operating procedures;
Understanding of the healthcare administration landscape and CVS Health business model, including patient and payer concerns, as well as the operational considerations in support of the business objectives;
Excellent written and oral communication skills, including conveying analytic concepts and findings to executive and non-technical audiences with the goal of obtaining feedback and defining next steps to make the analytic insights actionable.
Preferred Qualifications
Experience with campaign design and consumer market research, such as survey design, implementing large-scale campaigns, and performing A/B testing;
Experience applying behavioral economic concepts to drive behavior change;
Developing roadmaps, business cases, and project plans;
Managing projects and processes, including coordinating activates across diverse departments and ensuring that contributions across different teams are aligned and integrated as part of overall delivery;
Experience developing methodology to measure program and intervention outcomes;
Experience conducting data analysis in a healthcare setting;
Working knowledge of healthcare industry products/services and operations.
Education
Bachelors degree in qualitative field, such as statistics, biostatistics, analytics, epidemiology, public health, or economics. A graduate degree strongly preferred.

Business Overview
At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.",2.9,"CVS Health
2.9","Northbrook, IL",10000+ Employees,1963,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
Data Engineer,-1,"Summary

As a Data Engineer (Level II), you are familiar with the data warehousing technical components, infrastructure, and their integration. You'll analyze large amounts of data, discover and solve real world problems. You love the idea of being able to provide insight as well as presenting those insights. You are responsible for high level design/architecture. You are comfortable fostering relationships with internal business partners and other members of the development team.

Key Responsibilities
Design, develop, and maintain modular code base to solve real world problems.
Conduct regular peer code reviews to ensure code quality and compliance following best practices in the industry.
Work in cross-disciplinary teams to understand client needs and ingest rich data sources.
Research, experiment, and utilize leading Big Data technologies in AWS
Help drive the process for pursuing innovations, target solutions, and extendable platforms for ampliFI's products.
Participate in developing and presenting thought leadership and assist in ensuring that ampliFI's data source technology stack incorporates and is optimized for using specific technologies.
Required Skills and Experience
Qualified individuals possess the ampliFI attributes of being smart, curious, committed to vision, passionate, fun/pleasant, an achiever and having a sense of urgency
Minimum of three years of big data experience with multiple programming languages and technologies, three years as a lead / team manager.
Bachelor's degree or master's degree from an accredited college/university in Computer Science, Computer Engineering, or related field (i.e. math and physics);
Ability to manage established relationships internally as well as with clients.
Ability to communicate complex technical concepts succinctly to non-technical colleagues, understand & manage interdependencies between all facets of a project.
Ability to interface with clients; Must have demonstrated advanced proficiency in complex, mature and sophisticated Design & Analysis technologies and solutions.
Skilled ability to rapidly ingest, transform, engineer, and visualize data, both for ad hoc and product-level (e.g., automated) data & analytics solutions.
Experience with large-scale, AWS big data methods such as EC2, S3, EMR, Kinesis, DynamoDB, and Redshift.
Ability to work efficiently under Unix/Linux environment, having experience with source code management systems like GIT.
Strong knowledge with programming methodologies (version control, testing, QA) and agile development methodologies.
3-5 years' experience
Physical Requirements
Frequently required to sit and stand
Occasionally required to stoop, kneel and crouch
Required to use hands to handle or feel objects, tools or controls
Other Duties

Duties, responsibilities and activities are not all encompassing and may change at any time with or without notice. To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions

PI122947362",-1,ampliFI Loyalty Solutions,"Naperville, IL",-1,-1,-1,-1,-1,-1
Actuary/Data Scientist,"$66K-$112K
(Glassdoor Est.)","This position is located in the Railroad Retirement Board's Bureau of the Actuary and Research. The incumbent will be responsible for assisting in the activities of the financial interchange (FI) division, which is a multibillion dollar project mandated by the Railroad Retirement Act (RRA).

This job announcement may be used to fill one or more vacancies.See Basic Education Requirements above.As a Actuary/Data Scientist, you will:
Provide technical advice and assist in reviewing the accuracy of calculations for inclusion in the annual FI determinations as specified by law.
Independently plan and develop complex actuarial and statistical programs involving mainframe and personal computer applications.
As an expert subject matter analyst, work closely with the bureau's computer specialists and other staff in the development of computer programs for the processing of data.
Conduct individual research in the fields of social insurance, private insurance, and pensions, and makes comparisons between the railroad retirement program and similar programs for workers in other industries.
Compose a variety of technical publications, memoranda, etc., pertaining to aspects of the FI.
Prepare data processing requests for program changes, review documentation, prepare test data, and review test output.
Work with reviewers and auditors from the Social Security Administration (SSA), the Centers for Medicare and Medicaid Services (CMS), Government Accountability Office (GAO), and Office of the Inspector General (OIG) to coordinate case reviews and audit issues.
Utilize SAS, R, and Microsoft Office software packages to accomplish a variety of work assignments.
This work requires a professional actuary or data scientist.
In order to qualify, you must meet the education and experience requirements described below:

Basic Education Requirements for Series 1510 (Actuary):

A. A bachelor's degree that included courses in actuarial science, mathematics, relevant statistics, business, finance, economics, insurance, or computer science totaling at least 24 semester hours. This course work must have included a minimum of 12 semester hours of mathematics that included differential and integral calculus and one or more courses in mathematics for which these calculus courses were prerequisites.

OR

B. A combination of education and experience that includes both of the following requirements:
Technical work experience in actuarial support work or in mathematics; and
Completion of a minimum of 24 semester hours of courses in actuarial science, mathematics, relevant statistics, business, finance, economics, insurance, or computer science at a four year college or university. This course work must have included a minimum of 12 semester hours of mathematics that included differential and integral calculus and one or more courses in mathematics for which these calculus courses were prerequisites.
Basic Education Requirements for Series 1530 (Statistician):

A. Successful completion of a full 4-year course of study in an accredited college or university leading to a bachelor's or higher degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing.

OR

B. Combination of education and experience -- courses as shown in A above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.

In addition to the Basic Requirements listed above, applicants must also have the following specialized experience:

At the GS-14 level for both series, applicants must have one year of specialized experience at or equivalent to at least the GS-13 grade level in the Federal service.

Specialized experience is defined as experience performing a wide range of professional actuarial and/or statistical functions which included applying actuarial and/or statistical principles and techniques in the analysis, evaluation, and projection of data with an emphasis on complex retirement and pension plans or other similar employee benefit programs.

You MUST provide transcripts or other documentation to support your educational claims.Official or unofficial transcripts are acceptable. All materials must be submitted by the closing date of the announcement. Official transcripts will be required if selected.

Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional, philanthropic, religious, spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.

Only experience obtained by the closing date of this announcement will be considered.",3.4,"Railroad Retirement Board
3.4","Chicago, IL",501 to 1000 Employees,-1,Government,Federal Agencies,Government,Less than $1 million (USD)
Data Engineer,-1,"Data Engineering is the foundational layer of our Data & Analytics stack at Arrive. Data Engineers build, maintain and optimize the entire infrastructure of the data team that powers decision making across the organization. They empower our Business Analysts with raw data, tools and expertise to serve the business in an efficient and scalable manner.

We’re looking for a Data Engineer to help us grow and maintain our data infrastructure and platform. If you're seeking a role that is high impact and full of ownership....please read on.

Please note...we are fully open to remote candidates for this position! Being in Chicago would be great, but isn't necessary.
What you'll tackle
Accountable for daily completion, accuracy and performance monitoring of all ETL and data warehousing tasks
Develop new ETL processes to ingest source data from our on-line transactional systems as well was 3rd party services
Maintain our CI/CD pipeline to ensure Business Analysts can build, test, deploy and iterate quickly
Maintain infrastructure in AWS and other 3rd party service to support all data team operations and company business intelligence as a whole
Manage and optimize Redshift clusters/data lake to ensure current health and performance and future scaling needs
Detect quality issues, track them to their root source, implement fixes and preventative audits
Become the “go to” expert of our data. Work closely with staff to understand all data from our core systems, partner services, and any other platforms we rely on
What you bring to the table
Experience with AWS; expertise in Redshift, Postgres or other RDBSs (preferably column-oriented)
Proficiency in SQL and ability to write and optimize complex queries
Experience with Docker, Elastic Container Service, Lambda a plus
DevOps and Linux systems administration fundamentals
Ability to write customized software in Python, Bash, Go or other common open source languages.
Experience with Airflow or similar scheduling service a plus
Experience with CI/CD tools like Jenkins or Drone
Creativity in approaching data organization challenges with an understanding of the end goal
A collaborative nature and entrepreneurial spirit. Prior startup experience a huge plus
A sense of ownership and accountability for your work and the success of the team",-1,Arrive,"Chicago, IL",Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD)
Product Development Scientist - Covid 19,"$55K-$89K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

Tempus Insights is our business to develop, validate and launch new predictive tests, in oncology and new disease areas, by leveraging our clinical + molecular + imaging data to provide novel insights to clinicians and patients.

We are seeking a highly motivated and capable product development scientist with extensive experience and interest in genomics algorithm development and algorithm validation in clinically regulated environments. This position requires experience with dry lab assay validation, analysis of genomic data, algorithm development and evaluation, and statistical modeling. Top candidates will also have experience deploying and operating bioinformatics algorithms within a clinical setting.

Duties and Responsibilities:
Validate and implement predictive algorithms which leverage molecular, clinical and imaging data inputs to generate novel insights.
Conduct thorough dry lab assay validations to ensure that our novel algorithms are performing as expected in a clinical setting
Collaborate with clinicians and scientists to design and perform analyses on cancer clinical sequencing data in order to improve quality of care.
Produce high quality and detailed documentation for all projects.
Develop and implement rigorous testing and validation infrastructure to support the use of predictive algorithms in clinical care.
Required Experience:
Advanced degree in Bioinformatics, Cancer Biology, Molecular Biology, Bioengineering, Biochemistry or a related field (PhD preferred)
Deep understanding of CLIA/CAP validation protocols
Experience with statistical analysis of next-generation sequencing data
Ideal candidates will possess:
Self-driven and works well in interdisciplinary teams
Experience with communicating insights and presenting concepts to a diverse audience
Demonstrated programming ability
Background in predictive or prognostic algorithm development
Strong background in the development of statistical models",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Data Scientist II,"$74K-$125K
(Glassdoor Est.)","Conagra Brands has the most energized, highest-impact culture in food. Our people persistently challenge and disrupt marketplace/business conventions and we are respected for our great brands, great food, great margins and consistent results. Conagra Brands, be part of building something BIG.

Position Summary:

Reporting to the Director, Data Science, this person will be helping Conagra’s Demand Science team influence decisions with rigorous data analysis that drive results. The Data Science team supports Brand, Marketing, Innovation, and R&D and works closely with the Brand and Go-To-Market Insights teams to achieve the company’s growth objectives. The Data Scientist II will work on a variety of high-visibility projects and will have the opportunity to apply advanced analytics, data modeling and machine learning concepts to create recommendations and solutions to solve business challenges.

Position Qualifications:
Experience producing high quality, well-regarded insights & analytics work
A higher degree in statistics, econometrics, machine-learning, physics, chemistry, applied mathematics or other related quantitative field is preferred
Masters with 1+ years or Bachlors with 4+ years experience
Strong coding skills, preferable python or other similar language
Experience with relational databases / SQL
Understanding AWS S3, HDFS, Hbase, or other non-relational DB
Experience in working with un-cleaned data
Modeling skills required, from machine learning to more ad-hoc methods
Experience in Time Series and Forecasting
Have worked full problem solutions, from research definition from a business need, through data handling, modeling and result interpretation.
Abilty to work both in a group, and unsupervised individually
Proven track record of delivering actionable business recommendations, influencing decisions, and impacting results
Strong priority management skills so to ensure analytical resources are leveraged and applied to the most important business issues.
Hands on experience with large scale data processing software and tools (Hadoop, Spark, MapReduce etc.) preferred
Proven strong oral and written communication skills, especially the ability to explain difficult concepts in simple, applicable business terms
Position Responsibilities:
Analyze large volumes of data and create advanced algorithms to generate insights and improve business operations
Establish himself/herself as a key advisor with Brand Directors and Manager, Sales and Customer Development team members and the Marketing team
Must be able to translate advanced analytics into top and bottom line business impact.
Partner with Brand and Shopper Insights to identify and define business issues requiring data science solutions and then scoping the resources needed to address them
Communicate technical needs to technology partners as well as clearly and concisely presenting findings and recommendations in a non-technical way to business leaders in multiple functions.
Provide strategic advice to brands and customers derived from a strong analytical rigor and maintain focus on improving the effectiveness of our investments and resources
Continuously deliver high quality analytics, algorithms and models with a focus on driving results
#LI-AB1

SF-G

Conagra Brands is an equal opportunity employer and considers qualified applicants for employment without regard to sex, race, color, religion, ethnic or national origin, gender, sexual orientation, gender identity or expression, age, pregnancy, leave status, disability, veteran status, genetic information and/or any other characteristic or status protected by national, federal, state or local law.",3.5,"Conagra Brands
3.5","Chicago, IL",10000+ Employees,1919,Company - Public,Food & Beverage Manufacturing,Manufacturing,$10 to $25 million (USD)
Data Engineer,"$81K-$100K
(Glassdoor Est.)","Job Description

Data Engineer

At Citadel, data is the core of the investment process. Data Engineers architect and build our data platforms which drive how we source, enrich, and store data that integrates into the investment process. These Data Engineers own the entire data pipeline starting with how we ingest data from the outside world, transforming that information into actionable insights, and ultimately designing the interfaces and APIs that our investment professionals and quantitative researchers use to monetize ideas. Throughout the process, our Data Engineers partner with top investment professionals and data scientists to design systems that solve our most critical problems and answer the most challenging questions in finance.

YOUR OPPORTUNITY:

Develop solutions that enable investment professionals to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, sensor collection), transformations (Spark, SQL, Kafka, Python/C++/Java), and interface (API, schema design, events)
Partner with the industry’s top investment professionals, quantitative researchers, and data scientists to design, develop, and deploy solutions that answer fundamental questions about financial markets
Build tools and automation capabilities for data pipelines that improve the efficiency, quality and resiliency of our data platform
Drive the evolution of our data strategy by challenging the status quo and identifying opportunities to enhance our platform
YOUR SKILLS & TALENTS:

Passion for working with data in order to accurately model and analyze complex systems such as a publicly traded company, commodity market, economy, or financial instruments
Strong interest in financial markets and a desire to work directly with investment professionals
Proficiency with one or more programming languages such as Java or C++ or Python
Proficiency with RDBMS, NoSQL, distributed compute platforms such as Spark, Dask or Hadoop
Experience with any of the following systems: Apache Airflow, AWS/GCE/Azure, Jupyter, Kafka, Docker, Kubernetes, or Snowflake
Strong written and verbal communications skills
Bachelor’s, Master’s or PhD degree in Computer Science or equivalent experience
About Citadel


Citadel is a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For a quarter of a century, Citadel’s hedge funds have delivered meaningful and measurable results to top-tier investors around the world, including sovereign wealth funds, public institutions, corporate pensions, endowments and foundations.

With an unparalleled ability to identify and execute on great ideas, Citadel’s team of more than 675 investment professionals, operating from offices including Chicago, New York, San Francisco, London, Hong Kong and Shanghai, deploy capital across all major asset classes, in all major financial markets.",3.9,"Citadel
3.9","Chicago, IL",1001 to 5000 Employees,1990,Company - Private,-1,-1,$50 to $100 million (USD)
Chief Data Scientist,-1,"Uptake is a Chicago-based predictive analytics SaaS platform provider that empowers major industry leaders to optimize performance, reduce asset failures and enhance safety. At Uptake, we combine our strengths—machine learning, analytics, data visualization and software development—with the expertise of our industrial partners. The result is an enormous savings in development time and resources for Uptake’s partners and a proven industrial grade software platform that delivers value to partners and their end customers.

What you’ll do:


Uptake is built on Data Science. Data and actionable insights are at the very core of everything we are and that we aspire to be. Uptake’s Chief Data Scientist provides practice leadership to all Uptake Data Scientists and acts as an Uptake Brand Ambassador to the world. The Chief Data Scientist has a responsibility for the art and science of Data Science at Uptake.

Internal Focus: Define and shepherd the practice of data science at Uptake. Set the standards and approaches for applying data science. Attract and retain superstar data scientists. Coach and mentor data scientists. Develop and Maintain the platform and solution architecture in service of the simple, fast, and cost-effective realization of data science in the industrial world.

External Focus: Be the face of Uptake Data Science excellence to customers, industry practitioners, partners, analysts and investors. Through your clear, concise and cross channel communication, build the brand of Uptake to represent knowledge of industrial assets and tireless pursuit of continuously improving asset productivity, low-cost maintenance and availability.

Responsibilities:


As Chief Data Scientist, your responsibilities may include, but are not limited to, the following:
Ownership of Data Science tools, technologies and solution patterns built for scale, re-usability, and continuous improvement.
Ownership of vision for rapidly turning machine data into valuable insights on the Uptake Platform.
Act as the key stakeholder and driver of the end-to-end Uptake Platform architecture.
Lead the Data Science Practice at Uptake.
Publish best practices and standards of excellence.
Create the Uptake Data Science Career path and guide scientists along that path.
Mentor Data Scientists company-wide.
Challenge the status quo and continuously reinvent the application of data science with a strong bias towards simplification, re-usability, and network effects.
Publish select topics in industry journals and trade publications building the Uptake brand.
Participate in customer, investor, analyst and external facing meetings building the Uptake Brand (and helping close deals).
Convert customer data and industry data into strategic assets building Uptake enterprise value.
Qualifications:


PhD or Masters degree in Data Science or related field
11+ years of system building experience
6+ years of people management experience
A passion for new approaches to Data Science at scale.
A passion for solving customer problems and helping them win.
Experience building and deploying data science in a production environment.
A strong reputation as a Data Science thought leader.
Strong passion for technology and building great systems
Excellent communication skills
Agile methodology practitioner
Ability to work quickly and collaboratively in a fast-paced, entrepreneurial environment
Preferred skills:


We value these qualities, but they’re not required for this role:
Ph.D. in related field
Experience as an open-source contributor
Startup and/or Product Experience
Applicants must be authorized to work in the U.S.

Uptake welcomes and encourages applications from all individuals, without regard to any prohibited ground of discrimination, including from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.",2.2,"Uptake
2.2","Chicago, IL",501 to 1000 Employees,2014,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable
Data Engineer,"$68K-$128K
(Glassdoor Est.)","Interested in joining a collaborative team that provides modern Analytics and Cloud Solutions to business? You will work with our core Analytics team of Data Scientists, Business Intelligence Analysts, Data Engineers and Product Analysts to provide advanced analytics solutions that transform data into meaningful insights and help business with data-driven decisions.

Job Summary

We are looking for a Data Engineer who can provide support with Data Architecture, Data Integrations, ETL, and transition data workloads to the Cloud. You will collect, parses, manages, and analyzes large sets of data across different domains for analysis. You will design data pipelines (data ingestion and ETL processes) that are scalable, repeatable and secure for partner needs.

Responsibilities

Data Architecture and Data Management
Build data architecture to support data strategy
Provide guidance and share best practices on data architecture and design
Help create the data management strategies to support business intelligence efforts for different partners
Lead the design of the logical data model and implement the physical database structure
Constructs and implements operational data stores and data marts
Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and
other data consumers by identifying data problems and guiding issue resolution
Data Pipeline Management
Develop real-time and batch ETL data processes aligned with our needs (on-premise and in the Cloud)
Manage and expand the data pipeline from raw OLTP databases to data solution structures
Document data flow diagrams, security access, data quality and data availability across all business systems",4.3,"Federal Reserve Bank (FRB)
4.3","Chicago, IL",1001 to 5000 Employees,1913,Government,Federal Agencies,Government,Unknown / Non-Applicable
Cloud Data Engineer,"$53K-$100K
(Glassdoor Est.)","Who We Are!

At Maven Wave, we are relentless in hiring the industrys top talent. Each employee is hand-picked not only for their skills, but for their personality and broad expertise. We are looking for this rare combination of talent that sets us apart in the industry.

Maven Wave helps leading companies make the shift to digital and shorten the fuse to innovation. We combine the expertise of top-tier consulting with the agility of a cutting-edge technology firm. This multidisciplinary blend of skills allows us to create unique digital advantages for our clients. Maven Waves digital solutions are agile, mobile, rooted in analytics, and built in the cloud.


Maven Wave, Google, and YOU: Help us build data driven cloud solutions.

We are looking for a skilled Cloud Data Engineer to design, build, and test data ingestion and ETL programs with a strong focus on performance and data quality management.

Your Life As a Maven:
Build and implement complex data solutions in the cloud (AWS, GCP and/or Microsoft).
Uncover and recommend remediations for data quality anomalies.
Investigate, recommend and implement data ingestion and ETL performance improvements.
Document data ingestion and ETL program designs, present findings, conduct peer code reviews.
Develop and execute test plans to validate code.
Your Expertise:
4+ years experience building complex ETL programs with Informatica, DataStage, Spark, Dataflow, etc.
3+ years experience in Python and/or Java, developing complex SQL queries, and working with relational database technologies.
Experience configuring big data solutions in a cloud environment (AWS, Azure or GCP).
Experience using cloud storage and computing technologies such as BigQuery, RedShift, or Snowflake.
Experience developing complex technical and ETL programs within a Hadoop ecosystem.
Must have a bachelors degree in Computer Science, Technology, Computer Information Systems, Computer Applications, Engineering, or a related field.
Your X-Factor:
Aptitude - You have an innate capacity to transition from project to project without skipping a beat.
Communication - You have excellent written and verbal communication skills for coordination across projects and teams.
Impact - You are a critical thinker with an emphasis on creativity and innovation.
Passion - You have the drive to succeed paired with a continuous hunger to learn.
Leadership - You are trusted, empathetic, accountable, and empower others around you.
Why Were Proud To Be Mavens!
Google Cloud North America Services Partner of the Year 2019, 2018
#21 Best Workplaces in Chicago, FORTUNE, 2018
Great Place To Work Certification, Great Place to Work, 2017 & 2018
Fast Fifty, Crain's Chicago Business
101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR)
Top Google Cloud Partner, Clutch
Fastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine
Top IT Services Companies, Clutch
Google Global Rising Star Partner of the Year
Ready to Learn More?
Life as a Maven
Check out the Data Team
See what Glassdoor has to say
Real Customer Stories",4.4,"Maven Wave Partners
4.4","Chicago, IL",201 to 500 Employees,2008,Company - Private,Consulting,Business Services,$50 to $100 million (USD)
Computational Scientist-Secure Data,"$32K-$60K
(Glassdoor Est.)","Please make sure to read the job posting in its entirety as it reflects both the University roles and responsibilities, followed by the specific description.
Department
86755 Research Computing Center
About the Unit
The University of Chicago Research Computing Center (RCC), a unit in the Office of Research and National Laboratories (RNL), provides high-end research computing resources to researchers at the University of Chicago. It is dedicated to enabling research by providing access to centrally managed High Performance Computing (HPC), storage, and visualization resources. These resources include hardware, software, high-level scientific and technical user support, and the education and training required to help researchers make full use of modern HPC technology and local and national supercomputing resources. The Office of Research and National Laboratories oversees the conduct of sponsored research, research program development, multi-institutional research institutes, national laboratory board, and contract management functions. RNL supports the development and coordination of research-related communications and educational programs at The University of Chicago. RNL oversees the management of two Department of Energy contracts for Argonne National Laboratory and Fermi National Accelerator Laboratory. When combined with the Lab R&D budgets, the office oversees approximately $1.4 billion in sponsored research. RNL works closely with individual scholars, departments, and divisions to encourage, seed, and coalesce research across the University, Argonne, and Fermilab campuses.
Job Family
ResearchResponsible for all aspects of research projects and research facilities. Plans and conducts clinical and non-clinical research; facilitates and monitors daily activities of clinical trials or research projects. Directs engineering and technical support activities to develop and maintain tools and computational methods needed to gather and analyze data.
Career Track and Job Level
Research ComputingCreates research focused user interfaces web front-ends, back-end services that scale, and integrate scientific workflows that automate and accelerate the scientific output of multi-institutional collaborative projects. This role involves software development in support of research projects involving data acquisition, ingestion, and integration from heterogeneous sources (metadata extraction from a corpus of diverse data sets, both structured and unstructured data).P2: Requires knowledge and experience in own discipline; still acquiring higher-level knowledge and skills. Builds knowledge of the organization, processes and customers. Solves a range of straightforward problems. Analyzes possible solutions using standard procedures. Receives a moderate level of guidance and direction.
Role Impact
Individual Contributor
Responsibilities
The job develops software to support the data acquisition, ingestion, and integration for research projects. Assists in the development of user interfaces and scalable back-end services to automate and accelerate the scientific output of multi-institutional research projects.1) Participates in the product development life cycle, providing professional assistance to the design of front-end applications and database systems back-end schema. Analyzes high-level system specifications and makes sure that all application development standards are met., 2) Develops and presents technical training materials and web-based documentation. Ensures timely systems support and updates. Assists in conducting information security assessments and risk analysis of computing environment., 3) Evaluates past and present technologies to help develop new tools. Ensures all the new tools have been through quality control reviews., 4) With a moderate level of guidance, provides hardware, user and application level authentication and authorization. Implements modern web authentication methods such as XACML, SAML, OAuth2, Shibboleth, and LDAP directory server administration. Applies theoretical expertise and innovation to create or apply new technology, such as adapting principles for applying computers to new uses., 5) Performs other related work as needed.

Job Summary

The University of Chicago Research Computing Center (RCC), a unit in the Office of Research and National Laboratories, is seeking a motivated Computational Scientist-Secure Data to work closely with faculty and researchers at the University of Chicago. This position will serve as a multi-disciplinary technical expert in supporting and advising faculty on using sensitive high-end computing environments and related technologies for their research.

Unit-Specific Responsibilities

1) Engage the community of researchers using sensitive data at UChicago across application areas.
2) Work closely with faculty to identify, develop, and implement useful computational methods and resources that support or advance their research.
3) Assist faculty, researchers, and students with using resources and services available in the UChicago Secure Data Enclave (SDE) and through the UChicago Secure Research Data Strategy.
4) Serve as a central resource and point person for RCC’s secure computing environments; assist with onboarding new users.
5) Plan and deliver SDE training to faculty, staff, and other researchers.
6) Develop and maintain user guides, training materials, and other documentation.
7) Install, configure, and maintain software and tools.
8) Ensure proper process workflows are followed, recommend data protection best practices, and ensure requirements outlined in the standard operating procedures for working with sensitive research data are followed.
9) Evaluate new technologies and software products to determine feasibility and desirability of incorporating their capabilities within research projects.
10) Support and contribute to research grant proposal development.
11) Provide computational science advance technical support in your area of expertise.
12) Perform other duties as assigned.

Unit-Preferred Competencies
1) Excellent interpersonal, verbal, written, and presentation skills.
2) Understand and translate researchers’ scientific goals into computational requirements.
3) Identify and gain expertise in appropriate new technologies and/or software tools.
4) Function as part of an interactive team while demonstrating self-initiative to achieve project’s goals and Research Computing Center’s mission.
5) Strong analytical skills and problem-solving ability.
6) Work well with faculty and researchers.
7) Dedicated to meeting the expectations and requirements of faculty and researchers.

Education, Experience, and Certifications
Minimum requirements include a college or university degree in related field.Minimum requirements include knowledge and skills developed through 2-5 years of work experience in a related job discipline.

Preferred Qualifications

Education

1) PhD.

Experience

1) Work in a research related institution.

2) Experience in high-end computing environment.

Technical Skills

1) Expertise with at least two of the following: C/C++, Python, R, Matlab, Julia.

2) Compiling and building scientific applications.

3) Job schedulers such as SLURM or PBS and ability to write shell scripts.

4) Statistical and numerical methods.

5) Parallel programming.

6) Git and svn.

7) Knowledge of best practices.

8) Familiarity with data management considerations of sensitive data.

9) Knowledge of data security and privacy standards.

Required Documents

1) Cover letter

2) Resume

NOTE: When applying, all required documents MUST be uploaded under the Resume/CV section of the application.

FLSA Status
Exempt
Pay Frequency
Monthly
Pay Grade
Depends on Qualifications
Scheduled Weekly Hours
37.5
Benefits Eligible
Yes
Drug Test Required
No
Health Screen Required
No
Motor Vehicle Record Inquiry Required
No
Posting Date
2020-05-27-07:00
Remove from Posting On or Before
2020-11-27-08:00
Posting Statement


The University of Chicago is an Affirmative Action/Equal Opportunity/Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.

Staff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via Applicant Inquiry Form.

The University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: http://securityreport.uchicago.edu. Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637.",4.0,"University of Chicago
4.0","Chicago, IL",10000+ Employees,1890,College / University,Colleges & Universities,Education,$2 to $5 billion (USD)
Data Scientist-2,"$65K-$109K
(Glassdoor Est.)","Please make sure to read the job posting in its entirety as it reflects both the University roles and responsibilities, followed by the specific description.
Department
20139 Public Health Sciences
About the Unit
The Department of Public Health Sciences is the home for biostatistics, epidemiology and health services research at the University of Chicago. We study individual, collective, environmental and organizational factors that affect the health of human populations, as well as methods for carrying out such research. Department members draw on the disciplines of statistics, epidemiology, genetics, psychology, sociology, demography and economics in the study of health, health care and biomedical science from a population perspective. The Department provides a unique environment where cross-disciplinary research in these areas of inquiry can flourish. The Department has students and faculty in the disciplines of biostatistics, epidemiology, and health services research. In addition, the Department provides methodologic expertise to researchers in other departments through Biostatistics Laboratory. The Biostatistics Laboratory has 9 full-time biostatisticians, epidemiologists, and computer scientists. They have active collaborations with every clinical department in the Biological Sciences Division, as well as projects involving faculty members throughout the University. The Department's educational programs provide both professional and academic training. We offer two graduate degree programs, one leading to the Ph.D. degree, and the other to a Master of Science in Public Health Sciences for Clinical Professionals (MSCP). We also offer a certificate in clinical research methods in conjunction with the Institute for Translational Medicine. This at-will position is wholly or partially funded by extramural funds (e.g., grant, gift, endowment) which is renewed under provisions set by the grantor. Your employment will be contingent upon the continued receipt of these extramural funds and your satisfactory job performance. If this position is eliminated due to the discontinuation of extramural funding, you will be given a minimum of one pay period’s written notice (If exempt: 30 days, If non-exempt: 2 weeks), or pay in-lieu of notice.
Job Family
ResearchResponsible for all aspects of research projects and research facilities. Plans and conducts clinical and non-clinical research; facilitates and monitors daily activities of clinical trials or research projects. Directs engineering and technical support activities to develop and maintain tools and computational methods needed to gather and analyze data.
Career Track and Job Level
Data ScienceConducts data investigation, including data wrangling, cleaning, sampling, management, exploratory analysis, regression and classification, prediction, and data communication. Implements foundational concepts of data computation, such as data structure, algorithms, parallel computing, simulation, and analysis. Utilizes knowledge in game theory, statistical quality control, exponential smoothing, seasonally adjusted trend analysis, or data visualization to gain insights, develop new strategies, and cultivate actionable business intelligence in diverse career tracks across the University.P1: Performs routine assignments in the entry level to a professional job progression. Typically requires a college or university degree or the equivalent work experience that provides knowledge and exposure to fundamental theories, principles and concepts. Develops competence by performing structured work assignments. Uses existing procedures to solve routine or standard problems. Receives instruction, guidance and direction from others.
Role Impact
Individual Contributor
Responsibilities
Under direct supervision, this job performs a broad range of operational activities, which may include collecting, organizing, and analyzing information from the University's various internal data systems as well as from external sources. This job also performs assignments related to data manipulation, statistical applications, programming, analysis and modeling.1) Assists in analyzing data for the purpose of extracting applicable information. Performs research projects that provide analysis for a number of programs and initiatives., 2) May assist staff or faculty members with data manipulation, statistical applications, programming, analysis and modeling on a scheduled or ad-hoc basis., 3) Collects, organizes, and may analyze information from the University's various internal data systems as well as from external sources., 4) Maintains and analyzes statistical models using general knowledge of best practices in machine learning and statistical inference. Performs maintenance on large and complex research and administrative datasets. Responds to requests and engages other IT resources as needed., 5) Performs other related work as needed.

Unit-specific Responsibilities

1) Calculate genetic risk scores for prediction of breast cancer.

2) Analyze big genetic/genomic data (such as SNP, RNA splicing, and gene expression) by using existing software and/or developing statistical and computational tools.

3) Develop figures, tables, and reports and participate in manuscript writing.

4) This position can be renewed after one year depending on the NIH funding availability.

Unit-preferred Competencies

1)Training in computer science, statistics, and/or other quantitative skills.

Education, Experience, and Certifications
Minimum requirements include a college or university degree in related field.Minimum requirements include knowledge and skills developed through

Preferred Qualifications

Education

1) Bachelor’s, or Master's degree in a computer science or other quantitative fields, such as bioinformatics, computational biology, statistics, biostatistics, mathematics, physics, economics, or social sciences, with interest in genetics/genomics.2) Candidates with degrees in genetics or related fields with strong computational and statistical expertise are also encouraged to apply.

Experience

1) Possess practical experience in data analysis.

2) Fluency in Linux, standard bioinformatics tools (R and/or Python)

Required Documents

1) Cover letter

2) Resume

Note: When applying, all required documents MUST be uploaded under the Resume/CV section of the application.

FLSA Status
Non-Exempt
Pay Frequency
Biweekly
Pay Grade
Depends on Qualifications
Scheduled Weekly Hours
40
Benefits Eligible
Yes
Drug Test Required
No
Health Screen Required
No
Motor Vehicle Record Inquiry Required
No
Posting Date
2020-09-04-07:00
Remove from Posting On or Before
2021-03-04-08:00
Posting Statement


The University of Chicago is an Affirmative Action/Equal Opportunity/Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.

Staff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via Applicant Inquiry Form.

The University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: http://securityreport.uchicago.edu. Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637.",4.0,"University of Chicago
4.0","Chicago, IL",10000+ Employees,1890,College / University,Colleges & Universities,Education,$2 to $5 billion (USD)
"Senior Data Scientist, Zoro","$89K-$147K
(Glassdoor Est.)","Company Summary:
Zoro.com is an eCommerce company that sells business supplies, equipment, and tools—but we’re much more than just a website. We’re a team of people who win and lose together (we prefer winning!). Since 2011, Zoro has been working hard to make it easy for our customers to purchase everything they need to make their businesses go. Zoro currently offers 3 million products, fast and free shipping, no-hassle returns, and exceptional customer service. We’ve grown quickly in a short time, recently surpassing 400 team members and reaching annual revenue of over $500 million. Add to that our award-winning culture—we were named a Great Place to Work for 2019-20, among other accolades—and we think Zoro is a pretty amazing place to work and grow.
Primary Function:
Our Sr. Data Scientists are key contributors to the development of Zoro’s customer, product, eCommerce, and pricing plans. The Data Science team covers a broad scope of projects including customer segmentation, A/B testing, marketing investment optimization, predictive modeling, promotion forecasting, and pricing analysis. We are closely integrated with our business leaders and support their ability to make critical decisions. At Zoro, you will be challenged by new questions every day.
Duties and Responsibilities:
Lead data science projects from beginning to end: develop and refine the idea, create a project plan and methodology, collaborate with business partners, execute, and provide recommendations for the company
Collaborate with other data scientists to develop and implement algorithms, write code, evaluate relevant academic research, and deliver outputs
Advise the company about tools, data sources, and best practices to facilitate digital marketing, pricing, and web analytics
Build predictive and inference models using Python and R to support business initiatives in the areas of customer acquisition, activation, engagement, retention, or channel investment optimization
Document code and data science processes that are critical to the company, and develop strategies to ensure those processes are robust and fault-tolerant
Communicate findings to business leaders and colleagues using data visualizations, presentations, and written means
Qualifications:
Experience leading data science projects that have a direct impact on company objectives
Demonstrated ability to assist business decision-making through data mining and machine learning
Strong communication skills to collaborate effectively with business stakeholders. Must be able to interact cross-functionally and drive both business and technical discussions
5+ years’ progressive business experience in areas including marketing analytics, database marketing, data mining, or statistical modeling. Experience using data science or advanced analytics in an Internet retailer or a top-tier consumer-focused company is required
Ability to translate complex business problems into project plans and solve them by analyzing large amounts of data
Familiarity with Python or R for statistical modeling, clustering, classification, machine learning, and data mining
Demonstrated proficiency in SQL and cloud-hosted data platforms (Google Cloud Platform, AWS, etc)
Familiarity with BI tools such as Tableau or Looker, and ability to communicate results to business partners
Master’s degree preferred in quantitative fields such as Statistics, Engineering, Operational Research, or Economics
Knowledge of web tracking technology and web analytics tools (Google Analytics, Adobe Analytics, etc.) a definite plus

Final note: We share a commitment to our Zoro values – Win & Lose Together (We prefer winning!), Take Ownership, We Are Transparent, and Aspire to be Customer-Obsessed. Everything we do at Zoro is centered around delighting our customers. It's a natural extension of our company culture and how we care for each other. We believe when we act in ways that are consistent with these values, we can solve any technical challenge that lies ahead of us. As a Zoro employee, you can expect to work with smart, energetic people, learn something every day, and be valued for your perspective.

Zoro is an Equal Opportunity Workplace and an Affirmative Action Employer.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.


Apply Now",3.7,"Zoro Tools
3.7","Chicago, IL",10000+ Employees,1927,Company - Public,Wholesale,Business Services,$10+ billion (USD)
Staff Scientist,"$37K-$85K
(Glassdoor Est.)","Please make sure to read the job posting in its entirety as it reflects both the University roles and responsibilities, followed by the specific description.
Department
20145 Org.Bio./Anatomy
About the Unit
Teaching human anatomy (histology, gross anatomy, medical imaging and embryology) and managing the anatomy laboratory.
Job Family
Research
Responsible for all aspects of research projects and research facilities. Plans and conducts clinical and non-clinical research; facilitates and monitors daily activities of clinical trials or research projects. Directs engineering and technical support activities to develop and maintain tools and computational methods needed to gather and analyze data.
Career Track and Job Level
Research Professional
Facilitates and promotes a research project or contributes to the scientific direction of a research resource.
P3: Requires in-depth knowledge and experience. Uses best practices and knowledge of internal or external University issues to improve products or services. Solves complex problems; takes a new perspective using existing solutions. Works independently, receives minimal guidance. Acts as a resource for colleagues with less experience.
Role Impact
Individual Contributor
Responsibilities
The job develops and implements programs to promote a research project or contributes to the scientific direction of a research resource.
1) Serves as a resource for collecting data and performing analysis. Facilitates and promotes a research project by providing scientific or intellectual information., 2) Develops laboratory protocols and training on new techniques. Manage, analyze and make recommendations on complex data sets for research., 3) Creates first drafts for scientific writing and publications, including protocols and grants., 4) Trains and mentors laboratory personnel., 5) Performs other related work as needed.
Unit-specific Responsibilities
1) Preparation of course materials for anatomy course.
2) Develop and implement safety protocols in the anatomy laboratory.
3) Supervise graduate/medical student teaching assistants.
Unit-preferred Competencies
1) Teaching Anatomy.
2) Management of anatomy laboratory.
3) Supervision with teaching assistants.
Education, Experience, and Certifications
Minimum requirements include a PhD in related field.
Minimum requirements include knowledge and skills developed through 5-7 years of work experience in a related job discipline.
Preferred Qualifications
Education
1) PhD in anatomy, musculoskeletal biology, or evolutionary biology.
Required Documents
1) Cover Letter
2) Resume
3) Contact information for at least 2 references
NOTE: When applying, all required documents MUST be uploaded under the Resume/CV section of the application
FLSA Status
Exempt
Pay Frequency
Monthly
Pay Grade
Depends on Qualifications
Scheduled Weekly Hours
37.5
Benefits Eligible
Yes
Drug Test Required
No
Health Screen Required
No
Motor Vehicle Record Inquiry Required
No
Posting Date
2020-07-08-07:00
Remove from Posting On or Before
2021-01-08-08:00
Posting Statement
The University of Chicago is an Affirmative Action/Equal Opportunity/Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.
Staff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via Applicant Inquiry Form.
The University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: http://securityreport.uchicago.edu. Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637.",4.0,"University of Chicago
4.0","Chicago, IL",10000+ Employees,1890,College / University,Colleges & Universities,Education,$2 to $5 billion (USD)
"Lead Data Scientist, Client Insights - Analytics","$127K-$205K
(Glassdoor Est.)","Position Summary


Nuveen is in the process of transforming its distribution model to expand our client engagement by utilizing digital and predictive analytics. The VP, Lead Data Scientist will be responsible for developing Nuveen’s data science capabilities enhancing the effectiveness of client acquisition, development and retention. They will collaborate across the Global Distribution, Product, Marketing, Client Servicing and Technology teams and lead a team of onshore and offshore data science and engineering resources.

Primary Responsibilities
Lead a team of data scientists and engineers onshore and offshore to deliver data sciences capabilities
Collaborate with the organization to create use cases for predictive and prescriptive analytics
Design and develop analyses based on prioritized use cases
Identify and use appropriate investigative and analytical technologies to interpret and verify results
Develop statistical and machine learning techniques to build models that improve how we engage with clients
Apply and learn a wide variety of tools and languages to achieve results (e.g., Python, R, SPSS, Hadoop)
Lead the integration of data and predictive models into decision making across the organization
Utilize effective project planning techniques to break down complex projects into tasks and ensure deadlines are kept
Communicate findings to team and leadership to ensure models are well understood and incorporated into how we go to market
Document model development and maintain models in appropriate platforms in partnership with technology
Cultivate an innovation mindset within the team and the organization to continue learning and driving data into the core of decision making
Define requirements for data science environment and tools required to be successful. Ensure these requirements are met and environment maintained in partnership with technology.
Requires minimum 5 years experience in advanced analytics, model building and deployment, and machine learning
Advanced degree in relevant field required (computer science, statistics, applied mathematics)
Experience in normalization of data, data mining, and tools
Experience in building and maintaining environments and platforms required for effective data sciences efforts
Experience with third party API integration and visualization capabilities
Strong executive presence, with the ability to communicate effectively with stakeholders at all levels
Demonstrated leadership skills and ability to work across multiple teams and platforms in a matrixed organization

Additional Information



Requisition ID: 1726953",3.3,"Nuveen
3.3","Chicago, IL",1001 to 5000 Employees,1898,Company - Private,Investment Banking & Asset Management,Finance,$1 to $2 billion (USD)
Actuary/Data Scientist,"$69K-$116K
(Glassdoor Est.)","Help Help
Overview
Open & closing dates
Opening and closing dates 08/17/2020 to 09/17/2020
Service
Competitive
Pay scale & grade
GS 14
Salary
$119,559 to $155,424 per year
Appointment type
Permanent
Work schedule
Full-Time
Help Help
Location
1 vacancy in the following location:
Chicago, IL
Chicago, IL
Relocation expenses reimbursed
No
Telework eligible
No
Help Help
This job is open to
The public
U.S. citizens, nationals or those who owe allegiance to the U.S.
Apply
Print Print
Share Share
Email
Facebook
LinkedIn
Twitter
Shorten link
Save
Announcement number
20-DEU-08 10885747MOC
Control number
576375900
Duties
Help Help
Duties
Summary
This position is located in the Railroad Retirement Board's Bureau of the Actuary and Research. The incumbent will be responsible for assisting in the activities of the financial interchange (FI) division, which is a multibillion dollar project mandated by the Railroad Retirement Act (RRA).

This job announcement may be used to fill one or more vacancies.
Learn more about this agency
Responsibilities
As a Actuary/Data Scientist, you will:
Provide technical advice and assist in reviewing the accuracy of calculations for inclusion in the annual FI determinations as specified by law.
Independently plan and develop complex actuarial and statistical programs involving mainframe and personal computer applications.
As an expert subject matter analyst, work closely with the bureau's computer specialists and other staff in the development of computer programs for the processing of data.
Conduct individual research in the fields of social insurance, private insurance, and pensions, and makes comparisons between the railroad retirement program and similar programs for workers in other industries.
Compose a variety of technical publications, memoranda, etc., pertaining to aspects of the FI.
Prepare data processing requests for program changes, review documentation, prepare test data, and review test output.
Work with reviewers and auditors from the Social Security Administration (SSA), the Centers for Medicare and Medicaid Services (CMS), Government Accountability Office (GAO), and Office of the Inspector General (OIG) to coordinate case reviews and audit issues.
Utilize SAS, R, and Microsoft Office software packages to accomplish a variety of work assignments.
This work requires a professional actuary or data scientist.
Travel Required
Not required
Supervisory status
No
Promotion Potential
14
Job family (Series)
1510 Actuarial Science
1530 Statistics
Similar jobs
Actuaries
Actuaries, Health
Actuaries, Insurance
Health Actuaries
Insurance Actuaries
Mathematical Statisticians
Requirements
Help Help
Requirements
Conditions of Employment
Must be a U.S. Citizen
Males born after 12/31/59 must be registered for Selective Service
Suitable for Federal employment, determined by a background investigation
May be required to successfully complete a probationary period
Qualifications
In order to qualify, you must meet the education and experience requirements described below:

Basic Education Requirements for Series 1510 (Actuary):

A. A bachelor's degree that included courses in actuarial science, mathematics, relevant statistics, business, finance, economics, insurance, or computer science totaling at least 24 semester hours. This course work must have included a minimum of 12 semester hours of mathematics that included differential and integral calculus and one or more courses in mathematics for which these calculus courses were prerequisites.

OR

B. A combination of education and experience that includes both of the following requirements:
Technical work experience in actuarial support work or in mathematics; and
Completion of a minimum of 24 semester hours of courses in actuarial science, mathematics, relevant statistics, business, finance, economics, insurance, or computer science at a four year college or university. This course work must have included a minimum of 12 semester hours of mathematics that included differential and integral calculus and one or more courses in mathematics for which these calculus courses were prerequisites.
Basic Education Requirements for Series 1530 (Statistician):

A. Successful completion of a full 4-year course of study in an accredited college or university leading to a bachelor's or higher degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing.

OR

B. Combination of education and experience -- courses as shown in A above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.

In addition to the Basic Requirements listed above, applicants must also have the following specialized experience:

At the GS-14 level for both series, applicants must have one year of specialized experience at or equivalent to at least the GS-13 grade level in the Federal service.

Specialized experience is defined as experience performing a wide range of professional actuarial and/or statistical functions which included applying actuarial and/or statistical principles and techniques in the analysis, evaluation, and projection of data with an emphasis on complex retirement and pension plans or other similar employee benefit programs.

You MUST provide transcripts or other documentation to support your educational claims.Official or unofficial transcripts are acceptable. All materials must be submitted by the closing date of the announcement. Official transcripts will be required if selected.

Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional, philanthropic, religious, spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.

Only experience obtained by the closing date of this announcement will be considered.
Education
See Basic Education Requirements above.
Additional information
INTERAGENCY CAREER TRANSITION ASSISTANCE PLAN (ICTAP):
ICTAP provides eligible displaced Federal competitive service employees with selection priority for competitive service vacancies. You must be determined to be well-qualified for the vacancy to be eligible for special selection priority. After submission of an acceptable application which meets ICTAP eligibility, you will be determined to be well-qualified for a vacancy if your rating places you in the best qualified category.
ICTAP eligibles must submit proof of eligibility for special selection priority, such as: a separation notice; an agency certification that you cannot be placed after injury compensation has been terminated; an OPM notification that your disability annuity has been terminated; or a Military Department or National Guard Bureau notification that you are retired under 5 U.S.C. 8337(h) or 8456. You must also submit a ""Notice of Personnel Action"" (SF-50) notating your current position, grade level, and duty location, and a copy of your most recent Performance Rating. Click here for more information on ICTAP.

If you are a male applicant who was born after 12/31/59 you are required to register under the Military Selective Service Act; the Defense Authorization Act of 1986 requires that you be registered or you are not eligible for appointment in this agency.

If you are unable to apply online or need to fax a document you do not have in electronic form, view the following link for information regarding an Alternate Application.
Read more
How You Will Be Evaluated
You will be evaluated for this job based on how well you meet the qualifications above.
This position will be filled using direct hire procedures. You will be evaluated for this job based on how well you meet the qualifications above. Traditional rating and ranking of applications does not apply to this vacancy. Applications will be evaluated against the basic qualifications. Qualified candidates will be referred for consideration in accordance with the Office of Personnel Management direct hire guidelines. Veterans' preference does not apply to direct hire recruitment procedures.
Read more
Background checks and security clearance
Security clearance
Not Required
Drug test required
No
Required Documents
Help Help
Required Documents
To apply for this position, you must provide a complete Application Package which includes:
Resume showing work schedule, hours worked per week, dates of employment and duties performed.
Transcripts: You must submit transcripts. Original transcripts will be required if selected.
Interagency Career Transition Assistance Plan (ICTAP) documentation: If you are eligible under ICTAP, you must submit all required materials verifying your eligibility as listed in ""Other Information.""
Benefits
Help Help
Benefits
A career with the U.S. Government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Learn more about federal benefits.
Review our benefits
Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time, or intermittent. Contact the hiring agency for more information on the specific benefits offered.
How to Apply
Help Help
How to Apply
Please read the entire announcement and all the instructions before you begin an application. To apply for this position, you must complete the initial online application, to include submission of the required documentation specified in the Required Documents section. The complete application package must be submitted by 11:59 PM (ET) on the closing date of the announcement to receive consideration. The application process is as follows:

If you have not already, create a login.gov account:
Enter an email address during the account set up - use the same email address you use for USAJOBS (your primary or secondary email address).
Create a new password.
Have a working phone number (mobile or landline) near you - login.gov will send you a security code.
Finish setting up your login.gov account.
Once you've finished setting up your login.gov account, you'll go back to USAJOBS to finish the process. Double check your USAJOBS Profile to make sure all of your information is accurate.
Note: We recommend you don't use a .gov, .mil or .edu email address. Instead, you should use a personal (non-government) email address when you create your login.gov account.

You also cannot use an email address you share with someone else.

** For any issues signing into login.gov, go to https://login.gov/contact/

Once you have a login.gov account:
You need to use your login.gov email address, password and security code every time you want to sign into USAJOBS.
Follow the prompts in USAJOBS to take the online questionnaire, and submit the required documents. See Required Documents section for more details.
Click the Submit Application button prior to 11:59PM (ET) on the announcement closing date.
To update your application, including supporting documentation, at any time during the announcement open period by returning to your USAJOBS account. There you will find a record of your application, the application status, and an option to Update Application. This option will no longer be available once the announcement has closed.

To verify the status of your application both during and after the announcement open period, log into your USAJOBS account. All of your applications will appear on the Welcome page. The application record in your USAJOBS account provides an Additional Application Information page that provides information regarding the documentation you submitted and any correspondence we have sent related to this application. The Application Status will appear along with the date your application was last updated. For information on what each Application Status means, visit: https://www.usajobs.gov/Help/how-to/application/status/.
Read more",4.1,"Centers for Medicare & Medicaid Services
4.1","Chicago, IL",5001 to 10000 Employees,1977,Government,Federal Agencies,Government,Unknown / Non-Applicable
Data Engineer,"$97K-$114K
(Glassdoor Est.)","Job Overview


We are looking for a Data Engineer to join our growing team of analytics experts, where you will have the opportunity to author and manage data pipelines from ingest to insights and all the plumbing in between. The Data Engineer will support our data scientists with both existing and net new projects, ensuring that data delivery is consistent and optimized. The right candidate will be excited by the prospect of optimizing or even re-designing our companys data architecture to support our next generation of products and data initiatives.

Responsibilities for Data Engineer
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets to meet functional and non-functional business requirements.
Author the pipeline code required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Work with Data Scientists and Systems Engineers to design data delivery architecture.
Work with stakeholders including the Executive and Product teams to assist with data-related technical issues and support their data insight needs.
Create data tools for team members that assist them in building and optimizing our products.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. PostgreSQL administration familiarity a plus.
Strong Python scripting skills. Ruby a plus.
Familiarity with API endpoint interactions and techniques for handling query complications.
Understanding of Containerization, Micro-Service, and Server-less a strong plus.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
The ideal candidate would have 3+ years of experience in a Data Engineer role, or 5+ years in any Software Engineering role with demonstrable familiarity of the Data Engineering/Science space. Work experience, academic instruction, and/or code portfolio will all considered.
Powered by JazzHR",4.3,"Strike Social
4.3","Chicago, IL",51 to 200 Employees,2013,Company - Private,Advertising & Marketing,Business Services,$50 to $100 million (USD)
Senior Data Scientist,"$89K-$142K
(Glassdoor Est.)","Aon is looking for a Senior Data Scientist

As part of an industry-leading team, you will help empower results for our clients by delivering innovative and effective solutions supporting Risk, in Boston, Chicago, New York, Seattle, Spokane or Virtual.

Your impact as a Senior Data Scientist

Aon Intellectual Property Solutions helps clients protect and maximize their most valuable asset in today’s business world—their intellectual property. Aon brings the best minds and strong analytical tools to provide a comprehensive approach to intellectual property strategy, valuation, and risk management across a client’s business.

As a Senior Data Scientist with Aon IP Solutions, you will join a dynamic team seeking to answer complex questions related to IP analysis, valuation and building predictive risk models.

Our larger team consists primarily of computer science, math and physics majors and PhDs. We value a genuine work-life balance and offer excellent compensation and stability. Our ideal candidate balances subject matter expertise, initiative, accuracy, self-motivation, organization, and articulate & precise communications. Intellectual curiosity, creativity, honesty, and professionalism are critical traits for success in this role.

Job Responsibilities:
Run a data science/modeling project from start to finish with help from domain experts and other coworkers.
Represent the leadership and management of IP Solutions in a way that mirrors the adopted mission, core values, and culture of IP Solutions.
Help all business units on an as-needed basis achieve and surpass sales, profitability, cash flow, and business goals and objectives.
Assist in providing timely, accurate and complete reports on the progress of IP market-making efforts.
Ensure delivery of timely, innovative, accurate, and best in class solutions.
Educate members of Aon’s network with thought leadership that shares best practices
You Bring Knowledge and Expertise

Required Experience:

Technical Skills:
2-5 years Experience with data mining tools such as Python, R, or Matlab
2-5 years Experience with data analysis and statistical packages (NumPy, Pandas, Scikit-learn, PyMC etc.)
2-5 years Experience building mathematical/statistical models
Experience working with a variety of data sources such as SQL, AWS, Azure, BigQuery, etc.
Natural Language Processing experience a plus
Non-technical Skills:
Ability to understand and communicate complex ideas effectively to technical and non-technical audiences
Ability to cooperate effectively with people at all levels in the organization
Impeccable standards of honesty and accuracy; high degree of self-motivation
Represent attributes of stewardship, humility, integrity, trust, and gratitude
Instill a can-do and collaborative culture that connects across teams and Aon
Be a role model who develops others by providing timely feedback and coaching
Highly articulate and precise English speaking and writing skills
Education:
Undergrad with significant quantitative coursework
Degree(s) should be from top-100 national universities, engineering schools, and/or liberal arts colleges – or -
Work experience or internships with top-tier companies or governmental organizations
We offer you

A competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.

Our Colleague Experience:

From helping clients gain access to capital after natural disasters, to creating access to health care and retirement for millions, Aon colleagues empower results for our clients, communities, and each other every day. They make a difference, work with the best, own their potential, and value one another. This is the Aon Colleague Experience, defining what it means to work at Aon and realizing our vision of empowering human and economic possibility. To learn more visit Aon Colleague Experience.

About Aon:

Aon plc (NYSE:AON) is a leading global professional services firm providing a broad range of risk, retirement and health solutions. Our 50,000 colleagues in 120 countries empower results for clients by using proprietary data and analytics to deliver insights that reduce volatility and improve performance.

By applying for a position with Aon, you understand that, should you be made an offer, it will be contingent on your undergoing and successfully completing a background check consistent with Aon's employment policies. Background checks may include some or all of the following based on the nature of the position: SSN/SIN validation, education verification, employment verification, and criminal check, search against global sanctions and government watch lists, fingerprint verification, credit check, and/or drug test. You will be notified during the hiring process which checks are required by the position.

Aon provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, veteran, marital, or domestic partner status. Aon is committed to a diverse workforce and is an affirmative action employer.

DISCLAIMER:
Nothing in this job description restricts management's right to assign or reassign duties and responsibilities to this job at any time.

2476034",3.6,"Aon
3.6","Chicago, IL",10000+ Employees,1892,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD)
SAP Data Analyst,"$75K-$100K
(Employer Est.)","POSITION PURPOSE:

The Data Analyst will be part of the OWI Analytic team, working closely with our business partners, proactively developing and delivering analytic solutions. The primary deliverables include creating data visualization such as Dashboards, Charts, Histograms and Projective Analysis. This will be accomplished by utilizing OWI data architecture, data workflows from local data sources.

OWI is a fast-paced and dynamic organization. Individuals will be handling multiple activities in a team as well as individual contributor environment.

DUTIES, TASKS AND RESPONSIBILITIES:
Experience and expertise creating visualizations that provide business insights for our global customers. Examples: Pie Charts, Dashboards, Cash-flow projections with Histograms– Projections analysis– Financial Analysis – KPI’s Service level Agreements
Expertise in SQL, independently mine data to translate Business data needs into creative visualizations.
Performance tuning specific to Tableau data sets– requires in depth understanding of data.
Assist the Enterprise Data Warehouse team create, design data models that will be published to our Tableau environment.
Assess data quality, design data quality management procedures, clean and correct data quality defects, establish data governance.
Experienced utilizing HANA studio including calculations and analytical views, data base schemas, creating attribute user/role creation.
Assist setting up security, Analytic privileges, user integration services, SQL script, SLT, SDA, SDI and HANA Live solution models.
Demonstrate critical thinking, analytical skills, and employ judgment to offer thoughtful, concise input toward resolutions of problems.
Assist team building the BW4HANA modeler including standard and custom development and deployment of EWD design building BW objects e.g. Composite Providers, Advanced DSO’s, ODS Views, Data Sources, Data Loading using SLT.
Requires the skill set to work with a wide range of stakeholders and functional teams and data analysts/scientists to develop data visualizations that provide business insights
Finance/Operations/Sales/Marketing/IT functional leads PTP/PTM/RTR etc.
Projects management capabilities - include requirements gathering, design, deployment, and change request, future enhancements management
Capabilities to build/design prototypes to demo to stakeholders - peer groups, Business partners, and senior leaders.
Training and support peers and stakeholders e.g. Subject Matter Expert (SME) throughout the report creations and support - troubleshooting, analysis of results.
Leadership skills needed to successfully promote ideas, coordinate work activities, and plan deliverables within a project team.


SKILLS, KNOWLEDGE AND ABILITIES:


Advanced expert database handling languages (SQL and variants)
Experience with data analytics, diagrams, data dictionary, data mapping, normalize de-normalize, agile data modeling
Practical skill sets in BI and Data visualization tools
Working knowledge of ETL
Working knowledge of SAP
Basic Project Management and Business Process modeling
Minimum Bachelor’s Degree in Engineering Technology, Computer Science, or closely related field.
A minimum of 3 years’ experience in Tableau, SAP Data Governance, SAP Data Services (Data Extract, Data Profiling, de-duplication)
Advanced competency in Tableau and Alteryx
Excellent verbal and written communication skills with a strong focus on the ability to clearly articulate and discuss technical issues with both technical and business personnel.
Bachelor’s degree in computer science, Math or a related IT field or equivalent work experience in an IT field required
Strong analytical skills, able to effectively solve problems in a timely manner",3.1,"Old World Industries
3.1","Northbrook, IL",201 to 500 Employees,1973,Company - Private,Chemical Manufacturing,Manufacturing,$1 to $2 billion (USD)
Materials Scientist,"$20K-$127K
(Glassdoor Est.)","Position Description

In this position, you will characterize and analyze the behavior of nuclear fuels and structural materials used in current- and next-generation nuclear energy systems and research reactors. You will develop correlations to describe the characteristics of materials and models to describe their behavior in typical reactor environments. You will participate in planning, developing, and implementing research in the area of nuclear materials. You will perform experiments at the Argonne Intermediate Voltage Electron Microscope (IVEM), Argonne Tandem Linac Accelerator System (ATLAS), or Advanced Photon Source (APS). You will also perform post-irradiation examinations using FIB, SEM, and TEM. Furthermore, you will compare and validate predictions of nuclear material performance characteristics with experimental results and/or alternative benchmark models, and evaluate and document the results of analytical activities for presentation to the technical community. You will perform analysis and interpretation of in-reactor post-irradiation examination data to support reactor fuel conversion programs. You will support the preparation of proposals to attract internal/external funding for new projects.

Position Requirements
To be considered for this position, you must have:
Experience operating TEM, FIB and SEM, and analyzing experimental results is required;
Experience in one of the X-ray techniques such as diffraction, scattering, tomography, fluorescence, etc. is a plus
Knowledge of materials science principles, theories, advanced characterization techniques, and practices for the design, analysis, and testing of candidate nuclear fuel and cladding materials is essential.
Knowledge of one or more specialized areas in finite element modeling is a plus
Skill in the conception, design, and evaluation of innovative approaches and solutions to quantitative problems is necessary.
Skills in the use of computers and in the analysis of computational results, in the clear and effective documentation and communication of results, and in interaction with co-workers and support personnel is required.
Some knowledge of programming is required.
To perform the essential functions of this position successful applicants must provide proof of U.S. citizenship, which is required to comply with federal regulations and contract. Illegal drug testing as defined in 10 CFR 707.4 and a background investigation will be required prior to employment.

This level of knowledge is typically achieved through a formal education in nuclear engineering, mechanical engineering, physics, or associated field at the Ph.D. degree level & 0 years’ of professional experience.

As an equal employment opportunity and affirmative action employer, and in accordance with our core values of impact, safety, respect, integrity and teamwork, Argonne National Laboratory is committed to a diverse and inclusive workplace that fosters collaborative scientific discovery and innovation. In support of this commitment, Argonne encourages minorities, women, veterans and individuals with disabilities to apply for employment. Argonne considers all qualified applicants for employment without regard to age, ancestry, citizenship status, color, disability, gender, gender identity, genetic information, marital status, national origin, pregnancy, race, religion, sexual orientation, veteran status or any other characteristic protected by law.

Argonne employees, and certain guest researchers and contractors, are subject to particular restrictions related to participation in Foreign Government Talent Recruitment Programs, as defined and detailed in United States Department of Energy Order 486.1. You will be asked to disclose any such participation in the application phase for review by Argonne’s Legal Department.

As an equal employment opportunity and affirmative action employer, and in accordance with our core values of impact, safety, respect, integrity and teamwork, Argonne National Laboratory is committed to a diverse and inclusive workplace that fosters collaborative scientific discovery and innovation. In support of this commitment, Argonne encourages minorities, women, veterans and individuals with disabilities to apply for employment. Argonne considers all qualified applicants for employment without regard to age, ancestry, citizenship status, color, disability, gender, gender identity, genetic information, marital status, national origin, pregnancy, race, religion, sexual orientation, veteran status or any other characteristic protected by law.

Argonne employees, and certain guest researchers and contractors, are subject to particular restrictions related to participation in Foreign Government Talent Recruitment Programs, as defined and detailed in United States Department of Energy Order 486.1. You will be asked to disclose any such participation in the application phase for review by Argonne’s Legal Department.
Back to top",4.5,"Argonne National Laboratory
4.5","Lemont, IL",1001 to 5000 Employees,1946,Nonprofit Organization,Federal Agencies,Government,Unknown / Non-Applicable
Data Scientist (Optimization Team),"$87K-$144K
(Glassdoor Est.)","Company Description

Positioned at Publicis Groupe's core, Conversant is a marketing tech platform that helps brands transform ordinary customer experiences into meaningful, human experiences. The Conversant platform powers a connected suite of products and services called Epsilon PeopleCloud, combining leading-edge identity management, industrial-strength data and technology expertise with big brand acumen gained over five decades of working with the industry’s top brands. Our human-powered, data-led marketing delivers unmatched depth, breadth and scale to help brands create exceptional business outcomes. For more information, visit www.epsilon.com. Follow us on Twitter at @EpsilonMktg.

Job Description

External Title: Data Scientist
Internal Title: Decision Science Scientist

As a Data Scientist in our Decision Sciences R&D organization, you will be responsible for researching and building optimization, control theory, simulation, and machine learning applications to extend Epsilon CORE Personalization Platform. Epsilon CORE Personalization Platform analyzes anonymized data at Internet scale and evaluates more than one trillion advertising opportunities per month in real-time. You will work on real-world problems as part of our highly collaborative R&D team, and your solutions will directly and rapidly impact our business. This includes analyzing raw source data and derived data; researching and developing models, algorithms, and applications; building tools and analyses for new and existing products; and presenting findings.

RESPONSIBILITIES
Develop an understanding of Epsilon CORE Personalization Platform and proprietary datasets
Use your optimization, control theory, simulation, or machine learning expertise to research and recommend the best approaches to solving our technology and business problems
Design, implement, and validate your solutions in Apache Spark and Apache Hive using Scala or Python on large state-of-the-art computing clusters
Work with our Engineering teams to integrate your solutions into Epsilon’s CORE Personalization Platform
Participate fully in our collaborative approach to research and applications projects
Qualifications
Ph.D. in Computer Science, Operations Research, Electrical Engineering, Statistics, Mathematics, Physics, Economics, or related scientific discipline
Research experience and coursework in Optimization, Control Theory, Machine Learning, or Simulation
Experience with distributed computing, such as Hadoop, Spark, or related technologies
Familiarity with Scala, Python, SQL, or Java; or
Strong understanding of modeling and statistical techniques
Desire to work in a highly collaborative environment
ADDITIONAL USEFUL BUT NOT REQUIRED SKILLS
Experience modeling or analyzing consumer behavior, market dynamics, or auctions
Additional Information

Great People, Deserve Great Benefits
We know that we have some of the brightest and most talented associates in the world, and we believe in rewarding them accordingly. If you work here, expect competitive pay, comprehensive health coverage, and endless opportunities to advance your career.

Epsilon is an Equal Opportunity Employer. Epsilon’s policy is not to discriminate against any applicant or employee based on actual or perceived race, age, sex or gender (including pregnancy), marital status, national origin, ancestry, citizenship status, mental or physical disability, religion, creed, color, sexual orientation, gender identity or expression (including transgender status), veteran status, genetic information, or any other characteristic protected by applicable federal, state or local law. Epsilon also prohibits harassment of applicants and employees based on any of these protected categories.

Epsilon will provide accommodations to applicants needing accommodations to complete the application process.

#LI-AL1

REF17386U",3.4,"Epsilon
3.4","Chicago, IL",5001 to 10000 Employees,1969,Subsidiary or Business Segment,Advertising & Marketing,Business Services,$2 to $5 billion (USD)
Data Scientist - Environment Modeling,"$75K-$125K
(Glassdoor Est.)","Position Overview:

The Environment Modeling Team at Climate is seeking a highly-motivated, PhD-level Senior Researcher with demonstrated experience applying advanced statistics and data science to challenging problems.

This position is within the science R&D team that leverages process, statistical, and machine-learning models, big data, and cloud computing to address scientific challenges in precision agriculture. The Environment Modeling Team focuses on the environmental aspects of predictive models that are used both in-house and by farmers, agronomists, and consultants to optimize their management programs and economic returns.

This position will involve working with diverse data resources, and will require the ability to not only apply statistical and machine learning models to data but to also identify, understand and communicate limitations and solutions surrounding data quality and/or quantity, as well as methodologies, to an interdisciplinary team of scientists and engineers. You will have the opportunity to work with the richest agricultural datasets available in the world to help growers meet the challenges of feeding a growing population.

What You Will Do:
Lead cross-functional projects that identify the best use of environmental layers and/or integrate them into predictive models, with a particular focus on crop disease models
Explore, munge and visualize large and diverse agronomic datasets as part of building models
Design, prototype, and test predictive models using diverse techniques that include, but are not limited to, statistical modeling and machine learning
Write high-quality research code in Python
Work closely with a team of world-class scientists, engineers and data scientists to deliver impactful, high-quality and reproducible scientific research
Effectively communicate research findings to key stakeholders and propose recommendations to senior management

Basic Qualifications:
PhD in Statistics, Biostatistics, Data Science, Applied Mathematics, Machine Learning, or another highly related discipline
Demonstrated ability to apply advanced statistical methodology and data science to real-world problems
Demonstrated ability to work in cross-functional environment
Strong proficiency with Python or R coding
Preferred Qualifications:
At least 1 year of work experience applying statistics and data science to real-world problems
Applied experience with epidemiological and disease models and more generally, with spatio-temporal modeling
Strong proficiency with Python coding
Experience using probabilistic programming languages, such as Tensorflow probability, Stan, Pyro, PyMC3
Experience in SQL, PySpark or SparklyR/Spark
Applied experience with agricultural science and/or agricultural datasets
Excellent interpersonal and communication skills
Strong organizational skill
Strong drive to learn new topics and skills
What We Offer:

Our teams are composed of industry experts, top scientists, and talented engineers. The environment is extremely engaging and fast-paced, with dozens of specialties coming together to provide the best possible products and experiences for our customers.

We provide competitive salaries and some of the best perks in the industry, including:
Superb medical, dental, vision, life, and disability benefits, and a 401k matching program
A stocked kitchen with a large assortment of snacks & drinks to get you through the day
Encouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used
Workshops, conferences, meet-up groups, tech-talks, and hackathons to encourage participation and growth in both community involvement and career development
We also hinge our cultural DNA on these five values:
Inspire one another
Innovate in all we do
Leave a mark on the world
Find the possible in the impossible
Be direct and transparent
Learn more about our team and our mission:

The Climate Corporation - The Technology Behind Making A Difference

https://youtu.be/c5TgbpE9UBI or visit https://climate.com/careers

Climate aims to create a welcoming and collaborative environment for our employees in which a diverse set of perspectives and voices are represented and celebrated.

As part of our dedication to the diversity of our workforce, The Climate Corporation is committed to Equal Employment Opportunity and does not discriminate based on race, religion, color, national origin, ethnicity, gender, sex (including pregnancy), protected veteran status, age, disability, sexual orientation, gender identity, gender expression, or any unlawful criterion existing under applicable federal, state, or local laws. If you need assistance or an accommodation due to a disability, you may contact us at accommodations@climate.com.",3.3,"The Climate Corporation
3.3","Chicago, IL",501 to 1000 Employees,2006,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable
Health Scientist (Informatics),"$49K-$83K
(Glassdoor Est.)","This Direct Hire recruitment is to fill positions based on a critical hiring need resulting from the outbreak and spread of the""Coronavirus Disease 2019"" (COVID-19), which has caused a public health emergency. As such, all applicants who meet the OPM General Medical and Healthcare Series requirements and the minimum specialized experience qualifications stated in this announcement will be referred to hiring managers for further consideration.Education completed in colleges or universities outside the United States may be used to meet the education requirements. You must provide acceptable documentation that the foreign education is comparable to that received in an accredited educational institution in the United States. For more information on how foreign education is evaluated, visit: https://www.cdc.gov/jobs/future-applicant-information.html.As a Health Scientist (Informatics) you will:
Conduct assigned statistical studies or continuing projects that represent an important segment of the center's primary investigative program.
Participate with scientists and program consultants in various aspects of the study or survey design process, and other study support duties including analyzing and reporting of data and data dissemination to audiences.
Manage projects involved with public health informatics and serves as a subject matter expert in the design and implementation of IT systems integrating epidemiologic and other information from a scientific perspective.
Create specialized programs to track and diagnose IT problems and uses utility programs to both prevent and recover from IT systems failures.
Coordinate the sharing of health-related informational materials so that scientific advice and assistance is shared.
Utilize database software, communications software, operating systems, statistical analysis systems, and mainframe software to ensure database and software are compatible with other applicable environmental, epidemiologic, and surveillance systems both within and outside the agency.
Perform other duties as assigned.
Continuation of Requirements:
Promotion Potential: Please be advised there is no promotion potential for these positions, any position filled with this announcement will be filled at the single grade level requested.
Research position: No
Supervisory position:No
Basic Qualifications:
I have completed a Bachelor's or graduate/higher level degree: major study in an academic field related to the medical field, health sciences or allied sciences appropriate to the work of the position. This degree must be from an educational program from an accrediting body recognized by the U.S. Department of Education (https://ope.ed.gov/accreditation/) at the time the degree was obtained.

Minimum Qualifications GS-11:
Applicants must have at least one year of specialized experience at or equivalent to the GS-9 in the Federal service as defined in the next paragraph.
Specialized experience is experience which is directly related to the position which has equipped the applicant with the particular knowledge, skills and abilities (KSAs) to successfully perform the duties of the position to include experience in performing projects involved with public health informatics and/or in assisting in the design and implementation of IT systems integrating epidemiologic and other information from a scientific perspective.
OR
I have completed a Ph.D. or equivalent doctoral degree, or completed three full years of progressively higher level graduate education leading to such a degree, or LL.M., if related
OR
I have a combination of experience and education that meets 100% of the qualification requirements.

Minimum Qualifications GS-12:

Applicants must have at least one year of specialized experience at or equivalent to the GS-11 in the Federal service as defined in the next paragraph.
Specialized experience is experience which is directly related to the position which has equipped the applicant with the particular knowledge, skills and abilities (KSAs) to successfully perform the duties of the position to include experience evaluating and developing approaches for strengthening the standardization and utility of national health information systems.

Minimum Qualifications GS-13:
Applicants must have at least one year of specialized experience at or equivalent to the GS-12 in the Federal service as defined in the next paragraph.
Specialized experience is experience which is directly related to the position which has equipped the applicant with the particular knowledge, skills and abilities (KSAs) to successfully perform the duties of the position to include experience in designing, coordinating and maintaining public health informatics project goals, objectives and priorities.",4.0,"Centers for Disease Control and Prevention
4.0","Chicago, IL",10000+ Employees,1946,Government,Federal Agencies,Government,Less than $1 million (USD)
Data Engineer,"$54K-$102K
(Glassdoor Est.)","Who are we?
Q-Centrix is a leading healthcare information solutions provider with offices in Chicago and San Diego, plus more than 900 clinical experts working remotely in 49 states. Our team of smart, ambitious, and fun-loving healthcare professionals are 100% focused on improving the quality of patient care at hospitals throughout the country.
What’s the job?
Q-Centrix is implementing a robust data infrastructure solution to provide further analysis capabilities for our partners in the areas of quality reporting, analysis and improvement. We’re searching for an ambitious and curious team member to report into the Sr Product Manager, Business Intelligence. The Data Engineer will embrace challenging work; while showcasing superior Nerf gun talents throughout the day.You’ll have a leg up if you don’t mind a few orange darts decorating your desktop, love memes and awful puns, and are open to wearing apparel prominently featuring the letter Q.
As a Data Engineer, you will…
Work closely with the Data Architect to create and maintain optimal data architecture
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies
Support the Product Development, Operations and Finance Teams in creating and analyzing reports both for our partners and internally
Envision and create reports that are translated from internal ideas, client feedback and competitive analysis
Partner with other disciplines within Q-Centrix to ensure project requirements are comprehensive and thoroughly planned and documented
Work with internal and market-facing stakeholders to validate suggested features and enhancements to Q-Apps
Be a vital contributor on a product development team accountable for building the industry’s only Healthcare Quality Information System
You’re a great fit if you…
Have a Bachelor’s Degree in computer science, information technology, MIS, mathematics, or a related field
Have 2-5 years of experience in healthcare or a related field (basically, you’ve been in the game for a minute, but you’re not yet an expert)
Have 2-5 years of experience in at least two BI tools like Tableau, Business Objects, Power BI, or Qlikview
Have 2-5 years of experience in SQL with a common RDBMS like SQL Server, Oracle, Teradata, MySql
Are experienced with Visualization and Analytics in a BI platform like Birst, Tableau, GoodData, Power BI, Microstrategy or Business Objects
Understand how Database Management Systems work
Are comfortable implementing Business Intelligence systems for internal or customer-facing groups, including analysis, dashboards, reporting, performance management, KPIs
Have worked within the framework of common Project Management structures and practices including waterfall, agile, project planning, scope control, customer relationship management
Have had exposure to data modeling for data warehousing - star, snowflake schema designs
Have worked with ETL/data integration tools like Informatica, MSFT SSIS, Oracle Warehouse Builder, Data Integrator, Data Stage, Ab Initio
Have an appreciation for design--with an understanding of the interplay of color, shape and size
Brownie points if you’re experienced with PostgreSQL and have healthcare industry experience
Sound like you? Apply now!

Who are we?
At Q-Centrix, we hire people who love learning, value innovation and believe in our mission and values to improve outcomes in healthcare. We applaud qualified applicants who are accountable and committed to producing quality work. As an Equal Opportunity Employer, we support and value diversity, dignity and respect in our work environment, and are committed to creating an inclusive environment in which everyone can thrive.
We employ people based on the needs of the business and the job, and their individual professional qualifications. Here’s what does not impact our employment decisions: race, religious creed, religion, color, sex, sexual orientation, pregnancy, parental status, genetic information, gender, gender identity, gender expression, age, national origin, ancestry, citizenship, protected veteran or disability status, health, marital, civil union or domestic partnership status, or any status or characteristic protected by the laws or regulations in locations where we operate. If you are an individual with a qualified disability and you need an accommodation during the interview process, please reach out to your recruiter.
We celebrate and embrace these differences, and take pride in our commitment to being an equal opportunity team.",4.2,"Q-Centrix
4.2","Chicago, IL",1001 to 5000 Employees,2010,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Data Engineer,"$67K-$130K
(Glassdoor Est.)","Join SADA as a Data Engineer!

Your Mission

As a Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data issues facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring a combination of batch or streaming data pipelines, data lakes and data warehouses.

You will be recognized as an established contributor by your team. You will contribute design and implementation components for multiple projects. You will work mostly independently with limited oversight. You will also participate in client-facing discussions in areas of expertise.

Pathway to Success

#BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage adaptability. This means that not only do our engineers understand that change is inevitable, but they embrace this change to continuously broaden their skills, preparing for future customer needs.

Your success comes from your enthusiasm, insight, and positive impact. You will be given direct feedback quarterly with respect to the scope and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, your collaboration with your peers, and the consultative skill you demonstrate in customer interactions.

As you continue to execute successfully, we will build a personalized development plan together that leads you through the engineering or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events. Due to the COVID-19 pandemic, travel has been temporarily restricted.

Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.

Training - Ongoing with a first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:
Google Professional Data Engineer Certified or able to complete within the first 45 days of employment
Required Qualifications:
Expertise in at least one of the following domain areas:
Big Data: managing Hadoop clusters (all included services), troubleshooting cluster operation issues, migrating Hadoop workloads, architecting solutions on Hadoop, experience with NoSQL data stores like Cassandra and HBase, building batch/streaming ETL pipelines with frameworks such as Spark, Spark Streaming and Apache Beam, and working with messaging systems like Pub/Sub, Kafka and RabbitMQ.
Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for minimizing downtime. May involve conversion between relational and NoSQL data stores, or vice versa.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Experience writing software in one or more languages such as Python, Java, Scala, or Go
Experience building production-grade data solutions (relational and NoSQL)
Experience with systems monitoring/alerting, capacity planning and performance tuning
Experience in technical consulting or other customer-facing role
Useful Qualifications:
Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)
Experience with IoT architectures and building real-time data streaming pipelines
Applied experience operationalizing machine learning models on large datasets
Knowledge and understanding of industry trends and new technologies and ability to apply trends to architectural needs
Demonstrated leadership and self-direction -- a willingness to teach others and learn new techniques
Demonstrated skills in selecting the right statistical tools given a data analysis problem
About SADA

Values: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA's values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.
Make them rave
Be data driven
Be one step ahead
Be a change agent
Do the right thing
Work with the best: SADA has been the largest partner in North America for GCP since 2016 and has been named the 2019 and 2018 Google Cloud Global Partner of the Year. SADA has also been awarded Best Place to Work by Inc. as well as LA Business Journal!

Benefits: Unlimited PTO, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, RRSP, professional development reimbursement program as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.",4.8,"SADA
4.8","Chicago, IL",201 to 500 Employees,2000,Company - Private,IT Services,Information Technology,$100 to $500 million (USD)
Data Engineer II,"$99K-$174K
(Glassdoor Est.)","Grubhub is dedicated to connecting hungry diners with our wide network of restaurants across the country. Our innovative technology, easy-to-use platforms and streamlined delivery capabilities make us an industry leader today, and in the future of online food ordering.
We strive to create a workplace that reflects the diversity of our customers and the communities we serve. When you join our team, you become part of a community that works together to innovate, solve problems, take risks, grow, work hard and have a ton of fun in the process!
Why Work For Us
We have a fast-paced environment and that is what our teams thrive on. Grubhub believes in empowering people and offering opportunities for development, as well as professional growth. We value strong, positive relationships in all areas: with each other, our customers and our greater community. Want to be a part of a team of diverse collaborators in an authentically fun culture? If so, we want to talk to you - and hear what’s your favorite restaurant for food delivery!
More About the Role
Data Engineer will be responsible for building efficient data pipelines that transform raw data into a format usable by downstream applications that serve both analytical and operational use cases.

This Data Engineer will be working closely with business stakeholders, product managers and engineering teams to meet data requirements of various initiatives in Grubhub.

Working with high volumes of data to efficiently process and expose for analysis
Collaborating with other engineering teams on strategies for data
Work with cutting edge data processing technologies
Understand our stakeholder (Finance, Marketing, Product) requirements and write complex and efficient code to transform raw data into an easy to approach data marts.
Doing deep dives on business verticals where you become one of the foremost experts on that vertical in the company
Analyze data to measure impacts of data schemas and use it to iterate on improvements
Translate from technical to business, and vice versa. You need to be able to speak with the least technically-minded client (internal or external) and make technology make sense to them. Then turn around and do it the other way

Excellent knowledge on SQL, data modelling and patterns.
5-7 years experience with Python or another general purpose programming language
Background in writing ETL jobs within a Business Intelligence context
A bachelor's degree, preferably in a computer-related discipline.
Enthusiasm for the job. Are you excited about data? Do you love your users? Good, the same goes for us
Got These? Even Better:
Experience big data processing with Spark and other big data tools a plus
Excellent communication skills, including the ability to crystallize and broadly socialize insights
Problem analysis and problem-solving skills
Rigorous attention to detail and accuracy
Exposure to Amazon AWS or another cloud provider
Adaptability and collaborative skills

Flexible PTO. Grubhub employees are provided a generous amount of time to recharge their batteries.
Health and Wellness. We provide programs that support your overall well-being such as generous medical benefits, employee network groups, company-wide fitness challenges, and a comfortable and casual workplace! We also support our parents by offering 8 weeks of paid parent bonding time, a 4-week returnship program, and 6-8 weeks paid medical leave.
Learning and Career Growth. Your personal and professional development is a priority at Grubhub. From day one, we empower you to lead and be an active participant in your career growth. We provide continuous learning opportunities, training, and coaching and mentorship programs.
MealPerks. Who’s ready for some lunch? We provide our employees with a weekly Grubhub credit to enjoy and support local restaurants. We also offer company-wide meals several times a year to bring our Grubhub family together.
Fun. Every Grubhub office has an employee-led Culture Crew that connects people through fun, meaningful events and initiatives. Some of our popular past events include: Wing-eating contests, Grubtoberfest, 5k Runs, Bring Your Child to Work Day, regular happy hours, and more!
Social Impact. We believe in the importance of serving the communities that support our business. In addition, employees are given paid time off each year to support the causes that are important to them.

Grubhub is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics. The EEO is the Law poster is available here: DOL Poster. If you are applying for a job in the U.S. and need a reasonable accommodation for any part of the employment process, please send an e-mail to TalentAcquisition@grubhub.com and let us know the nature of your request and contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address.
CA Privacy Notice: If you are a resident of the State of California and would like a copy of our CA privacy notice, please email privacy@grubhub.com.",3.9,"Grubhub
3.9","Chicago, IL",1001 to 5000 Employees,2004,Company - Public,Internet,Information Technology,$100 to $500 million (USD)
"Senior Applied Data Scientist, Government","$105K-$167K
(Glassdoor Est.)","What we do

At Civis, we take a science-first approach to solving business problems using person-level data. With a blend of proprietary technology and statistical advisory services, we help public and private sector organizations find, understand and connect with the people they care about, so they can stop guessing and start using mathematical proof to guide decisions. We know others use ""data science"" and ""analytics"" as buzzwords, but at Civis we don't stand for fluff, and we will always deliver scalable products and technologies — not PowerPoints — to drive your business forward. Learn more about Civis at www.civisanalytics.com.

Our mission

Our mission is to bring objective, data-driven truth to organizational decision-making – all the way from the boardroom to the world's largest social causes.

About the Role

The Applied Data Science (ADS) Team is the advisory arm of Civis Analytics, working closely with governments, companies, nonprofits, and campaigns to help solve their toughest challenges with data science. They are critical components of the project team and are expected to take leadership in understanding how to design and implement data science solutions for each client's unique situation. This position will be part of the ADS Public Sector team, which most commonly works with state and local governments, federal agencies, and public utilities.

As a Senior Applied Data Scientist, you will structure hard problems, define our methodological approach, build predictive models, collaborate in cross-functional teams, and be responsible for project milestones and presentations. You will also be a mentor to other data scientists, potentially managing newer hires, contributing to internal assets, and fostering learning and collaboration. You will work closely with our Applied Data Science Leads and our Managing Director to develop relationships, partnerships, and proposals for new governmental work, and may take responsibility for entire projects or accounts as you grow in your role.

**This is a temporary, full-time, salaried position with benefits slated to end Dec. 31, 2020. There is a possibility of extension if the business requires it.**

Due to the uncertainty of COVID-19, all Civis offices are closed and all employees are remote for the foreseeable future. This is being closely monitored as things change and it's likely our offices will reopen. Because of this uncertainty, we want to ensure candidates are open to relocating to one of our offices in the future, but other locations may be negotiable.

Responsibilities
Work with colleagues to scope out and define our approach to complex client problems
Enhance, find patterns in, and build predictive models on large data sets
Work with other Applied Data Scientists, as well as other departments within Civis, to derive clear, actionable, and timely insights from analyses
Work with the Applied Data Science Lead to create deliverables such as data assets, pipelines, dashboards, and presentations that are client-ready, clear, and error-free
Work with the Applied Data Science Lead to develop business opportunities, proposals, and pitches for new work throughout the public sector market
Minimum Qualifications
Bachelor's degree in an analytical subject (statistics, math, economics, sociology, psychology, physics, etc.) or equivalent
Minimum of 4 years of related work experience
Proven business results using both SQL as well as either R or Python
Experience with machine learning techniques
Experience with persuasive writing and presentation
Demonstrated ability to work independently and in teams
Excellent interpersonal and communication skills
Preferred Qualifications:
MA or MS in an analytical subject
Experience leading projects, including managing the work of colleagues
Proven affinity for and experience mentoring teammates
Experience with analytics for the public sector or for utilities
Experience with collaborative coding tools including Docker and Github
Significant experience fielding and analyzing web panel surveys
Why join our team?
The opportunity to be part of a growing tech startup focused on solving interesting and meaningful problems, invested in internal promotion, and committed to fostering a diverse, equal and inclusive workplace.
Competitive benefits, including unlimited PTO, 401K match with immediate vesting, health, dental, and vision benefits, fully paid parental leave, breastfeeding support including breastmilk shipping services for traveling moms, commuter benefits, wellness initiatives including weekly group meditations, monthly on-site massage therapy, and pet insurance.
To support employees in our now fully remote work environment, we also have expanded our virtual journal and book clubs, Donut Pals (organized virtual coffee meet-ups), Lightning Talks (5-minute presentations on anything you'd like), Lunch-and-Learns, and HR Open Discussions (bi-weekly meet-up where we discuss ideas and topics of the day in a casual format). We are also able to support and accommodate flexible work from home schedules to help employees juggle responsibilities at home.
Civis Analytics embraces the individuality of our employees and we celebrate each other's differences. Our products, services, and culture benefit from and thrive on the unique perspectives brought by each person in our community. We're proud to be an equal opportunity workplace, and we are committed to equal employment opportunity regardless of race, age, sex, color, ancestry, religion, national origin, sexual orientation, gender identity, citizenship, marital status, disability, or Veteran status. If you have a disability or special need that requires accommodation, please contact internalrecruiting@civisanalytics.com

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States.

EEO IS THE LAW

EEO Supplement

Pay Transparency",3.2,"Civis Analytics
3.2","Chicago, IL",51 to 200 Employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,$25 to $50 million (USD)
Data Engineer - Webscraping,"$85K-$158K
(Glassdoor Est.)","The Job Details are as follows:

OVERVIEW

We are looking for a creative and meticulous Data Engineer to join our Webscraping team. The data we provide drives investment decisions across the firm and we work hard to make sure it’s timely and accurate. The optimal candidate will be strongly self-motivated with the ability to work and solve problems independently. In your role, you will:
Collaborate with analysts to understand and anticipate requirements
Design, implement, and maintain webscrapes for a wide variety of alternative datasets
Author tests to validate data availability and integrity
Maintain alerting systems to ensure smooth day-to-day operations
Investigate and defuse time-sensitive data incidents
REQUIRED
Bachelors/Masters degree in Computer Science or a related field
1-3 years web development experience (Python/SQL/HTML/CSS/HTTP)
Linux experience (Windows experience a plus)
Excellent verbal and written communication skills
PREFERRED
Aptitude for designing infrastructure, data products, and tools for Data Scientists
Familiarity with scraping and common scraping tools (Selenium, scrapy, Fiddler, Postman, xpath)
Experience containerizing workloads with Docker (Kubernetes a plus)
Experience with build automation (Jenkins, TeamCity)
Experience with AWS",3.9,"Balyasny Asset Management
3.9","Chicago, IL",501 to 1000 Employees,2001,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable
Senior/Principal Data Engineer (Data Insights),"$128K-$235K
(Glassdoor Est.)","Join Rally Health as a Senior or Principal Data Engineer where you will partner with internal and external stakeholders with their data needs which can include building custom dashboards and architecting and coding solutions for large-scale pipelines. As part of the larger Data Insights team, you will report to an Engineering Manager.

You Will:
Manage the development of essential enterprise E2E Business Intelligence ETL solutions in Hadoop, sourcing data from HDFS, Kafka, Amazon Redshift, MongoDB or Postgres environments and using Python, Spark, Airflow and Hive
Architect and code solutions for large-scale ETL pipelines with data processing frameworks
Develop data solutions to promote applicable insights for population health management and positive recommendations for ways individuals can improve their health and manage their costs
Assess current processes, recommend and implement approaches to handle increasing volumes of data
Communicate technical specifications to ensure that proper and optimized techniques, queries, data standards, and final outputs are understood and incorporated into data and analytics processes
Participate in business analysis activities to gather required reporting and dashboard requirements
Handle the product's or project's conception, translate requirements, design initial technical specifications and develop data solutions
Develop reports and dashboards with data from potentially multiple data sources
You Have:
Advanced working knowledge and ability to write complex SQL and HQL queries in an HDFS environment
Experience working with Python and PySpark for the purposes of data transformations and ETL
Experience with backend and distributed systems and experience working with MapReduce-based architectures
Familiarity with Kimball, OLAP, and EDW data design methodologies
5+ years experience in ETL, Data Engineering, or BI fields with concentration on data transformations
Understanding of several data extraction and transformation techniques with data sourced in HDFS, MongoDB, and Postgres
Working familiarity with Tableau, Airflow, or Oozie
Knowledge of Scala is a bonus
Familiar with Data Visualization standard methodologies
Dedication to team goals including the support of live 24/7 production systems
BS in Computer Science, Engineering or a related technical role or equivalent experience
Rally Health™ is about putting health in the hands of the individual. With our easy-to-use online and mobile tools, we empower people by helping them take charge of their health and health care. Our culture is built on a belief of helping people live healthier lives, and we know that a diverse workforce enriches us with the talent, perspective and inspiration we need to achieve our mission. Rally knows that we are strongest when our teams reflect the diversity of the world around us, and when Rallyers can do their best work in a workplace where they feel a sense of belonging.

Our Benefits:
Great compensation package
Comprehensive benefits package for full-time employees, including medical, dental, vision coverage, stock purchase plan, and 401(k)
Wellness programs, including physical and mental health services
Flexible paid time off for full-time employees & paid leave for new parents
Rally Health believes in a policy of equal employment and opportunity for all people. It is our policy to train and promote individuals in all job titles, and administer all programs, without regard to race, color, religion, national origin or ancestry, citizenship, sex, age, marital status, pregnancy, childbirth or related medical conditions, personal appearance, sexual orientation, gender identity or expression, family responsibilities, genetic information, disability, matriculation, political affiliation, veteran status, union affiliation, or any other category protected by applicable federal, state or local laws.

Individuals with disabilities and veterans are encouraged to apply. Applicants who require an accommodation related to the application or review process should notify Talent Acquisition (recruiting@rallyhealth.com).

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",3.4,"Rally Health
3.4","Chicago, IL",1001 to 5000 Employees,2010,Subsidiary or Business Segment,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Data Engineer,"$77K-$86K
(Glassdoor Est.)","GoHealth is looking for Data Engineers who will be responsible for the design, development, and delivery of its various batch and streaming data pipelines. We are seeking candidates who have experience in building large batch pipelines, as well as experiencing building stable, high throughput streaming systems. In this role, you will work with other members of Engineering, Product and Project Management, and various business groups to ensure timely availability of usable data to all parts of the business that need it.

Due to the unprecedented situation of COVID-19, GoHealth has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities' and the CDC.

Responsibilities:
Design, develop and deploy batch and streaming data pipelines.
Monitor and ensure operational stability of data pipelines.
Create and maintain documentation of the technical detail design, operational support and maintenance procedures for all data pipelines.
Ensure data quality and compliance with development, architecture, reporting, and regulatory standards throughout entire data pipeline.
Collaborate with the rest of the Engineering Team, subject matter experts and department leaders to understand, analyze, build and deliver new data-related processes and/or reports.
Skills and Experience:
Bachelor's Degree in computer science or equivalent experience required.
2+ years of experience in the design and development of data pipelines and tasks.
Strong analytical and problem solving ability with strong attention to detail and accuracy.
Understanding of data warehousing concepts and dimensional data modeling.
Hands-on experience with troubleshooting performance issues and fine tuning queries.
Experience extracting data from relational and document databases.
Experience consuming data over HTTP and in formats such as HTML, XML, and JSON.
Knowledge of and experience with a version control system (such as Git, Mercurial, SVN, etc).
Proficiency in Java or Python programming languages.
Familiarity with data warehousing platforms, such as Redshift, Snowflake, SQL Server, etc.
Benefits and Perks:
Open vacation policy
401k program with company match
Medical, dental, vision, and life insurance benefits
Flexible spending accounts
Commuter and transit benefits
Professional growth opportunities
Casual dress code
Generous employee referral bonuses
Happy hours, ping-pong tournaments, and more company-sponsored events
Subsidized gym memberships
GoHealth is an Equal Opportunity Employer
#LI-JC1",3.1,"GoHealth
3.1","Chicago, IL",501 to 1000 Employees,2001,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Lead Audit Data Scientist,"$107K-$170K
(Glassdoor Est.)","Discover. A brighter future.

With Discover, you’ll have the chance to make a difference at one of the world’s leading digital banking and payments companies. From Day 1, you’ll do meaningful work you’re passionate about, with the support and resources you need for success. We value what makes each employee unique and provide a collaborative, team-based culture that gives everyone an opportunity to shine. Be the reason millions of people find a brighter financial future, while building the future you want, here at Discover.

Job Description


About Internal Audit

Discover’s Internal Audit (IA) Department has a commitment to provide insightful perspectives, leverage specialized talent, and deliver a refreshing experience to all of our stakeholders. This commitment is met through collaborative, hard-working, highly motivated, and technically skilled professionals who consistently deliver high-quality work in a challenging and fast-paced environment. IA brings a consultative and progressive approach to their work, which is predicated on a culture of enhancing risk management and business outcomes for Discover, actively contributing to the development of its professionals, and embracing a mindset of innovation and continuous improvement. The department of approximately 150 professionals globally is viewed as a critical piece of the risk management framework and is valued as a trusted voice and indispensable partner.

What You’ll Do
Lead the development and implementation of advanced analytics, including customer and behavioral segmentation, prescriptive analytics and machine learning capabilities to support DFS Internal Audit Department objectives.
Operate as a subject matter expert on statistical analysis, test and design of experiments, deployment of advanced analytics and modeling techniques.
Collaborate with cross-functional partners to understand their business needs and formulate and complete end-to-end analysis that includes data gathering, analysis and ongoing scaled deliverables.
Oversee assigned audit staff through the completion of the entire audit, perform independent reviews of model validations and related model risk monitoring activities to ensure compliance with policy and procedures as well as consistency in ratings, approval decisions and documentation of supporting rationale.
How You’ll Do It
Stay current with regulatory guidance and issuances, industry best practice, and business risk drivers that impact the state of the Model Risk Management framework to ensure that policy and procedures are adopted in a manner that minimizes model risk exposure consistent with company’s risk appetite.
Lead periodic meetings with internal audit management and the business units.
Contribute to the direction and focus of the Internal Audits activities through active engagement in risk assessment, audit planning, and continuous monitoring processes. Understanding the comprehensive vision on managing model risk and actively influence the Banks culture to exceed best practices on model hygiene.
Develop audit staff and educate team in area of expertise to improve the department skill set. (Define expectations with audit staff at the beginning of the audit. Provide leadership and guidance to team in area of expertise.)
Peer review staff audit code for completeness, effectiveness and accuracy.
Use knowledge of company/industry practices and processes to define key business risks, expected controls and to assess actual controls
Work closely with IT, operational, compliance and financial auditors to ensure a comprehensive and coordinated effort in covering the audit entity.
Establishes and maintains effective performance tracking; identify improvement opportunity, form hypothesis, proposes, designs and implements tests to drive strategy enhancement and optimization.
Manages multiple priorities, communicate business performance and project progress to management & business partners.
Develops and automates reports, iteratively build and prototype dashboards to provide insights at scale, solving for analytical needs. Facilitates implementation of work product and ensure accuracy.
Consistently follows standard work processes and documentation requirements. Recommends improvement to work processes to increase efficiency while maintaining quality of work.
Continuously improves technical and leadership skills through training and development.
Qualifications You’ll Need

At a minimum, here’s what we need from you:
Bachelor's Degree in Analytics, Engineering, or Statistics
4+ years of experience in Credit Risk, Fraud Risk, Marketing Analytics, Optimization, Operations Analytics, Modeling/Data Science or related.


Preferred Qualifications

Bonus Points if you have:
Master's Degree in Analytics, Engineering, or Statistics
2+ years of experience in Credit Risk, Fraud Risk, Marketing Analytics, Optimization, Operations Analytics, Modeling/Data Science; hands on experience in Machine Learning (supervised, unsupervised and ensemble methods), Natural Language Processing, Computer Vision, or Deep Learning applications
Solid theoretical understanding of advanced analytics and modeling methodologies
Experience with statistical modeling concepts, development, validation, or other related audit or compliance testing work
Proficiency in statistical and model development software packages and languages such as SQL, SAS, R, Python
Practical experience in risk based auditing, compliance, risk management activities or regulatory examinations
Knowledge about model risk and associated regulatory requirements such as SR11-7/15-19 is preferred
Experience in project management or Agile methodologies
CIA, CAMS, CRMC, CPA, CISA, or related certification
#LI-AP1

What are you waiting for? Apply today!

The same way we treat our employees is how we treat all applicants – with respect. Discover Financial Services is an equal opportunity employer (EEO is the law). We thrive on diversity & inclusion. You will be treated fairly throughout our recruiting process and without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status in consideration for a career at Discover.",3.9,"Discover
3.9","Riverwoods, IL",10000+ Employees,1985,Company - Public,Financial Transaction Processing,Finance,$5 to $10 billion (USD)
Data Engineer - Analytics,"$75K-$120K
(Glassdoor Est.)","Why VillageMD?

VillageMD is changing the trajectory of healthcare by empowering primary care physicians to make informed decisions and engage patients in meaningful ways. We work with thousands of clinicians and healthcare disruptors across the country to build and contribute to our platform to improve patient health while driving down the cost to deliver it.

We are a mission-oriented organization and are thrilled about the work that we do every day. We're transparent, collaborative, and relentless in pursuit of our mission, all while doing so with humility and a low ego. We believe that diverse backgrounds and experiences create the best opportunity for innovation and the community that we are creating is greater than any individual.

We've built our technology using the best of cloud and open-source technologies to create an open, data-first platform that is enriched with analytical models and modernly connected to internal and external apps. These apps drive clinical decision support, patient engagement, and other facilitators of innovative, information-enriched health experiences.

Data Engineers (Analytics) at VillageMD build distributed components, pipelines, and tools that enable our organization to make analytical, data-driven decisions. We're in a unique position to impact everyone in primary care from independent, family-owned practices to world-class health systems. We aggregate, process, and deliver rich datasets to improve the effectiveness of primary care for our doctors and patients.

What are examples of work that Data Engineers (Analytics) have done at VillageMD?
Built and implemented a data profiling tool to reverse engineer data schemas from new data sources facilitating normalization of the data into our data model
Created a summary data platform supporting our presentation layer that allows clinicians and operators in our practices to pinpoint interventions on-demand to patients most in need
Analyzed and designed the best ways to expand our data model to incorporate more data that's mission critical
What will make you successful here?
Strong analytical and technical skills
A real passion for problem solving and learning new technology
Vision to balance speed and maintainability in solution design
The ability to handle multiple, concurrent projects
Crafting and implementing requirements, keeping projects on track, and engaging partners
Challenging the status quo to improve our processes and tools
Communicating complex technical details in meaningful business context
A low ego and humility; an ability to gain trust by doing what you say you will do
What you might do in your first year:
Own ten projects to design and implement best-in-class data processing enabling clean data flow directly to our data model and on to our presentation layer
Work with analytics, engineering and operations to design and implement a new analytics product that supports improving patient health
Design a new concept within our data model to meet a new operational or analytical need
The following experience is relevant to us:
5+ years of full-time experience including extensive experience with healthcare data
Ability to understand and design relational data structures required
Very strong capabilities manipulating data using SQL
Knowledge of, and/or willingness to learn, non-relational data structures and other technologies (e.g. Postgres, Redshift, Cassandra, MongoDB, Neo4j, S3, etc.)
Experience or willingness to learn building information pipelines utilizing Python or Java a plus
BS/MS in computer science, math, engineering, or other related fields is required.
Track record of successfully executing projects with multiple partners
What can we offer you?
Competitive salary, bonus, and health benefits
Paid gym membership
Fun, fast-paced, startup environment (with snacks)
Pre-tax savings on commute expenses
Remote flexibility
A highly-collaborative, conscientious, forward-thinking environment that welcomes the impact you can make from Day 1.
A clear link between our daily work on products and services and the improved quality of healthcare that this work facilitates for patients.
At VillageMD, we see diversity and inclusion as a source of strength in transforming healthcare. We believe building trust and innovation are best achieved through diverse perspectives. To us, acceptance and respect are rooted in an understanding that people do not experience things in the same way, including our healthcare system. Individuals seeking employment at VillageMD are considered without regard to race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"VillageMD
4.0","Chicago, IL",1001 to 5000 Employees,2013,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Software Engineer in Big Data Infra,"$69K-$131K
(Glassdoor Est.)","Who we are


Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 305 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom, enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.

When applying for a job you are required to create an account, if you have already created an account - click Sign In.

Creating an account will allow you to follow the progress of your applications. Our system does have some requirements that will help us process your application, below are some guidelines for creation of your account:
Provide full legal First Name/Family Name – this is important for us to ensure our future hires have the right system set up.
Please Capitalize first letter of your First and Last Name.
Please avoid using fully capitalized text for your First and/or Last Name.
NOTE: If your name is hyphenated or has multiple capitalization, please use the same format as your government ID.
Job Description Summary:

We are solving one of the most impactful problems affecting productivity of data scientist and analysts - setting up and ephemeral environments. Our solution involves creating a highly scalable and available cloud infrastructure for PayPal’s data scientists to be able to explore PayPal’s 100+PB datasets. As an engineer in this group, you would get to work on cloud technologies and solve problems around building, managing, governing, automating and monitoring elastically scalable compute infrastructure for data scientists.

Job Description:

What you will work on
As an engineer you will be building services that can help operate and scale the infrastructure
Take responsibility for services you build
Work directly with Lead engineer, Architecture, Product Managers, Program Managers and stakeholders
Work directly with Product Managers, Program Managers, Data Scientists/Customers
Mentor engineers locally and globally
Analyze platform behavior to optimize resource usage and cost
Build services to support Multi-tenant environment with 100+ PBs in Datasets.
Job requirements

Basic Qualifications:
A successful candidate will be a strong engineer who can be part of a high performance engineering team, with excellent communication skills, and an ability to deliver results in a fast paced environment.
Excellent team player and great attitude. Willingness to understand and work through global software development approaches and inherent problems it surfaces
Experience with design and development of scalable services and platforms
3+ years’ experience in one or more of the following language: Golang (big plus), Java, C++, NodeJS, python and scripting.
Knowledge and experience with cloud technologies
Preferred Qualifications:
Experience with big data technologies like Spark
Experience with GCP Big data services
Experience with DevOps methodologies and tools for automating and monitoring
If you feel that your experience matches only some of the basic qualifications, please don't hesitate and apply to this role. Let us decide if you are a good fit.

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public as

Subsidiary:

PayPal

Travel Percent:

0

Primary Location:

San Jose, California, United States of America

Additional Locations:

Austin, Bellevue, Chicago, Los Angeles, Remote California, Remote Colorado, Remote Massachusetts, Remote Tennessee, Remote Texas, Remote Wisconsin, Scottsdale

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.",3.9,"PayPal
3.9","Chicago, IL",10000+ Employees,1998,Company - Public,Internet,Information Technology,$10+ billion (USD)
Field Application Scientist,-1,"Company Description

Personalized immunotherapies are the future of the fight against cancer, and IsoPlexis (www.isoplexis.com) is Making the Difference in enabling the lofty goal of employing immunotherapies to combat our toughest diseases. Our integrated systems, named #1 Innovation by Scientist Magazine & World-Leading Design by Red Dot, are changing cancer research by connecting biological readouts to what is actually happening in patients. Our game changing hardware technologies, originally from Cal Tech and Yale, combined with our next generation software and data visualizations, are powered by our amazing R&D team and used throughout the world. We work with a growing list of leading researchers who are publishing findings that connect our readouts to what is truly happening in patients, and that excites & drives all of us to do more! If you like working at the intersection of biological sciences and healthcare, and you enjoy intellectually challenging yet fulfilling projects, give us a call. Our fast growing, 140+ person team has a sense of integrity, energy, and urgency to ‘make things happen’ in our collective careers and in the broader world, and we look forward to talking.

IsoPlexis is welcoming self-motivated, high energy biologists who are looking for career growth working with cutting edge technology, to apply today!

Responsibilities
Support customers, vendors, and business partners on education and training of IsoPlexis instruments and technology
Partner with customers to ensure they are optimally using our protocols and products.
Pitch IsoPlexis to our customer base our new and exciting products and publications that have been released.
Collect data and assist Isoplexis Marketing/Communication team with the development of marketing materials.
Communicate all relevant customer information including product and/or customer experience or opportunities to Field Sales, Marketing, Internal Consulting Group and Technical Support. Including keeping CRM up to date with customer information and interactions
Actively pursues tasks/projects, and ways to enhance their team and the business beyond their day to day responsibilities
Travel 50% of the time
Desire to thrive in a light-speed start-up environment
Skills/Experience

· No FAS experience required

· Bachelor’s degree biology, or related field

· 2 yrs biological lab experience in a small lab is preferred, including experience with most basic laboratory techniques

· Biomedical or biotechnology industry background is preferred but not required

· Immunology/ flow cytometry a plus

· Ability to handle multiple tasks and meeting short-notice deadlines, with daily reprioritization of work

Traits

· Coachable

· Collaborative / Team Player

· Commitment to quality

· Self-motivated

· High energy

· Sense of humor

ISOPLEXIS is only considering applicants who have valid authorization to work in the U.S., in this position, for the Company. ISOPLEXIS does not sponsor employment-based visas for this position.

Job Type: Full-time

Required education:

· Bachelors

Job Type: Full-time

Pay: $60,000.00 per year

Benefits:
401(k)
Dental insurance
Health insurance
Life insurance
Paid time off
Vision insurance
Experience:
lab research: 3 years (Required)
wet lab environment: 3 years (Required)
immunology: 3 years (Required)
Education:
Bachelor's (Required)
Work Location:
On the road
Work Remotely:
Yes",4.0,"IsoPlexis
4.0","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
1030 Data Scientist,-1,"Position: Marketing Measurement Data Scientist
Location: Remote ok (Minneapolis, Chicago, or Milwaukee preferred but open to all locations)
Contract to Hire

Please see job description below:

Marketing Measurement (MTA) Data Scientist

Client is looking for a digital marketing data scientist to help build a multi-channel, multi-touch attribution (MTA) framework.
The role will work with the marketing and analytics team to rebuild the MTA framework across channels and devices using advanced attribution analytics, including conducting scenario analysis to evaluate impact of potential changes in marketing tactics on customer journey, conversions, and ROI.
This opportunity has potential to convert into permanent hire position.

Must Have Skills:
5+ years digital marketing quantitative performance measurement analytics
Extensive hands-on experience with multi-touch attribution (MTA) analytics and advanced MTA modeling (Markov, ML, advanced time decay) including cross-device and cross-channel measurement
Excellent understanding of digital marketing data and ad tech ecosystem including strong understanding of ad tech analytics
Strong experience of R and/or Python programming language
Professional experience with ML and statistical approaches such as ANOVA, regression, time-series modeling, PCA, decision trees, experimental design and clustering
Bachelors or advanced degree in quantitative field such as applied math, statistics, engineering, data science
Strong collaboration and cross-functional interaction skills
Desired Skills:
Minneapolis, Milwaukee, or Chicago preferred. Other locations/remote considered
Banking experience preferred
Sudhanshu Karmalkar
Technical Recruiter
ReqRoute, Inc
Phone: 415-691-4708
Email: sudhanshu@reqroute.com",4.0,"ReqRoute,Inc
4.0","Chicago, IL",1 to 50 Employees,-1,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (USD)
Data Engineer,"$75K-$139K
(Glassdoor Est.)","ActiveCampaign’s category-defining Customer Experience Automation Platform helps over 100,000 businesses in 170 countries meaningfully engage with their customers. The platform gives businesses of all sizes access to hundreds of pre-built automations that combine email marketing, marketing automation, CRM, and machine learning for powerful orchestration, segmentation and personalization across social, email, messaging, chat, and text. Over 70% of ActiveCampaign’s customers use its 300+ integrations including Shopify, Square, Facebook, Eventbrite, and Salesforce. ActiveCampaign scores higher in customer satisfaction than any other solution in both Marketing Automation and CRM All-In-One on G2.com.

As the fastest-growing SaaS company in Chicago, we are scaling rapidly to keep up with market demand. We are growing all of our teams and looking for people who share our values, deliver innovation frequently and join us in our mission to grow our customer base from 100,000 today to millions.

We are currently seeking a creative Data Engineer to join our Data Science team. At ActiveCampaign the Data Engineer will deal with terabytes of platform transactional data, user UI interaction time series, email and marketing content, user e-commerce trails, email enrichment tags, etc. Our team is passionate about leveraging value from this data for end user e.g. predict deal closures, predict best email send schedules, predictively suggest best email and marketing automation and much more. If this sounds like you and your next career move, then we would love to hear from you!

What your day could consist of:

Owns data loads between data lake, internal data structures, internal and external API’s
Brainstorms with data science team and suggest data and architectural solutions.
Participates in data exploration, analytics insight (machine learning models).
Maintains data science IT infrastructure (data stores, ETL tools, visualizations and runtime environments.
Validates any incoming data.
Helps with data science model productionalization as containerized micro service.

What is needed:

Script scheduled data manipulation (excellent python).
Excellent SQL skills.
Experience with common file and concept data structures (JSON, CSV, lists, dictionaries, data frames, etc.)
Ability to quickly grasp and troubleshoot internal and external API’s for data ingest and output.
Experience with AWS (access, admin, etc.)
Administer databases (SQL, no-SQL, etc.) for scale, stability, security, multi-user load management and performance
Administering ETL scheduling environments for global data validation and process stability
Experience with any data visualization and reporting tools (D3, Tableau, etc.)
Optimization of large data processes (500GB to -5TB)
Experience with both batch and streaming data processing
Desire to acquire//sharpen data science skills (statistical data exploration, machine learning, etc.)
Experience with any containerized micro service (preferred)
Experience with distributed data environments (Hadoop, Spark) (preferred)
Scripting in GO (preferred)
Experience implementing ETL processes with Airflow (preferred)
ActiveCampaign is an employee-first culture. We take care of our employees at work and outside of work. We'll share all the details later on but in summary: comprehensive health and wellness benefits including no premiums for employees on our HSA plan, open time off plan, generous 401(k) matching with no vesting, education budgets, ongoing learning and development, a proactive approach to diversity and inclusion, career pathing and lots of swag.",4.1,"ActiveCampaign
4.1","Chicago, IL",501 to 1000 Employees,2003,Company - Private,Computer Hardware & Software,Information Technology,$50 to $100 million (USD)
Supply Chain Data Scientist,"$65K-$109K
(Glassdoor Est.)","Topco Associates is currently seeking a Supply Chain Data Scientist to join our team in Elk Grove Village, IL.
The Supply Chain Data Scientist will utilize a blended approach of statistical, predictive, and optimization modeling methodologies to lead new analytical approaches, translate them into appropriate mathematical representations, and develop recommendations to solve business challenges. As a key part of Topco’s Supply Chain organization, this role collaborates with partners in sourcing/purchasing, category management, and logistics to define problems, identify data, establish predictive and prescriptive models, and deliver optimal solutions to support our demand planning strategy. This role will lead and continuously improve the Demand Planning process flow within the company and imbed advanced analytical solutions into everyday decision making and problem solving within Supply Chain.

Modeling
Develop advanced analytics applications from use case concept to experimental design to industrialization / deployment to end users
Develop and maintain predictive models of demand for Topco items at the Member (regional grocery retailer and wholesaler) and consumer level
Define, develop and implement robust, efficient, and scalable algorithmic based learning models (including regression models) in SAS or other statistical software
Research, design, develop, test, and implement data science methodologies across a wide range of business applications
Work as a data strategist and predictive modeler by researching, identifying and integrating datasets and innovative algorithms that drive products and services forward
Analyze performance of forecast models and quickly identify root cause of underperformance
Demand Planning
Create accurate demand plans in business categories by utilizing statistical forecasting tools, historical data, and sales projections from cross-functional partners for a business category
Understand dependencies and tradeoffs of promotions, price, cross item derived demand that predict and fine tune regional grocery retailer and wholesaler needs
Improve existing methodologies by developing new data sources, test model enhancements, and fine-tune model parameters; implement enhancements to the forecasting process resulting in improved forecast accuracy, inventory bias, and customer service levels
Incorporate item-customer-warehouse level forecast updates from the customer, sales, and planning into the system forecast
Monitor store sales, macro/micro economic factors and constantly evaluate how to best predict demand
Maintain accuracy of planning data
Manage metrics such as Demand Accuracy and Variance to appropriate thresholds
Collaboration & Strategic Management
Hold collaborative planning meetings with suppliers to ensure they understand the need and cadence for production and ensure that suppliers have an accurate, time phased view of future demand
Coordinate with Category Management and Sourcing to integrate human based intelligence into the demand models
Serve as a central knowledge center for relevant data science tools and techniques
Present insights and recommendations to audiences at the desired levels of understanding
Mentor and develop the technical skills of analysts

Bachelor's degree in Statistics, Computer Science, Mathematics, Operations Research, Economics, Engineering or equivalent.
Master’s degree in data science, predictive analytics, mathematics or statistics preferred
Excellent analytical and quantitative skills
Proficient at gathering and manipulating large datasets
Experience developing predictive/self-learning AI or ML tools
Ability to communicate well with others
Strong statistical background, with an emphasis in predictive modeling.
Strong Experience writing queries and conducting analysis with data manipulation and analysis tools (R, Python, SAS, SQL) and techniques (machine learning, statistical analysis).
2+ years professional experience applying statistical modeling in an operations environment, preferably in supply chain for a retail organization.
Other qualifications:
A self-starter with strong passion for success
Highly adaptive to a fast-moving environment
Ability to prioritize and deliver on multiple threads of work
Track record of personal initiative and ability to drive change
Strong interpersonal skills and teamwork spirit
Excellent communication skills and ability to present detailed analytical results to executives in verbal or written form, especially in PowerPoint format",3.4,"Topco Associates
3.4","Elk Grove Village, IL",201 to 500 Employees,1944,Company - Private,Wholesale,Business Services,$10+ billion (USD)
Physical Scientist,"$106K-$139K
(Glassdoor Est.)","The Department of Energy is seeking motivated and highly-qualified candidates for exciting positions available in multiple locations throughout the United States.

The mission of the Energy Department is to ensure America’s security and prosperity by addressing its energy, environmental and nuclear challenges through transformative science and technology solutions.

To learn more about the Department of Energy, please visit the website at www.energy.gov.

This position has a positive education requirement. Therefore, you MUST provide documentation supporting any education claims in your application. This documentation can include unofficial transcripts or any report listing institution, course title, credits earned and final grade. For specific education requirements, please see the Education Requirements. If selected, official transcripts may be requested.

Education must be obtained from an accredited institution recognized by the U.S. Department of Education.
Foreign education must be reviewed by an organization recognized by the U.S. Department of Education. For special instructions pertaining to foreign education and a list of organizations that can evaluate foreign education, see the Department of Education website.

This series includes positions that involve professional work in the physical sciences and may include work in a combination of physical science fields.

As a Physical Scientist, at minimum you will:
Provide scientific advice and guidance to officials, managers, scientists, and engineer.
Serve as an expert for a significant segment of a specific area in one or more of the following: advanced scientific computing research; basic energy sciences; biological and environmental research; fusion energy sciences; high energy physics; nuclear physics; and workforce development.
Provide technical guidance on proposed research projects and programs of interest.
Coordinate, implement, and evaluate segments of research programs in the assigned area of responsibility.
Assemble essential information on topics of assigned segments of research through various source materials.
Basic Requirement:

A. Degree: physical science, engineering, or mathematics that included 24 semester hours in physical science and/or related engineering science such as mechanics, dynamics, properties of materials, and electronics.

or

B. Combination of education and experience: education equivalent to one of the majors shown in A above that included at least 24 semester hours in physical science and/or related engineering science, plus appropriate experience or additional education.

You must meet the Basic Requirement and""Specialized Experience"" to qualify for this series as described below.

SPECIALIZED EXPERIENCE REQUIREMENTS

The specialized experience listed are the minimum requirements for the series, each particular vacancy may have additional experience necessary to meet the applicable grade level.

A qualified candidate's online application and resume must demonstrate at least one year of specialized experience equivalent to the next lower grade level in the Federal service. Specialized experience for these positions are defined as:

GS-11: You must have one year of experience at a level of difficulty and responsibility equivalent to the GS-09 grade level in the Federal service. Experience includes conducting site investigations and surveys to determine compliance requirements; participating in policy and guidance development to enable organizational implementation of policy or program initiatives; assisting in preparing technical reports, standard operating procedures, correspondence, and local guidance documents to achieve and support compliance with Federal and local guidelines; and providing research and science support information for program policy or program management.

OR

3 years of progressively higher level graduate education leading to a Ph.D. degree or Ph.D. or equivalent doctoral degree.

GS-12: You must have one year of experience at a level of difficulty and responsibility equivalent to the GS-11 grade level in the Federal service. Experience includes communicating progress, status, and approval in order to evolve efficient and technically adequate responses; providing assistance in the planning, coordination, implementation, and evaluation of research programs; analyzing regulations to resolve environmental compliance issues during project execution; leading a research group and/or project; and/or assisting with monitoring program implementation and making recommendations on the allocation of resources.

NOTE: There is no substitution of education for specialized experience at the GS-12 level.

GS-13: You must have one year of experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Experience includes communicating progress, status, and approval in order to evolve efficient and technically adequate responses; preparing reports to recommend solutions to compliance issues; performing consulting or other professional, scientific, technical, administrative, fiscal, or other specialized work; and/or performing management planning duties such as concept development, master integration planning, and programming design for programs or projects, taking into account feasibility, costs, and economics.

NOTE: There is no substitution of education for specialized experience at the GS-13 level.

GS-14: You must have one year of experience at a level of difficulty and responsibility equivalent to the GS-13 grade level in the Federal service. Experience includes performing consulting or other professional, scientific, technical, administrative, fiscal, or other specialized work; reviewing and evaluating program priorities and conduct periodic scientific reviews to evaluate facility performance; preparing, justifying, and supporting the portions of the budget relating to the program; and/or analyzing regulations to resolve compliance issues during project execution.

NOTE: There is no substitution of education for specialized experience at the GS-14 level.

GS-15: You must have one year of experience at a level of difficulty and responsibility equivalent to the GS-14 grade level in the Federal service. Experience includes evaluating the effect of technical developments on fundamental policies, objectives and goals; developing new concepts, plan, and evaluate long-range programs and projects; planning and executing specialized programs on scientific, technical, administrative, and fiscal matters; and/or developing and managing funding for scientific research programs, determining funding levels, and recommending proposal, denials and program determinations for assigned programs.

NOTE: There is no substitution of education for specialized experience at the GS-15 level.

""Experience"" refers to paid and unpaid experience. Examples of qualifying unpaid experience may include: volunteer work done through National Service programs (such as Peace Corps and AmeriCorps); as well as work for other community-based philanthropic and social organizations. Volunteer work helps build critical competencies, knowledge, and skills; and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.

CTAP/ICTAP candidates: To be considered""well qualified"" you must meet all of the requirements as described in this section.

This public notice may be used to fill multiple positions as needed; therefore, applicants must meet the qualifications at the time the applications are reviewed.

OPM Qualification Standards for the GS-1301 series can be found at the following website: https://www.opm.gov/policy-data-oversight/classification-qualifications/general-schedule-qualification-standards/1300/general-physical-science-series-1301/",3.7,"US Department of Energy
3.7","Chicago, IL",10000+ Employees,1977,Government,Federal Agencies,Government,Unknown / Non-Applicable
Data Engineer,"$74K-$130K
(Glassdoor Est.)","About Our Team:

DRIVIN is looking to expand our data team as we continue to grow our data platform in support of a mission of digital transformation in automotive wholesale markets. The data engineering team is responsible for the ingestion and persistence of data supporting an array of data products supporting KAR Global’s automotive wholesale business.

DRIVIN has a polyglot data model using many cutting-edge data platforms including AWS Redshift for Data Warehouse, Elastic Search for location-based searching, and Postgres for transactional data and product delivery. Our delivery framework is comprised of Python/Docker on ECS, Spark on EMR, and Jenkins for CI/CD and a roadmap focused on strategic data integrations and products and expansion of platform capabilities including Snowflake and Informatica.

About Our Candidate:

This candidate should be a self-starter who is interested in learning new systems/environments and is passionate about developing quality supportable data service solutions for internal and external customers. We value natural curiosity about data and technology that drives results through quality, repeatable, and long-term sustainable database and code development. The candidate should be highly dynamic and excited by the opportunities to learn many different products and data domains and how they drive business outcomes and value for our customers.

What You Will Be Doing:

Members of the Data Engineering team participate daily in ceremonies of Agile sprint to help design, plan, build, test, develop, and support DRIVIN’s data products and platforms consisting of Pythion ETL pipelines and Postrgres, Redshift, Dynamo DB, and Elastic search, and Snowflake databases. Our team works in a shared services delivery model supporting seven lines of business, including front-end customer facing products, B2B portals, mobile applications, business analytics, and data science initiatives.

Responsibilities include:
Work with product, data science, analytics, and engineering teams to learn project data needs and define project scope
Design and planning of data services solutions on the Drivin DAAS Platform
Building and delivery of Python/Docker feed framework data pipeline jobs and services
Contribute to the Data Engineering team delivery framework including building of re-usable code, implementing industry best practices, and maintain a common delivery framework
Monitoring, maintenance, documentation, and incident resolution of scheduled production data jobs supporting internal and external customers data needs
What You Need to Be Successful:
5+ years experience Postgres SQL development including functions, stored procedures, and indexing or equivalent (required)
Experience in production data management in high availability product delivery ODS / RDBMS or equivalent (required)
Experience planning and designing maintainable data schemas (required)
Experience with Python, Docker, and data warehouse environments (preferred)
Experience using Github / Jenkins (CI/CD) / Artifactory / PyPy or comparable delivery stacks (preferred)
Experience with Postgres, Elastic Search, AWS EMR, and AWS ECS (preferred)
Experience with AWS Redshift, MPP, or Dynamo DB (preferred)
Experience with Kinesis/Kafka (preferred)
Experience working with large enterprise data lakes / Snowflake (preferred)
Who We Are:

KAR Global powers the world’s most trusted automotive marketplaces through innovation, technology and people. Our end-to-end platform serves the remarketing needs of the world’s largest OEMs, dealers, fleet operators, rental companies and financial institutions.
We’re a technology company delivering next generation tools to accelerate and simplify remarketing.
We’re an analytics company leveraging data to inform and empower our customers with clear, actionable insights.
And we’re an auction company powering the world’s most advanced and integrated mobile, digital and physical auction marketplaces.
DRIVIN, a KAR Global brand, is comprised of a team that is passionate about the intersection of data, technology and cars. As the Chicago-based innovation and data science hub for KAR, this team of data scientists and analysts creates new products to help power the company’s physical, online, and digital/mobile automotive auction marketplaces. DRIVIN was founded in 2015 and joined the KAR family of companies in April 2017. Since then, DRIVIN has expanded its capabilities across the organization, shifting from a transactional marketplace to a full-service data and analytics platform. The DRIVIN data engine is unmatched, fueling powerful insights and recommendations that help KAR’s customers optimize risk, price and automotive inventory.

We want you to be well and thrive. Our benefits package includes:
Competitive compensation
Insurance coverage that includes medical, dental, vision and life insurance
Flexible spending account
Wellness program
401(k) with employer match
Employee stock purchase program
Paid holidays and generous paid time off
Paid parental leave
Learning and development resources
Job Type: Full-time

Pay: $0.00 per year

Schedule:

Monday to Friday
COVID-19 considerations:
Our employees are working remotely with the intent to have the option to work in the office in the future.

Company's website:
karglobal.com
Company's Facebook page:
https://www.facebook.com/KARglobal
Work Remotely:
Temporarily due to COVID-19",3.0,"KAR Global
3.0","Chicago, IL",10000+ Employees,2007,Company - Public,Wholesale,Business Services,$2 to $5 billion (USD)
"Applied Data Scientist, Commercial","$61K-$102K
(Glassdoor Est.)","What we do

At Civis, we take a science-first approach to solving problems. With a blend of proprietary technology and statistical advisory services, we help public and private sector organizations find, understand and connect with the people they care about, so they can stop guessing and start using mathematical proof to guide decisions. We know others use “data science” and “analytics” as buzzwords, but at Civis we don’t stand for fluff, and we will always deliver scalable products and technologies — not PowerPoints — to drive your business forward. Learn more about Civis at www.civisanalytics.com.

Our mission

Our mission is to bring objective, data-driven truth to organizational decision-making – all the way from the boardroom to the world’s largest social causes.

What we are looking for

Are you interested in using data science to solve new and challenging problems in innovative ways — like helping a green energy startup find new areas of growth, building a resource optimization solution for a healthcare provider network, or shaping the product and engagement strategy for a large Fortune 500 company? Civis Analytics is looking for an Applied Data Scientist to join our commercial ADS practice in Chicago and help us solve some of the most challenging and interesting questions facing businesses today.

The Applied Data Science (ADS) team is the solutions and advisory arm of Civis Analytics and works closely with organizations to help solve their toughest challenges with data science. This role of Applied Data Scientist will support clients in our commercial verticals specifically and report to an Applied Data Science Lead.

Responsibilities
An Applied Data Scientist is responsible for the end-to-end execution of client engagements utilizing data science, which includes:
Unifying large 1st- and 3rd-party datasets and building predictive models
Deriving clear, actionable, and timely insights from analyses
Creating client-ready materials and solutions for stakeholders of varying technical experience or familiarity with methods
Working with cross-functional teams of data scientists and software engineers where necessary to create and implement solutions
Other job responsibilities of an Applied Data Scientist include:
Creatively identifying opportunities in the solution delivery process for scalable applications, and collaborating with other teams to further construct these tools
Maintaining a continuous and independent education of cutting-edge statistical techniques and programming languages
Travel requirements:
Qualifications
Bachelor’s degree in an analytical subject (statistics, math, economics, physics, engineering, business, political or social science, computer science, etc.)
Proven affinity for and experience working with large or messy data sets
SQL experience a plus
Experience with statistical programming languages (R, Python, etc.) and proven ability to work pragmatically with statistical concepts
Experience with presentation or data visualization software, such as Microsoft PPT, Tableau, Shiny, etc.
Excellent interpersonal and communication skills
US work authorization
Preferred Qualifications
Practical understanding of and experience with predictive analytics, machine learning, and/or causal inference
Familiarity with software development tools and practices (Git, code review, etc.)
Who we are

At Civis, we have opportunities for applicants who are newcomers, seasoned professionals, and anywhere in between. Our teams are energized by complex challenges and value diversity of thought. Opportunities to stand out and inspire happen daily and we trust and encourage you to act on your ideas – no matter how big they are. We offer you the tools and community you need to do your best work. Each of us is committed to holding ourselves accountable for results, challenging the status quo and finding new ways to grow our company and each other.

Why join our team?
The opportunity to be part of a growing tech startup focused on solving interesting and meaningful problems, invested in internal promotion, and committed to fostering a diverse, equal and inclusive workplace.
Competitive benefits, including unlimited PTO, 401K match with immediate vesting, health, dental, and vision benefits, fully paid parental leave, breastfeeding support including breastmilk shipping services for traveling moms, commuter benefits, wellness initiatives including weekly group meditations, monthly on-site massage therapy, and pet insurance.
To support employees in our now fully remote work environment, we also have expanded our virtual journal and book clubs, Donut Pals (organized virtual coffee meet-ups), Lightning Talks (5-minute presentations on anything you’d like), Lunch-and-Learns, and HR Open Discussions (bi-weekly meet-up where we discuss ideas and topics of the day in a casual format). We are also able to support and accommodate flexible work from home schedules to help employees juggle responsibilities at home.
Civis Analytics embraces the individuality of our employees and we celebrate each other's differences. Our products, services, and culture benefit from and thrive on the unique perspectives brought by each person in our community. We're proud to be an equal opportunity workplace, and we are committed to equal employment opportunity regardless of race, age, sex, color, ancestry, religion, national origin, sexual orientation, gender identity, citizenship, marital status, disability, or Veteran status. If you have a disability or special need that requires accommodation, please contact internalrecruiting@civisanalytics.com

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States.

EEO IS THE LAW

EEO Supplement

Pay Transparency",3.2,"Civis Analytics
3.2","Chicago, IL",51 to 200 Employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,$25 to $50 million (USD)
Sr. Data Scientist,"$94K-$151K
(Glassdoor Est.)","About Our Team:

At our core, we are an analytics company. The insights we gain from our analyses guide our strategic path forward as we grow revenue, enter new markets, and strengthen our customer relationships. The Data Science team proactively leads and collaborates to identify the most valuable problems to solve, constructs a Roadmap to delivery, and executes our plan. All of the outputs of the Data Science team models will feed into the Product portfolio at DRIVIN, aiding tens of thousands of internal and external stakeholders in their decision-making processes.

About Our Candidate:
Can think for themselves and discover new and insightful ways to solve difficult problems without having a clear roadmap laid out
Can communicate effectively with data science teammates and non-technical audiences alike
Can deliver quality code in an Agile framework that ships to a production environment
Has confidence, hustle, energy, and drive – accountability is key and the impact of your work is crucial to our success
What You Will Be Doing:
Own the development of predictive modeling and machine learning for data products helping to optimize the value and efficiency of our business
Run experiments to measure model performance and build visualizations to communicate important performance metrics to a non-technical audience
Work in an Agile environment with team members, delivering solutions quickly and continuously exploring ways to improve our results
Work closely with colleagues in Engineering, Product, Operations, and Sales to structure problems and understand the impact across various departments within the company
What You Need to Be Successful:
Candidates tend to have at least a Bachelor's Degree in a quantitative field, but if you can explain how your experience and background can be leveraged as a senior contributor to a data science team we are all ears
Significant experience (roughly 5 years) in a Data Science, Deep Learning, or Machine Learning position building data products in a production environment
Experience in the full project lifecycle from requirements gathering to proof of concept to production delivery
Experience designing and implementing machine learning models that are production-ready
Experience coding with Python and SQL
Experience with developing within a cloud environment. Amazon Web Services preferred
Familiarity with the Agile framework for software delivery
Who We Are:

KAR Global powers the world’s most trusted automotive marketplaces through innovation, technology and people. Our end-to-end platform serves the remarketing needs of the world’s largest OEMs, dealers, fleet operators, rental companies and financial institutions.
We’re a technology company delivering next generation tools to accelerate and simplify remarketing.
We’re an analytics company leveraging data to inform and empower our customers with clear, actionable insights.
And we’re an auction company powering the world’s most advanced and integrated mobile, digital and physical auction marketplaces.
DRIVIN, a KAR Global brand, is comprised of a team that is passionate about the intersection of data, technology and cars. As the Chicago-based innovation and data science hub for KAR, this team of data scientists and analysts creates new products to help power the company’s physical, online, and digital/mobile automotive auction marketplaces. DRIVIN was founded in 2015 and joined the KAR family of companies in April 2017. Since then, DRIVIN has expanded its capabilities across the organization, shifting from a transactional marketplace to a full-service data and analytics platform. The DRIVIN data engine is unmatched, fueling powerful insights and recommendations that help KAR’s customers optimize risk, price and automotive inventory.

We want you to be well and thrive. Our benefits package includes:
Competitive compensation
Insurance coverage that includes medical, dental, vision and life insurance
Flexible spending account
Wellness program
401(k) with employer match
Employee stock purchase program
Paid holidays and generous paid time off
Paid parental leave
Learning and development resources
Job Type: Full-time

Pay: $0.00 per year

Schedule:

Monday to Friday
COVID-19 considerations:
Our employees are working remotely with the intent to have the option to work in the office in the future.

Company's website:
karglobal.com
Company's Facebook page:
https://www.facebook.com/KARglobal
Work Remotely:
Temporarily due to COVID-19",3.0,"KAR Global
3.0","Chicago, IL",10000+ Employees,2007,Company - Public,Wholesale,Business Services,$2 to $5 billion (USD)
Principal Data Scientist 200000CC,-1,"Principal Data Scientist 200000CC
Work Location: Columbus, IN (During Covid19 duration, remote work highly probable)

No, this isnt one of those ordinary jobs.
We are a team of dependable, innovative thinkers, who are empowered to generate and deliver solutions for customers, community, and environment. Our employees develop their careers through the challenges only a diverse, global innovator can promise. This is a collaborative culture where thinking beyond your desk is more than part of the job. It is the job.

Description
Technology. Flexibility. Diversity. At the center of it all are the Digital Accelerator and Advanced Analytics teams and working together as a high-energy startup within a Fortune 500 organization. At this Midwestern technology hub, todays sharpest, most curious minds transform what-ifs into realities.
Youll have global opportunities to develop your career and make your community a better place - to break ground professionally and be your best personally.
This is an exciting opportunity in Columbus, IN for a Principal Data Scientist
Manages and Implements advanced analytics projects which solve complex analytical problems using quantitative approaches through a combination of analytical, mathematical and technical skills
Researches, designs, implements and validates cutting-edge algorithms to analyze diverse sources of data to achieve targeted outcomes by leveraging complex statistical and predictive modeling concepts, machine-learning approaches, clustering and classification techniques
Liaises with business stakeholders and leverages business knowledge to industrialize and monetize insights from advanced analytics projects
Leads key objectives and business goals through the use of data science methodology
Leverages data science methodology to more complex business problems
Creates algorithms using more complex statistical methodologies through the use of statistical programming languages and tools
Partners with domain experts to verify model capabilities and translate modeling outputs from statistical inferences into business language
Partners with IT resources to enable appropriate data flow/data model, development using appropriate tools/technology, rapid prototyping and informs the design of analytical products
Trains and mentors less experienced employees on data science tools and methodologies.
Experience
Minimum of 7 years of professional experience
Skills
Abstract Reasoning - Envisions a solution before implementation by analyzing data, extracting patterns and relationships to establish a problem or solution's feasibility; develops new algorithms and analytical models using process diagrams, flow charts, and textual documentation to explain or conceptualize a complex problem.
Data Mining - Identifies relationships and patterns in data by using a suite of data exploration and data visualization techniques using tools such as PowerBI, R Shiny, SAS JMP, and extracts insights into multivariate data by applying principles of multivariate data mining, small sample statistical inferential tests, dimension reduction techniques to understand the underlying structure of the data and enable sound conclusions upon model building.
Predictive Modeling - Develops statistical and machine learning models using appropriate variable transformations, feature selection strategies, imputation strategies, class rebalancing, resampling strategies and performance metrics to generate descriptive, explanatory or predictive models.
Statistical Foundations - Builds statistical explanatory models for regression, classification, outlier detection, anomaly detection, time series forecasting using knowledge of foundational statistics such as Null Hypotheses Significance Tests, regression models, generalized linear modeling, time series analysis, rank statistics, probability distribution fitting survival analysis, etc. to validate hypotheses or generate predictions for any given statistical or business question.
System Simulation - Creates models of interconnected systems under dynamic operating conditions using mathematical models for physical and mechanical systems (such as Markov chains and Monte Carlo methods) and various simulation packages to reproduce the behavioral characteristics of the system(s) being simulated and to gain insight into how the system(s) reacts under different operating conditions.
Requirements Analysis - Evaluates relationships and interdependencies between requirements based upon their complexity and value to the business in order to determine feasibility and prioritization.
Strategic Roadmap Planning - Produces a high-level, multi-year product and capability roadmap utilizing internal and external business resource, asset and market knowledge and experience to communicate the organization's focus and priorities to internal and external stakeholders.
Customer focus - Building strong customer relationships and delivering customer-centric solutions.
Manages complexity - Making sense of complex, high quantity, and sometimes contradictory information to effectively solve problems.
Balances stakeholders - Anticipating and balancing the needs of multiple stakeholders.
Directs work - Providing direction, delegating, and removing obstacles to get work done
Drives results - Consistently achieving results, even under tough circumstances.
Education, Licenses, Certifications
College, university, or equivalent degree in statistics, information systems or related field required.
PhD or Masters degree in Statistics, Econometrics, Computer Science, or equivalent experience preferred.
Compensation and Benefits
Base hourly rate commensurate with experience . Additional benefits vary between locations and include options such as our 401(k) Retirement Savings Plan, Cash Balance Pension Plan, Medical/Dental/Life Insurance, Health Savings Account, Domestic Partners Coverage and a full complement of personal and professional benefits.
E-verify
We are an equal opportunity and affirmative action employer dedicated to diversity in the workplace. Our policy is to provide equal employment opportunities to all qualified persons without regard to race, gender, color, disability, national origin, age, religion, union affiliation, sexual orientation, veteran status, citizenship, gender identity and/or expression, or other status protected by law. Cummins validates right to work using E-Verify.
We will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS), with information from each new employees Form I-9 to confirm work authorization. To learn more about E-Verify, including your rights and responsibilities, please visit www.dhs.gov/E-Verify .",2.0,"Tech-Connect
2.0","Chicago, IL",1 to 50 Employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,$1 to $5 million (USD)
Data Analyst,"$38K-$69K
(Glassdoor Est.)","Data Analyst
Submit
#495754
/
Regular Full-Time
/
Chicago – 55 East Monroe Street, IL
/
Statistics & Methodology
JOB DESCRIPTION:
NORC at the University of Chicago is seeking a Data Analyst to support a diverse range of research projects. At NORC, Data Analysts work with our Data Scientists, and play a strategic role in supporting our research teams to produce valuable insights for our clients. They work collaboratively and help break down silos and barriers across the company to help drive innovative work. A person in this position, under the leadership of Data Scientists, contributes to the design and implementation of algorithms, models, and work flows to discover valuable information in large volumes of data from various sources; organizes, harmonizes, and analyzes data sets; uses various technologies to enable data visualization; and creates applications of general value to the company’s business.

Due to current COVID-19 safety measures, employees who can work from home, are required to do so. Once it is safe to resume standard practices of commuter travel and social interaction per government guidelines, we expect employees to maintain an office presence as required by projects needs and department leadership.
DEPARTMENT:
The Statistics and Methodology department pioneers innovations in survey research, analytics, and data science. We work in collaboration with all NORC subject area departments, while also conducting our own industry research. In the survey research arena, members of our team help understand the cognitive processes underlying respondents’ reactions to surveys; design and implement rigorous, efficient methods for sampling from populations and weighting resultant survey data; and employ advanced techniques for analyzing and interpreting survey and secondary data. NORC statisticians utilize a broad range of analytic methods such as predictive modeling, survival analysis, item response theory, latent variable analysis, small area estimation, GIS/spatial analysis, psychometrics, and econometrics in deriving insights from data. NORC data scientists apply advanced techniques such as machine learning, natural language processing, data linkage, data visualization, network analysis, optimization, simulation, and parallel processing in working with large and multiple datasets.
RESPONSIBILITIES:
Interpreting data from multiple sources;
Developing programs and scripts for data transformation, integration, or reduction;
Enhancing previously developed in-house applications such as those for data coding;
Perform various types of analysis involving multiple data sets.
REQUIRED SKILLS:
Bachelor’s degree in one of the following fields: math, statistics, computer science, data science, or a social science or public policy related field.
At least two years’ experience in positions of increasing responsibility, preferably working with large data sets and conducting statistical and quantitative modeling, melding analytics with programming, data mining, clustering and segmentation is required.
Strong foundation in areas of statistics, mathematics, and computer programming. Additional expertise in areas of data mining such as topic modeling, natural language processing, and machine learning preferred
Strong skills in problem solving and quantitative/qualitative analysis are required. Able to organize and prioritize work assignments to meet project needs.
Some familiarity with the social science domain is preferred.
Strong communication skills; able to quickly comprehend requirements and assignments and then explain his/her solutions in both writing and speech.
WHAT WE DO:
NORC at the University of Chicago is an objective, non-partisan research institution that delivers reliable data and rigorous analysis to guide critical programmatic, business, and policy decisions. Since 1941, our teams have conducted groundbreaking studies, created and applied innovative methods and tools, and advanced principles of scientific integrity and collaboration. Today, government, corporate, and nonprofit clients around the world partner with us to transform increasingly complex information into useful knowledge.
WHO WE ARE:
For over 75 years, NORC has evolved in many ways, moving the needle with research methods, technical applications and groundbreaking research findings. But our tradition of excellence, passion for innovation, and commitment to collegiality have remained constant components of who we are as a brand, and who each of us is as a member of the NORC team. With world-class benefits, a business casual environment, and an emphasis on continuous learning, NORC is a place where people join for the stellar research and analysis work for which we’re known, and stay for the relationships they form with their colleagues who take pride in the impact their work is making on a global scale.
EEO STATEMENT:
NORC is an affirmative action, equal opportunity employer that values and actively seeks diversity in the workforce. NORC evaluates qualified applicants without regard to race, color, religion, sex, national origin, disability, veteran status, sexual orientation, gender identity, and other legally- protected characteristics.
8.7.2020
/
Back",3.1,"NORC at the University of Chicago
3.1","Chicago, IL",1001 to 5000 Employees,1941,Nonprofit Organization,Research & Development,Business Services,$100 to $500 million (USD)
Computational Scientist,"$32K-$60K
(Glassdoor Est.)","Please make sure to read the job posting in its entirety as it reflects both the University roles and responsibilities, followed by the specific description.
Department
86755 Research Computing Center
About the Unit
The University of Chicago Research Computing Center (RCC), a unit in the Office of Research and National Laboratories (RNL), provides high-end research computing resources to researchers at the University of Chicago. It is dedicated to enabling research by providing access to centrally managed High Performance Computing (HPC), storage, and visualization resources. These resources include hardware, software, high-level scientific and technical user support, and the education and training required to help researchers make full use of modern HPC technology and local and national supercomputing resources. The Office of Research and National Laboratories oversees the conduct of sponsored research, research program development, multi-institutional research institutes, national laboratory board, and contract management functions. RNL supports the development and coordination of research-related communications and educational programs at The University of Chicago. RNL oversees the management of two Department of Energy contracts for Argonne National Laboratory and Fermi National Accelerator Laboratory. When combined with the Lab R&D budgets, the office oversees approximately $1.4 billion in sponsored research. RNL works closely with individual scholars, departments, and divisions to encourage, seed, and coalesce research across the University, Argonne, and Fermilab campuses.
Job Family
ResearchResponsible for all aspects of research projects and research facilities. Plans and conducts clinical and non-clinical research; facilitates and monitors daily activities of clinical trials or research projects. Directs engineering and technical support activities to develop and maintain tools and computational methods needed to gather and analyze data.
Career Track and Job Level
Research ComputingCreates research focused user interfaces web front-ends, back-end services that scale, and integrate scientific workflows that automate and accelerate the scientific output of multi-institutional collaborative projects. This role involves software development in support of research projects involving data acquisition, ingestion, and integration from heterogeneous sources (metadata extraction from a corpus of diverse data sets, both structured and unstructured data).P2: Requires knowledge and experience in own discipline; still acquiring higher-level knowledge and skills. Builds knowledge of the organization, processes and customers. Solves a range of straightforward problems. Analyzes possible solutions using standard procedures. Receives a moderate level of guidance and direction.
Role Impact
Individual Contributor
Responsibilities
The job develops software to support the data acquisition, ingestion, and integration for research projects. Assists in the development of user interfaces and scalable back-end services to automate and accelerate the scientific output of multi-institutional research projects.1) Participates in the product development life cycle, providing professional assistance to the design of front-end applications and database systems back-end schema. Analyzes high-level system specifications and makes sure that all application development standards are met., 2) Develops and presents technical training materials and web-based documentation. Ensures timely systems support and updates. Assists in conducting information security assessments and risk analysis of computing environment., 3) Evaluates past and present technologies to help develop new tools. Ensures all the new tools have been through quality control reviews., 4) With a moderate level of guidance, provides hardware, user and application level authentication and authorization. Implements modern web authentication methods such as XACML, SAML, OAuth2, Shibboleth, and LDAP directory server administration. Applies theoretical expertise and innovation to create or apply new technology, such as adapting principles for applying computers to new uses., 5) Performs other related work as needed.

Job Summary

The Research Computing Center and the Chevrier Lab at the Pritzker School for Molecular Engineering are looking for a highly motivated Computational Scientist to work closely with faculty and researchers at the University of Chicago. The successful candidate will play a key role in characterizing and engineering the immune system in health and disease by working with the Chevrier Lab and in collaboration with researchers and clinicians at the University of Chicago and beyond. Emphasis will be to (i) generate new biological insights by developing new approaches to analyzing large-scale and high-throughput data (e.g., next-generation sequencing, high-throughput screening), (ii) maintain, upgrade and train users on existing pipelines in the lab, and (iii) develop new pipelines as needed.

Unit-Specific Responsibilities

1) Develop, apply, document, and maintain computational tools, both for own use and to support analysis by biologist colleagues without formal computational training; critically evaluate computational solutions.

2) Develop customized computational solutions supporting new kinds of assays and experiments; understand the analytical needs of new experiments, working closely with wet-lab experimental biologists.

3) Implement and optimize successful algorithms and methods to be shared for use by the broader community.

4) Develop figures and reports, which provide transparency into the data quality and characteristics, and automate the production of such reports as routine components of computational analysis pipelines.

5) Report data to supervisor and team, attend team meetings to share results, plan projects and experiments, and ensure that projects support current team goals.

6) Maintain and organize computational infrastructure and resources.

7) Contribute to generation of protocols, publications, and intellectual property.

Unit-Preferred Competencies

1) Understand and translate researchers' scientific goals into computational requirements.

2) Work well with faculty and researchers.

3) Identify and gain expertise in appropriate new technologies and/or software tools.

4) Function as part of an interactive team while demonstrating self-initiative to achieve project's goals and Research Computing Center's mission.

5) Strong analytical skills and problem-solving ability.

Education, Experience, and Certifications
Minimum requirements include a college or university degree in related field.Minimum requirements include knowledge and skills developed through 2-5 years of work experience in a related job discipline.

Preferred Qualifications

Education

1) PhD in computer science, computational biology, bioinformatics, quantitative science or related field.

Experience

1) Must possess practical experience in data analysis, preferably in an independent project in an academic research laboratory setting.

Technical Skills

1) Fluency in Unix, standard bioinformatics tools (Python, R, or equivalent), and a programming language (C/C++, Java).

2) Background in statistics and machine learning.

3) Knowledge of SLURM or other job scheduler, and/or bioinformatics tools.

4) Excellent communication skills and the ability to interact professionally with all levels of staff and with external contacts in a fast-paced environment.

5) Excellent organization and time management skills..

6) Knowledge of biology or immunology; inclination to acquire such knowledge.

Required Documentation

1) Resume/CV

2) Cover Letter

NOTE: When applying, all required documents MUST be uploaded under the Resume/CV section of the application.

FLSA Status
Exempt
Pay Frequency
Monthly
Pay Grade
Depends on Qualifications
Scheduled Weekly Hours
37.5
Benefits Eligible
Yes
Drug Test Required
No
Health Screen Required
No
Motor Vehicle Record Inquiry Required
No
Posting Date
2020-08-20-07:00
Remove from Posting On or Before
2021-02-20-08:00
Posting Statement


The University of Chicago is an Affirmative Action/Equal Opportunity/Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.

Staff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via Applicant Inquiry Form.

The University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: http://securityreport.uchicago.edu. Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637.",4.0,"University of Chicago
4.0","Chicago, IL",10000+ Employees,1890,College / University,Colleges & Universities,Education,$2 to $5 billion (USD)
Data Engineer,"$74K-$135K
(Glassdoor Est.)","77 West Wacker Dr (35012), United States of America, Chicago, Illinois

At Capital One, were building a leading information-based technology company. Still founder-led by Chairman and Chief Executive Officer Richard Fairbank, Capital One is on a mission to help our customers succeed by bringing ingenuity, simplicity, and humanity to banking. We measure our efforts by the success our customers enjoy and the advocacy they exhibit. We are succeeding because they are succeeding.

Guided by our shared values, we thrive in an environment where collaboration and openness are valued. We believe that innovation is powered by perspective and that teamwork and respect for each other lead to superior results. We elevate each other and obsess about doing the right thing. Our associates serve with humility and a deep respect for their responsibility in helping our customers achieve their goals and realize their dreams. Together, we are on a quest to change banking for good.

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative,inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.

We are seeking Data Engineers who will be a part of a team thats building new analytical and machine learning tools and frameworks to exploit advantages in the latest developments in cloud computing. As aCapital One Data Engineer, youll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about#lifeatcapitalone and our commitment todiversity & inclusion by jumping toslides 25-40 on our Corporate Social Responsibility Report.

What Youll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance
Basic Qualifications:
Bachelors Degree
At least 2 years of experience in application development
At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)
Preferred Qualifications:
Master's Degree
3+ years of experience in application development
1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink
1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service
1+ years of experience with Ansible / Terraform
2+ years of experience with Agile engineering practices
1+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)
1+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of experience developing Java based software solutions
2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)
2+ years of experience developing software solutions to solve complex business problems
2+ years of experience with UNIX/Linux including basic commands and shell scripting
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.",3.9,"Capital One
3.9","Chicago, IL",10000+ Employees,1994,Company - Public,Banks & Credit Unions,Finance,$10+ billion (USD)
Data Scientist Sr,"$84K-$138K
(Glassdoor Est.)","Under general direction, the Data Scientist is responsible for modeling complex problems, discovering clinical insights and identifying opportunities using statistical, algorithmic, mining, and visualization techniques. In addition to analytic skills, this role requires experience in preparing large, varied datasets, and communicating results with clinical and operational stakeholders. Other responsibilities include developing and applying data quality measures to ensure that data congruent and reliable. The Data Scientist will collaborate with operational leaders, data stewards, physicians, project/program managers, informaticists and other analysts to turn data into critical information and knowledge to be used to make sound organizational decisions. Leads and Mentor junior data scientists. Other duties as assigned.

KNOWLEDGE, SKILLS AND ABILITIES REQUIRED:
Required Education, Skills, and/or Experience:
PhD. in Statistics/Biostatistics, Computer Science, Epidemiology, Mathematics, Healthcare, Physics, or other quantitative discipline (STEM area) required
Minimum 3 years of analyzing healthcare data in either a provider or payer environment is required. Academic experience in analyzing similar data in statistics or other quantitative disciplines will be considered as equivalent experience
Formal training or extensive applied experience with advanced statistical methods such as regression-type modeling and data-mining methods (e.g. classification trees)
2+ years of data and statistical analysis
Intermediate to advanced proficiency with SQL, SAS, R, STATA or other high-level data programming language
Intermediate to advanced proficiency with Python, PHP, Perl, VB, JavaScript, C++ or other programming language
Advanced programming skills required
Demonstrates excellent follow-up skills and the ability to take initiative as well as a proactive problem solving approach
Excellent verbal and written communication skills
Team oriented with good interpersonal skills and the ability to collaborate effectively with peers and customers
Comfortable providing input and alternate views in a healthy, constructive way
Agile software development methodology experience and test-driven development experience
Take pride in writing clean dependable algorithms
Sharp critical thinking skills, including systems and business analysis, problem analysis and resolution, and sound judgment/decision making ability
Proven ability to work in a rapid release product environment
Preferred Education, Skills, and/or Experience:
Minimum 5 years of Epic software experience required
Minimum of 5 years functioning as Data Scientist role required
5 years of directly related experience is preferred. Health care reporting experience is highly preferred
3 years Caboodle and Clarity experience is highly desired
Preferred Licensure/Certification:
Epic certification desired",3.8,"Elmhurst Memorial Healthcare
3.8","Warrenville, IL",5001 to 10000 Employees,-1,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Data Scientist/SR Analyst (Marketing),-1,"Leverage your “science first” mentality, curiosity, deep technical expertise, and problem-solving skills to explore, discover, and predict patterns and insights within complex data sets. This includes enabling government to capitalize on the value proposition of advanced analytics, and the derivation of clear narratives that help our clients understand their data and how those insights address their research questions.
This position is located in Chicago, IL. Onsite at the John C. Klucyznski Federal Building, 230 S. Dearborn St. Suite 3098, Chicago, IL 60604.
(Telework is in progress currently due to COVID.)
An active DoD Secret clearance is required upon start date

Responsibilities:
Facilitate access to all-inclusive marketing event and response details that encompass both national, local, and virtual marketing platforms. This information will create a common operating picture to provide immediate input on marketing effectiveness of events planned and executed at all levels of the command. This is particularly important to demonstrate the linkage between local marketing campaigns and all the responses that they may generate, even to the national platforms to justify the resourcing.
Facilitate analytics from GoArmy.com, Adobe Analytics, Salesforce Datorama, and Google Analytics by:
Developing and maintaining reporting metrics, providing data extracts, and conducting analysis on website-wide metrics for general situational awareness for Army Recruiting Command leadership and staff.
Conducting regional/local website analysis over specific timeframes to aid in the assessment of Training and Doctrine Fusion Board events.
Developing and maintaining reporting metrics and conducting analysis on local ad placements linked to website calls to action as part of Army Recruiting Command marketing campaigns.
Conducting analysis on unit-level websites; compare effectiveness among the commands and teasing out best practices.
Facilitate social media analytics with tools such as Digimine by:
Developing and maintaining reporting metrics, providing data extracts, and conducting analysis on the collective social media marketing effort across all platforms used in Army Recruiting Command
Conducting regional/local and platform-specific analysis of Army Recruiting Command Social Media campaigns.
Developing reporting techniques and formats for easy consumption by Army Recruiting Command leadership and staff
Tracking all common metrics (e.g. Likes, Shares, Comments, Retweets, Reach, Engagement Rate, Followers, Response Times, etc.) to determine the most effective ways to measure team performance; highlight best practices for optimal engagement of the target audience; and associate responses to particular campaigns.
Qualifications:
Degree (Master’s required) in science, technology, engineering, mathematics, computer science, economics, or other related business or technical discipline is required
Extensive experience in social media analytics and marketing campaign effectiveness.
Experience in Adobe Analytics - marketing analytics background
At least 5+ years of experience in the field
DoD Secret clearance required
Experience with data analytical tools, languages, and libraries such as Python with Pandas, scikit-learn, and others, and R using RStudio
Experience with regression models, time series models, decision trees, random forests, and text analytics using additional support models and methods to analyze and model marketing and lead data for trends and effectiveness.
Ability to frame and scale data problems to analyze, visualize, and find data solutions, and translate customer qualitative requirements into quantitative and technical approaches
Experience creating meaningful data visualizations and interactive dashboards using platforms such as Tableau, Qlik, Power BI, RShiny, plotly, and d3.js to communicate findings and relate them back to how your insights create business impact
Working knowledge of databases and SQL; preferred qualifications include linking analytic and data visualization products to database connections
Superior communication skills, both oral and written
Preferred Experience:
DoD experience is preferred, with marketing and recruiting.
Data science methods across all aspects of analytics to include descriptive, predictive, and prescriptive.
Unstructured text and natural language processing
Supervising algorithm implementation in on-premises and cloud-based computing environments
Developing software to generate reports and visualizations that summarize data sets and provide data-driven insights

Serco Inc. (Serco) is the Americas division of Serco Group, plc. Serco serves every branch of the U.S. military, numerous U.S. Federal civilian agencies, the Intelligence Community, the Canadian government, state and local governments, and commercial clients. We help our clients deliver vital services more efficiently while increasing the satisfaction of their end customers. Headquartered in Herndon, Virginia, Serco Americas has approximately 8,000 employees and is part of a $4 billion global business that helps transform government and public services around the world. At Serco, our employees are our most valuable asset - we listen, respect and support them throughout their career at Serco. We invite you to become part of our dynamic team. Serco is an equal opportunity employer committed to diversifying our workforce (Race/ Color/ Sex/ Sexual Orientation/ Gender Identity/ Religion/ National Origin/ Disability/ Vets).",5.0,"Serco Inc.
5.0","Chicago, IL",51 to 200 Employees,-1,Company - Private,Building & Personnel Services,Business Services,Less than $1 million (USD)
Computer Vision / Deep Learning Scientist,"$97K-$117K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

We are looking for Computer Vision / Deep Learning Scientist who are passionate about the prospect of building the most advanced data platform in precision medicine.

What You'll Do
Research and development of novel imaging data based machine learning algorithms for the product platform
Apply statistical and machine learning methods to analyze large, complex data sets
Communicate highly technical results and methods clearly
Interact cross-functionally with a wide variety of people and teams
Qualifications
PhD degree in a quantitative discipline (e.g. statistics, statistical genetics, imaging science, computational biology, computer science, applied mathematics, applied physics or similar) or equivalent practical experience
Experience developing, training, and evaluating deep-learning models using public deep learning frameworks (e.g. PyTorch, TensorFlow, and Keras)
Experience developing, training, and evaluating classical machine/deep learning models, such as, SVMs, Random Forests, Gradient Boosting, CNN, FCN, ResNet, GAN, etc.
Familiar with CUDA and GPU computing
Knowledge of different medical imaging modalities, such as DICOM formats and pathology images
Self-driven and work well in an interdisciplinary team with minimal direction
Thrive in a fast-paced environment and willing to shift priorities seamlessly
Nice to Haves
Kaggle.com competitions and/or kernels track record
Experience with AWS architecture
Experience working with survival analysis, clinical and/or genomic data
Experience working with Docker containers and cloud-based compute environments.
Familiarity with neural network techniques (batch-norm, residual connections, inception modules, etc)",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Research Scientist,"$64K-$135K
(Glassdoor Est.)","Research Scientist - Public Affairs and Media Research
Submit
#495661
/
Regular Full-Time
/
Chicago – 55 East Monroe Street, IL
/
Public Affairs & Media
JOB DESCRIPTION:
NORC at the University of Chicago seeks a qualified Research Scientist to join its Public Affairs and Media Research Department in our Chicago, IL or Bethesda, MD office.
DEPARTMENT: Public Affairs and Media Research
The Public Affairs and Media Research Department conducts high-quality research for our clients in order to deliver reliable insights that fuel effective business and communication strategies. We provide the nuanced understanding of people’s opinions, beliefs, and behaviors that organizations need to understand and serve their audiences in a world of vast and accelerating change. Our clients comprise some of the nation’s most influential and forward-looking media companies, PR and consulting firms, philanthropies, and policymaking organizations.

Through The AP-NORC Center and our relationships with other leading news and media organizations, we are able to work with our clients to position research findings for the journalists, policymakers, and thought leaders who can amplify their impact.
RESPONSIBILITIES:
Managing research projects end-to-end under the direction of senior staff, or assisting with project management for larger projects as a task lead
Providing substantive input and direction to task leaders and project directors
Preparing and analyzing data collected during pretests and main components of studies in accordance with professional standards
Assisting with the design of experiments and other methodological research for data collection efforts.
Working on questionnaire content and design, bringing an understanding of the literature and seminal research of the substantive field to the design of the instrument
Writing publication quality research reports
Manage project logistics, including budget monitoring, junior staff oversight, and timeline
Work directly with clients to keep them updated on project progress, respond to project requests, and understand their goals for the project
This position also has responsibilities for developing grant applications and contract proposals, generally contributing to sections in which understanding of the substantive area is vital, in assisting communications with clients, consultants, and members of the research community, and obtaining information about and interpreting upcoming and issued Requests for Proposals (RFPs), Requests for Applications, Program Announcements, and other solicitation information
REQUIRED SKILLS:
Master's Degree or Bachelor’s Degree and equivalent experience required; PhD in political science, social psychology, communications, survey methodology, or other social science discipline preferred
At least 7 years’ experience in positions of increasing responsibility in survey research or related field (or equivalent education) including at least 3 years' of social science project management
Experience with the design and execution of social science research and in publishing research results.
Knowledge and experience in a substantive field is highly desirable. Training or experience in journalism, communications, or elections research is a plus
In addition to a substantive background in a relevant discipline, the ideal candidate will have experience and knowledge of the principles of survey design, regression analysis and causal modeling in the social sciences, sampling, standard statistical software packages (such as SAS, R, or Stata), and quantitative data file construction
Strong problem solving, project management, relationship management skills
Demonstrated ability to work on multiple projects simultaneously
Some experience in client communications and relationship management
The candidate must have very good oral and written communication skills and a strong orientation toward working in teams and coordinating work with other teams
Experience mentoring or supervising junior staff is required
Experience with estimating project and proposal costs is a plus
ABOUT NORC:
NORC at the University of Chicago is an objective, non-partisan research institution that delivers reliable data and rigorous analysis to guide critical programmatic, business, and policy decisions. Since 1941, NORC has conducted groundbreaking studies, created and applied innovative methods and tools, and advanced principles of scientific integrity and collaboration. Today, government, corporate, and nonprofit clients around the world partner with NORC to transform increasingly complex information into useful knowledge.

NORC conducts research in five main areas: Economics, Markets, and the Workforce; Education, Training, and Learning; Global Development; Health and Well-Being; and Society, Media, and Public Affairs.

We provide comprehensive and integrated services that span the research cycle, and offer solutions that anticipate and address critical needs in research and data science. We approach all work with deep technical expertise, a spirit of collaboration, and a commitment to scientific integrity.
A TRADITION OF EXCELLENCE:
As one of the oldest not-for-profit, academic research organizations in the United States, and through its affiliation with the University of Chicago, NORC maintains the highest standard of professional excellence and scientific rigor, and is committed to broad dissemination of its findings.
A PASSION FOR INNOVATION:
NORC’s subject matter experts and survey professionals develop and employ innovative study designs, research methods, and technical applications to derive meaningful and accurate results.
A COMMITMENT TO COLLEGIALITY:
NORC cultivates an interdisciplinary culture of achievement in which senior investigators from diverse fields and professional backgrounds collaborate with the next generation of researchers in an open, collegial environment.
EEO STATEMENT:
NORC is an affirmative action, equal opportunity employer that values and actively seeks diversity in the workforce. NORC evaluates qualified applicants without regard to race, color, religion, sex, national origin, disability, veteran status, sexual orientation, gender identity, and other legally- protected characteristics.
7.2.2020
/
Back",3.1,"NORC at the University of Chicago
3.1","Chicago, IL",1001 to 5000 Employees,1941,Nonprofit Organization,Research & Development,Business Services,$100 to $500 million (USD)
Data Engineer,"$60K-$116K
(Glassdoor Est.)","Job Description


We’re hiring!

Aon is currently recruiting a Data Engineer to join our team in Singapore.

About Aon

Headquartered in London, Aon Plc is a leading global professional services firm providing a broad range of risk, retirement and health solutions. Our 50,000 colleagues in 120 countries empower results for clients by using proprietary data and analytics to deliver insights that reduce volatility and improve performance.

At Aon, you’ll be part of a team which will support and inspire you and provide the opportunities and resources to develop your skills. It’s an environment which encourages you to achieve your best - together we’ll empower results.

The Opportunity

The Innovation Center is growing rapidly, with new ideas continually forming. We are looking for dedicated individuals to brainstorm exciting and new strategic opportunities, and quickly build working prototypes to transform those ideas into reality.

The successful candidate will be part of the team based in Singapore, supporting the delivery of analytics solutions around client data, aimed to help business leaders in Aon drive performance. This is a great opportunity for someone aiming to consolidate and further improve their skills as a Data Engineer through collaboration with Senior Data Engineer and working closely with experienced full-stack developers and data analysts to building solutions with the latest technologies.

Responsibilities:
Work closely with other data engineers, developers, data analysts and colleagues on the vision, design, requirements and delivery of analytics applications
Independently design, build, test and maintain ETL processes
Enhance existing processes by identifying opportunities for improvement
Maintain and extend documentation
Promote and adhere to policies, standards and best practises through automation tooling and manual controls incl. JIRA
Requirements
3+ years of relevant experience as a Data Engineer
Working knowledge on SQL and R or Python to perform data querying, building data models and conducting data analysis.
Professional expertise in ETL processes
Proficiency and professional experience in troubleshooting issues
Attention to detail and desire to probe further into data sets
Good communication skills – both written and verbal
Keen interest to learn new technologies
Ability to work collaboratively with both technical and non-technical colleagues
Ability to prioritize the development of key features and enhancements across projects to meet business goals
Experience with the following is a plus
SSIS (SQL Server Integration Services)
Cloudera WorkBench
Tableau, Qlikview, PowerBI or other relevant visualization tools
Version-control systems (Git/SVN)
Agile Methodology
How to Apply

Your opportunity to empower results could start right here. Make your mark and apply online today with a brief covering letter and your resume, sharing relevant achievements for this position.

We Offer You

A competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.

Our Colleague Experience

Every day, our colleagues make a difference, work with the best, own their potential, and value one another. Together, we share this one purpose: to empower economic and human possibility around the world. This unifying goal is at the heart of our identity, and it lives in everything we do. To learn more about our colleague experience, visit Aon Colleague Experience.

Aon is an equal opportunities employer. We are committed to creating a winning and inclusive culture where everyone feels valued and has opportunities for growth and development.

2477388",3.6,"Aon
3.6","Chicago, IL",10000+ Employees,1892,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD)
Principal / Lead Data Scientist,"$93K-$151K
(Glassdoor Est.)","Premier Research helps highly innovative biotech and specialty pharma companies transform life-changing ideas into reality. We have positioned ourselves right in the middle of the action, targeting unmet needs in analgesia, neuroscience, oncology, pediatrics, and rare diseases.

We’re looking for a talented and energetic Lead Data Scientist to join our team! This is a very exciting opportunity to join a dynamic and innovative team and grow with a forward-thinking organization that is changing to course of medicine.

Working at Premier Research means being an individual - you will be recognised for what you do and you will truly have an impact. You will be working in a friendly environment with colleagues who are genuinely supportive regardless of location or seniority.

Premier Research is on an exciting journey - there is a true buzz throughout the company, so come and be part of it!

As a Lead Data Scientist with Premier Research, you’ll have the opportunity to work very closely with the Project Manager on studies as the point of contact for all data management responsibilities on multiple studies, including serving as the program or portfolio manager for a key client.

What you’ll be doing:
Oversee the preparation of data management plans, data entry guidelines, data management reports and other documents required for preparing and completing databases
Review draft protocols and CRFs for potential data collection and representation, database structure or data entry problems, and provides feedback to the project team; Reviews CRFs, data listings, and database to ensure all captured data follow the rules outlined by the protocol and data management plan; track CRFs as they are processed through the Data Management department
Generate queries to appropriate internal or external personnel (investigational sites, vendors, Clinical Research Associates, client representatives) to resolve problematic data identified during every aspect of the data management process
Review responses to queries for appropriateness, resolves any discrepancies and modifies the database accordingly
Mentors newly hired Data Coordinators and junior Leads
You’ll need this to be considered:
Minimum of a Bachelor's Degree, preferably in Science, Engineering, or Math, or RN, RPh, or LPN certification preferred along with a minimum of 8 years of mastery in data management/science/analytics/informatics and at least 7 years leading studies
Proven expertise in ICH/GCP and/or ISO14155 requirements; knowledge of site and institution specific contract requirements; clinical trials support or pharmaceutical industry experience; working knowledge of medical terminology and experience with clinical research; working knowledge of FDA Guidance Documents and clinical monitoring procedures; proficient in the development and review of Informed Consent Form templates
Understanding and experience at least one Database Management System (e.g., Medidata Rave, DataLabs EDC, Oracle RDC or Inform, etc.); knowledge of web based communication tools for conferences
Known for being customer-focused in approach to work and communications with the ability to professionally Interact with site, clients, vendors and other functional areas; strong verbal and written communication and negotiation skills
Maintains a positive, results orientated work environment; excellent team player, collaborative and able to build an effective team.
Excellent organizational and time-management skills, able prioritize work to meet deadlines; Ability to multitask and work effectively in a fast-paced environment with changing priorities; accountable, dependable and strong commitment.
#LI-BL1",3.2,"Premier Research Group Limited
3.2","Chicago, IL",1001 to 5000 Employees,1996,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$100 to $500 million (USD)
Data & Analytics Consultant |,"$86K-$132K
(Glassdoor Est.)","WHO WE LOOK FOR

An SEI Consultant is a master communicator and active listener who understands how to navigate an audience. Self-aware, almost to a fault, SEI consultants keenly understand how to adjust their approach based on the situation. Following a logical, fact-based approach, our consultants possess the superior ability to see correlations others may not, ask the right questions and drive solutions.

As super-connectors, our consultants connect not only people, but data, trends and experiences. Mature, humble, and genuine, SEI Consultants frequently go above and beyond for both their clients and their colleagues. SEI Consultants are ethical and trustworthy individuals who do what they say. SEI Consultants have an insatiable curiosity and love to learn. These individuals are commonly tech savvy and early adopters. Their passion for learning is infectious and excites others.

As every project is different, an SEI Consultant must be adaptable and comfortable with unexpected situations. An SEI Consultant must be at ease with ambiguity because although a client knows that a problem exists – they need SEI to figure it out and drive a solution. SEI Consultants define ambition differently. SEI Consultants are authentic, low-maintenance individuals who like to hang out with colleagues outside of work. Whether it be cooking, traveling, hiking, or volunteering, SEI Consultants enjoy working with genuine, thoughtful folks who want to steer clear of the traditional grind and share the joy of day-to-day life and activities with colleagues, friends and family.

WHAT WE DO

Our consultants work with clients at all levels of the organization, from the C-suite to the shop floor, helping them to deliver on their most strategic initiatives. We’re known for making realistic, data-driven decisions that deliver value in tangible ways to our clients. Our clients ask for us on projects that require a superior combination of technical and business capabilities, people and management skills, and a collaborative mindset. We excel in understanding complex programs and strategic initiatives and breaking them into actionable pieces.

We are actively looking for professionals in the following areas:
Data Strategy and Governance
Database Architecture and Development
Data Analysis
Reporting and Data Visualization
The ideal candidate will:
Have experience understanding and solving real business problems
Solid writing and speaking skills to support data storytelling
Ideal candidates may call themselves Data Engineers, Data Scientists and Analysts and Data Governance professionals. Experience may include but is not limited to the following:
Experience with statistical and mathematical modeling, artificial intelligence and machine learning software and methods
Specialization in architecting enterprise solutions with visualizations and data-discovery tools such as Tableau, QlikView, Spotfire, Amazon Web Services, Cloud, Salesforce
Technical capabilities that include designing scalable data architectures, solution performance tuning, and hardware sizing
Experience and knowledge of programming and scripting languages, such as , Python, Java, C#, PL/SQL, R and SAS
Experience and knowledge of relational and dimensional database structures, theories, principles, and practice used in data warehousing and analytics solutions
Experience managing, populating, and querying database technologies including RDBMS, NOSQL, and big data platforms and experience working with these technologies’ ecosystems
QUALIFICATIONS

Required
Demonstrated business and technology acumen
Proven track record of delivering results
Experience working with and/or leading a team
Ability to work independently
Ability to work across industries, roles, functions & technologies
Positive can-do attitude
A curiosity for new technology
Authorization for permanent employment in the United States (this position is not eligible for immigration sponsorship)
Preferred
Bachelor’s degree (Mathematics, Computer Science, or related field preferred)
8+ years professional experience
Consulting experience
Experience across our service offerings",4.6,"Systems Evolution
4.6","Chicago, IL",201 to 500 Employees,1992,Company - Private,Consulting,Business Services,$50 to $100 million (USD)
Data Scientist - Sr. Analyst,"$114K-$143K
(Glassdoor Est.)","Hi,

Greetings from HR Pundits!!!

We have the high priority contract position for one of our Direct Client. If interested share profiles asap

Title: Data Scientist - Sr. Analyst
Location: Lake Forest, IL
Duration:6Months
(only GC/GC EAD/C)

Job Description:

The Data Scientist – Sr. Analyst will work on the SRG product recommendation engine for their eCommerce site. This person will be required to have good communication, the ability to understand business problems and use cases and have three or more years of relevant experience

Skills
Mandatory Technical Skills: R, Python, machine learning algorithms, Hadoop
Nice to have technical skills: Scala, Spark

Duties",2.0,"HR Pundits
2.0","Chicago, IL",1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$1 to $5 million (USD)
Data Engineer - QuantumBlack,"$66K-$113K
(Glassdoor Est.)","You will be working on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact.

We are passionate about life-long learning and professional development individual to each of our employees.

Role responsibilities
Work with clients to model their data landscape, obtain data extracts, and define secure data exchange approaches
Plan and deliver secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for bleeding edge Advanced Analytics and Data Science
What you’ll learn
Influence, develop and master best-practice around modern tools that support rapid development of analytics solutions like Python, Spark, Airflow and others.
Apply cutting edge data solutions to real world problems
Learn to deeply understand the data science and data engineering process and develop impactful and reusable patterns and abstractions
Collaboratively advance the state of art in QuantumBlack’s practice and for our clients
Build products alongside the core engineering team and evolve the engineering process to handle more users, resolutions for complex problems and advanced client situations.
Work with an extensive range of technologies around big data tools.
Work with clear objectives for your Data Engineering expertise while collaborating with the Data Science, Machine Learning Engineer and Design teams
You will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.
Real-World Impact – No project is ever the same; we work across multiple sectors, providing unique learning and development opportunities internationally.
Fusing Tech & Leadership – We work with the latest technologies and methodologies and offer first class learning programmes at all levels.
Multidisciplinary Teamwork - Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.
Innovative Work Culture – Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.
Striving for Diversity – With colleagues from over 40 nationalities, we recognise the benefits of working with people from all walks of life.
Our projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimising a Formula1 car’s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture:
Healthcare Efficiency – We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.
Environmental Impact – We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.
Product Development – We worked with the CEO of an elite automotive organisation to reduce the 18-month car development timeframe by improving processes, designs and team structures.
Visit our Careers site to watch our video and read about our interview processes and benefits.",4.4,"McKinsey & Company
4.4","Chicago, IL",10000+ Employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable
Operations Research Scientist,"$59K-$127K
(Glassdoor Est.)","Description

We are seeking an Operations Research Scientist who can help us work on high value, complex, global supply chain opportunities with our Advanced Analytics team at Koch. We love passionate, forward thinking individuals who are driven to innovate through the intersection of cutting-edge research and high-quality data available within Koch’s impressive portfolio of companies.

You will have the opportunity to engage with other leading operations research and data science talent, business leaders, and analytics infrastructure experts as you design and execute experiments; including the opportunity to pursue patents on novel, successful outcomes. Our advanced analytics team is backed by world class engineering and analysis talent that helps source data, establish baselines, and transition successful solutions into production, allowing operations research scientists to focus on their comparative advantages. We work with diverse business scenarios and data types, experimenting and piloting at a rapid pace – exciting for a candidate who loves solving complex, global business problems.

Koch Business Solutions (KBS) is the global problem-solver of business needs for Koch Industries. We serve more than 120,000 Koch employees worldwide and partner with 11 Koch companies from a diverse number of industries; ranging from making fabric, glass and paper products, to manufacturing cell phone components. Since 2003 we have invested over $80 Billion in acquisitions and other capital expenditures and are proud to reinvest more than 90% of our earnings back into our companies.

Want to come help create the future of advanced analytics at Koch?

This role is open to remote candidates with preference to sit in Dallas, Chicago, Atlanta, or Wichita.

What you will do in your role.
Work with product managers and clients to better understand the business problem
Create a list of potentially relevant supporting data elements
Work with data engineers and/or data analysts to procure data and test it for problems
Collaborate with other scientists and analysts
Propose modeling approaches
Mine the data to check completeness, value distributions, etc.
Test models for quality and scalability
Collaborate with product managers to find the best way to present the results
Work with developers on productionizing models
The experience you will bring.
An advanced Degree (Masters or PhD) in Operations Research, Industrial Engineering, Mathematics, Physics, Statistics, or Chemistry
A minimum of 3 years of post-academic experience developing and deploying advanced optimization models
Experience putting emerging ideas into practice through rapid experimentation and prototyping
Expert in mathematical optimization and decomposition of complex problems for custom solutions
Experience with commercial (Gurobi, Cplex, Xpress) or free/open source (GLPK, lp_solve, MIPCL) solvers
Experience in scheduling and routing optimization problems
Experience developing in Python, Java, or C++ within a collaborative production environment
High quality understanding of stochastic processes and uncertainty modeling, experience formulating and solving mixed integer linear, non-linear, and quadratic programming models
Experience developing proof of concepts and testing new ideas, as well as scaling these ideas into production ready models that can be deployed
Education
An advanced Degree (Masters or PhD) in Operations Research, Industrial Engineering, Mathematics, Physics, Statistics, or Chemistry
Salary and benefits commensurate with experience.
Equal Opportunity Employer.
Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.

This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf

]]>",3.7,"Koch Business Solutions
3.7","Chicago, IL",10000+ Employees,1940,Company - Private,Oil & Gas Exploration & Production,"Oil, Gas, Energy & Utilities",$10+ billion (USD)
Principal Data Scientist – Digital Touch,"$120K-$190K
(Glassdoor Est.)","Principal Data Scientist – Digital Touch
Customer Success | Seattle, Washington, San Francisco, California and Chicago, Illinois

Our agreement with employees
DocuSign is committed to building trust and making the world more agree-able for our employees, customers and the communities in which we live and work. You can count on us to listen, be honest, and try our best to do what's right, every day. At DocuSign, everything is equal. We each have a responsibility to ensure every team member has an equal opportunity to succeed, to be heard, to exchange ideas openly, to build lasting relationships, and to do the work of their life. Best of all, you will be able to feel deep pride in the work you do, because your contribution helps us make the world better. And for that, you'll be loved by us, our customers, and the world in which we live.

The team
Our Customer Success team is the largest organization in the world focused entirely on agreement processes and technologies. We are the Agreement Experts. With hundreds of thousands of successful customers worldwide, we know how to help our customers see results quickly. And that experience is just one of the reasons our customers trust us to connect, automate, and integrate their systems of agreement, everywhere they need to get work done. As part of our global team of Agreement Experts – in professional services, customer success management, learning and enablement, and customer support – you'll bring your knowledge, insights, and proven expertise to help our customers achieve more than they ever thought possible.

This position
The Principal Data Scientist – Digital Touch is responsible for designing and building models & algorithms for the Digital Customer Success, Adoption Enablement and Success Marketing that power the next generation of actionable insights for the Customer Success organization at DocuSign. The ideal candidate has a rich experience across one or more domains of Customer Success, Adoption Marketing, Digital Analytics, Advertising, Consumer behavior, Customer Journeys and Sales Lifecycle. The candidate is a lead decision / data scientist with a track record of driving successful data science initiatives, advanced predictive and prescriptive analytics for business and customer facing outcomes. In this role you will leverage statistical analysis and machine learning to help DocuSign Customer Success teams drive adoption & consumption campaigns leading to higher retention, upsell and cross-sell. You will partner closely with other data scientists and analysts in Customer Success Analytics, product engineering, marketing, sales and finance, while collaborating & partnering with customer success teams on business & customer requirements to improve customer journeys and drive targeted customer outcomes with tangible ROI. This role requires the ability to deliver in matrixed organization at global scale. The candidate is deeply analytical with keen understanding of business process and programs and the ability to translate data and insights into executive readouts.

This position is an individual contributor position and reports to the Director Customer Success Analytics.

Responsibilities
Design and build predictive & prescriptive models across the Customer Success lifecycle marketing and Success Marketing – understand & track events and interactions – drive analytics on attribution to usage and adoption – predict journeys customer will take with campaigns & content navigation
Create models to deliver meaningful insights & analysis on the effectiveness and impact of campaign, webinars, events and communications on customer usage & adoption.
Design and build models to influence decisions for optimal audience targeting for different outreach programs based on program goals, system constraints, and customer lifecycle analysis
Drive consistency in data collection and processes within the Customer Success Lifecycle Marketing team and Customer Success content teams
Coordinate with the Marketing Operation team on campaign audience builds and results
Partner with cross-department to report accurately on data sourced from many different data sources including Support, Product, DocuSign University, and Professional Services
Create requirements for dimensional models to support the required analysis in a more automated fashion
Design and report on A/B tests for new and modified campaigns and programs, including design of control groups
Collaborate with front-line, customer-facing Customer Success teams to gather customer insights and best practices to inform and drive content asset creation, performance and measurement.
Create methodology for understanding content effectiveness across the Support Site, DocuSign University, and any other platforms
Drive and develop the customer journey analytics across enablement experiences. Use analytics and data to evaluate effectiveness, drive changes, identify enhancements for new programs.
Deliver on insights and analytics to help business leaders answer critical questions related to Customer lifecycle marketing, Success marketing, customer experience, and impacts on adoption, usage and health
Report on key metrics and KPIs to all key business partners, including Sr. Leadership, across Customer Success Enablement, Professional Services, field CSM roles, and regional CSM organizations in EMEA and APAC
Determine opportunities for improvement across process, tooling and data automation to optimize costs and decrease turnaround time for analytics consumers
Basic Qualifications
12+ years of experience in solving complex business problems using advanced analytics, statistical techniques (preferred exposure to machine learning) to drive marketing analytics, campaign targeting and analytics, event analytics, customer journey analysis
4+ years Python, knowledge and hand-on experience in statistical programming and data science toolkits – one or more of Pandas/Jupyter/SCIKIT/Tensorflow
3+ years of experience in executing on complex projects, extracting, cleansing, and manipulating diverse structured and unstructured data sets on relational – SQL, NOSQL databases
3+ years of experience working in an agile environment with iterative development & business feedback
3+ years of provide insights to support strategic decisions, including preparing and delivering insights and recommendations
3+ years of experience across Customer and Marketing scenarios with knowledge of data science concepts related to customer lifecycle marketing, content management - customer journeys, lifetime value
3+ years of SQL with excellent hands-on exposure to creating complex queries across multiple database schemas
3+ years working with multi-million rows of data
3+years of experience in Enterprise Visualization Tools: Tableau / QlikView /PowerBI and proficient in MS Office Suite with advanced Excel skills - pivot tables, macros, PowerPivots, advanced functions
A Bachelor's or Master's degree in Computer Science, Business Analytics, Marketing Analytics, Applied Mathematics or Statistics, Econometrics, or closely related field
Preferred Qualifications
Experience applying machine learning solving real business and customer problems
Comfortable with loosely defined requirements where you exercise your analytical skills to collaborate with the rest of the team to build solutions
Excellent problem-solving skills with ability to synthesize & communicate complex results to senior leaders
Attention to detail with focus on data quality, data consistency and criticality
Ability to shape ambiguity, govern & prioritize in a matrixed environment across organizational boundaries
Strong desire to stay ahead of industry trends & technologies with a commitment to continuous learning
Preferred experience using machine learning to build recommender systems
Exposure to AI, Deep Learning, Neural Networks, NLP
Exposure to big data platforms – Snowflake, Redshift, Azure, Matillion, Hadoop
Excellent at articulating vision and planning execution of projects
About us

DocuSign® helps organizations connect and automate how they prepare, sign, act on, and manage agreements. As part of the DocuSign Agreement Cloud, DocuSign offers eSignature: the world's #1 way to sign electronically on practically any device, from almost anywhere, at any time. Today, hundreds of thousands of customers and hundreds of millions of users in over 180 countries use DocuSign to accelerate the process of doing business and simplify people's lives. Plus, we save more trees together! And that's a good thing.

DocuSign is an Equal Opportunity Employer. DocuSign is committed to building a diverse team of talented individuals who bring different perspectives to the discussion and who feel a sense of inclusion and belonging when they join our team. Individuals seeking employment at DocuSign are considered without regards to race, ethnicity, color, age, sex, religion, national origin, ancestry, pregnancy, sexual orientation, gender identity, gender expression, genetic information, physical or mental disability, registered domestic partner status, caregiver status, marital status, veteran or military status, citizenship status, or any other legally protected category.

#LI-DS1",4.6,"DocuSign
4.6","Chicago, IL",5001 to 10000 Employees,2003,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD)
Data Engineer,"$59K-$112K
(Glassdoor Est.)","Data Engineer

27-Aug-2020

Job Description
Health Data & Management Solutions, Inc. (HDMS), a subsidiary of CVS/ Aetna, is a software development company on the cutting edge of health IT data solutions. Offering data warehouse, management and analysis tools for the healthcare industry, HDMS strives to improve and enhance its product suite for health plans, employers and providers through constant innovation. HDMS' web-based products and services provide flexible, high-value reporting tools that empower users to maximize the value of their health care data and support benefit decisions.

The Data Engineer supports the HDMS client use of ART, DART and Enlight data reporting applications by managing internal and external client issues toward resolution. Involve in monthly data load activities.
And tableau reporting

Participates and collaborates with subject matter experts and works with cross-functional teams to address problems using various technologies available within HDMS.

Req#
72585BR

Job Group
Data & Analytics

Full or Part Time
Full Time

Supervisory Responsibilities
No

Percent of Travel Required
0 - 10%

Posting Job Title
Data Engineer

Potential Telework Position
No

Additional Locations
IL-Chicago

Primary Location (City, State)
IL-Chicago

EEO Statement
Aetna is an Equal Opportunity, Affirmative Action Employer

Resource Group
6

Fundamental Components
Responsible for refreshing the database on a monthly basis
Responsible for meeting 100% database refresh SLA
Maintaining the reporting environment using Tableau
Responsible for handling Support tickets with respect to Data Enquiry and for any Issue reporting
Responsible for working with current support resources to setup JIRA workflows for DART, Enlight & ART
Partner with lead and other teams to develop process and on-boarding documentation for Operations Support team using Confluence
Responsible for handling deployment activities
Help create and maintain communication/documentation repository for the JIRA application (confluence), where users can access generally available information about access, contents, and documentation
Perform data analysis support and work collaborate with current Ops support team
Communicate with end users and business stakeholders to take support incidents to closure, maintain SLAs, status reporting
Exposure to Tableau reporting tool to gain insight into the operations
Background Experience
Required
3+ years of experience with Relational Database Management Systems- RDBMS (ex. SQL, Oracle databases, etc.), data systems and data warehouses
3+ years of experience with Tableau development
3+ years of experience with bash shell scripts, Informatica, JIRA, Mongo DB, MySQL, Python, HIVE and/or Hadoop
Preferred:
Healthcare experience
Experience with the Software Development and Product Development Lifecycles
Experience with the software support ticketing systems and processes
Experience communicating statistical and technical ideas and results to non-technical clients
Experience with perform ETL data load job execution and monitoring in Spark/Scala
Experience in Exasol and AppDynamics is good to have
Experience using complex systems and solve challenging analytical
Strong reporting and experience using Excel, Access, Word and/or PowerPoint
Benefits Program
Benefit eligibility may vary by position.

Candidate Privacy Information
Aetna takes our candidate's data privacy seriously. At no time will any Aetna recruiter or employee request any financial or personal information (Social Security Number, Credit card information for direct deposit, etc.) from you via e-mail. Any requests for information will be discussed prior and will be conducted through a secure website provided by the recruiter. Should you be asked for such information, please notify us immediately.

Clinical Licensure Required
N/A",3.3,"Aetna
3.3","Chicago, IL",10000+ Employees,1853,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD)
Operations Research Scientist,"$59K-$127K
(Glassdoor Est.)","Description

We are seeking an Operations Research Scientist who can help us work on high value, complex, global supply chain opportunities with our Advanced Analytics team at Koch. We love passionate, forward thinking individuals who are driven to innovate through the intersection of cutting-edge research and high-quality data available within Koch’s impressive portfolio of companies.

You will have the opportunity to engage with other leading operations research and data science talent, business leaders, and analytics infrastructure experts as you design and execute experiments; including the opportunity to pursue patents on novel, successful outcomes. Our advanced analytics team is backed by world class engineering and analysis talent that helps source data, establish baselines, and transition successful solutions into production, allowing operations research scientists to focus on their comparative advantages. We work with diverse business scenarios and data types, experimenting and piloting at a rapid pace – exciting for a candidate who loves solving complex, global business problems.

Koch Business Solutions (KBS) is the global problem-solver of business needs for Koch Industries. We serve more than 120,000 Koch employees worldwide and partner with 11 Koch companies from a diverse number of industries; ranging from making fabric, glass and paper products, to manufacturing cell phone components. Since 2003 we have invested over $80 Billion in acquisitions and other capital expenditures and are proud to reinvest more than 90% of our earnings back into our companies.

Want to come help create the future of advanced analytics at Koch?

This role is open to remote candidates with preference to sit in Dallas, Chicago, Atlanta, or Wichita.

What you will do in your role.
Work with product managers and clients to better understand the business problem
Create a list of potentially relevant supporting data elements
Work with data engineers and/or data analysts to procure data and test it for problems
Collaborate with other scientists and analysts
Propose modeling approaches
Mine the data to check completeness, value distributions, etc.
Test models for quality and scalability
Collaborate with product managers to find the best way to present the results
Work with developers on productionizing models
The experience you will bring.
An advanced Degree (Masters or PhD) in Operations Research, Industrial Engineering, Mathematics, Physics, Statistics, or Chemistry
A minimum of 3 years of post-academic experience developing and deploying advanced optimization models
Experience putting emerging ideas into practice through rapid experimentation and prototyping
Expert in mathematical optimization and decomposition of complex problems for custom solutions
Experience with commercial (Gurobi, Cplex, Xpress) or free/open source (GLPK, lp_solve, MIPCL) solvers
Experience in scheduling and routing optimization problems
Experience developing in Python, Java, or C++ within a collaborative production environment
High quality understanding of stochastic processes and uncertainty modeling, experience formulating and solving mixed integer linear, non-linear, and quadratic programming models
Experience developing proof of concepts and testing new ideas, as well as scaling these ideas into production ready models that can be deployed
Education
An advanced Degree (Masters or PhD) in Operations Research, Industrial Engineering, Mathematics, Physics, Statistics, or Chemistry
Salary and benefits commensurate with experience.
Equal Opportunity Employer.
Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.

This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf

]]>",3.7,"Koch Business Solutions
3.7","Chicago, IL",10000+ Employees,1940,Company - Private,Oil & Gas Exploration & Production,"Oil, Gas, Energy & Utilities",$10+ billion (USD)
Senior Data Scientist (Consulting),"$81K-$133K
(Glassdoor Est.)","At West Monroe, our people are our business.
We pride ourselves on bringing a different mindset to consulting—and that takes a different approach: highly collaborative, flexible, and tenacious.

Our people-first, highly collaborative culture is core to our identity. It’s something we care about, and something we strive to enrich and preserve. No hierarchies. No siloes. No egos. Just smart ideas, and the drive to make an impact for our clients.

Every day our clients rely on us to help them tackle their greatest challenges, by strategically deploying technology through a business-focused and industry-specific lens. We bring together both the right knowledge and the right approach, so that they can capitalize on opportunities and deliver real results. That takes the right team. And that’s where you come in.

Ready for the next step on your career journey?
West Monroe is seeking a Data Science Architect join our Data Engineering & Analytics practice and contribute to the continuous development of our advanced analytics and data science offerings. We’re looking for a deep technologist and thought-leader, confident in building solutions for clients from the ground up. The architect will also help develop and market our analytics platforms-as-as-service solutions, while collaborating with client analytics SMEs to implement data science models across a variety of industries.

Responsibilities:

Client Delivery

Oversee advanced analytics work and architect predictive models for clients in a variety of industries, I.e. Healthcare, Retail, Financial Services, Manufacturing, Energy & Utilities, etc.
Act as a thought leader and engage with client analytics SMEs to collaborate in the build and deployment of deep AI/ML/NLP solutions
Oversee multiple concurrent analytics engagements, including leading junior consultants and communicating/reporting project status to key client stakeholders (budget, risks, issues, etc.)
Make key decisions regarding the direction of your projects including tools, approach, and methodology
Define responsibilities, work tasks, and targets for each consultant according to the technical work plan
Assess stakeholder interests and plan and execute strategies to address their needs while quickly responding to client requests for immediate issues and driving projects to completion

Practice Development

Engage in developing and marketing analytics platforms-as-a-service solutions, repeatable models, and other data science offerings
Collaborate cross-functionally leadership across various West Monroe practices to develop applicable client project opportunities
Contribute to the development/enhancement of West Monroe’s advanced analytics methodologies, best practices, and approaches to client delivery
Continuously enhance your knowledge of the firm’s Data Engineering & Analytics solution lines by attending training and KTS sessions
Complete case studies for all engagements and document for future use
Develop more junior data science consultants who will be working under your guidance to deliver on client work
Attract top tier talent (MS/PhD programs, competing firms, etc.) to continue building out our analytics and data science capabilities

Qualifications:

Bachelor’s degree in relevant field preferred, or equivalent experience required
Consulting firm/industry experience preferred
7-11+ years of experience in technology with 3+ years of experience working in a data science capacity
Proficient understanding of AI/ML concepts, and other contemporary data science logic; proven experience with advanced analytics and/or data mining tools
Confident in the application of AI, ML, and/or NLP solutions to solve complex business problems across a variety of industries
Hands-on experience with multivariate analytic techniques: linear and logistic regression, decision tree, cluster and factor analysis, time-series forecasting methods, SVM models, and/or neural networks
Skilled in programming languages like Python, R, Java, SQL, Scala, etc.
Confident project management ability including leading consultants, requirements analysis, scheduling, providing scope, mitigating issues, risk management, change management, and strategic planning & analysis
Strong communication skills to be able to work with clients and present to C-level executivesAbility to travel for client engagementsBonus technologies:
NoSQL – HBase, Cassandra, Accumulo, Mongo, Neo4j, etc.
Cloud/Data – Azure, AWS, Azure ML, Amazon ML, AWS DeepLens, AWS EMR, etc.

Ready to get started? Join our team and make an impact.

Senior Data Scientist (Consulting)

222 W Adams St, 11th Floor
Chicago, Illinois, 60606
United States

At West Monroe, our people are our business.
We pride ourselves on bringing a different mindset to consulting—and that takes a different approach: highly collaborative, flexible, and tenacious.

Our people-first, highly collaborative culture is core to our identity. It’s something we care about, and something we strive to enrich and preserve. No hierarchies. No siloes. No egos. Just smart ideas, and the drive to make an impact for our clients.

Every day our clients rely on us to help them tackle their greatest challenges, by strategically deploying technology through a business-focused and industry-specific lens. We bring together both the right knowledge and the right approach, so that they can capitalize on opportunities and deliver real results. That takes the right team. And that’s where you come in.

Ready for the next step on your career journey?
West Monroe is seeking a Data Science Architect join our Data Engineering & Analytics practice and contribute to the continuous development of our advanced analytics and data science offerings. We’re looking for a deep technologist and thought-leader, confident in building solutions for clients from the ground up. The architect will also help develop and market our analytics platforms-as-as-service solutions, while collaborating with client analytics SMEs to implement data science models across a variety of industries.

Responsibilities:

Client Delivery
Oversee advanced analytics work and architect predictive models for clients in a variety of industries, I.e. Healthcare, Retail, Financial Services, Manufacturing, Energy & Utilities, etc.
Act as a thought leader and engage with client analytics SMEs to collaborate in the build and deployment of deep AI/ML/NLP solutions
Oversee multiple concurrent analytics engagements, including leading junior consultants and communicating/reporting project status to key client stakeholders (budget, risks, issues, etc.)
Make key decisions regarding the direction of your projects including tools, approach, and methodology
Define responsibilities, work tasks, and targets for each consultant according to the technical work plan
Assess stakeholder interests and plan and execute strategies to address their needs while quickly responding to client requests for immediate issues and driving projects to completion
Practice Development
Engage in developing and marketing analytics platforms-as-a-service solutions, repeatable models, and other data science offerings
Collaborate cross-functionally leadership across various West Monroe practices to develop applicable client project opportunities
Contribute to the development/enhancement of West Monroe’s advanced analytics methodologies, best practices, and approaches to client delivery
Continuously enhance your knowledge of the firm’s Data Engineering & Analytics solution lines by attending training and KTS sessions
Complete case studies for all engagements and document for future use
Develop more junior data science consultants who will be working under your guidance to deliver on client work
Attract top tier talent (MS/PhD programs, competing firms, etc.) to continue building out our analytics and data science capabilities
Qualifications:
Bachelor’s degree in relevant field preferred, or equivalent experience required
Consulting firm/industry experience preferred
7-11+ years of experience in technology with 3+ years of experience working in a data science capacity
Proficient understanding of AI/ML concepts, and other contemporary data science logic; proven experience with advanced analytics and/or data mining tools
Confident in the application of AI, ML, and/or NLP solutions to solve complex business problems across a variety of industries
Hands-on experience with multivariate analytic techniques: linear and logistic regression, decision tree, cluster and factor analysis, time-series forecasting methods, SVM models, and/or neural networks
Skilled in programming languages like Python, R, Java, SQL, Scala, etc.
Confident project management ability including leading consultants, requirements analysis, scheduling, providing scope, mitigating issues, risk management, change management, and strategic planning & analysis
Strong communication skills to be able to work with clients and present to C-level executives
Ability to travel for client engagements
Bonus technologies:
NoSQL – HBase, Cassandra, Accumulo, Mongo, Neo4j, etc.
Cloud/Data – Azure, AWS, Azure ML, Amazon ML, AWS DeepLens, AWS EMR, etc.
Ready to get started? Join our team and make an impact.

West Monroe Partners is an Equal Employment Opportunity Employer
We believe in treating each employee and applicant for employment fairly and with dignity. We base our employment decisions on merit, experience, and potential, without regard to race, color, national origin, sex, sexual orientation, gender identity, marital status, age, religion, disability, veteran status, or any other characteristic prohibited by federal, state or local law.",4.2,"West Monroe Partners
4.2","Chicago, IL",1001 to 5000 Employees,2002,Company - Private,Consulting,Business Services,$100 to $500 million (USD)
E04 ComEd Principal Data Scientist- Engineering and Smart Grid Reliability Analysis and Regulatory Reporting Oak Brook,"$99K-$159K
(Glassdoor Est.)","Description

At Exelon, we've got a place for you!

Join the nation's leading competitive energy provider, with one of the largest electricity generation portfolios and retail customer bases in the country. You will be part of a family of companies that strives for the highest standards of power generation, competitive energy sales, and energy delivery. Our team of outstanding professionals is focused on performance, thought leadership, innovation, and the power of ideas that come from a diverse and inclusive workforce.

Exelon will provide you the tools and resources you need to design, build and enhance a successful career. We are also dedicated to motivating the success of our employees through competitive base salary, incentives, and health and retirement benefits.

Join Exelon and share your passion at a forward-thinking Fortune 100 company. Establish yourself in a place where you can truly shine and create a brighter, more sustainable tomorrow. Energize your career at Exelon!


PRIMARY PURPOSE OF POSITION
We are building a
true top tier analytics group - a small, nimble, autonomous team of cross
functional specialists.

Goal is simple -
do maximum good - have a true impact TODAY (climate change, aging infrastructure,
limited human and monetary resources, other calamities are challenging the
granted persistence of a fundamental pillar of our edification - always on
electricity).

Method - anything
goes (continuously improving Tools, Techniques, Technology). Long term plan -
build a (true) AI into the distribution grid (decentralized - estimated 700
trillion - not billion - rows of data processed on the edge).

Reason - self monitoring
(interconnected - IOT, AMI, PMU, oscillography, drones, satellite images,
lidar, weather radar like NEXRAD, human generated reports, etc...), self-healing
(DA devices, relays, automated alerts, AI requested repairs and inspections,
rerouted current, lowered voltage, etc...) - a true ""hive mind"" with
different ""species"" of IOT incorporating the mass collected nform

ation
into the huge number of decisions the ""hive"" will be executing on.

Apply the scientific
method to extract knowledge and insights from data, which may take the form of time-series
(smart-meters, smart-grid, weather and other IoT), structured (relational data
stores), and unstructured (text and multi-media) data sets. Leverage these insights
to deploy data-driven applications in support of strategic business priorities.
Possess an advanced knowledge of predictive modeling techniques,
and prior exposure with high-performance computing technologies. Use your skills to manage several projects
running in parallel.

Closely collaborate with various internal stakeholder and external
partners to understand business needs, by providing and receiving regular
feedback. Use these collaborations to plan, execute, and deploy analytics-based
solutions.

Mentor to more junior peers and oversee their
activities where needed. Provide subject matter
expertise in the areas of artificial intelligence, machine learning, feature
engineering, data mining, data manipulation/storage, and high-performance computing.

A successful candidate will quickly adopt the team’s established
working processes and toolkit while growing his/her knowledge of the utilities
industry.
Position may be required to work extended hours, including 24 x 7
coverage during storms or other energy delivery emergencies.

PRIMARY DUTIES AND
ACCOUNTABILITIES
Develop
key predictive models improving grid reliability and resiliency, improving grid
response to severe weather events as well as gray sky day and long term
climate change effects, operating performance improvement, and increased
safety best practices.
Analyze data using advanced analytics techniques in
support of process improvement efforts using modern analytics frameworks,
including but limited to: Python, R, or equivalent; ArcGIS or equivalent, weather data collection and analysis systems
Access and analyze data sourced from various Company
systems of record. Lead the development of strategic business, resiliency, weather
impact reduction, and program implementation plans.
Access and enrich data warehouses
across multiple Company departments. Build, modify, monitor and maintain
high-performance computing systems.
Provide
expert data and analytics support to multiple business units. Provide guidance
and be a mentor to junior peers.
Represent
the Company at analytics focused industry forums and peer group events,
bringing back leading practices to evolve the Company’s analytics maturity.


POSITION SPECIFICATIONS

Minimum:

Education:
Bachelor’s degree in a Quantitative or Climate related discipline.
Ex: Applied Mathematics, Computer
Science, Finance, Operations Research, Physics, Statistics, Climatology,
Geography or related field

Experience:
Minimum of 8 years of experience analyzing datasets.

Minimum
of 3 years of experience applying advanced analytics techniques to diverse data
sets data.

Minimum
of 3 years of experience in data mining in a business environment with large,
complex datasets.

Analytical Abilities:
Demonstratable strong knowledge in the following areas: machine learning,
artificial intelligence, statistical modeling, data mining, information
retrieval, or data visualization.

Technical Knowledge:
Proven
experience in developing and deploying predictive analytics projects using one
or more leading languages (Python, R, Scala, etc.).

Experience working
within an open source environment and Unix-based OS.

Communication Skills:
Ability to translate data analysis and findings into coherent conclusions and
actionable recommendations to business partners, practice leaders, and executives.
Strong oral and written communication skills. Experience presenting to diverse
audiences including presenting to conferences and business symposia.

preferred:

Education: Masters, or PhD from a leading program in a Quantitative or Climate related
discipline.

Experience:Prior professional experience
in the utilities or broader energy sector.Prior exposure to data structures pertaining to smart-meters, billing, or
outage management systems.

Demonstratable strong
knowledge around the full spectrum of data science lifecycle, including analytics-driven
product delivery.

Analytic Abilities: Superior understanding of relevant theories in machine learning, statistics,
probability theory, data structures and algorithms, optimization, etc.

Strong understanding of weather-related
data, collection and analysis, impact of climate on grid, preferably with
machine learning modeling experience in that discipline.

Technical Knowledge: Strong coding skills (Python, R, Scala, etc).

Proficiency in working with
various databases and data storage systems.

Communication Skills: Ability to clearly translate executive and analytics leaders’ vision and
guidance into methods and analytics.

Strong time management and
presentation skills. Strong track record of (academic preferably) publications.

Leadership Skills:

Ability to build consensus, establish trust, communicate
effectively and foster culture change.

Qualifications
POSITION SCOPE
Research
and experiment on data science technologies, discover opportunities for new
data analytics features, and influence resiliency planning, investment and
technology strategies of the company.
Develop
algorithms (machine learning, statistical modeling, optimization) that power
data analytics solutions.
Drive
the productization of the algorithms either by writing high-quality, reusable
code modules or advising the engineering teams on implementing the algorithms.
Communicate
research results effectively in written and spoken forms to various audiences
including product managers, system engineers, business executives, and customers.
Become
a trusted mentor to peers and collaborators.
Educate
the organization on data science technologies and data analytics through
internal presentations, training workshops, and publications.
Represent
the organization and advocate its data analytics efforts and capabilities through
external conferences and publication opportunities.
Exelon is proud to be an equal opportunity employer and employees or applicants will receive consideration for employment without regard to: age, color, disability, gender, national origin, race, religion, sexual orientation, gender identity, protected veteran status, or any other classification protected by federal, state, or local law.

VEVRAA Federal Contractor

EEO is the Law Poster

]]>",3.9,"Exelon Corporation
3.9","Oakbrook Terrace, IL",10000+ Employees,2000,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$10+ billion (USD)
Data Engineer,"$67K-$124K
(Glassdoor Est.)","Turn it up to 11 as a Data Engineer!

Do you want to solve some of the biggest challenges facing companies today using data and analytics? Do you want the opportunity to work with a team of incredibly intelligent, fun-loving, and collaborative individuals? Are you looking to grow and develop your skills across a variety of technologies and tools?

If you answered yes to any of those questions, then Inspire11 could be a great fit for you! We are a full services local consulting firm that is building out customized solutions to help our clients stay relevant in an ever-changing technological environment. Our project work spans across a variety of specialties from data warehousing to data science and a variety of industries.

We partner with our clients to optimize their business, and ultimately blow their minds with the solutions we're able to implement. Our team is always tackling the most difficult problems that client teams face, and are never stuck in maintenance mode.

Our team is always learning from each other and pushing the boundaries of what's possible.

You're still not sold? There's More:
Growth opportunity: We are always learning new technologies and educating our clients on what's available in the data space. You also will have the opportunity to engage in growing the team and there are ample opportunities to take ownership
Work life balance: We are respectful of people's boundaries and have unlimited time off so that our team has time to recharge and do their best work
Flexible hours: We understand that our team members have different needs and do our best to work with their schedules while accommodating client needs
Inclusive environment: We are committed to building an inclusive environment where all teammates feel comfortable and supported
Fun! We love to keep things fun, both within our client work and at company wide events
So what do I have to do to join?
Participate in the full life-cycle of development, through definition, design, implementation, and testing
Identify data sources, provide data flow diagrams and documents source to target mapping and process
Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Work with the client and consulting team to help gather requirements; understand different processes as it relates to different parts of the business and where there is overlap
Assist with report development using tools such as: Tableau, PowerBI, Qlickview
Regularly contribute to ongoing improvements in engineering process and product development
Support business decisions with ad hoc analysis as needed
I can do that! Any other skills that I need?
5+ years of experience as a data/software engineer
Strong understanding of data modeling concepts and design
Strong understanding of data warehousing technologies, ETL processes and data flow architectures and tools
Experience in Software Development Lifecycle (SDLC) utilizing the Agile approach
Organized, detailed oriented, and can manage multiple projects at the same time
Excellent communication skills
Comfortable working in fast paced environments, are able to wear many hats, and have a general fear of being bored
We believe that everyone drives change, and everyone is an owner. Nothing excites us more than having the ability to collaborate with intelligent, highly-motivated and talented people on challenging problems as we work to change the face of the digital and analytics space.",4.8,"Inspire11
4.8","Chicago, IL",51 to 200 Employees,2016,Company - Private,Consulting,Business Services,Unknown / Non-Applicable
Data Engineer,"$97K-$115K
(Glassdoor Est.)","Description


At our heart, we are technologists with a keen understanding of business environments, challenges, and initiatives. Our team of experts bring decades of technical and consulting knowledge, project leadership, and an understanding of complex problem-solving. We have an established track record in all things Microsoft Azure and Microsoft 365 including Application Services, Azure Infrastructure, Data Platform Services, Machine Learning, User Experience, and IoT.

We are seeking Data Engineers as a critical part of our Azure Cloud Enablement (ACE) team.
Location: Chicago IL
Travel: Up to 30%
ACE in a nutshell


The ACE team sits at the intersection of technology, innovation, creativity, and blended learning. At our core, we are obsessed with providing customers with the best solutions to their biggest challenges.

We build B2B enterprise software: smart vehicles, custom web apps that hit hundreds of thousands of people, and big data warehouses are just some of what you will have the opportunity to develop. We are Microsoft Gold Certified in Application Development, Cloud Platform, Data Analytics, Data Platform and many more.

You’ll work out of our bustling Chicago office, side-by-side with experts in all things Data Platform, Data Science, Application Development, User Experience, and Cloud Infrastructure. Expect rapid career growth—we preach recognition and reward those with the aptitude and attitude to get it right.

Once you’re here…


You'll have full access to our reference architecture. Our services methodology is built on reusable technology components, patterns, and processes that have been refined and proven on thousands of production solutions. You’ll learn to develop complex data architectures, solve for real-time data needs of large businesses, and navigate the changing landscape of the Azure stack.

You will collaborate regularly with our experts, work across numerous industries, clients, and technologies. You will learn something new every day and begin adding value to our team almost immediately. You’ll join our flagship Launch Program to get you up to speed as quickly as possible.

You will partner with clients across several key industries including Healthcare, Manufacturing and Industrial Products, Financial Services, Professional Services, Engineering and High Technology, Retail and more.

Beyond the tech, you'll benefit from dollar for dollar 401(k) matching (up to 6% of your salary), ongoing structured learning opportunities, subsidized healthcare, vision, and dental plans (amongst others), a fully stocked snack, coffee, and drink bar, and a laid-back team looking to disrupt the status quo.

Relevant experience


Our basic requirement is that you must have completed a relevant job, program, degree, or internship at some point in the recent past. You should have experience working with others collaboratively, thinking critically about solving problems and technically executing. You should be hungry to learn new technology, humble with your willingness to help others, and socially capable of working collaboratively.
You must be able to work with customer stakeholders to understand business and technical requirements.
You should have skill in SQL at an advanced level, including complex queries, data definition, constraint specification, coding with SQL or similar, and database modeling.
You are inherently iterative, with knowledge of Agile methodologies, estimation techniques, and (optionally) workshop and prototype techniques.
You have a strong understanding of one or more of the following:
Power BI or similar data visualization tool
Azure or similar cloud platform
Python or Spark or similar Data Engineering language
PowerShell or similar scripting language
Azure Data Warehouse (ADW) or similar MPP database platform
Azure Data Lake (ADL)
Nice to haves:

Experience with Azure Data Platform (Azure Data Factory v.2, Azure Data Warehouse, Databricks, etc.)
Knowledge of the overall internal structure of a database system including indexing, query processing, transaction management, and fault tolerance.
Ability to design a database, implement a design in a real database system, and construct user interfaces to the database via an API or 3rd party tool.
2+ internships in related roles.",4.7,"Capax Global
4.7","Chicago, IL",51 to 200 Employees,1998,Subsidiary or Business Segment,IT Services,Information Technology,$25 to $50 million (USD)
"Data Analyst, Panel Operations","$37K-$65K
(Glassdoor Est.)","Data Analyst, Panel Operations
Submit
#495797
/
Regular Part-Time
/
Chicago – 55 East Monroe Street, IL
/
Business Ventures and Innovation
JOB DESCRIPTION:
AmeriSpeak is a fast-growing, fast-paced, innovative, probability-based panel housed within NORC at the University of Chicago, a world leader in research excellence. The Data Analyst for Panel Operations is a singular opportunity to develop, hone, and use your statistical and data management skills. You will perform strategic actions and collaborate on strategic planning to ensure that AmeriSpeak continues as the gold standard of the probability-panel panel in the nation. You will have the opportunity to work with, assist, and coordinate a multidisciplinary, cross-functional team that includes statisticians, data scientists, survey programmers, IT personnel, client account development staff, client support staff, and telephone center staff.

The Data Analyst, Panel Operations has significant involvement in a broad range of critical management functions, including productivity analysis and reporting, survey data processing and reporting, quality assurance, and methodological improvement and financial reporting. This position exercises independent judgment and discretion with regards to matters of significance, such as changes to customer’s products.

Due to COVID-19, this position will initially be remote, but will be based in our 55 East Monroe office when it is safe to resume office work.
DEPARTMENT:
AmeriSpeak® is the first U.S. multiclient household panel to combine the speed and cost-effectiveness of panel surveys with enhanced representativeness of the U.S. population, an approach designed to achieve an industry-leading response rate and an innovative sample quality report card. AmeriSpeak has become the primary survey partner of the nation's preeminent news service, The Associated Press.

Developed and funded by NORC, AmeriSpeak randomly identifies Americans—including the country’s hardest-to-reach populations—and recruits them to provide their opinions and insights on a wide range of topics critical to our clients. The outcome is a truly representative picture of America and, thus, more accurate research results for use in statistical surveys.
RESPONSIBILITIES:
• Create, produce, and validate weekly and monthly panel performance and new panel initiative metrics. As new project initiatives commence, research and evaluate their efficacy (including consulting with stakeholders) by developing accurate performance tracking reports. As reports are produced, analyze content, highlight relevant issues, and make recommendations. Working with the rest of the AmeriSpeak Panel Operations Group, develop and participate in implementation of strategies to address problems revealed through the reports.

• Ensure smooth implementation of processes needed to maintain a high quality survey panel. Ensures that registration and panel demographic data is captured and processed accurately and regularly, that subsequent on-boarding steps are initiated on-time. Create and maintain clear, concise, and detailed documentation of such processes, including work flow document and data dictionaries.

• Take a lead role in special projects as required, for example, analysis of call history data, analysis of panelist experience feedback, preparation of training materials, auditing compliance with certain procedures, or literature reviews of methodological issues.

• Support business development activities for proposal, pricing, and contracting support for web survey projects.
• Perform other duties as assigned.
REQUIRED SKILLS:
• Bachelor's degree.

• At least 1 years’ experience in quantitative analysis using SAS syntax. Some experience with other statistical tools such as R or SPSS is preferred.

• At least 1 years’ experience in database maintenance of tracking data.

• Strong knowledge of survey research; knowledge of data collection and data flow processes preferred.

• Ability to communicate effectively (oral and written) at all levels.

• Proficiency with data management in SAS, STATA, R, or SPSS ; Microsoft Office software, including word processors, spreadsheets and graphics (Outlook, Word, Excel, and PowerPoint).
WHAT WE DO:
NORC at the University of Chicago is an objective, non-partisan research institution that delivers reliable data and rigorous analysis to guide critical programmatic, business, and policy decisions. Since 1941, our teams have conducted groundbreaking studies, created and applied innovative methods and tools, and advanced principles of scientific integrity and collaboration. Today, government, corporate, and nonprofit clients around the world partner with us to transform increasingly complex information into useful knowledge.
WHO WE ARE:
For over 75 years, NORC has evolved in many ways, moving the needle with research methods, technical applications and groundbreaking research findings. But our tradition of excellence, passion for innovation, and commitment to collegiality have remained constant components of who we are as a brand, and who each of us is as a member of the NORC team. With world-class benefits, a business casual environment, and an emphasis on continuous learning, NORC is a place where people join for the stellar research and analysis work for which we’re known, and stay for the relationships they form with their colleagues who take pride in the impact their work is making on a global scale.
EEO STATEMENT:
NORC is an affirmative action, equal opportunity employer that values and actively seeks diversity in the workforce. NORC evaluates qualified applicants without regard to race, color, religion, sex, national origin, disability, veteran status, sexual orientation, gender identity, and other legally- protected characteristics.
8.31.2020
/
Back",3.1,"NORC at the University of Chicago
3.1","Chicago, IL",1001 to 5000 Employees,1941,Nonprofit Organization,Research & Development,Business Services,$100 to $500 million (USD)
Data Engineer,-1,"Vertical Trail LLC is a rapidly growing consultancy focused on delivering modern Analytics, Big Data, and Cloud solutions.

Vertical Trail is looking for a strong Data Engineer to become an integral part of our advanced analytics team. This Data Engineer will focus on using modern technologies to transform mountains of data into meaningful insights.

Candidates must be able to work for Vertical Trail as a W2 employee. Vertical Trail is not considering third party or contract candidates for this role.

Our Data Engineer will:

· Assist with development and data management tasks as needed to support Big Data and analytics projects

· Work closely with developers, consultants, and business analysts to understand needs

· Design, build, and launch new data extraction, transformation, and loading processes in production

· Assist with the design, build, and launch of new production data models

· Support existing processes running in production

· Monitor cluster connectivity and security

· Develop scripts and tools to automate common administration tasks

· Troubleshoot data load, transformation scripts, and performance issues

Data Engineer Requirements:

· 4+ years of working experience as a Data Engineer

· 3+ years of experience using ETL tools to perform data cleansing, transforming, and scheduling various workflows

· Strong experience with AWS RedShift and RDS

· Experience creating different S3 buckets and writing Lambda functions

· Proficient coding and scripting in Python

· Experience creating and maintaining large-scale data structures that help users generate, store, and manage Big Data

· Expert knowledge of relational database modeling concepts

· Strong understanding of data warehousing

· Experience with AWS cloud services: Lambda, S3, Glue, and Redshift

Employment with Vertical Trail is an exciting opportunity that offers ample avenues for professional growth and development as well as attractive benefits including:
Comprehensive Health, Dental, and Vision insurance
Employer-Paid Life and Disability insurance
401(k) / Retirement Plan
Professional Development Plan
If this opportunity sounds like the right one for you, please contact us today!

This is a remote position.",5.0,"Vertical Trail
5.0","Chicago, IL",1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable
Sr Data Scientist,"$120K-$150K
(Glassdoor Est.)","Data Scientist

Chicago, Illinois, United States

DESCRIPTION

CreditNinja is a FinTech company founded in 2017 by veteran serial entrepreneurs who were part of the core team behind Enova (NYSE:ENVA), a leading publicly traded consumer financial services company. CreditNinja's mission is to provide hardworking Americans with financial solutions when unexpected expenses arise. Unlike traditional banks, CreditNinja works hard to ensure that people with less-than-perfect credit can have quick access to the money they need. Headquartered in downtown Chicago, we are a lean and innovative team seeking like-minded talent to help us disrupt the consumer finance industry.

CreditNinja is seeking a Sr. Data Scientist to join a team of analytics and machine learning experts. The hire will focus on building machine learning models and running exploratory data analysis to make a direct impact in a data-driven company. The individual must be self-directed and comfortable working with cross functional teams. This is an exciting and rare opportunity to join a well-capitalized startup on the ground floor and help drive our success.

Key Responsibilities:
Develop, improve and test companys models to optimize lending decisions by using advanced statistical modeling and simulation techniques
Support implementation of the models working closely with software engineering team
Research, test and operationalize new analytics techniques and data sources to improve portfolio performance
Conduct ad hoc analysis using advanced data mining tools to support risk management, operations and marketing strategies
Assist with development of technical tools and platforms to standardize and streamline model development and monitoring processes
Work with cross-functional teams to explore new ways of finding insights from data and provide recommendations. Conduct exploratory research into our data, our metrics, and how we can better use these commodities
REQUIREMENTS
A Bachelor's, Master's or PhD in math, statistics, computer science, engineering or related field
5+ years of experience with data analytics and statistical modeling
Advanced programming skills in Python
Experience building machine learning models
Experience working with relational databases, such as SQL
Experience working within an open source environment
Strong quantitative and problem-solving skills with key attention to detail
Strong project management and organizational skills and the ability to work independently in a fast-paced, quickly changing environment
Experience supporting and working with cross-functional teams in a dynamic environment
Experience working with specialty finance or FinTech is a plus
Start-up experience is a plus
Applicants must be currently authorized to work in the U.S. on a full-time basis
BENEFITS
Competitive salary and benefits package, including material equity grant
Casual dress policy
Fun, fast-paced work environment
Dynamic start-up culture
Ability to make an immediate impact in a growth stage company
Convenient downtown Chicago office located in the heart of the city
Equal opportunity employer",5.0,"CreditNinja
5.0","Chicago, IL",1 to 50 Employees,-1,Company - Private,Lending,Finance,Less than $1 million (USD)
Lead Data Scientist,"$85K-$137K
(Glassdoor Est.)","We are Farmers!
Join a team of diverse professionals at Farmers to acquire skills on the job and apply your learned knowledge to future roles at Farmers. Farmers Insurance also offers extensive training opportunities through the award winning University of Farmers named by Training magazine amongst top 10 corporate training units in the world.

Want to learn more about our culture & opportunities? Check out farmers.com/careers and be sure to follow us on Instagram and LinkedIn!
Job Summary
This role has the potential to be virtual
Leader of a group of data scientists to apply state of the art analytics and ETL to Distribution, Life and Financial Services challenges. (note: we are growing quickly and will consider all sr. level candidates from newer managers to seasoned as well as sr. individual contributors)
Leverages customer information such as macro and micro (transactional) behavioral data to influence strategic business decisions while using complex, innovative analytics, multi-variate models, machine learning and data mining technologies.
Helps operationalize business decisions. Drives home a Measures of Success culture within Farmers with a focus on profitable growth initiatives.
Deepens and expands the data science toolkits available to Farmers.
Contributes to Farmers understanding of market intelligence.
Includes business, strategy and IT implications in all initiatives.
Manages other data scientists to both succeed as well as grow professionally.
Opportunity for on-the-job exposure to grow both team and personal skills in all data science dimensions (data structures, hardware environments, complex modeling, strategy, and IT integrations of analytics)
Essential Job Functions
Owns complex and often vague business challenges involving data science for Farmers. Scopes projects, defines measures of success, and a data science vision for project success. Obtaining business and IT buy-in and a roadmap for success given the talent and tools available. Executes on projects with a sense of urgency succeeding in hitting deliverable dates.
30%
Partners closely with IT, business, and Data Management teams in understanding and utilizing our data infrastructure for projects both improving ingestion of information as well as operationalization of results.
15%
Responsible for a deep knowledge of consumer analytics including closure models, retention models, agency economics, and lead optimization.
15%
Hands on ability to program, ETL, and advanced modeling methods to drive home projects and lead the team through examples of good technical skills. Python, GitHub, Machine Learning and multi-variate modeling, APIs, SQL, ETL software.
15%
Collaborates with business partners, executives and other leaders to understand/prioritize analytical needs, to deliver solutions and drive implementation. Advises and serves as an objective and transparent partner to drive fact-based decision making and a measures of success culture.
5%
Ability to present complex information clearly to both technical and non-technical audiences at all levels of a project. Skills include PowerPoint.
10%
Manages directing and indirectly a team of professionals that provide analytic capabilities for solutions. Ability to coach technical and non-technical skills including programming skills.
10%
Physical Environment
Education Requirements
Bachelors and Master’s Degree in Statistics, Economics, Data Science, Mathematics or related field preferred. On the job experience could substitute for Master’s degree.
Experience Requirements
7-10 years of Business planning, analytics or statistics with Farmers or equivalent external experience.
Track record of success solving quantitative problems using data science for complex business questions with a focus on consumer behavior; implementing these solutions across multiple business teams (analytics, IT, business, etc.).
Experience designing and implementing analytics and modeling processes across a team of data science analysts.
Special Skill Requirement
Possesses strong technical aptitude in Python, GitHub, ETL software like SQL,

PowerPoint. Expert level skills in Excel. Proficient in English written and verbal communication skills.
Ability to build strong internal and external customer relationships.
Work is accomplished without considerable direction. Exercises judgment in selecting methods, techniques, and evaluation criteria in obtaining results. Exerts significant latitude in determining objectives of assignment. Takes calculated risks with consultation from the team.
Works on complex issues where analysis of situations or data requires in-depth evaluation of variable factors. Constructs and may pursue alternative paths towards a solution. Exercises judgment in selecting method, techniques and evaluation criteria for obtaining results consistent with broadly defined policies and practices. Problem/Task resolution timeframe: Inclusive of shorter timeframes, but typically six to twelve months or more to resolve.
Uses policies and general objectives with little functional guidance. Rarely refers specific cases to manager unless clarification or interpretation of organization policies is involved.
Does not make erroneous decisions or recommendations that would normally result in the inability to reach crucial organizational objectives and may have prolonged effect, as well as the expenditure of substantial resources.
Frequently takes part in inter-organizational and outside customer / vendor contacts. Part of a team who represents the organization. Monitors activities and communicates information across the organization.
Farmers is an equal opportunity employer, committed to the strength of a diverse workforce.

Schedule: Full-time

Job Posting: 08/28/2020

Other Locations: United States, Illinois, Chicago",3.4,"Farmers Insurance
3.4","Chicago, IL",10000+ Employees,1928,Subsidiary or Business Segment,Insurance Carriers,Insurance,$1 to $2 billion (USD)
"Software Development Engineer, Data Engineering","$83K-$145K
(Glassdoor Est.)","Groupon’s mission is to become the daily habit in local commerce and fulfill our purpose of building strong communities through thriving small businesses by connecting people to a vibrant, global marketplace for local services, experiences and goods. In the process, we’re positively impacting the lives of millions of customers and merchants globally. Even with thousands of employees spread across multiple continents, we still maintain a culture that inspires innovation, rewards risk-taking and celebrates success. If you want to take more ownership of your career, then you're ready to be part of Groupon.

Are you a passionate, energetic and technology enthusiast eager to work at a rapid pace with the flexibility to work across our suite of technologies? Are you a problem solver; someone who enjoys debugging code, resolving issues, and creating solutions for common problems? Do you get a little obsessed with the details?

The Data Engineering team at Groupon is at the heart of all things “data”, working on designing and building the next-generation data pipelines for data-science/machine learning community users. Our mission is to empower data analysts & data-scientists across all business units to make better business decisions. This role offers a unique combination of skills in computer science (distributed systems, big data), cloud, scalable and high-performance production systems.

We're a ""best of both worlds"" kind of company. We're big enough to have resources and scale, but small enough that a single person has a surprising amount of autonomy and can make a meaningful impact. We're curious, fun, a little intense, and kind of obsessed with helping local businesses thrive. Does that sound like a compelling place to work?

Our development ecosystem:
Python/Scala
pySpark
Snowflake
Airflow
AWS
Hadoop
GitHub
JIRA
You’ll spend time on the following:
Design, and implement the data pipelines providing access to large datasets and transforming power for data across the org
Write complex but efficient code to transform curated data into business questions oriented datasets and data visualizations.
Work with big data and distributed systems using technologies such as Spark, AWS EMR, and Python.
Actively contribute to the adoption of strong software architecture, development best practices, and new technologies. We are always improving the process of building software; we need you to help contribute.
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using open sources and AWS big data technologies
Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency
Collaborate with Business Users, Infra Engineers , Data Scientists to recognize and help adopt best practices in data gathering and transforming big data
Identify, design and develop new tools and processes to improvise the data storage and compute to help the Data Engineering and Data Consumption teams and users
Interface directly with stakeholders, gathering requirements and owning automated end-to-end data data engineering solutions.
Provide technical guidance and mentoring to other engineers for best practices on data engineering
We’re excited about you if you have:
Bachelor’s degree in computer science, mathematics, or a related technical field
5+ years of relevant employment experience in data engineering or related field
At least 1 year experience working with Kafka, Avro, and Delta or similar technologies
At least 3 years of SPARK development experience
At least 1 year experience with Airflow, NiFi, Luigi or Azkaban
Clear understanding of testing methodologies and AWS Best Practices
A big plus if you have AWS Certification
Mastery to big data technologies (e.g. Hadoop, Hive, Spark, EMR)
Excellence in technical communication and experience working directly with stakeholders
Experience maintaining data pipelines using big data technologies like Hadoop, Hive, Spark, EMR etc.
Demonstrated ability to coordinate projects across functional teams, including engineering and product management
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
We value engineers who are:
Customer-focused: We believe that doing what’s right for the customer is ultimately what will drive our business forward.
Obsessed with quality: Your production code just works & scales linearly
Team players. You believe that more can be achieved together. You listen to feedback and also provide supportive feedback to help others grow/improve.
Fast learners: We are willing to disrupt our existing business to trial new products and solutions. You love learning how to use new technologies and then rapidly apply them to new problems.
Pragmatic: We do things quickly to learn what our customers desire. You know when it’s appropriate to take shortcuts that don’t sacrifice quality or maintainability.
Owners: Engineers at Groupon know how to positively impact the business.
inclusive employee groupsGroupon’s purpose is to build strong communities through thriving small businesses. To learn more about the world’s largest local ecommerce marketplace, click here for the latest Groupon news. Plus, be sure to check out the values that shape our culture, guide our strategy and make our company a great place to work. And just don’t take our word for it. Hear from real Groupon team members and learn more about our inclusive employee groups. If all of this sounds like something that’s a great fit for you, then click apply and let’s see where this takes us.",3.3,"Groupon
3.3","Chicago, IL",5001 to 10000 Employees,2008,Company - Public,Internet,Information Technology,$1 to $2 billion (USD)
Principal Data Scientist – Digital Touch,"$120K-$190K
(Glassdoor Est.)","Principal Data Scientist – Digital Touch
Customer Success | Seattle, Washington, San Francisco, California and Chicago, Illinois

Our agreement with employees
DocuSign is committed to building trust and making the world more agree-able for our employees, customers and the communities in which we live and work. You can count on us to listen, be honest, and try our best to do what's right, every day. At DocuSign, everything is equal. We each have a responsibility to ensure every team member has an equal opportunity to succeed, to be heard, to exchange ideas openly, to build lasting relationships, and to do the work of their life. Best of all, you will be able to feel deep pride in the work you do, because your contribution helps us make the world better. And for that, you'll be loved by us, our customers, and the world in which we live.

The team
Our Customer Success team is the largest organization in the world focused entirely on agreement processes and technologies. We are the Agreement Experts. With hundreds of thousands of successful customers worldwide, we know how to help our customers see results quickly. And that experience is just one of the reasons our customers trust us to connect, automate, and integrate their systems of agreement, everywhere they need to get work done. As part of our global team of Agreement Experts – in professional services, customer success management, learning and enablement, and customer support – you'll bring your knowledge, insights, and proven expertise to help our customers achieve more than they ever thought possible.

This position
The Principal Data Scientist – Digital Touch is responsible for designing and building models & algorithms for the Digital Customer Success, Adoption Enablement and Success Marketing that power the next generation of actionable insights for the Customer Success organization at DocuSign. The ideal candidate has a rich experience across one or more domains of Customer Success, Adoption Marketing, Digital Analytics, Advertising, Consumer behavior, Customer Journeys and Sales Lifecycle. The candidate is a lead decision / data scientist with a track record of driving successful data science initiatives, advanced predictive and prescriptive analytics for business and customer facing outcomes. In this role you will leverage statistical analysis and machine learning to help DocuSign Customer Success teams drive adoption & consumption campaigns leading to higher retention, upsell and cross-sell. You will partner closely with other data scientists and analysts in Customer Success Analytics, product engineering, marketing, sales and finance, while collaborating & partnering with customer success teams on business & customer requirements to improve customer journeys and drive targeted customer outcomes with tangible ROI. This role requires the ability to deliver in matrixed organization at global scale. The candidate is deeply analytical with keen understanding of business process and programs and the ability to translate data and insights into executive readouts.

This position is an individual contributor position and reports to the Director Customer Success Analytics.

Responsibilities
Design and build predictive & prescriptive models across the Customer Success lifecycle marketing and Success Marketing – understand & track events and interactions – drive analytics on attribution to usage and adoption – predict journeys customer will take with campaigns & content navigation
Create models to deliver meaningful insights & analysis on the effectiveness and impact of campaign, webinars, events and communications on customer usage & adoption.
Design and build models to influence decisions for optimal audience targeting for different outreach programs based on program goals, system constraints, and customer lifecycle analysis
Drive consistency in data collection and processes within the Customer Success Lifecycle Marketing team and Customer Success content teams
Coordinate with the Marketing Operation team on campaign audience builds and results
Partner with cross-department to report accurately on data sourced from many different data sources including Support, Product, DocuSign University, and Professional Services
Create requirements for dimensional models to support the required analysis in a more automated fashion
Design and report on A/B tests for new and modified campaigns and programs, including design of control groups
Collaborate with front-line, customer-facing Customer Success teams to gather customer insights and best practices to inform and drive content asset creation, performance and measurement.
Create methodology for understanding content effectiveness across the Support Site, DocuSign University, and any other platforms
Drive and develop the customer journey analytics across enablement experiences. Use analytics and data to evaluate effectiveness, drive changes, identify enhancements for new programs.
Deliver on insights and analytics to help business leaders answer critical questions related to Customer lifecycle marketing, Success marketing, customer experience, and impacts on adoption, usage and health
Report on key metrics and KPIs to all key business partners, including Sr. Leadership, across Customer Success Enablement, Professional Services, field CSM roles, and regional CSM organizations in EMEA and APAC
Determine opportunities for improvement across process, tooling and data automation to optimize costs and decrease turnaround time for analytics consumers
Basic Qualifications
12+ years of experience in solving complex business problems using advanced analytics, statistical techniques (preferred exposure to machine learning) to drive marketing analytics, campaign targeting and analytics, event analytics, customer journey analysis
4+ years Python, knowledge and hand-on experience in statistical programming and data science toolkits – one or more of Pandas/Jupyter/SCIKIT/Tensorflow
3+ years of experience in executing on complex projects, extracting, cleansing, and manipulating diverse structured and unstructured data sets on relational – SQL, NOSQL databases
3+ years of experience working in an agile environment with iterative development & business feedback
3+ years of provide insights to support strategic decisions, including preparing and delivering insights and recommendations
3+ years of experience across Customer and Marketing scenarios with knowledge of data science concepts related to customer lifecycle marketing, content management - customer journeys, lifetime value
3+ years of SQL with excellent hands-on exposure to creating complex queries across multiple database schemas
3+ years working with multi-million rows of data
3+years of experience in Enterprise Visualization Tools: Tableau / QlikView /PowerBI and proficient in MS Office Suite with advanced Excel skills - pivot tables, macros, PowerPivots, advanced functions
A Bachelor's or Master's degree in Computer Science, Business Analytics, Marketing Analytics, Applied Mathematics or Statistics, Econometrics, or closely related field
Preferred Qualifications
Experience applying machine learning solving real business and customer problems
Comfortable with loosely defined requirements where you exercise your analytical skills to collaborate with the rest of the team to build solutions
Excellent problem-solving skills with ability to synthesize & communicate complex results to senior leaders
Attention to detail with focus on data quality, data consistency and criticality
Ability to shape ambiguity, govern & prioritize in a matrixed environment across organizational boundaries
Strong desire to stay ahead of industry trends & technologies with a commitment to continuous learning
Preferred experience using machine learning to build recommender systems
Exposure to AI, Deep Learning, Neural Networks, NLP
Exposure to big data platforms – Snowflake, Redshift, Azure, Matillion, Hadoop
Excellent at articulating vision and planning execution of projects
About us

DocuSign® helps organizations connect and automate how they prepare, sign, act on, and manage agreements. As part of the DocuSign Agreement Cloud, DocuSign offers eSignature: the world's #1 way to sign electronically on practically any device, from almost anywhere, at any time. Today, hundreds of thousands of customers and hundreds of millions of users in over 180 countries use DocuSign to accelerate the process of doing business and simplify people's lives. Plus, we save more trees together! And that's a good thing.

DocuSign is an Equal Opportunity Employer. DocuSign is committed to building a diverse team of talented individuals who bring different perspectives to the discussion and who feel a sense of inclusion and belonging when they join our team. Individuals seeking employment at DocuSign are considered without regards to race, ethnicity, color, age, sex, religion, national origin, ancestry, pregnancy, sexual orientation, gender identity, gender expression, genetic information, physical or mental disability, registered domestic partner status, caregiver status, marital status, veteran or military status, citizenship status, or any other legally protected category.

#LI-DS1",4.6,"DocuSign
4.6","Chicago, IL",5001 to 10000 Employees,2003,Company - Public,Computer Hardware & Software,Information Technology,$1 to $2 billion (USD)
Director of Data and Analytics Engineering,-1,"Who We Are:

Founded by a seasoned group of serial software entrepreneurs who have years of experience in policing and city governance, Benchmark Analytics is a SaaS solutions provider housed in the Ravenswood technology corridor on Chicago’s north side. In collaboration with our research partners, led by a strategic alliance with the University of Chicago to commercialize their research, we have built a predictive analytics platform for law enforcement workforce management and early intervention. We are a double-bottom line company – our management team is comprised of former police personnel, former city officials, and current change makers who believe in (and have witnessed) the power of data to transform government.

We are currently seeking a talented Director of Data and Analytics Engineeringto join us as we continue to grow our predictive analytics business for improving officer behavior to scale to our quickly growing user base.

As a Director of Data and Analytics Engineering, you’ll get to:
Build a team of engineers to design, build and integrate a platform for importing, analyzing, and visualizing data from myriad data sources;
Collaborate with the technology leadership team to roadmap and iteratively improve our systems;
Report to the Chief Research Officer and join a team of data scientists and consultants that focus on improving law enforcement officer behavior.
If you are interested in building the platform for improving public sector operations while collaborating with experienced entrepreneurs, we believe this is an unprecedented opportunity to experience it first-hand.
Responsibilities

Working with leadership and peers to deliver a unique, multi-tenant data platform. Specifically, you will be responsible for…
Designing and delivering the data pipeline platform:
Rearchitecting and designing a high throughput data system (multi-tenant data lake and databases)
Building automated tools for importing standardized and non-standardized customer data
Building automated tools for detecting and importing data from our transactional platform
Building dynamic, high performance system for processing millions of records daily
Building self-service UI/UX for managing pipelines
Building product specific UI for customer visualizations
Automating deployment of white-labeled BI (Izenda)
Managing an existing python-based toolset for ETL (django+airflow) and modeling (Scikit learn and licensed software)
Integrating machine learning models developed by our data scientists
Integrating user experience with transactional platform
Integrating with Java/NodeJS/ReactJS transactional platform
Deploying/embedding BI system (Izenda) into ReactJS front-end
Deploying/embedding custom visualizations
Quality Assurance
Ensuring high quality, scalable, maintainable code
Delivering accurate results
Managing change in a robust, secure manner
Management
Building a team of data, full-stack, and QA engineers
Managing team to balance on-time delivery and high engagement
Defining and overseeing technical roadmap
Coordinating efforts with peers in other parts of the organization
Projecting future hiring needs
The Candidate
The ideal candidate will be someone who:
Manage and participate
Build a team while delivering improved software
Set goals, communicate plans, and track progress against roadmap
Motivate team members to focus, solve problems, and iteratively improve
Participate in implementing plans
Works and communicates well with others:
Has empathy for colleagues and customers
Able to receive and respond positively to feedback
Able to work both independently and collaboratively
Able to effectively communicate across multiple levels (team members, managers) in a fast-paced environment
Able to focus on the needs of our users, both internal and external
Has 10+ years of experience in engineering data pipelines, analytics infrastructure, visualizations, and integrating platforms:
Experience with building python-based data pipeline and ETL systems
Experience building applications for end-users and in-house analysts
Experience with embedding BI tools into platforms (eg Izenda, Tableau, Looker, etc)
Experience building visualization systems
Experience with Python 3
Experience with ReactJS
Experience working with and without AWS infrastructure/software
Experience building compliant software for regulated industries
Experience troubleshooting problems throughout the stack
What We Offer:
A truly unique experience to work for a fast-growing, young company
The satisfaction that comes with being part of a solution that makes a big difference in the world
The excitement that comes with the need to endlessly innovate and transform our market
A competitive base salary and flexible PTO policy
We cover 75% of Medical (BCBS) Premiums, Dental & Vision Premiums, and offer 100% company sponsored Life Insurance as well as a 401k plan
The Fine Print and How to Apply:
Thank you for your interest in our company and what we are building.
Benchmark Analytics is an Equal Opportunity Employer. We value diversity of all kinds in our effort to create a stellar workforce of committed and passionate team members.
Unfortunately, we are not able to sponsor employment visas at this time, so we can only accept applications from candidates who are authorized to work in the US.
Job Type: Full-time

Pay: $94,386.00 - $200,000.00 per year

Benefits:
401(k)
Dental insurance
Health insurance
Life insurance
Paid time off
Retirement plan
Vision insurance
Schedule:
Monday to Friday
This Job Is Ideal for Someone Who Is:
People-oriented -- enjoys interacting with people and working on group projects
Detail-oriented -- would rather focus on the details of work than the bigger picture
Achievement-oriented -- enjoys taking on challenges, even if they might fail
Autonomous/Independent -- enjoys working with little direction
Innovative -- prefers working in unconventional ways or on tasks that require creativity
Company's website:
https://www.benchmarkanalytics.com/
Work Remotely:
Temporarily due to COVID-19",3.6,"Benchmark Analytics
3.6","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Mid Level Environmental Scientist,-1,"Toeroek Associates, Inc. is seeking a motivatedMid Level Environmental Scientistto provide technical support for all phases of a Targeted Brownfields Assessment in Kansas City, MO, Chicago, IL, St. Louis, MO, or San Francisco Bay Area, CA. The successful candidate will assist senior staff performing Phase I and II Environmental Site Assessments, supporting a team that assesses the nature and the extent of contamination at brownfields and identifies potential cleanup alternatives and associated costs for site redevelopment. Periodic travel is required.

This is an excellent opportunity for an early-career professional to develop brownfields knowledge and grow a rewarding career path with Toeroek. Applicants should apply with a resume and cover letter at https://toeroek.applicantpool.com/jobs/. Toeroek is a small business headquartered in Colorado with satellite offices located in Chicago, Berkeley, Dallas, and Northern Virginia. Toeroek provides specialized support services to the Federal Government, including the U.S. Environmental Protection Agency (EPA).

Specific Responsibilities Include:
Conducting Phase I and II Environmental Site Assessments (ESAs)
Collecting and evaluating environmental data in field and office settings
Field activities will consist of soil, groundwater, sediment, and soil gas sample collection; geological logging and interpretation; and oversight of investigation and remediation subcontractors including laboratories and excavation and drilling companies
Support providing soil and groundwater assessments, soil gas sampling, asbestos inspections, lead-based paint assessments, geophysical surveys, and waste determinations
Preparing technical reports and other documents on topics associated with site characterization, remedial optimization, and remedy implementation
Recognizing technical discrepancies in analytical results and making appropriate corrections following standard procedures
Providing support in organizing public meetings to address the findings of ESAs
Work within quality/budget/schedule expectations and scope-specific assignments
TECHNICAL REQUIREMENTS:
BS degree in Engineering, Geology, Environmental Science or related field
6+ years of practical experience related to contaminated site characterization and remediation at contaminated sites including Superfund, Brownfields, and RCRA Corrective Action sites
Strong knowledge of federal and state environmental laws and regulations under Federal (e.g., Superfund, RCRA, Brownfields), state, or other cleanup programs
Experience with Phase I and Phase II ESAs
Experience conducting quantitative analyses using Microsoft Excel
PREFERRED CREDENTIALS/CERTIFICATIONS:
40-Hour HAZWOPER
EPA Lead Inspector/Risk Assessor
AHERA accredited Building Inspector
Asbestos Inspector License in any of the following states: California, Arizona, Nevada, Missouri, Iowa
California Certified Asbestos Consultant/Certified Site Surveillance Technician
CDPH Lead Sampling Technician
PROFESSIONAL SKILLS:
Demonstrated attributes to become a strong consultant team player, eagerness to learn and grow, self-starter who takes initiative, versatile, and service-oriented mentality
Effective written/verbal communication and organization/analytical skills; experience writing and compiling technical data and reports
Ability to multi-task, maintain flexibility, travel, and work independently with minimal supervision
Strong attention to detail with the ability to manage multiple priorities at once
Toeroek is proud to be an Affirmative Action / Equal Employment Opportunity employer.

Toeroek does not accept recruiting agency resumes.",3.7,"Toeroek Associates, Inc.
3.7","Chicago, IL",51 to 200 Employees,1993,Company - Private,Consulting,Business Services,$10 to $25 million (USD)
Data Engineer,"$63K-$120K
(Glassdoor Est.)","Company Description

CapTech is a team of master builders, creators, and problem solvers who help clients grow efficient, successful businesses. We unite diverse skills and perspectives to transform how data, systems, and ingenuity enable each client to advance what’s possible in a changing world.

As perceptive partners, our U.S-based consultants find inspiration in the unknown and enjoy getting our hands dirty solving our clients’ myriad of challenges. Across industries and business goals, we fuse technical depth and analytical prowess with creative savvy to move clients forward. This drive helps each organization use technology, management, and insight to turn ideas into action. Together, we create outcomes that exceed the expected — which is one of the reasons we’ve been on the Inc. 500/5000 list for over a decade.

Job Description

The Data Engineer, Analytics role falls into the Data Management & Business Intelligence practice area at CapTech, through which our consultants provide a broad spectrum of services to help our clients define and implement a strategy to deliver lasting and mission-critical information capabilities. Our Data Integration consultants bridge the gap between the business and IT side of companies. By partnering with clients to fully understand both their business philosophy and IT strategy, CapTech consultants maintain the vision that data integration should be built to help the organization make better decisions by providing the right data at the right time.

Specific responsibilities for the Data Engineer, Analytics position include:
Design, develop, document, and test advanced data systems that bring together data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, C, etc)
Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insights
Design, develop, and implement data processing pipelines at scale
Present programming documentation and design to team members and convey complex information in a clear and concise manner.
Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes.
Write and refine code to ensure performance and reliability of data extraction and processing.
Communicate with all levels of stakeholders as appropriate, including executives, data modelers, application developers, business users, and customers
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.
Collaborate with Quality Assurance resources to debug code and ensure the timely delivery of products.
Some of our technologies might include: HDFS, Cassandra, Spark, Java, Scala, Informatica, SQL Server, Oracle, Ab Initio, Kafka.
Qualifications

Specific qualifications for the Data Engineer, Analytics position include:
Bachelor's degree in Computer Science, Software Engineering, MIS or equivalent combination of education and experience
Minimum of 3 years experience designing, developing, and testing software aligned with defined requirements
Development experience building ETL graphs using the Ab Initio GDE, EME and Co-Operating system
Strong SQL development skills
Development experience with at least two different programming languages (Python, Java, C, etc.)
Development experience with Unix tools and shell scripts
Development experience with at least two different database platforms (Teradata, Oracle, MySQL, MS SQL, etc.)
Experience tuning SQL queries to ensure performance and reliability
Software engineering best-practices, including version control (Git, TFS, JIRA, etc.) and test driven development
Exposure to Business Intelligence tools such as Business Objects, Informatica, SSRS, Cognos, MicroStrategy, Tableau, QlikView, SpotFire, etc.
Additional Information

We offer challenging and impactful jobs with professional career paths. All CapTechers can keep their hands-on technology no matter what position they hold. Our employees find their work exciting and rewarding in a culture filled with opportunities to have fun along the way.

At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:
Competitive salary with performance-based bonus opportunities
Single and Family Health Insurance plans, including Dental coverage
Short-Term and Long-Term disability
Matching 401(k)
Competitive Paid Time Off
Training and Certification opportunities eligible for expense reimbursement
Team building and social activities
Mentor program to help you develop your career
CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace.

Candidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements). At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.

CapTech is a Drug-Free work place.
Candidates must have the ability to work at CapTech’s client locations.
All positions include the possibility of travel.
CapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly.",3.8,"CapTech
3.8","Chicago, IL",1001 to 5000 Employees,1997,Company - Private,IT Services,Information Technology,$100 to $500 million (USD)
"Big Data Machine Learning Engineer in Chicago, IL at Key Bank","$69K-$127K
(Glassdoor Est.)","Job Description

ABOUT THE JOB

The Decision Sciences team is part of the Enterprise Payments and Analytics organization. Its mission is to lead KeyBank’s journey to become an innovative, data driven enterprise by building advanced analytics solutions for solving business problems. Our experienced team of AI/ML and Data Science practitioners focuses on engaging, enabling, and empowering decision-makers across the enterprise by developing, managing and supporting advanced analytics products and scalable digital solutions, such as real time and on demand predictive models and prescriptive analytics, and continuously researching, specifying, and deploying next-generation analytics capabilities. We are an internal consulting and services organization that works directly with users across the firm, including Lines of Businesses and partners in Enterprise Strategy, Marketing, Data Analytics, and Enterprise Architecture, to facilitate the development of innovative solutions that help KeyBank compete and win with analytics.

The Big Data ML Engineer fills a critical data, analytics, technology support, and innovation role for the business analytics and advanced analytics functions within the organization. The Engineer is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organization’s enterprise analytics and advanced analytics capabilities.
ESSENTIAL JOB FUNCTIONS

The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use cases—primarily focused around open source technologies including cloud infrastructures. This individual evaluates short/long-term business needs required to support key business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on Key Enterprise systems. Under the guidance of the Group’s Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on key data assets for business decision management solutions. The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions. The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions. The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organization’s AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.
REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
FLSA STATUS:Exempt

KeyCorp is an Equal Opportunity and Affirmative Action Employer committed to engaging a diverse workforce and sustaining an inclusive culture. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.

42178BR",3.3,"KeyBank
3.3","Chicago, IL",10000+ Employees,1849,Company - Public,Banks & Credit Unions,Finance,$5 to $10 billion (USD)
Data Science Senior Intern Summer,"$83K-$133K
(Glassdoor Est.)","Zurich is currently looking for a Data Science Senior Intern to join the Data & Analytics Team to work out of our North American head-quarters in Schaumburg, Illinois.

Zurich’s Data & Analytics team derives insights from a wide range of proprietary and external aggregated data to identify future risks and inform strategic decision-making. Our methods provide a deeper and broader analysis of catastrophic damage and hard-to-predict events — those of low frequency but high severity. Proactive solutions can also help organizations reduce their total cost of risk and create more effective strategies.

Zurich’s Data & Analytics team makes a real difference to how Zurich and Zurich’s customers manage risk. The Data & Analytics team uses their insurance expertise, data and advanced analytics to solve real business problems.

As a Data Science Intern, you will:
Work with a project team to solve business problems. Examples of what we do include: build models to set the appropriate price for various insurance products, predict claims that will cost over $100,000, detect fraud and predict crop yields for crop insurance.
Improve and gain understanding of Data & Analytics techniques such as, data mining, deep learning and other machine learning modeling methodologies
Use Python, R, SQL languages as well as Jupyter, ArcGIS, H2O, Spark and Github tools.
Learn from our summer training program covering insurance basics and advanced machine learning methods.
We have a collaborative and inquisitive environment where you can apply educational knowledge to create insights to impact change for current business problems while gaining mentorship and hands-on training from experienced data scientists.

Basic Qualifications:
Currently enrolled in Master’s program and will be enrolled in the fall of 2021
Possess undergraduate degree from an accredited educational institution
Preferred Qualifications:
Master’s degree in Statistics, Mathematics, Computer Science, Engineering, or related quantitative field.
Demonstrated project experience including the use of statistical techniques such as regression, generalized linear modeling (GLM), econometrics, machine learning, decision trees, clustering, neural networks, and natural language processing (NLP)
Ability to apply statistical methodology to solve business problems
Problem solving skills including identification of issues and offering solutions
Experience with programming and data tools such as R, Python, Hadoop, ArcGIS, H20, Spark, Github, etc.
Strong written and verbal communication skills; experience summarizing and presenting information in a way that provides clarity and interest
Self-motivated and able to work independently in support of project and team goals
Imagine working for a company that truly cares about their employees, customers, stakeholders, and communities they serve.

Imagine working for a values-driven organization that has the ambition and desire to be the best global insurance provider in the world.

Zurich is that place where 55,000 employees across 200 countries and territories are all focused on helping people and helping companies protect what is truly most important to them. We are a values-driven organization that takes pride in the work that we do every day and we have the ambition to be the best global insurer in the world.

EOE Disability / Vets

Zurich does not accept unsolicited resumes from search firms or employment agencies. Any unsolicited resume will become the property of Zurich American Insurance. If you are a preferred vendor, please use our Recruiting Agency Portal for resume submission.",3.2,"Zurich North America
3.2","Schaumburg, IL",10000+ Employees,1912,Company - Public,Insurance Carriers,Insurance,$500 million to $1 billion (USD)
Data and Software Engineer,"$97K-$121K
(Glassdoor Est.)","Data and Software Engineer


The Data and Software Engineer will join the engineering team of a rapidly growing and global start-up in the Alternative Data and FinTech space. You will be responsible for developing cutting edge data analytics, and AI applications as well as onboarding new datasets to be used by our Data Showcasing and PaaS Financial Technology Businesses. You will be responsible for working on numerous innovative technologies and projects that enable date vendors to accelerate their data sales and for global fundamental and quantitative investment managers to generate a higher ROI on their data purchases.

We have developed innovative, next-generation data exploring, and algorithmic testing and trading systems. This position will have the opportunity to participate in pushing your technology and knowledge skills to the next level. The learning curve never stops at CloudQuant.

Day to Day Responsibilities


• Dataset onboarding: You will work with new datasets and internal tools to bring datasets into our data driven systems. This includes mapping data to related companies and building configurations for APIs that utilize those datasets.

• Software Development: Python and C++ development projects depending upon skill set.

Compensation & Benefits:


This is a full-time salaried position with paid time-off, medical and dental benefits, and opportunities for advancement. Bonuses are paid based upon individual and company performance.

Requirements:


• Python 3 (2+ years) with understanding of Pandas, Numpy, Asyncio

• C++ with Templates (2+ years)

• Jupyter Hub / JupyterLab / Jupyter Notebooks (1+ years)

• Bachelor’s Degree – Financial or Technical

• Debugging

• GIT

• Linux

• Continuous Building and Test Systems

• Communication skills (verbal, written)

Would be great if you also have:


• Trading industry interest and/or experience (stocks, futures, FX, crypto, etc.)

• Data science/engineering experience

• Exposure to Machine learning and Recommendation Systems

• Kubernetes

• QT experience

• Javascript

• Grafana
• Airflow

Location:


Chicago, IL

About CloudQuant


CloudQuant provides alternative data showcasing services to alternative data providers including bespoke AI, Machine Learning, and data science services. Fundamental and quantitative investors utilize the cloud-based institutional-grade analytics technology and detailed backtests to quickly research alternative datasets in a novel “try-before-you-buy” data shopping experience.

CloudQuant demonstrates the value in alternative data to accelerate data sales for vendor partners and increase ROI for data purchasers.

We are Quantitative Investors, Proprietary Traders, Machine Learning Experts, Fundamental Investors, CPAs, CFAs, MBAs, PhDs, MFMs, CIOs, Data Scientists, AI Research Consultants

We are a global crowd research network.

We use and license PaaS technology solutions for Visualization, Data Science, Advanced Data APIs, Artificial Intelligence, High-Resolution Backtesting, High-Frequency Trading Engines, Machine Learning, Natural Language Processing, and Proprietary Alpha Signal broadcasting.",3.2,"Kershner Trading
3.2","Chicago, IL",51 to 200 Employees,-1,Company - Private,Investment Banking & Asset Management,Finance,$10 to $25 million (USD)
Data Engineer,"$56K-$109K
(Glassdoor Est.)","Cloudbakers is looking for creative, dedicated, and personable technology business professionals for a data engineer position. We are looking for someone with a broad range of technical skills and aptitude with 4-6 years relevant experience.

As a key contributor to the Engineering team, you will be responsible for delivering solutions for a variety of customers. To be effective in this position, you must be comfortable working with sometimes ambiguous business requirements and able to get up to speed with new technologies quickly.

Responsibilities

Our ideal candidate will understand the value of teamwork. We are looking for the right fit with our growing organization and we will invest in training. This is a Chicago based position.

A Cloudbakers Data Engineers responsibilities and duties are as follows:
Develop data pipelines using frameworks such as
Apache Beam
Google Cloud Dataflow (managed Apache Beam)
Apache Spark
Google Cloud Dataproc (managed Apache Spark)
Apache Airflow
Google Cloud Composer (managed Apache Airflow)
Other relevant Google Cloud services
Consult with clients on best practices for data engineering workloads on Google Cloud
Write Terraform or other Infrastructure as Code (IaC) relevant to data pipelines and consult with clients on best practices
Manage Google Cloud deployments for our clients
Communicate directly with clients in a technical or non-technical capacity
Act as a technical subject matter expert for business users
Manage multiple concurrent projects from initial communication to project completion - this is a client facing role, must be comfortable working directly with clients to understand their needs
Anything else that needs to be done that adds value to the business, our clients and your co-workers
Qualifications
Relevant education or experience, preferred fields are mathematics, physics, computer science or engineering
Python, Java, or other programming languages
Experience with data engineering
Familiarity with Linux, MacOS, or Windows command lines
Experience using a code repository to track code changes, preferably in a team environment
Entrepreneurial attitude, flexibility, and comfort with ambiguity
Strong interpersonal and collaboration skills
Collaborate with a team using shared task and project tracking tools
Ability to demonstrate technical concepts to non-technical audiences
Comfortable in presentation settings with C-level executives
Confidence to clearly articulate information
Ability and desire to take initiative and identify gaps in an implementation plan
Thrive in a fast-paced work environment
Capability to stay calm and defuse high stake situations
Capacity to travel to client sites as needed and requested when normal business travel practices resume
Nice-to-Haves
Experience with Python programming in particular and engagement in the Python community
Experience setting up and working with CI/CD tools
Experience with Docker and the containerization process
Google Cloud Certified or certified from another public cloud (AWS, Azure)
Previous Experience with the Google Cloud Platform (App Engine, Compute Engine, Datastore)
Core Traits

Cloudbakers also requires that team members possess the following traits:
Build trustworthy relationships with our clients and team through integrity and accountability.
Desire to learn and advance in work and in life.
Possess a positive, unrelenting, creative approach to problem solving.
Give and receive constructive criticism for the benefit of all.
Be Authentic. Be Yourself.
Cloudbakers is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to actual or perceived race, color, religion, sex, national origin, age, weight, height, marital status, sexual orientation, veteran status, disability status or other legally protected class.

Powered by JazzHR",4.3,"Cloudbakers LLC
4.3","Chicago, IL",51 to 200 Employees,2010,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable
Environmental Scientist/Engineer (Jr. Level),"$44K-$56K
(Glassdoor Est.)","Are you ready to take the next step in your career? Do you want to do meaningful work that improves quality of life? At Tetra Tech, you will work with high-performing teams who are passionate about using their expertise to find solutions to complex problems in water, environment, infrastructure, resource management, energy, and international development. Tetra Tech is a leading provider of high-end consulting and engineering services for projects worldwide. We combine the resources of a global, multibillion dollar company with local, client-focused delivery in more than 400 locations around the world. We are Leading with Science® to provide sustainable and resilient solutions for our clients

Tetra Tech is seeking an Environmental Scientist or Engineer (Jr. Level) to work at our Chicago, IL office to provide support on a variety of environmental projects, including emergency response with significant travel and on-call support.

This position will involve providing technical support in the areas of emergency response, removal assessment, and removal action. Members of the emergency response team are responsible for maintaining on-call readiness to handle emergency responses and provide remedial and restoration guidance/solutions to clients in the Midwestern United States. Members of the team are also responsible for the planning and oversight of operations and site health and safety. Work will include multi-media sampling, field audits and inspections, organizing and reviewing data, preparing reports, file reviews, collection of air monitoring data, training and exercise support, contractor oversight, and related services. Responsibilities may also include training presentations; preparation of statement of qualifications and proposals, and other consulting activities. Work for other government and private sector clients in these areas is also possible.
1-5 years experience in environmental consulting, HazMat response, or related field required. Strong emergency response and remediation management skills and the ability to respond quickly within a mandatory response time required. Knowledge of federal and state regulations also required. Experience with remedial design, feasibility studies, hazardous waste, site investigations, site remediation, field sampling, air quality, ecological restoration, water resources desirable. Previous experience working on EPA projects a plus.

Must be highly motivated, customer focused, and work well in a team environment. Must also have the ability to manage a heavy workload, travel, and be on-call as needed. Excellent communication, client interaction, and organizational skills, as well as proficiency with MS Office applications are required. Expertise in training curriculum development and implementation is also desired. Hydraulic and hydrologic modeling, GIS data analysis and geostatistics, coding (VBA, Python, etc.), and data management skills a plus. Must be able to drive a motor vehicle and pass a motor vehicle records check.

B.A/B.S. in environmental science or related degree required. 40-hour OSHA, ICS or related training, or demonstrated first responder (environmental emergency response) experience required. Asbestos certification preferred but not required. Heavy lifting of field sampling and other equipment will be required. Candidate must also meet physical demands of hazardous waste site work. Travel is required and varies based on project requirements; may include weekend travel and work. Candidate may be exposed to various weather conditions while performing field work outside.

At Tetra Tech, we provide a collaborative environment that supports individual performance, innovation, and creativity. We are proud to offer competitive compensation and benefits. Learn more by visiting http://www.tetratech.com/en/benefits. For more information on our company, please visit our website at www.tetratech.com. To apply, please submit your resume and cover letter on the Careers portion of our website at www.tetratech.com/careers.

We thank all applicants for their interest; however only those selected for an interview will be contacted. Tetra Tech is committed to creating a diverse environment and is proud to be an Equal Opportunity Employer. We invite resumes from all interested parties including women, minorities, veterans and persons with disabilities.

Tetra Tech is a VEVRAA federal contractor and we request priority referral of veterans for available positions. EOE AA M/F/Vet/Disability - No calls or agencies

Additional Information



Organization: 103 EMI",3.6,"Tetra Tech
3.6","Chicago, IL",10000+ Employees,1966,Company - Public,Architectural & Engineering Services,Business Services,$2 to $5 billion (USD)
Senior Data Scientist,"$97K-$160K
(Glassdoor Est.)","Who We Are!

At Maven Wave, we are relentless in hiring the industrys top talent. Each employee is hand-picked not only for their skills, but for their personality and broad expertise. We are looking for this rare combination of talent that sets us apart in the industry.

Maven Wave helps leading companies make the shift to digital and shorten the fuse to innovation. We combine the expertise of top-tier consulting with the agility of a cutting-edge technology firm. This multidisciplinary blend of skills allows us to create unique digital advantages for our clients. Maven Waves digital solutions are agile, mobile, rooted in analytics, and built in the cloud.


Maven Wave, Google, and YOU: Drive and deliver business results with data-based insights.

We are looking for a Senior Data Scientist who will utilize their analytical, statistical, and programming skills to develop data-driven solutions to complex business challenges.


Your Life As a Maven:
Leverage company data to drive business solutions for enterprise clients using R and Python.
Perform data collection for Data Science operations including Machine Learning.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.
Assess Model accuracy using common metrics (AUC, F1, etc.) and explain the results to client stakeholders.

Your Expertise:
7+ years of experience manipulating data sets and building statistical models.
Cloud experience in a major platform, such as AWS, GCP, or Azure.
Experience using Data Science languages (R, Python) to manipulate data and draw insights.
Knowledge of a variety of Machine Learning and advanced analytical techniques and their real world advantages/drawbacks.
Familiarity with the following software/tools: Python, C, Java, Jupyter Notebooks, SQL, ML platforms (H2O, DataRobot), distributed data (Map/Reduce, Hadoop), and visualization (Tableau, qikview)
Must have a bachelors degree in related field.
Your X-Factor:
Aptitude - You have an innate capacity to transition from project to project without skipping a beat.
Communication - You have excellent written and verbal communication skills for coordination across projects and teams.
Impact - You are a critical thinker with an emphasis on creativity and innovation.
Passion - You have the drive to succeed paired with a continuous hunger to learn.
Leadership - You are trusted, empathetic, accountable, and empower others around you.
Why Were Proud To Be Mavens!
Google Cloud North America Services Partner of the Year 2019, 2018
#21 Best Workplaces in Chicago, FORTUNE, 2018
Great Place To Work Certification, Great Place to Work, 2017 & 2018
Fast Fifty, Crain's Chicago Business
101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR)
Top Google Cloud Partner, Clutch
Fastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine
Top IT Services Companies, Clutch
Google Global Rising Star Partner of the Year
Ready to Learn More?
Life as a Maven
Check out the Data Team
See what Glassdoor has to say
Real Customer Stories",4.4,"Maven Wave Partners
4.4","Chicago, IL",201 to 500 Employees,2008,Company - Private,Consulting,Business Services,$50 to $100 million (USD)
Data Analyst,-1,"Role Type: Data Analyst

Reports To: Data Scientist

*
About Us

CareAdvisors is a technology company that helps patients get access to healthcare and social service benefits they need by automating the manual enrollment role taken on by hospitals.

Many patients who receive care at hospitals are eligible for Medicaid and other social service benefits, but some have barriers to enroll or re-enroll in their benefits. Using technology focused on automation, CareAdvisors remove barriers so that patients can get access to the benefits they need.

Our Customer Relationship Management tool empowers care navigators and social workers with a platform that is connected to a network of community resources and hospitals. We use the data gathered across our network to power our analytics engine. Join us in building out our platform so we can connect people to the care they need!

About the Role

As a Data Analyst, you will research and develop predictive models for population health. Overall, you will support our enterprise strategy and delivery of analytic services by performing various analyses and interpretations to support business needs for assigned functions. The analyst will collaborate across analytic teams, business partners, and customers to ensure a coordinated flow of information, documentation, and relationships to support the delivery of leading-edge analytics. Due to the dynamic nature of this role, we are looking for entrepreneurial candidates with the ability to derive analytical insights from a variety of business contexts.

Responsibilities
Compile analytical and statistical reports.
Formulate, define, and recommend scope of reports.
Review information for accuracy and reconcile data.
Provide support and education to staff on how to access reports and interpret the data.
Synthesize raw data into digestible and actionable information.
Identify trends and make recommendations for quality and operational improvement.
Collaborate with leaders to understand key value drivers and challenges within their business units and determine the key metrics and insights that can help improve performance as a result.
Continually think of new ways that data-driven insights can help support Care Advisors.
We are looking for a team member with the following background
Currently based in the Chicagoland area (REQUIRED)
Master's degree in business, economics, finance, accounting, marketing analytics, MIS, computer science, engineering, or equivalent work experience.
4+ years of related experience guiding strategic decision making using data and analytics.
2+ years of experience working in a healthcare environment.
Experience with topics in public health, population health, social determinants of health, data science, or social science, preferred.
Experience with report/dashboard development, data/report automation, self-service capabilities, data design and integration, data quality and governance, preferred.
SQL, Python, and/or Tableau skills are preferred.
Familiar with predictive programming in R and/or Python.
Proficiency in Microsoft Excel, Powerpoint and Word.
Ability to take insights and turn them into actionable steps that can drive business value.
At Care Advisors we value diversity and endeavor to treat everyone with respect, no matter their age, gender, race, ethnicity, or sexual, cultural or ideological preferences.

Due to the unprecedented situation of COVID-19, CareAdvisors has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding, and daily operations. Please consider that our roles will not be remote long-term and we will return to an office environment once it is deemed safe to do so following the guidance of local health authorities and the Centers for Disease Control.

*

Job Type: Full-time

Benefits:
Dental Insurance
Employee Assistance Program
Health Insurance
Paid Time Off
Parental Leave
Professional Development Assistance
Schedule:
Monday to Friday
Experience:
healthcare : 2 years (Required)
data and analytics: 4 years (Required)
Education:
Master's (Required)
Location:
Chicago, IL 60654 (Required)
Work Location:
One location
This Job Is Ideal for Someone Who Is:
Innovative -- prefers working in unconventional ways or on tasks that require creativity
High stress tolerance -- thrives in a high-pressure environment
Benefit Conditions:
Waiting period may apply
Work Remotely:
No",-1,CareAdvisors,"Chicago, IL",-1,-1,-1,-1,-1,-1
Managing Enterprise Architect - IoT Data Scientist,"$74K-$142K
(Glassdoor Est.)","Manager –
Capgemini AI & Analytics Team

IoT Data
Scientist

The
AI & Analytics group is the fastest growing digital practice at Capgemini
demanding agile innovation. As part of the AI & Analytics group, you will
work in a collaborative environment with internal and client resources to
understand key business goals, build solutions, and present findings to client
executives while solving real-world problems. If you are passionate about
solving problems in the realm of cognitive computing, big data, and machine
learning while utilizing business acumen, statistical understanding, and
technical know-how, the AI & Analytics practice group at Capgemini is the
best place to grow your career.

Role &
Responsibilities:


Work in a collaborative environment with
global teams to drive client engagements in a broad range of industries to
design and build scalable AI and Machine Learning solutions to solve business
problems and create value by leveraging client data
Provide guidance on engagements to
ensure successful delivery while balancing internal initiatives
Provide engineering services for PoCs,
pilots, production
Lead projects in IoT architecture with
data science
Provide end-to-end prototype and
transformation solutions. Contribute to thought leadership and facilitate
client relations across network of existing and potential clients.
Participate in client discussions,
interact with CxOs at client organization to articulate the value of data
science approaches, different AI service offerings and guide them on
implementation of the same.
Quickly understand client needs, scope
of work effort, assemble teams, manage delivery, and articulate findings to
client executives
Mentor, lead and develop junior staff,
including performance appraisals and career pathing
Review and analyze developed models
for complete, robustness and meeting of client needs
Assist in growing data science
practice by meeting business goals through client prospecting, responding to
proposals, identifying and closing opportunities within identified client
accounts.

Qualifications:


MS or PhD in Computer Science,
Statistics, Economics, Mathematics, or other closely related field
Strong mathematics skill
5+ years data science experience in an
IoT environment
5+ years as a Solutions Architect
6+ years professional work experience
as a data scientist or on advanced analytics / statistics projects with 5+
years’ experience in one of the following sectors: Aerospace & Defense, Automotive, Banking,
Consumer Products & Retail, Financial Services, Healthcare, High Tech,
Industrial Products, Insurance, Life Sciences, Manufacturing, Public Sector,
Telecom, Media & Entertainment, and Energy & Utilities.
Application development cycle in an IoT
environment, CI/CD pipeline
Knowledge of the device connectivity
protocols, WiFi, Bluetooth, MQTT, CoAP, Websockets, REST API, HMI, MWM and
device security.
Hands-on experience building
mobile (iOS, Android) and WebUI applications using React, React Native
Experience with at least one of
the major cloud platforms: AWS, Azure, GCP
Application of Graph data models and
algorithms as well as graph databases such as Neo4j
Excellent team-oriented and interpersonal
skills, with a strong interest for consulting
Outstanding communication skills with the
ability to clearly articulate findings and present solutions to business
partners
Preferred
Qualifications:


Experience with Deep Learning methods in NLP
& Computer Vision, Sentiment analysis, topic modeling and graph theory and
databases
Experience with common data science tools such
as Python, R, Pytorch, TensorFlow, Keras, NLTK, Spacy, or Neo4j, and a good
understanding of modelling platforms (Azure AutoML, SageMaker, DataBricks, DataRobot
and H2O.ai)
Experience working with big data distributed
programming languages, and ecosystems: Spark, Hadoop, MapReduce, Pig, Kafka
Familiarity with Cloud-based environments such
as AWS (S3/EC2), Azure, Google Cloud
Knowledge of other coding languages such as
Java, Matlab, SAS, C++
Experience with
building and deploying predictive and prescriptive analytics models
Experience with conflicts resolution and
people influence techniques
Click the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

About Capgemini

Capgemini is a global leader in consulting, digital transformation, technology and engineering services. The Group is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50-year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. Today, it is a multicultural company of 270,000 team members in almost 50 countries. With Altran, the Group reported 2019 combined revenues of €17billion.

Visit us at www.capgemini.com. People matter, results count.",3.8,"Capgemini
3.8","Chicago, IL",10000+ Employees,1967,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (USD)
"Director, Data Management","$104K-$203K
(Glassdoor Est.)","The Job Details are as follows:

ROLE OVERVIEW

Working within a global team of data analysts, data scientists, and content experts within each of BAM’s key geographic locations you will serve as a steward and Product Manager for BAM’s internal and external data products. Key responsibilities include:
Partnering with the firm’s Portfolio Management, Data Science, and Technologies teams to uncover new data driven initiatives and define product roadmaps.
Designing and implementing programmatic data accuracy, outlier detection, error correction and remediation processes.
Evaluating new and differentiated data within the firm and helping strategically prioritize new data initiatives.
Working closely with our Data Engineering and Platform teams and defining the on-boarding and production requirements for all new data.
Help prioritize the firm’s new data on-boarding pipeline.
QUALIFICATIONS & REQUIREMENTS:
5+ years of product management experience developing data products with experience across data infrastructure, data science, and/or analytics.
Strong understanding of time-series data, third party data vendors, and how they apply to quant and fundamental analysis. Prior experience with quantitative investors (either as a quant or vendor) is strongly preferred.
Serve as an in-house expert on data, leveraging your knowledge of vendor and market data collection methodologies to build data, which investors can act on.
Demonstrated track record of ownership, leadership, high achievement and raising the standard of those around you.
Understanding of logical and physical data modeling, data architecture, data taxonomy, and both structured and unstructured data.
Ability to understand the technical implementation trade-offs to ensure that requirements are not misunderstood or being ignored by a given implementation plan
Strong SQL skills as well as experience with big data and/or complex data sets
Hands-on programming experience with simple Python (e.g., Jupyter, Pandas, NumPy, SciKit)
Ability to be an active participant in architecture and design reviews
Familiarity with Emerging Data Technologies such as Cloud, Big Data and AI/ML trends that enable data-centric solutions for business problems
Experience in defining data and ML products and applications to solve business problems
Experience working in an agile environment and with development teams. We expect you and your solutions to be organized and pragmatic.",3.9,"Balyasny Asset Management
3.9","Chicago, IL",501 to 1000 Employees,2001,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable
Data Visualization Engineer,"$47K-$84K
(Glassdoor Est.)","The Financial technology space ""Fintech"" is booming and Guaranteed Rate is at the center of it. We are growing like crazy, and are one of the most successful Chicago startups. We are focused on automating the mortgage process for consumers. Imagine getting a mortgage with no email, no faxing, no stack of papers in 10 days or less instead of 40 or more! If you have been through the process of buying a home you know how amazing this will be. We are the #5 lender in the country and one of only 2 that is independent (not a bank) so we are in a good spot to win this race. We have already made tremendous strides and we are looking for someone who wants to help us finish the job and disrupt the entire industry.

Who is GR?

Guaranteed Rate is not your typical company and certainly not your typical mortgage company. We are technology driven, have tons of energy and we love what we do – great people and great products alongside our impeccable customer service (83 NPS, unheard of!). We’re in a River North office with exposed brick and duct work, windows we can actually open during the summer. The awesomeness doesn’t end there, we also have:
Holiday parties? We got’em! Not just major holidays, any holiday….Mardi Gras, Valentine’s Day, St. Paddy’s Day, Opening Day, Boxing Day (for our Canadian employee), Sweetest Day, Groundhog Day, etc..
Game room, library and white board paint for collaboration – yeah, it’s awesome.
Access to our free GR nurse practitioner. Psshh who needs a doctor’s appointment when our nurse can do it all? Did we mention the free part?
401k with some matching, Blue Cross health care coverage – yup, dental and vision too, short-term disability, life insurance – we got ya covered on this one, legal assistance – for a small monthly fee.
Oh and did we mention you get a big fat employee discount on the origination fees to get a new mortgage or refinance thru Guaranteed Rate?
So what do we want from you?

We are looking for a Data Visualization Engineer to join our team. This role will analyze big data stored in data lakes, data warehouse, data marts, and available through APIs to build actionable insights consumed by internal business units as well as external customers. This is a technical role with strong business acumen to ensure we build solutions that impact business. Looking for a truly results oriented individual to work with a team of data engineers and data scientists.

Tasks
Author documentation of customer reporting requirements and finished reports.
Broad business experience with a proficient ability to talk to executives in business terms. Work with the functional business area to identify, gather, investigate, and document business processes related to data architecture.
Work with large amounts of data. You will need to see through the data and analyze it to find conclusions. Represent results in accurate and actionable insights.
You will need to write and speak clearly, easily communicating complex ideas.
Critical Thinking: Candidate must look at the numbers, trends, and data and come to new conclusions based on the findings.
Collect, organize, and analyze data using data profiling and data analysis tools or by writing custom SQL queries
Ingest data from disparate systems using data integration tools or writing custom code in SQL, Python, or other scripting languages
Visualize data insights using data visualization tools such as Tableau, Power BI, or Quicksight.
Identify, analyze, and interpret trends or patterns in complex data sets.
Understand the fundamental concepts of object oriented programming
Perform root-cause analysis to understand data problems and find solutions by understanding user requirements.
Cleanse data using technical and business validation rules.
Minimum Requirements
Strong database querying competency using SQL; Experience creating T-SQL queries in SSMS
Comprehensive grasp of data visualization methods
Familiarity with data modeling especially dimensional modeling, data marts, and data warehouses
2-5 years of experience in data viz tools creating tables, graphs, drill downs, drillthroughs, bookmarks, and KPIs
Ability to develop data visualization dashboards in Tableau, Power BI, or Quicksight
Knowledge of using satirical packages for data mining using Python and other open source tools.
Bachelor’s Degree in Computer Science or Computer Engineering
Ability to collaborate effectively and work as part of a team
Strong attention to detail
About Guaranteed Rate…

Guaranteed Rate is the seventh largest retail mortgage lender in the United States. Headquartered in Chicago, the company has approximately 195 offices across the U.S. and is licensed in all 50 states. Since its founding in 2000, Guaranteed Rate has helped hundreds of thousands of homeowners with home purchase loans and refinances and funded nearly $23 billion in loans in 2018 alone. The company has become the Home Purchase Experts® by introducing the world's first Digital Mortgage technology and offering low rate, low fee mortgages through an easy-to-understand process and unparalleled customer service. Guaranteed Rate won an American Business Award for its Digital Mortgage technology in 2016, ranked No. 1 in Scotsman Guide's Top Mortgage Lenders 2015, was chosen Top Lender 2016 by Chicago Agent magazine and made the Chicago Tribune’s Top Workplaces list five of the past six years. Visit rate.com for more information.

Click here to apply online",3.7,"Guaranteed Rate
3.7","Chicago, IL",5001 to 10000 Employees,2000,Company - Private,Lending,Finance,$500 million to $1 billion (USD)
"Research Scientist, HFE/HCI",-1,"Research Scientist, HFE/HCI

GN Hearing, a leading manufacturer of Hearing Health devices, is looking for a Research Scientist focused on addressing interaction problems in hearing healthcare by drawing from recent advancements in fields such as bio-sensing, machine learning, or VR. As part of the Research team you will investigate novel interfaces/experiences via prototyping and user studies to support evidence-based solutions. You will be expected to work with a cross functional team supporting translational and applied research efforts.

Areas of responsibility:
Be a user advocate within a research team, applying HFE/HCI driven methodologies to assess and define solutions.
Conduct systematic literature reviews, and synthesizing evidence to influence design decisions.
Drive the creation of conceptual models and usability objectives aligned with user-centered design goals and tasks.
Design and develop hardware and software prototypes for proof-of-concept and feasibility studies to formulate evidence-based solutions.
Coordinate and manage projects across a multi-disciplinary team of scientists.
Qualifications:

Education: Ph.D. or equivalent experience in one of the following disciplines: Human-Computer Interaction (HCI), Human Factors Engineering (HFE), Design Science, or Computer Science.

Experience: Preferred 2 - 3 years of research experience in HFE/HCI or equivalent graduate level research.
Rapid prototyping using hardware and software tools: Xamarin development, PCB etching, 3D printing, etc.
Experience with bio-sensing and novel input methods.
Human participant experimental design and data analysis.
Experience with applying machine learning methods, specifically computer vision and signal processing. Familiarity with tools such as TensorFlow, CoreML and ARKit a plus.
Experience with VR development and Unity a plus.
Experience coordinating input from stakeholders in multiple disciplines.
User-Centered Design – skilled in creating solutions from user research and iterative design process.
Location:

This position is being considered for placement in either our Chicago, IL or Minneapolis, MN research centers. The Chicago-based GN Research team is located in Glenview (the Glen). The Minneapolis-based GN Research team is located in the Center for Applied and Translational Sensory Science at the University of Minnesota (http://catss.umn.edu/).

Why GN Hearing:

The Hearing Healthcare industry provides you the grounds for creativity to help our end-users with innovative solutions. Our multi-disciplinary research team carries out applied research in a wide range of disciplines, including acoustics, signal processing, neuroscience, human-computer interaction, artificial intelligence, audiology, hearing science, and multiple fields of engineering.

Because research is globally located in Denmark, Netherlands, Chicago, and Minneapolis, some domestic and international travel will be required once it is safe to travel. GN currently has a strict travel ban to ensure the safety of our employees. If you’re passionate about Evidence-Based Practices and want to see your work utilized for the benefit of people with hearing loss, let’s start the dialogue.",3.7,"GN Store Nord
3.7","Glenview, IL",5001 to 10000 Employees,1869,Company - Public,Enterprise Software & Network Solutions,Information Technology,$5 to $10 billion (USD)
"Lead Data Scientist - Technology, Media Product Analytics","$72K-$119K
(Glassdoor Est.)","Lead, Media Product Analytics Kroger Precision Marketing

Kroger Precision Marketing (KPM) powered by 84.51°, is a leading retail media advertising solution. KPM closes the loop between media exposure and store sales by using first-party purchase data to make brand advertising more addressable, actionable, and accountable. Launched almost three years ago, we have activated campaigns for over 1000 brands. Our vision is to become the preferred media company for advertisers by creating a more accountable media supply chain that increases the effectiveness of investment dollars. We are a growing team of passionate and talented analysts, data scientists, marketing consultants, and media strategists who are committed to transforming the media industry.

As Lead, Media Product Analytics Kroger Precision Marketing you are joining a community of analysts, data scientists, and software engineers we are researchers in search of the customer story. We are the voice of the customer. Customers share their story with us each day, and it is our job to tell their story. Our Analysis team is known for solving client and customer problems, employing the most appropriate statistical and analytic approaches. You will be hands on with respect to the analysis of media with a robust retailer database of 60MM households, using the full suite of 84.51° technical and visual tools SQL, R, Python, Tableau, and other specific internal tools to create timely, relevant, and actionable insights.

Responsibilities:
Partner with engineering to build data pipelines, create new analytic methodologies, and bring them to scale within our media measurement platform
Our platform powers data science, client engagement, and our sales team to tell the story of advertising performance
Lead ad-hoc Kroger Precision Marketing research, ideation, and methodology work for our various media activations
Think creatively when building analytics solutions in order to bring the most value to the user
Be a data science / analytics ambassador to our engineering team. Able to explain the how and why around our analytics solutions
Influence our platform and product creation with outside media analytics expertise
Independently developing, defining, and completing custom projects and analytics that help drive media campaigns, customer insights, and client relationships forward
Leading and managing projects, tasks, and stakeholders to ensure that projects are delivered on time, within budget and to brief specification
Mentoring and developing junior data scientists on media measurement interpretation, results delivery, KPM-specific skills, and analytic techniques
Challenging and improving 84.51° analytical capabilities/products
Qualifications, Skills and Experience:
Bachelor's or Masters degree or equivalent in statistics, mathematics, analytics, economics, or marketing
4+ years of experience in analytics across ad technology, digital media and advertising
4+ years of experience working with partners across software engineering and product management to develop and scale new features and enhancements
4+ years of experience extracting and translating data from large, disparate data sources into actionable solutions
3+ years of experience accessing and manipulating large datasets via SQL, R and/or Python with Python being strongly preferred.
Strong interpersonal and communication skills including excellent verbal, written, presentation and consultation skills are required
Strong analytical, problem-solving and decision-making skills
Strong business acumen to link analysis to business impact
Excellent attention to detail, organization skills and ability to work in a collaborative environment
About 84.51°:

84.51° knows customers, and we know how to connect you.

Using a sophisticated, proprietary suite of tools and technology, we turn customer data into actionable knowledge. With unparalleled customer data and predictive analytics capabilities, we deliver personalized marketing strategies and ensure the best experience for customers of Kroger and more than 300 consumer-packaged-goods companies. We put the customer at the center of everything we do, resulting in a more dynamic, informed and personal approach to driving customer loyalty.",4.3,"84.51°
4.3","Chicago, IL",1001 to 5000 Employees,2015,Subsidiary or Business Segment,Consulting,Business Services,Unknown / Non-Applicable
Data Engineer,"$49K-$97K
(Glassdoor Est.)","Company Description

Daxko’s mission is to power health and wellness throughout the world. We provide solutions, services, and insights for the health and wellness industry to engage members, deliver delightful experiences, and improve the businesses we serve.

Job Description

Daxko is seeking a software engineer with experience in C#, SQL, and Data to be a hands-on engineer on our Data & Analytics team. This engineer will work with Daxko’s business intelligence and data warehouse products. We are an Agile/Scrum shop with a strong sense of teamwork and collaboration, where teams are encouraged to operate with the autonomy and flexibility of startups, while enjoying the benefits of being part of an established company. If you believe in community-driven development, consider writing code as a craft, and have a desire to be a lifelong learner, then we invite you to read on and apply.

Here are a few things you'll likely find yourself doing in this role...
Delivering high-quality, unit-tested code by practicing pragmatic software engineering principles
Working with the team to size and groom the product backlog
Collaborating with other teams across the organization (e.g., Product Management, Engineering, Data Science) to enable the better use and understanding of data
Leveraging Agile best practices (vertical vs. horizontal development, breaking things down into smaller pieces, driving to done)
Working with the team to own products and features end-to-end
Qualifications

Here's what you need to have...
Bachelor’s degree in an Engineering-based discipline or equivalent experience
1-3 year's work experience with C# or Java
Expert SQL skills and TSQL experience
Experience with BI reporting tools
Working knowledge of current .NET architectural/development best practices and design patterns
Knowledge of available tools, technologies, methodologies, processes, and best practices to develop software
Strong analytical/problem solving skills and a craving for details
An open mindset to new technologies, industry trends, and ability to adopt latest design methodologies
Solid interpersonal skills and comfort in a collaborative development environment
Ability to build positive relationships with internal and external stakeholders
A plus if you have experience with some of these...
Kimball methodology or dimensional models (star-schema)
Columnar databases (e.g. Amazon Redshift)
Realtime Data Streaming (e.g. Kafka, Kinesis)
Serverless Interactive Query Solutions (e.g. Athena, Redshift Spectrum)
Agile Methodology
NoSQL databases
REST Web Services
Unit Testing Frameworks (e.g. Machine.Specifications)",3.6,"Daxko
3.6","Chicago, IL",201 to 500 Employees,1998,Company - Private,Computer Hardware & Software,Information Technology,$50 to $100 million (USD)
Data Scientist Sr,"$90K-$148K
(Glassdoor Est.)","Under general direction, the Data Scientist is responsible for modeling complex problems, discovering clinical insights and identifying opportunities using statistical, algorithmic, mining, and visualization techniques. In addition to analytic skills, this role requires experience in preparing large, varied datasets, and communicating results with clinical and operational stakeholders. Other responsibilities include developing and applying data quality measures to ensure that data congruent and reliable. The Data Scientist will collaborate with operational leaders, data stewards, physicians, project/program managers, informaticists and other analysts to turn data into critical information and knowledge to be used to make sound organizational decisions. Leads and Mentor junior data scientists. Other duties as assigned.

KNOWLEDGE, SKILLS AND ABILITIES REQUIRED:
Required Education, Skills, and/or Experience:
PhD. in Statistics/Biostatistics, Computer Science, Epidemiology, Mathematics, Healthcare, Physics, or other quantitative discipline (STEM area) required
Minimum 3 years of analyzing healthcare data in either a provider or payer environment is required. Academic experience in analyzing similar data in statistics or other quantitative disciplines will be considered as equivalent experience
Formal training or extensive applied experience with advanced statistical methods such as regression-type modeling and data-mining methods (e.g. classification trees)
2+ years of data and statistical analysis
Intermediate to advanced proficiency with SQL, SAS, R, STATA or other high-level data programming language
Intermediate to advanced proficiency with Python, PHP, Perl, VB, JavaScript, C++ or other programming language
Advanced programming skills required
Demonstrates excellent follow-up skills and the ability to take initiative as well as a proactive problem solving approach
Excellent verbal and written communication skills
Team oriented with good interpersonal skills and the ability to collaborate effectively with peers and customers
Comfortable providing input and alternate views in a healthy, constructive way
Agile software development methodology experience and test-driven development experience
Take pride in writing clean dependable algorithms
Sharp critical thinking skills, including systems and business analysis, problem analysis and resolution, and sound judgment/decision making ability
Proven ability to work in a rapid release product environment
Preferred Education, Skills, and/or Experience:
Minimum 5 years of Epic software experience required
Minimum of 5 years functioning as Data Scientist role required
5 years of directly related experience is preferred. Health care reporting experience is highly preferred
3 years Caboodle and Clarity experience is highly desired
Preferred Licensure/Certification:
Epic certification desired",-1,Edward Hospital,"Warrenville, IL",1001 to 5000 Employees,-1,Hospital,Health Care Services & Hospitals,Health Care,$500 million to $1 billion (USD)
Lead Data Scientist,"$98K-$158K
(Glassdoor Est.)","Job Description
Manages and is responsible for the successful delivery of the algorithms, statistical models, and reporting tools to meet business needs. Acts as the analytic team lead for large and complex projects involving multiple resources and tasks, providing individual mentoring in support of company objectives around improving PBM member health through improved medication adherence.

• Develops complex algorithms and statistical predictive models and determines analytical approaches and modeling techniques to evaluate scenarios and potential future outcomes.
• Performs analyses of structured and unstructured data to solve multiple and complex business problems. Utilizing advanced statistical techniques and mathematical analyses and specialized expertise in the organization and/or industry.
• Applies analytical rigor and statistical methods to analyze large amounts of data, using advanced statistical techniques.
• Manages large and complex analytical projects from data exploration, model building, performance evaluation and testing.
• Behaves as mentor to junior team members to provide technical advice.
• Collaborates with business partners to develop technical /business approaches and new or enhanced technical tools.
• Interacts with internal and external peers and management to share highly complex information related to areas of expertise and/or to gain acceptance of new or enhanced technology / business solutions.

Required Qualifications
• 7-10 years of progressively complex related experience.
• Demonstrates proficiency in all areas of mathematical analysis methods, machine learning, statistical analyses, and predictive modeling and advanced in-depth specialization in some areas.
• Deep knowledge of advanced analytics tools and languages to analyze large data sets from multiple data sources.
• Strong skills to effectively communicate and negotiate across the business and in the external health care environment. Demonstrates strong ability to communicate technical concepts and implications to business partners.
• Strong organizational, management and leadership skills.
• Excellent analytical and problem solving skills.

Preferred Qualifications
• Solid understanding of health care industry, products, and systems, including Pharmacy Benefit Management
• Experience with programs and interventions that drive medication adherence
• Experience conducting data analysis in a healthcare setting
• Experience with campaign design and implementation
• Experience applying behavioral economic concepts to drive behavior change

Education
Bachelors degree in qualitative field, such as statistics, biostatistics, analytics, epidemiology, public health, or economics. A graduate degree preferred.

Business Overview
At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.",2.9,"CVS Health
2.9","Northbrook, IL",10000+ Employees,1963,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
(Python) Data Engineer,-1,"If you are an experienced Big Data Engineer looking to join a fast-growing advanced analytics consulting firm than this is the job for you. This is an opportunity to work for the top fortune 500 companies long term. If you love building Data pipelines and Data Warehouses from scratch using Python and big data, read below!

What Is The Job?

This role will be responsible for architecting, designing, and implementing advanced analytics capabilities.We are looking for Data Engineers to support the data and analytics by designing, optimizing, and developing data pipelines to support machine learning and AI models. You will work along side with Data Scientists and Software Developers to meet client business requirements.

What Skills Do We Need?
Deep understanding of Python (4 plus years Experience)
Big Data experience is a plus
ML and AI experience is a plus
Who Are We?

We are a high-quality analytics service provider with a primary focus on AI and Advanced Analytics for multiple fortune 500 companies. We provide top notch consultant's to our clients in need of long term placements.

Compensation:
$140,000- $180,000
Bonus
Full medical
Full Dental
401k
Very reasonable work hours
Whats in it for you?

This is an opportunity for longer term stability. This opportunity will allow you to broaden you tech skills and give you the chance to work on multiple longer term projects for a variety of name brand companies.

We are hiring for this role as soon as possible, so if you are interested, please apply today or reach out to me directly at: Chris.Decrescenzo@Averityteam.com.",5.0,"Averity
5.0","Chicago, IL",1 to 50 Employees,2014,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable
Senior Data Architect,"$113K-$178K
(Glassdoor Est.)","Are you looking for an opportunity to make a big impact in a world class organization? We are looking for a Senior Data Architect to fill a critical leadership role within our IT division. In your role as Senior Data Architect, you will direct and implement Shure’s data strategy. You will be accountable for Shure’s data architecture and development of Shure’s data management technology including adherence to data management best practices.
Additionally, you will be responsible for the development and support of Shure’s data pipelines, data catalogs, data security, data lake, warehouse and visualization technology. In this high visibility role, you will work directly with internal business partners and IT resources to leverage data and solve business problems.

Manages a globally located data engineering team.
Manages vendor relationships that are leveraged for implementation and to support deliverables.
Provides technical project management for projects identified in a multi-year data roadmap.
Delivers proof-of-concept projects and technical workshops and supports implementation projects.
Plays a key role in the development of data strategies for various groups (business leaders, data scientists, data analysts, and IT) to help shape the future of what data-centric organizations look like.
Evaluates business requirements and works closely with stakeholders to identify key business needs and translate that into a clear data strategy solution.
Defines and implements data management processes.
Provides input into Shure’s data roadmap.
Strives to continuously improve the effectiveness of the data management strategy by identifying new opportunities for data and analytics to advance business needs as well as identifying and conveying data quality and gaps.
Manages, benchmarks and ensures continuous testing, cleansing and refining of data integrity and quality assurance processes to enhance data and improve results.
Summarizes and conveys data findings to both a technical and non-technical audience.
Prepares and delivers presentations and/or workshops to educate Executive Staff, senior organizational leaders and various departments as requested.
Remains current with emerging technologies and industry best practices; guides others on major strategies and methodologies.
Maintains current job knowledge by participating in educational opportunities, reading professional publications, maintaining personal networks and/or participating in professional organizations

Bachelor’s Degree in Computer Science, Engineering, Statistics, Technical Science or related field. Master’s Degree is strongly preferred.
Minimum of 12 years of wide-ranging data experience working with and influencing multiple, cross-functional teams (business analysts, data analysts, data scientist, and IT) to ensure meaningful data collection or connections with responsibility for results, including costs and methods.
Skilled data development history working with cloud hosted data infrastructure platform. Certification preferred in one or more of the following cloud platforms: AWS, Microsoft Azure, Google.
Strong implementation and support experience of data engineering integration, quality, security, and cataloging applications,
Hands-on experience with various data technologies (RDBMS, NoSQL, Hadoop), as well as logical and physical data modeling.
Passionate about technology including data, analytics, machine learning, augmented intelligence, automated decision making
Ability to conceive and portray the big data picture and translate data and analysis into actionable insights
Ability to work well under pressure and within tight deadlines
Ability to communicate effectively, drive consensus, and influence relationships at all levels
Strong analytical and problem-solving skills; sound judgment and demonstrated leadership skills
Eager to learn and support the business strategy and desire to work on strategic projects
Excellent communicator with experience presenting technical solutions that solve business problems to executive level audiences
Exceptional in storytelling: i.e., the ability to structure and synthesize within your communication
Proven track record helping business customers/clients establish next generation data products and processes
Experience in a fast-paced agile development environment and has an ability to execute against timelines
Able to provide guidance to subordinates within the latitude of established company policies
Experience with advising subordinates how to meet schedules and/or resolve technical problems",4.1,"Shure Incorporated
4.1","Skokie, IL",1001 to 5000 Employees,1925,Company - Private,Consumer Products Manufacturing,Manufacturing,Unknown / Non-Applicable
Senior Data Scientist,"$98K-$131K
(Glassdoor Est.)","Job title: Senior Data Scientist
Job type: Permanent
Emp type: Full-time
Salary:
Negotiable
Location: Chicago, United States
Job published: 2020-01-15
Job ID: 41634

Job Description


Our client is looking for Senior Data Scientist to join their Chicago office. You will not be required to have any prior knowledge of the financial markets for this role.

Responsibilities:
Converting human pattern recognition and decision-making processes into automated aspects of the trading workflow.
Finding innovative solutions to known problems that will support and expand the core business.
Driving the firm forward with new ideas that will impact the way they leverage market data.
Defining best practices within the analytics team regarding prototyping and scaling solutions.
Assisting software developers in translating research results to production.
Mentoring junior researchers on the analytics and trading teams.


Requirements:
5+ years of experience in either machine learning, deep learning, stats, compute science/engineering, with at least 2 of those years focused on machine learning or deep learning.
A demonstrated track record of applying ML techniques to real-world problems.
Extensive knowledge of statistical modeling.
An interest in staying up-to-date with recent advances in machine learning.
The ability to collaborate with subject matter experts in defining appropriate features and metrics for a given model.
The confidence to take the lead on a project, work through the practical business decisions involved, and carry it to completion in a timely manner.
Comfort implementing new models from papers.
Experience working with large, noisy, or incomplete data sets.
Expertise in Python (Pytorch and Tensorflow preferred) and SQL.
Education:
Degree in machine learning, statistics, mathematics, computer science, or other quantitative disciplines
If you would like to be considered for the position of Senior Data Scientist or wish to discuss the role further then please leave your details below. Your resume will be held in confidence until you connect with a member of our team",4.2,"NJF Global Holdings
4.2","Chicago, IL",51 to 200 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (USD)
IT Data Engineer with Data Catalog,-1,"RiverPoint Group has an exciting permanent role that has opened up in Chicago for a skilled Data Catalog Engineer. This is a 6 month contract for hire role located in down town Chicago.

The Data Catalog Engineer will be responsible for the construction of an enterprise data catalog which will connect to data assets throughout the organization, tag the data, house technical and business meta data, intelligently discover relationships between the data, and enable usage by a wide variety of enterprise users.

Responsibilities:
Continually add to the data catalog by Ingestion of data from a wide variety of data sources, including relational databases, flat files, unstructured data, NoSQL data, ETL repositories, and reporting repositories.
Configure data sources, data domains, and their relationships.
Meet data definition, data quality, data profiling, and data lineage expectations by utilizing the data catalog functionality
Create and administer a data catalog security model to ensure the proper groups can access the right information; create a foundation for future data governance
Meet data privacy requirements by proper data classification and remediation of data privacy use cases
Work closely with the Lead Data Project Manager and Lead Data Business Analyst to ensure that the Data Catalog and Data Privacy programs are meeting expectations.
Collect data issues across the meta data ecosystem, work with business owners and data stewards to remediate issues.
Create a highly structured and comprehensive control environment so that data catalog content remains in high quality
Required Skills:
Bachelor’s Degree in Computer Science, Statistics, Information Systems or other related field
At least 1 year of experience with data catalog systems, technologies, and workflows. Broad technical skills necessary, with a solid understanding of data systems and infrastructure.
Strong SQL and data analysis skills to query a wide variety of data sources. Ability to analyze data models, data taxonomy, and deep appreciation of data standards and quality.
Previous hands-on experience with ETL, data profiling, and data lineage tools.
Ability to work with cross functional teams, perform root cause analysis and resolve complex issues.
Strong written and verbal communication skills, including the ability to articulate ideas concisely and clearly to both technical and non-technical audiences
#IND123",4.0,"RiverPoint
4.0","Chicago, IL",1 to 50 Employees,1988,Company - Private,Accounting,Accounting & Legal,$5 to $10 million (USD)
Data Engineer,"$73K-$130K
(Glassdoor Est.)","Overview


Job Summary: As a Data Engineer you will be joining a motivated team of professionals working to design and build solutions for entire breath of the firm, including Portfolio Managers, Analysts, Quants, Marketing, Compliance and Operations. You will gain exposure to a variety of partners at all levels, from Senior Technology leaders to Senior Business partners. In addition, you will obtain exposure and experience in the latest technologies. We are adopting a wide array of technology and approaches from some of the most proven Open Source projects to tried-and-true enterprise platforms.

Key Relationships: Business Product Owners & SMEs as well as IT project staff such as Architects, Developers, Testers, Delivery Managers, Production Services, Release & Change Management.

Background: The team delivers change to a range of business areas, front, middle and back-office. This role is an experienced hands-on contributor within the data engineering domain. The candidate is someone with a passion for data, data pipeline tools, data engineering patterns and understands that data-driven organizations lead to a competitive advantage.

This role will be responsible for re-engineering and modernization of data stores and data pipelines already in place as well as the implementation of net new solutions targeting customer focused value and drive the next generation of products and services. It will involve the build out of both strategic distributed systems as a greenfield development and the improvement and migration of legacy systems.

The candidate must be an excellent verbal and written communicator who is able to build strong relationships and act with a fiduciary-like approach working for product teams and business stakeholders, ultimately ensuring that the data product meets their requirements and expectations.

Our evolving data engineering tech-stack: AWS S3, AWS Glue, AWS Lambda, AWS Athena, AWS EMR, Python, PySpark, Scala, Confluent Kafka and AWS RDS (Aurora, Postgres and SQL Server).

Responsibilities


Required Skills

Proven Technology Development Experience with Minimum Years of Experience:• Data Engineering with Python and PySpark: 4+ years.• AWS Glue and/or AWS EMR: 2+ years.• AWS Lambda: 3+ years.• AWS Athena: 1+ years.• AWS S3: 4+ years.• AWS Boto 3 and AWS CLI: 4+ years.• AWS IAM: 4+ years.• Experience with Parquet or ORC file formats: 4+ years.• Continuous Integration/Continuous Deployment (CI/CD) and GIT source code control: 2+ years.• Procedural SQL (including set-oriented processing, table folding via normalization/de-normalization, exception handling and transaction control): 4+ years.• Experience with JSON file format: 2+ years

Proven Data Engineering Patterns and Concepts Experience with Minimum Years of Experience:• Implementation of canonical, object-oriented/parameterized data pipelines (ETL/ELT) to transform custom complex file formats into common standard storage formats for Big Data processing: 4+ years.• Experience building streaming and event-driven data pipelines: 2+ years.• Experience building batch data pipelines: 4+ years.• Experience implementing change data capture (CDC) methods: 4+ years.• Implementation of data pipelines to load Dimensional (Star) data models: 4+ years.• Relational database management system (RDBMS) concepts including scenario-based performance tuning (transaction control and exception handling, data integrity constraints, indexing, triggers, data types, transaction logging). Understanding of set oriented vs. sequential processing: 4+ years.• Ability to read, understand and performance-tune data models in the third normal form (3NF) or higher: 4+ years.• Object-oriented patterns including encapsulation/parameterization and loose coupling: 4+ years.• CAP theorem concepts and understanding of capabilities and limitations of distributed systems: 2+ years.• Data lineage/flow documentation and code documentation for full requirements traceability: 4+ years.• Data profiling with ability to effectively document via data model reverse engineering: 4+ years. • Agile: 4+ years.• Familiarity with DataOps.

Not Required but Nice to Have Technology Skills and Patterns• Automic Automation (UC4) Scheduler.• Scala• AWS Cloud Formation, AWS CloudFront, AWS Step Functions.• Confluent Kafka.• Apache NiFi, Apache Airflow, Apache Beam, Apache Presto.• Cloud-native columnar databases like AWS Redshift and Snowflake.• Microservices, REST API development for data provisioning and exchange.• Development with in-memory cache data stores like Redis and Memcached.• NoSQL databases like MongoDB, Cassandra.• Data visualization in Tableau, Python/Jupyter, D3.js or Highcharts.js.• DevOps.• Open source data lineage and metadata discovery tools like Marquez and Amundsen.• Bash Shell/PowerShell.• AWS Associate or Professional Certification.

Behavioural Competencies• Excellent verbal and written communication skills.• Experience consistently learning, experimenting with and applying new design patterns and technologies.• Preference and desire to work with open source (Apache Foundation) applications.• Strong team player, collaborative and self-motivated.• Strong desire to dissect production data issues and improve data quality.• Ability to handle stress and pressure gracefully while achieving continuous progress.• Ability to effectively work through ambiguity, road-blocks and contribute under limited supervision.• Proactive, desire to document and present improvement recommendations consistently.• Ability to commit and manage expectations with full ownership and follow-up.

Other Competencies and Characteristics• Learning doesn’t stop. You are perpetual student to all aspects of data engineering and methodologies, it is a passion of yours.• You understand the importance and impact of modern data architectures (e.g. event-driven architectures, data democratization, platform approaches to support ML/AI, stream processing and integrating real-time analytics into business applications).• You’ll be drawing on all of your passion for technology, hands-on experience and knowledge of latest Big Data and Engineering best practices to help you gain the respect and credibility of those around you.• Possess a passion for data modelling and design from conceptualization to optimization.• Communication is critical to our success. You must be able to demonstrate excellent verbal and written communication skills and the ability to interact professionally with a diverse group of partners, managers and subject matter experts.• You are constantly looking for a new and exciting challenge. You must be able to demonstrate the ability to contribute within the change team to tackle challenging requirements and tight timescales.

Minimum Academic Qualifications• Bachelor’s Degree in one or more of the following domains: Computer Science, Software Engineering, Information Systems or similar.

Other Competencies and Characteristics• Learning doesn’t stop. You are perpetual student to all aspects of data engineering and methodologies, it is a passion of yours.• You understand the importance and impact of modern data architectures (e.g. event-driven architectures, data democratization, platform approaches to support ML/AI, stream processing and integrating real-time analytics into business applications).• You’ll be drawing on all of your passion for technology, hands-on experience and knowledge of latest Big Data and Engineering best practices to help you gain the respect and credibility of those around you.• Possess a passion for data modelling and design from conceptualization to optimization.• Communication is critical to our success. You must be able to demonstrate excellent verbal and written communication skills and the ability to interact professionally with a diverse group of partners, managers and subject matter experts.• You are constantly looking for a new and exciting challenge. You must be able to demonstrate the ability to contribute within the change team to tackle challenging requirements and tight timescales.

Qualifications


Minimum Academic QualificationsBachelor’s Degree in one or more of the following domains: Computer Science, Software Engineering, Information Systems or similar.

EOE Statement


As an EOE employer, Legal & General Investment Management America will extend equal opportunity to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity, ancestry, national origin, age, disability, medical condition, genetic information, marital status, pregnancy, military status, and/or any other characteristic protected under applicable federal, state or local laws governing nondiscrimination in employment.",4.1,"Legal & General Investment Management America
4.1","Chicago, IL",201 to 500 Employees,2006,Subsidiary or Business Segment,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable
R&D Engineer/Scientist II,"$40K-$90K
(Glassdoor Est.)","Innovate to solve the world's most important challenges


The future is what you make it. When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who make the things that make the future. That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings smart and safe and even making it possible to breathe on Mars. Working at Honeywell isnt just about developing cool things. Thats why all of our employees enjoy access to dynamic career opportunities across different fields and industries. Are you ready to help us make the future?

Honeywell UOP is seeking a highly qualified individual for their R&D Materials Characterization group in Des Plaines, Illinois. Honeywell UOP R&D Materials Characterization in Des Plaines is a corporate center of excellence (CoE) supporting Honeywell UOP and corporate needs for chemical and materials analysis. The R&D Scientist II would work within a team of scientists utilizing advanced chromatography and high resolution mass spectrometry systems (including GCxGC, GCxGC/TOF-MS, GC/MS, LC/MS and FT-ICR MS) along with other CoE staff to support organic materials analysis needs.

Candidates should have a thorough understanding of organic chemistry matched with skills in chemical analysis. Familiarity with organic reaction mechanisms, classical and instrumental organic functional group analysis is required. The candidate must be able to assimilate information from a variety of analytical techniques, such as, chromatography, infrared spectroscopy, nuclear magnetic resonance spectroscopy and mass spectrometry to generate insights and critical recommendations for technology delivery projects. Direct experience in operating chromatography and mass spectrometry systems and data interpretation is required. Experience in in chemical separations is desirable.

Ability to stand on your feet to utilize instruments, climbs stairs/ladders, lift up to 30 pounds, and push up to 50 pounds is required.

Key Responsibilities

• Area: Research and Development
• Work within a team of scientists utilizing advanced chromatography and high resolution mass spectrometry systems
Operate and maintain an FT ICR-MS system
Analyze materials, particularly in the area of petroleum chemistry
• Collaborate with R&D staff and assimilate information from a variety of analytical techniques, such as, chromatography, infrared spectroscopy, nuclear magnetic resonance spectroscopy and mass spectrometry
Produce reports with insights and critical recommendations for technology delivery projects.

You Must Have
• PhD in Analytical Chemistry or Chemistry
• 0-3 years of experience in analytical chemistry
• 0-3 years of experience with gas chromatography and mass spectrometry

We Value

• 0-3 years of experience in analytical chemistry associated with organic chemistry preferred.
• Instrument operation and general trouble-shooting skills with chromatography and mass spectrometry including FT ICR-MS
• Interpretive skills with infrared spectroscopy, nuclear magnetic resonance spectroscopy and mass spectrometry applied to organic chemical analysis and particularly in the area of petroleum technology
• Able to interpret, organize and prepare concise written reports from analytical data.
• Act as a technical resource for analyzing and characterizing materials and organic compounds to contribute in the development and support of Honeywell UOP technologies.
• Project planning and leadership capability.
• Able to work effectively in a multidisciplinary team environment to manage multiple, complex and competing projects.
• Familiarity with design of experiments and statistical quality control desired.

Additional Information
JOB ID: req238825
Category: Engineering
Location: 50 E Algonquin Rd,Des Plaines,Illinois,60017-5016,United States
Exempt
Global (ALL)

Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, or veteran status.",3.7,"Honeywell
3.7","Des Plaines, IL",10000+ Employees,1885,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD)
Senior IT Data Scientist - Operations,"$120K-$193K
(Glassdoor Est.)","Job Description

Job Title: Senior IT Data Scientist - Operations

City: Lake Forest / State: Illinois

Job Description

Join Reynolds Consumer Products… a world of opportunities! At Reynolds Consumer Products, we are passionate about achieving results and have fun winning as a team! We provide amazing job opportunities for growth with competitive salaries and benefits in an exciting, dynamic, fast-paced, and fun workplace environment. Are you looking to build a strong career and make a positive impact? Then we have an opportunity for you! We currently have an opportunity for an Operations Senior Data Scientist to join our team located at our Company Headquarters in Lake Forest, IL.

Your Role:

As an Operations Senior Data Scientist, you will primarily be responsible for solving operations problems by processing and analyzing data from multiple sources to identify meaningful relationships, patterns and trends. You will prepare data insights and proposals in narrative and visual forms and leverage advanced data science methods to discover opportunities to increase equipment effectiveness, reduce costs and provide insights to plants on process disruptions. You will have the opportunity to:
Improve the manufacturing process by formulating hypotheses, conducting experiments and delivering improvements to KPIs based on findings
Maintain and tune analytical models to predict and monitor the condition of plant equipment
Influence manufacturing decision makers by presenting statistical insights
Ensure our manufacturing operations operate at peak efficiency
Ultimately, you will be a vitally important team member in our Digital Manufacturing Group and help Reynolds Consumer Products succeed by leveraging data insights.

You will love it here if…
You are not only a team-player, but you foster a collaborative team environment
You are analytic, enjoy new challenges and thrive in a fast paced manufacturing operation
You are committed to operational excellence and to keeping others safe in the workplace
We need you to have:
A strong proficiency in statistical analysis methods and tools, e.g., Python, Machine Learning
3-5 years of experience in data model development, data visualization, and application of advanced analytics to drive business outcomes
3-5 years of experience in the design and implementation of data infrastructures and data hierarchies
Experience in AWS Analytics platform
SQL query skills
Strong analytical and problem solving skills
BA/BS in Data Analytics, Engineering, Business, or a related field
Icing on the cake:
Experience developing and implementing predictive maintenance and predictive quality models
Data visualization skills in Power BI
Prior experience working in operations research or related field, e.g., Industrial Engineering or Manufacturing
For applicants or employees who are disabled, or require a reasonable accommodation for any part of the application or hiring process, you may request assistance by calling us at (847)482-3550 or email Recruitment@ReynoldsBrands.com.

No recruiter calls or emails please.

Reynolds Consumer Products is an Equal Opportunity Employer EEO AA M/F/Vet/Disability.

Qualified applicants will receive consideration for employment without regard to their race, color, religion, national origin, sex, protected veteran status or disability.

Reynolds Consumer Products is an Equal Opportunity Employer that complies with the laws and regulations set forth in the following EEO is The Law Poster: http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf

The Pay Transparency Policy Statement can be found on this link:

http://www.dol.gov/ofccp/PayTransparencyNondiscrimination.html

The poster and the supplement can be found on this link.

http://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm

For applicants or employees who are disabled, or require a reasonable accommodation for any part of the application or hiring process, you may request assistance by calling us at (847)482-3550 or email Recruitment@ReynoldsBrands.com.

No recruiter calls or emails please.",3.6,"Reynolds Consumer Products
3.6","Lake Forest, IL",1001 to 5000 Employees,2010,Company - Public,Consumer Products Manufacturing,Manufacturing,$2 to $5 billion (USD)
Senior Data Scientist,"$80K-$131K
(Glassdoor Est.)","Join a passionate and purpose-driven team of colleagues who contribute to Trustmark’s mission of helping people increase wellbeing through better health and greater financial security. At Trustmark, you’ll work collaboratively to transform lives and help people, communities and businesses thrive. Flourish in a culture where appreciation, mutual respect and trust are constants, not just for our customers but for ourselves.

We are currently seeking a Senior Data Scientist. In this role you will be responsible for working with a variety of business partners across all business units to design and implement predictive analytics to generate growth, reduce cost and improve efficiency across a variety of operational processes. You will be a key player in developing machine learning and other advanced models that drive business outcomes.

Key Accountabilities:
Identifies and quantifies predictive analytics opportunities for the organization.
Leads analytics projects and champions the use of new predictive analytics techniques and tools. Clearly sees the strategic value of data and applies internal and external data to grow business and improve operations and customer experience.
Partners well with business stakeholders to gain support and commitment for predictive analytics projects.
Develops complex algorithms and statistical predictive models and determines analytical approaches and modeling techniques to evaluate scenarios and potential future outcomes.
Behaves as mentor to citizen data scientists to provide technical advice.
Minimum Requirements:
Bachelor’s Degree required, Master's degree preferred
10+ years of related experience required
Experience conducting data analysis in a health benefits and/or life insurance setting preferred
Experience with DataRobot, SAS, SQL and Python preferred
Familiarity with Microsoft ADLS preferred
All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, age, or disability.",3.2,"Trustmark Companies
3.2","Lake Forest, IL",1001 to 5000 Employees,1913,Company - Private,Insurance Carriers,Insurance,$500 million to $1 billion (USD)
Data Engineer 134813,"$67K-$121K
(Glassdoor Est.)","Our client is seeking a Data Engineer to join their team in Chicago, IL.

Within this role, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The right candidate will be excited by the prospect of optimizing or even re-designing our companys data architecture to support our next generation of products and data initiatives.

Responsibilities

Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
Work with data and analytics experts to strive for greater functionality in our data systems

Qualifications

Bachelors degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field (Masters Preferred)
5+ years of experience in a Data Engineer role
Experience with health care datasets, clinical data, payer/claims data, SDOH data, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Skilled in problem-solving with strong attention to detail
Excellent customer service skills and the ability to react diplomatically and patiently to internal and external customers
Excellent follow-up skills paired with the ability to multi-task and determine root causes
Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Experience building and optimizing big data data pipelines, architectures and data sets
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Strong analytic skills related to working with unstructured datasets
Build processes supporting data transformation, data structures, metadata, dependency and workload management
A successful history of manipulating, processing and extracting value from large disconnected datasets
Working knowledge of message queuing, stream processing, and highly scalable big data data stores
Experience supporting and working with cross-functional teams in a dynamic environment
Apply",3.3,"Open Systems Technologies (NYC)
3.3","Chicago, IL",51 to 200 Employees,1990,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable
Senior Environmental Research Scientist,"$69K-$144K
(Glassdoor Est.)","General Statement

Under general direction, carries out more complex applied research projects in relation to wastewater treatment processes, individually or in conjunction with other investigators. Work is characterized by greater freedom of action than at the Environmental Research Scientist level.

Essential Job Functions

Essential job functions are fundamental, core functions common to positions in a classification. They are not intended to be an exhaustive list of all job duties for any one position in the class. Since class specifications are designed to be descriptive and not restrictive, incumbents may complete one or all of the job duties listed or tasks of similar kind not specifically listed here.
Conducts research assignments on new wastewater and sludge processing technology and in the fields of sanitary chemistry, sanitary microbiology, sanitary engineering, wastewater engineering, and environmental engineering.
Prepares technical work plans, manuscripts for publication and interim and final reports on research programs and projects.
Assists Maintenance and Operations in solving plant problems such as sludge dewatering and odor problems; conducts joint M&R/M&O plant monitoring programs.
Assists the Engineering Department through conceptual design of treatment processes.
Supervises and/or leads laboratory, pilot and field testing.
Assigns, supervises, and reviews work of subordinates.

Other Job Functions

Reviews technical documents from other District Departments or outside agencies.
Prepares or participates in seminar and lecture presentations related to research projects.
Initiates and processes requisitions and payment forms and other administrative duties.
Performs other duties as assigned.

Environmental Conditions

May involve exposure to a variety of chemical and biological materials, some of which may be hazardous or toxic. May involve exposure to fumes and noxious odors.

Desirable Knowledge, Skills and Abilities

Thorough knowledge of wastewater and sludge treatment processes employed at the District.
Thorough knowledge in the principles, practices and techniques of wastewater treatment, including sludge processing.
Thorough knowledge of research methods associated with air, sludge, and water quality monitoring and field and laboratory testing.
Considerable knowledge of analytical techniques pertaining to wastewater, sludge and air.
Considerable knowledge of statistical techniques used in analyzing data.
Considerable knowledge of environmental regulations.
Ability to direct, monitor and participate in the development of research projects.
Ability to communicate effectively, orally and in writing.

Minimum Qualification Requirements

A master's degree in water resources sciences, environmental sciences, environmental engineering or sanitary engineering from an accredited college or university. Three years of research experience in the fields of wastewater and sludge treatment technology related to the District's activities.

Substitution

Related graduate study above the master's degree may be substituted for the required experience on a year-for-year basis to a maximum of two years.

Promotional Requirement

One year of service with the District as an Environmental Research Scientist.
Civil service status as an Environmental Research Scientist.",4.1,"MWRD of Greater Chicago
4.1","Chicago, IL",1001 to 5000 Employees,-1,Government,Federal Agencies,Government,Less than $1 million (USD)
IT Data Engineering Intern,-1,"Summer 2021
Shure offers a challenging and rewarding summer internship program. The twelve week program is offered to undergraduate students that have completed at least 2 years of college, as well as graduate students. Each intern will receive a competitive salary and students who reside out of Illinois will receive a housing stipend to cover living expenses. Applications will be collected, reviewed and selected candidates will be contacted in late fall/early winter.
We are looking for a data passionate individual to join our growing Data and Analytics practice. The internship will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate enjoys solving business problems and delivering data insights. The Data Engineer will support our database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

Assist with data cataloging, data acquisition, data modeling and data quality.
Learn / leverage cloud-based data management capabilities
Assist with research on technology options and processes related to data management and governance
Assist with analytics to uncover potential opportunities
Building of data visualization in support of business projects
Help with data pipeline projects, as needed

In-process bachelor’s or advanced degree in computer science, data science / analytics related degree
Some experience with open-source programing languages, e.g. Python, R, etc.
Knowledge of the AWS data lake formation and/or Tableau a plus
Microsoft Office skills
Self-motivated, team player, detail oriented
Able to meet required deadlines
Ability to work independently with high degree of accuracy and attention to detail.
Excellent verbal and written communication skills.
Keen willingness to learn new concepts and skills.",4.1,"Shure Incorporated
4.1","Skokie, IL",1001 to 5000 Employees,1925,Company - Private,Consumer Products Manufacturing,Manufacturing,Unknown / Non-Applicable
Data Engineer,"$59K-$87K
(Glassdoor Est.)","What do incubators and Spectrum have in common? Well, they’re great for growth, and even better for stability. As an innovative software development and digital marketing company pioneering the field of artificial intelligence, we can offer our newest Data Engineer the best of both words – a high energy, forward-thinking start-up culture, inside of a well-established, profitable, and stable structure of a 3 decade old organization. So, if you’re interested in getting your hands dirty, and leading a small team, all while inciting change into a larger organization with a vision to change the world uses data today, then please read on.

Responsibilities

Beyond working with state of the art technology you will have many different fantastic projects to work on as a Data Engineer at Spectrum. Here are just a few different responsibilities you can expect off the bat:
Planning query efficient data store schemas with respect to the data requirements of our internal data warehouse
Communicate with data scientists and other software engineers to build proper data pipelines for efficient and cost-effective querying
Develop, construct, test, and maintain architectures with the help and feedback of software engineers
Determine and implement proper data schemas that align with Spectrum’s and Spectrum’s client’s business objectives
Recommend and implement ways to optimize data reliability, efficiency, and quality
Consult and suggest different technologies for our team to test and utilize together
Incorporate the business objectives of key stakeholders in the architecture of our data warehouse
Research new and interesting data acquisition opportunities
Some Characteristics That Define You

We understand that as a Data Engineer for Spectrum, you have many different professional goals and personal interests. As such here are just a few different things that typically define our team members on the Data Science team:
Self-Starter. Building a data warehouse is no simple task. You will need to come in with a self-starter attitude to not only make this data engineering role what you want it to be, but make a stellar and efficient data warehouse while you’re at it.
Analytical. In order to solve problems and build innovative new digital marketing campaigns, it is essential that you know how to take an idea and analyze it from all of its angles.
Developer. In the ever changing world of artificial intelligence, it’s not enough just to build models. You bring to the table an eye for data patterns along with a knack for relational database engineering.
Patient. As a data engineer, you know that you work with extremely large data sets on a daily basis. As such we are looking for someone who is not only meticulous, but patient enough to sit and sift through that data in a thorough way.
Creative. Beyond just analyzing data sets, you are an explorer and a puzzle solver. Pulling insights out of your data and understanding how those insights can better shape our tools is something that you live to do.
Student. More so than most industries, the field of data science is always changing and evolving. As such, you are always looking to learn new things and gain new skills.
Required Skills and Experience

On top of the many intangible skills you bring to the table, there are many skills that can help improve the efficiencies and success of your work at Spectrum. Here are a few of those required skills and experience that you will come in with as a Data Engineer on our team:
A bachelor’s degree/pursuing a bachelor’s degree in computer science, mathematics, statistics, information systems, or a related field
Experience with statistical modeling
1-3 years working experience with Python and/or SAS languages
1-3 years working experience with SQL databases and database querying languages
1-3 years working experience with C#/.NET
Familiarity with Microsoft Azure
Familiarity with Graph database structures
Experience with both RDBMS and TDMS
Experience with data mining and data cleaning
Experience with data visualization and reporting techniques
Written and verbal expression
Benefits

As a Data Engineer at Spectrum there are a ton of fantastic perks and benefits that come along with your work. Here are just a few of the benefits you can expect when joining the Spectrum family:
Comprehensive medical & dental insurance
Retirement planning & company matching
Generous PTO, including sick days & holidays
A state-of-the-art office environment
Nintendo Switch in-office gaming such as FIFA, Arms, Mario Kart, and Rocket League
Year-round gym memberships
Paid continuing education
Casual dress code
Flexible scheduling
Free-Lunch-Friday
Company sponsored parties and group activities outside of the office
About Us

For the past 25+ years, our mission at Spectrum has always been the same— growth. Whether that be helping our customers find quality new business, developing and challenging our team members, or evolving our products and services with advancements in technology and best practices, we have always been looking towards bettering ourselves for the future. Now as we continue to grow, we find ourselves as not only the nation’s leading digital marketing and software provider for the home services industry, but an innovator and ground-shaker for the world of artificial intelligence as well. From marketing automation software powered by AI, to top notch digital marketing services via those same AI insights, we love what we do and are excited to continue to innovate for the future together.

But don’t just take my word for it. Check out what our team is saying about in real time, and learn why we are a certified Great Place to Work today!",3.5,"Spectrum Communications and Consulting
3.5","Chicago, IL",51 to 200 Employees,1992,Company - Private,Advertising & Marketing,Business Services,$10 to $25 million (USD)
AI/ML Data Engineer,-1,"Â
Mandatory SkillsÂ

Knowledge and experience in APIÂdevelopment, AI/ML, SageMaker, Data Lake, Data Analytics, Cloud Monitoring and Analytics,Â
Â

Strong cloud programming skill with experience in API and AWS Lambda functions or any other scripting languages like Python / Bash using Python & Node.jsÂ
Â

Good understanding in using AWS CLI, Cloud formation, Terraform, Ansible with troubleshooting experiencesÂ
Â

Strong knowledgeÂof CloudÂSecurity practices and IAM Policy preparation for AWSÂ
Good to haveÂ

Knowledge on Experience with implementing containers using AWS container services cloud native container orchestrators in AWSÂ
Â

Strong working experience with AWS services as EC2, RDS, API Gateway, Lambda, DynamoDB, Elastic Cache, ECS, ALB/NLB Load Balancers, S3, EBS, VPCÂNetworking ,ÂSecret Manager, Parameter Store âetc.Â
Â

Ability to participate in fast-paced DevOps and System Engineering teams within Scrum agile processesÂ
Â

Experience with DevOps tools will be an added advantageÂ
Â

Know-how of working with Python / Bash scripting will helpÂ

Â",-1,softsnippets,"Chicago, IL",-1,-1,-1,-1,-1,-1
AI/ML Data Engineer,-1,"Â
Mandatory SkillsÂ

Knowledge and experience in APIÂdevelopment, AI/ML, SageMaker, Data Lake, Data Analytics, Cloud Monitoring and Analytics,Â
Â

Strong cloud programming skill with experience in API and AWS Lambda functions or any other scripting languages like Python / Bash using Python & Node.jsÂ
Â

Good understanding in using AWS CLI, Cloud formation, Terraform, Ansible with troubleshooting experiencesÂ
Â

Strong knowledgeÂof CloudÂSecurity practices and IAM Policy preparation for AWSÂ
Good to haveÂ

Knowledge on Experience with implementing containers using AWS container services cloud native container orchestrators in AWSÂ
Â

Strong working experience with AWS services as EC2, RDS, API Gateway, Lambda, DynamoDB, Elastic Cache, ECS, ALB/NLB Load Balancers, S3, EBS, VPCÂNetworking ,ÂSecret Manager, Parameter Store âetc.Â
Â

Ability to participate in fast-paced DevOps and System Engineering teams within Scrum agile processesÂ
Â

Experience with DevOps tools will be an added advantageÂ
Â

Know-how of working with Python / Bash scripting will helpÂ

Â",-1,softsnippets,"Chicago, IL",-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"TEXT ""DATA"" TO 847-908-5105 TO APPLY FROM A MOBILE DEVICE!

About Us

Mastery Logistics Systems is building the worlds first lovable Transportation Management System, or TMS.

Our customers large transportation companies and shippers who need those companies have struggled with systems that are outdated or inadequate. As shippers or transportation service providers, our customers have in the past been forced to use multiple systems to manage dedicated fleet operations, outsourced or insourced trans management, one way trucking, truckload brokerage, LTL, and Intermodal, or to sub-optimize one or more of those functions by attempting to fit it into a TMS that is adequate at another function.

Mastermind TMS allows our customers to bring all of these functions into a single platform, providing flexibility, visibility, control, and efficiency. Todays unprecedented global supply chain upheavals underscore how important the transportation industry is. We are building a system to allow this industry to work faster, smarter and more efficiently.

The challenges in this industry are big and exciting! We are tackling everything from fast and efficient data input to ingesting large amounts of data and applying AI to looking at blockchain to securely digitize paperwork. If you are passionate about humanizing an industry, automating in innovative ways, building for quality and scale, helping make people's lives easier and touching every part of our economy then this is the place for you.

Mastery Logistics Systems is committed to continuing to build an incredible company. We are a masterful mosaic of incredible people. We are specialists and experienced in our respective fields. We are dedicated to continuous improvement both professionally and personally. We are a collective group of really good people. We have different interests, backgrounds & talents and we work together to create really cool stuff! We believe in diversity of thought and are mindful and inclusive. We have deep respect for each other and work diligently at adding the right people to our teams.

At this moment we are all working from home and doing our part to combat the Covid 19 virus. We are creatively building our new work habits. We are respectful of each others time and personal life. We have flexible schedules but share in the mission that we are building and need to get it done. We offer an excellent suite of benefits. We are dedicated to finding new ways to add perks as we live and work from home.

Our team has the domain knowledge and connections to make an impact, and were looking for experienced and thoughtful people to who thrive on creating and building great products. We want people who have a true passion for servicing and taking care of our customers. We need people who are flexible problem solvers, thrive on collaboration and consistently know how to communicate their solutions well. We are small and nimble which is evident in how quickly we could pivot to our new reality. Each member of the team can make a tremendous impact both technically and culturally. While a start-up, we are well-funded, have an initial paying customer with which to test and launch, and are founded by top experts and veterans in the logistics industry.

Join us youll love it lets build a masterpiece!

About the Role

The transportation industry has no shortage of complex problems requiring creative, data-intensive solutions in order to effectively and efficiently automate operations at scale. In this role, you will be expected to work autonomously and contribute to several high impact projects including Masterys advanced matching and tour management engines.

Responsibilities
Build model-based optimization, simulation, and/or predictive tools to enable Masterys customers to efficiently match freight at scale
Closely collaborate with fellow Engineers and Product Managers and interact with stakeholders across the organization
Write clean, maintainable, and well-tested code
Help build and drive the Data Science and Analytics roadmap
Requirements
3+ years of industry experience as a Data Scientist or graduate degree in Operations Research, Industrial Engineering, or Transporation Engineering plus 1 year of industry experience
Excellent written and verbal communication skills
Expertise in the use of commercial solvers (e.g. CPLEX, Gurobi, XPRESS) and working knowledge of open-source solvers (e.g. PuLP, Google OR Tools)
Adept at interacting with technical and non-technical audiences
Practical experience implementing optimization models and tools
Experience with production systems using Operations Research algorithms
Strong sense of responsibility with a bias towards action
Comfortable self-directing and prioritizing your own work
Experience working with cloud-based infrastructure
Proficiency in Python
Deep understanding of LP, MIP, QP and stochastic optimization methods, preferred
Experience working with real-time, distributed systems, preferred
Experience working with ML models in production environments, preferred
Experience leading technical projects, preferred
Benefits

Mastery takes great pride in providing our employees a robust and highly competitive benefit package. Our benefits include Medical, Dental and Vision insurance covering 90% of premium costs. Company paid life insurance for 1x salary. Legal, AD&D, Additional Life and other employee assistance benefits. We have a 401k savings plan with a 4% match. We provide opportunities for professional growth and development. We fully support our work from home initiative as we do our part to combat the Covid 19 crisis. We have a manage your life and schedule Paid Time Off program. We are fully devoted to finding creative perks and benefits since we cannot currently enjoy our cool office culture. Our philanthropic partner is St. Jude Childrens Research Hospital.

We are an equal opportunity employer and actively seek a diverse community of professionals. Veterans, Women, non-binary, people of color, LGBTQIA, we welcome all to apply!

TEXT ""DATA"" TO 847-908-5105 TO APPLY FROM A MOBILE DEVICE!",-1,"Mastery Logistics Systems, Inc.","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Clinical Data Analyst NGS Genomics,"$46K-$82K
(Glassdoor Est.)","The successful candidate will work as part of a growing team of faculty laboratory directors, bioinformaticists, data scientists, and laboratory technologists whose goal is to bring comprehensive -omic analysis to pediatric patients treated at LCH. Functions include a mastery of technical knowledge of high complexity tests generating genomic data within a particular area, and analysis of this data sufficient to result in an interpretation and clinical report. The position actively supports the Hospital's and the Department's Continuous Quality Improvement and customer service goals through modeling of appropriate behavior and by providing a work environment conducive to attaining these goals.

1. Performs technical quality review of data from high complexity genetic testing methodologies such as Next-Generation Sequencing (NGS), MLPA, microarrays, fragment analysis and Sanger sequencing. 2. Using existing databases and newly-developed analysis tools, performs technical and clinical interpretation of genetic sequence alterations identified through Next-Generation Sequencing (NGS). 3. Performs initial analysis/quality review of test data and assists the Genetic Counselors/Medical Directors in drafting preliminary patient reports for molecular genetic tests. 4. In collaboration with laboratory technologists, identifies opportunities to improve data accuracy/integrity by evaluating, refining and improving analysis/variant interpretation workflows, and assists in the continued development of standard operating procedures. 5. Recognizes the clinical significance of each test performed, maintains the confidential and sensitive nature of patient information and results, and adheres to HIPAA regulations for transactions, security and confidentiality, and reports results within established time frames. 6. Maintains a professional level of knowledge of molecular biology and genetics to properly analyze molecular genetic test results; in particular, in the context of abnormal or atypical findings, by conducting comprehensive literature review. Keeps current with new and evolving clinical standards and workflows, particularly for next generation sequencing and variant interpretation guidelines from ACMG. 7. Participates in, and successfully completes all proficiency testing. Ensures compliance with CLIA/CAP requirements and adheres to the laboratory's documented Quality Management Plan. 8. Supports activities of the molecular diagnostic lab pertaining to new test and technology development and continued expansion of next-generation sequencing based tests. 9. Participates in education and mentorship of other lab staff through direct interaction and presentations. Serves as a technical resource on next-generation sequencing analysis pipelines and relates expertise to staff. 10. Involved in abstract, figure, and manuscript preparation and submission, and presentations at local or national professional conferences. 11. Other job functions as assigned.

1. Ph.D in a field directly related to human genetics and genomics required, with a strong desire to work in a clinical environment. 2. Experience analyzing Next-Generation Sequencing data (whole genome/exome, RNAseq and custom panels) with commonly used bioinformatics tools and databases preferred (e.g. Mutation Surveyor, ClinVar, OMIM, HGMD). 3. Experience in Next-Generation Sequencing or molecular biology bench work highly preferred. 4. Experience working in a team based environment with strong work ethic, time management skills, and proven productivity. 5. Excellent verbal and written communicator with strong technical documentation capabilities. 6. Demonstrated analytical and problem-solving skills with good attention to details.",3.9,"Ann & Robert H. Lurie Children's Hospital of Chicago
3.9","Chicago, IL",1001 to 5000 Employees,2012,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$500 million to $1 billion (USD)
Sr. Decision Scientist,"$107K-$175K
(Glassdoor Est.)","Grubhub is dedicated to connecting hungry diners with our wide network of restaurants across the country. Our innovative technology, easy-to-use platforms and streamlined delivery capabilities make us an industry leader today, and in the future of online food ordering.
We strive to create a workplace that reflects the diversity of our customers and the communities we serve. When you join our team, you become part of a community that works together to innovate, solve problems, take risks, grow, work hard and have a ton of fun in the process!
Why Work For Us
We have a fast-paced environment and that is what our teams thrive on. Grubhub believes in empowering people and offering opportunities for development, as well as professional growth. We value strong, positive relationships in all areas: with each other, our customers and our greater community. Want to be a part of a team of diverse collaborators in an authentically fun culture? If so, we want to talk to you - and hear what’s your favorite restaurant for food delivery!
About the team:
Grubhub is looking for an innately curious, business-minded, results-oriented Senior Decision Scientist with a strong statistics background to work on our Systems Analysis team. As part of our Delivery initiative, the Systems Analysis team is focused on providing analysis to accelerate and perfect our delivery systems. As a member of this extremely collaborative team you will get to partner with operations, finance, product, data science and engineering. In this highly visible role, you will be responsible for selecting and implementing appropriate statistical methods to evaluate and inform new business initiatives as well as the development and execution of technology roadmaps. Specific responsibilities include, but are not limited to, ad hoc data analysis, development of regression models for ongoing assessment, development of dashboards and proposing new metrics that can help us better understand our systems. You will also partner with our simulation team to help us better digest and interpret the output of our simulation tools.

Understand the business! Work directly with stakeholders to address their needs.
Work with our software engineers to understand the output of our services and ensure they meet analytical requirements
Model system interactions and behaviors for various holistic initiatives
Inform real-time data requirements design
Partner with Product and Engineering teams to understand new product ideas, assess risks and ensure that the necessary data is available
Understand our brands, markets, user behaviors, and long-term trends and help assess these
Develop and implement models to inform business decisions
Question our assumptions! Find new and better ways to do what we’re doing.
Assess new algorithms and business policies in partnership with our operations research team.
Relentlessly analyze and improve the performance of our business.

BA/BS in Computer Science, Math, Physics, Engineering, Economics, Statistics or other technical field OR
MS in quantitative discipline (Computer Science, Math, Physics, Engineering, Statistics or other technical field etc) or equivalent experience
4+ years experience with quantitative analysis
A passion for the power of statistics and a good understanding of when it is the right tool
Experience applying descriptive statistics, business process or scenario analysis, and visualization to solve real-world problems
Experience with PySpark, Hive and the Python data stack
Strong R programming experience
Strong data querying capabilities using SQL
Ability to explain the application of statistics in simple terms to business users
Experience with Plotly or other visualization tools a plus

Flexible PTO. Grubhub employees are provided a generous amount of time to recharge their batteries.
Health and Wellness. We provide programs that support your overall well-being such as generous medical benefits, employee network groups, company-wide fitness challenges, and a comfortable and casual workplace! We also support our parents by offering 8 weeks of paid parent bonding time, a 4-week returnship program, and 6-8 weeks paid medical leave.
Learning and Career Growth. Your personal and professional development is a priority at Grubhub. From day one, we empower you to lead and be an active participant in your career growth. We provide continuous learning opportunities, training, and coaching and mentorship programs.
MealPerks. Who’s ready for some lunch? We provide our employees with a weekly Grubhub credit to enjoy and support local restaurants. We also offer company-wide meals several times a year to bring our Grubhub family together.
Fun. Every Grubhub office has an employee-led Culture Crew that connects people through fun, meaningful events and initiatives. Some of our popular past events include: Wing-eating contests, Grubtoberfest, 5k Runs, Bring Your Child to Work Day, regular happy hours, and more!
Social Impact. We believe in the importance of serving the communities that support our business. In addition, employees are given paid time off each year to support the causes that are important to them.
Grubhub is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics. The EEO is the Law poster is available here: DOL Poster. If you are applying for a job in the U.S. and need a reasonable accommodation for any part of the employment process, please send an e-mail to TalentAcquisition@grubhub.com and let us know the nature of your request and contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address.
CA Privacy Notice: If you are a resident of the State of California and would like a copy of our CA privacy notice, please email privacy@grubhub.com.",3.9,"Grubhub
3.9","Chicago, IL",1001 to 5000 Employees,2004,Company - Public,Internet,Information Technology,$100 to $500 million (USD)
Senior Clinical Genomics Scientist,"$74K-$154K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

We are seeking a highly motivated and capable genomic scientist with extensive experience and interest in translational cancer research. This position requires experience in exome or whole genome NGS sequence analysis, variant interpretation and prioritization and an understanding of cancer biology and human genetics. Top candidates will also have experience translating research findings into clinically relevant and actionable information.

Duties and Responsibilities:
Identify gaps and contribute to the building of the Tempus clinical knowledge database.
Design and evaluate analysis for sequencing-based projects; discuss valid data collection methods.
Generate and maintain clinical SOPs
Collaborate with bioinformaticians, scientists, and clinicians to design and perform analyses and evaluate observed associations.
Produce high quality and detailed documentation for all projects.
Requirements:
Broad Biology background with a deep understanding of human genetics and oncology.
Ability to critically analyze medical and scientific literature with outstanding attention to details.
Familiarity with Exome and Whole Genome Sequencing in clinical testing space.
Familiarity with databases, tools, and resources commonly used in interpretation of genomic data.
Experience with genetic variant curation and/or interpretation of clinical relevance based on the AMP and ACMG guidelines is highly desired.
Familiarity with scripting and programming languages (perl, python or R)
Ph.D. or M.D. degree in Human Genetics, Molecular Genetics, Genomics or appropriately-related field is required.",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Data Engineer,"$53K-$99K
(Glassdoor Est.)","Data Engineer
Submit
#495732
/
Regular Full-Time
/
Chicago – 55 East Monroe Street, IL
/
Data Services, Infrastructure, Project Management
JOB DESCRIPTION:
NORC at the University of Chicago seeks a Data Engineer to support a diverse range of data-oriented research projects in the Information Technology Department. This role will overlap somewhat with Data Science, which plays a strategic role in supporting our research teams to produce valuable insights for our clients. The Data Engineer will work collaboratively in multi-disciplinary teams to help drive innovation in the areas of data storage, data ingestion, data quality, performance tuning, optimization, and system troubleshooting. This person will likely be involved in the design and implementation of algorithms, models, and work flows that lead researchers to discover valuable information within large volumes of data from various sources. He/she may organize, harmonize, and analyze data sets, use various technologies to enable data visualization, and create data-centric applications of enduring value to the company’s business.
DEPARTMENT: ADVANCED DATA SOLUTIONS
The ADS evolved out of the dynamic growth of the NORC Data Enclave®, an industry-defining platform for secure remote data access services, which supports large-scale, enterprise-wide, big data initiatives. NORC’s ADS has been a leader in the application of IT security and data governance best practices to enable access to sensitive data needed to inform evidence based decision making.

The ADS leverages NORC’s on-premise, hybrid-cloud and full cloud solution models to maximize our data and systems security posture and provide a stable platform to scale our computing resources. These secure, stable and scalable solutions enhances NORC’s ability to delivery end-to-end custom processes and products for our clients.
RESPONSIBILITIES:
The Data Engineer will engage in system setup, ETL pipeline development, production support, executing test plans, and writing data preparation and reporting programs. This role works as a part of a multi-faceted product team under the guidance of project and functional managers who will provide detailed specifications, schedules, and priorities, as well as thoroughly review the resource's work. The Data Engineer will be responsible for maintaining, testing, and supporting existing NORC data systems, which may include coding and testing ETL pipelines, data manipulation with integrity preservation, and training others in the end-use of that data. The Data Engineer must be proficient in many different platforms, including SQL, NoSQL, Hadoop/Spark, and data warehousing implementations. The Data Engineer must also be committed to staying up to date with new technologies, and recognizing when to use different or emerging technologies as most appropriate for each task.
REQUIRED SKILLS:
The successful candidate should have at least a Bachelors degree in one of the following fields: math, statistics, computer science, data science, or a social science or public policy related field.
He/she must have at least five years’ experience in positions of increasing responsibility, preferably working with large datasets and conducting statistical and quantitative modeling, melding analytics with programming, data mining, clustering, and segmentation.
He/she should have a strong foundation in areas of statistics, mathematics, and computer programming.
Mature fluency in Python programming and familiarity with both Linux and Windows operating environments required along with parallelization technologies for high performance computing.
Familiarity with utility scripting languages such as Bash and Powershell, code repository tools such as Git and Subversion (SVN), and Atlassian products JIRA and Bitbucket.
Experience with a broad array of data storage platforms, including, but not limited to: SQL (Postgres, MS SQL, MySQL), NoSQL (MongoDB), and data warehousing solutions (Vertica/Greenplum) with emphasis on performance tuning, query optimizations, big data workloads.
Extensive hands on experience in leading large-scale, full-cycle MPP enterprise data warehousing (EDW) projects.
Extensive hands on experience in data warehousing design, tuning, and ETL/ELT process development.
In addition, the successful candidate should:
Recommend solutions that follow accepted standards regarding database physical structure, functional capabilities, and security.
Maintain database performance by calculating optimal parameters values.
Perform query and database design optimization in addition to providing assistance/reviews/feedback to stakeholders in writing complex queries, stored procedures/functions, views, and DDL/DML scripts.
Troubleshoot complex database issues in accurate and timely manner ensuring compliance with SLAs.
Have strong skills in problem solving and quantitative/qualitative analysis required.
Be able to organize and prioritize work assignments to meet project goals.
WHAT WE DO:
NORC at the University of Chicago is an objective, non-partisan research institution that delivers reliable data and rigorous analysis to guide critical programmatic, business, and policy decisions. Since 1941, our teams have conducted groundbreaking studies, created and applied innovative methods and tools, and advanced principles of scientific integrity and collaboration. Today, government, corporate, and nonprofit clients around the world partner with us to transform increasingly complex information into useful knowledge.
WHO WE ARE:
For over 75 years, NORC has evolved in many ways, moving the needle with research methods, technical applications and groundbreaking research findings. But our tradition of excellence, passion for innovation, and commitment to collegiality have remained constant components of who we are as a brand, and who each of us is as a member of the NORC team. With world-class benefits, a business casual environment, and an emphasis on continuous learning, NORC is a place where people join for the stellar research and analysis work for which we’re known, and stay for the relationships they form with their colleagues who take pride in the impact their work is making on a global scale.
EEO STATEMENT:
NORC is an affirmative action, equal opportunity employer that values and actively seeks diversity in the workforce. NORC evaluates qualified applicants without regard to race, color, religion, sex, national origin, disability, veteran status, sexual orientation, gender identity, and other legally- protected characteristics.
8.3.2020
/
Back",3.1,"NORC at the University of Chicago
3.1","Chicago, IL",1001 to 5000 Employees,1941,Nonprofit Organization,Research & Development,Business Services,$100 to $500 million (USD)
Azure Big Data Engineer,-1,"If you are an experienced Big Data Azure Engineer looking to join a fast-growing advanced analytics consulting firm than this is the job for you. This is an opportunity to work for the top fortune 500 companies long term. If you love building Data pipelines and Data Warehouses from scratch using Azure and big data, read below!

What Is The Job?

This role will be responsible for architecting, designing, and implementing advanced analytics capabilities.We are looking for Data Engineers to support the data and analytics by designing, optimizing, and developing data pipelines to support machine learning and AI models. You will be building the Data Platforms and data ingestion pipelines using Azure You will work along side with Data Scientists and Software Developers to meet client business requirements.

What Skills Do We Need?
Deep understanding of Azure (4 plus years Experience)
Experience with Python, Scala or Java
Big Data experience- Hadoop, Spark, Hive, Kafka
ML and AI experience is a plus
Experience using Snowflake is a plus
Who Are We?

We are a analytics service provider with a primary focus on AI and advanced analytics for multiple fortune 500 companies. We provide top notch consultant's to our clients in need of long term placements.

Compensation:
$140,000- $180,000
Bonus
Full medical
Full Dental
401k
Very reasonable work hours
Whats in it for you?

This is an opportunity for longer term stability. This opportunity will allow you to broaden you tech skills and give you the chance to work on multiple longer term projects for a variety of name brand companies.

We are hiring for this role as soon as possible, so if you are interested, please apply today or reach out to me directly at: Chris.Decrescenzo@Averityteam.com.",5.0,"Averity
5.0","Chicago, IL",1 to 50 Employees,2014,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable
Bioinformatics Scientist,"$55K-$89K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

We are seeking a highly motivated and capable bioinformatics scientist with extensive experience and interest in translational cancer research and genomics algorithm development. This position requires experience with scientific programming, relational data systems, algorithms development, and statistical modeling. Top candidates will also have experience deploying bioinformatics code within a clinical setting.

Duties and Responsibilities:
Design and conduct analysis to improve variant calling, classification and analysis systems.
Translate insight from model systems into predictors and classifiers of therapeutic response and prognosis in clinical cancer care.
Collaborate with scientists, and clinicians to design and perform analyses on cancer clinical sequencing data in order to improve quality of care.
Work in interdisciplinary groups of scientists, engineers, and product developers to translate research into clinically actionable insights for our clients.
Develop algorithms used to gain insight into cancer variation through analysis of next generation sequencing data
Produce high quality and detailed documentation for all projects.
Required Experience:
Must have completed a Ph.D. in Cancer Biology or Molecular Biology related to cancer.
Computational skills using R, Bioconductor, and/or Python.
Ideal candidates will possess:
Experience in cancer genetics, immunology, or molecular biology
Experience working with next-generation sequencing data
Self-driven and works well in interdisciplinary teams
Experience with communicating insights and presenting concepts to a diverse audience
Demonstrated programming ability
Background in predictive or prognostic algorithm development
Strong background in the development of statistical models
#LI-SH1",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
"Director, Data Science and Machine Learning","$67K-$135K
(Glassdoor Est.)","Hyatt Hotels Corporation is an international hotel operating company with $4.5B in annual revenue and more than 850 properties spanning more than 60 countries. We are guest obsessed and dedicated to improving clock speed and providing first class guest interactions. In order to achieve this mission, we aim to be a data fueled organization focused on improving and simplifying the experience of our guests, customers, owners and colleagues.

Role Summary

Hyatt seeks an extraordinary data science (ML/AI) leader to define our data science vision and build the algorithmic assets and features that Hyatt guests, members, customers and internal users leverage to transform the guest experience and drive efficiencies across the operations of our business.

As a Director of Data Science and Machine Learning you are the team lead responsible for delivering technical and performant solutions across our environments and services for products and applications. You will be hands on with every stage of the product development lifecycle from collecting and distilling business requirements to delivering the finished product. You will also interface directly with product and project management and collaborate closely with other engineering disciplines to convey requirements and develop integrated solutions. This role is highly visible to leaders and key business stakeholders across the organization.

The team is responsible for data science and is embedded with product teams following an agile delivery methodology. Applying the latest techniques and approaches across the domains of data science, machine learning, and AI isn’t just a nice to have, it’s a must. In this role, you will drive value by creating consistently smarter and more data driven teams.

Day-to-day, your role includes:
Manage and develop a high performing team of data scientists and ML engineering by leveraging individuals strengths and fostering opportunities for improvement
Lead our Machine Learning capabilities and product offerings for the Hospitality Industry
Unlock hidden value by connecting new and existing data assets and by creating new analytics products in close collaboration with cross-functional internal teams
Create tactical and strategic plans for all existing and upcoming AI/ML products based on prior experience and industry-specific expertise
Frame business problems into actionable data science projects, which will, in turn, create business values for guests, customers, owners and colleagues
Develop and deploy high-performance AI/ML models as a leader of the core development team, leveraging supervised, semi-supervised, unsupervised, and/or reinforcement learning.
Recruit top talent in analytics and AI/ML to develop strong teams based on the growing needs of the business
Set standards of excellence for the team by demonstrating professional expertise, strong work ethic, integrity and professional behavior
The ideal candidate demonstrates a commitment to Hyatt core values: respect, integrity, humility, empathy, creativity, and fun.
Qualifications
10+ years of hands-on experience in end-to-end
development of machine learning (ML) and artificial intelligence (AI) products
and services required
High-level leadership skills and prior
experience of managing the creation and deployment of Machine Learning
solutions
A hands-on leader who has excelled at building
teams who have strong organization skills, attention to detail, tenacity for
success, and excellent communication skills
Strong experience in predictive analytics,
machine learning, optimization, and agile product development
Experience in designing a production
environment on Cloud, creating model scoring pipelines, and deploying AI/ML
models through REST API
Knowledge and experience in SQL, NoSQL
databases, Python, Flask, R, Java, C++/C#, AWS and/or other Cloud products and
services
Education: Master’s or Ph.D. degree (top-tier
research institutions, in Math, Statistics, Hard Science, Computer Science,
Engineering or other closely related disciplines preferred)
The position responsibilities outlined above are
in no way to be construed as all encompassing. Other duties, responsibilities,
and qualifications may be required and/or assigned as necessary",4.1,"Hyatt
4.1","Chicago, IL",10000+ Employees,1957,Company - Public,"Hotels, Motels, & Resorts",Travel & Tourism,$2 to $5 billion (USD)
SR STAFF SCIENTIST,"$46K-$100K
(Glassdoor Est.)","Job Title SR STAFF SCIENTIST
Position Number 8150697
Job Category University Staff
Job Type Full-Time
FLSA Status Exempt
Campus Maywood-Health Sciences Campus
Department Name DEPARTMENT OF CANCER BIOLOGY
Location Code Dept of Cancer Biology (06311A)
Is this split and/or fully grant funded? Yes
Duties and Responsibilities

The senior scientist will conduct research on a cancer health disparity research project entitled “SELENOF is a determinant of aggressive breast cancer disease in African American women”.
The scientist will conduct in vitro/cell-based experiments and in vivo experiments using mouse models to examine the role of the seleno-protein, SELENOF, in aggressive breast cancer disease.
The senior scientist will design experiments, collect data, co-ordinate the research efforts with our collaborator, analyze and present findings, and drive new research directions stemming from this project.
Evaluates need for new technologies and train laboratory staff on proper use of equipment.
Collaborates with faculty and other researchers
Participates in the preparation and writing of grant applications and reports and co-authors scientific research manuscripts
Operates and maintains a variety of scientific instrumentation which is essential to conducting the appropriate laboratory work. This would include equipment such as laboratory microscopes, centrifuges, incubators and autoclaves.
Employs safety measures in working with hazardous chemicals, laboratory animals, and radioisotopes as applicable.
Performs proper recording of procedures related to research studies in the laboratory and for the systematic organization of experimental data including the adequate.
Performs other duties as required.
Minimum Education and/or Work Experience

Required: Doctoral Degree (MD or PhD) Molecular Biology, Biology, Biochemistry, Physiology, Pharmacology, Microbiology, Immunology, other biomedical sciences.

Minimum 2-5 years of completed mentored postdoctoral scientific training and/or 7+ years of work experience.
Qualifications

Required: Doctoral Degree (MD or PhD)
Molecular Biology, Biology, Biochemistry, Physiology, Pharmacology, Microbiology, Immunology, other biomedical sciences.

Minimum 2-5 years of completed mentored postdoctoral scientific training and/or 7+ years of work experience.
Certificates/Credentials/Licenses

MD or PhD
Computer Skills

Familiarity with the Microsoft Office suite of programs is required.
Supervisory Responsibilities No
Required operation of university owned vehicles No
Does this position require direct animal or patient contact? Yes
Physical Demands Lifting, Standing, Repetitive Motions
Working Conditions Irregular Hours
Open Date 08/26/2020
Close Date
Special Instructions to Applicants
Quick Link for Posting http://www.careers.luc.edu/postings/14205",4.1,"Loyola University Chicago
4.1","Chicago, IL",1001 to 5000 Employees,1870,College / University,Colleges & Universities,Education,$500 million to $1 billion (USD)
Snowflake Data Engineer (remote),"$62K-$114K
(Glassdoor Est.)","Summary
We exist to help people achieve financial clarity. At Thrivent, we believe money is a tool, not a goal. Driven by a higher purpose at our core, we are committed to providing financial advice, investments, insurance, banking and generosity programs to help people make the most of all they’ve been given.

At our heart, we are a membership-owned fraternal organization, as well as a holistic financial services organization, dedicated to serving the unique needs of our clients. We focus on their goals and priorities, guiding them toward financial choices that will help them live the life they want today—and tomorrow.

Join our newly created Data Office as a Cloud Data Engineer! We have two positions open for mid and senior level within the data warehouse implementation team. We are in the early stages of a Snowflake cloud data warehouse implementation. You will be responsible for general ETL development and implementing new solutions. You will have the opportunity to help Thrivent modernize our hybrid technology solutions including the opportunity to work on modern warehousing and integration technologies. This role will require in depth understanding of cloud data integration tools and cloud data warehousing (Snowflake experience is critical), the ability to lead and execute to help drive and see tangible result.
Job Description


Job Duties and Responsibilities
Lead the implementation, execution, and maintenance of Data Integration technology solutions
Lead work to advance and support information management practices within business processes, applications and technology that underpin the EIM discipline (e.g. establishing data quality processes, performing data analysis, participating in technology implementation planning and verification to ensure successful installation of software and/or projects, implementing data integration processes, administering content, etc.).
Provide leadership for Data Integration tasks supporting projects
Lead the Management and proactive improvement of Thrivent's data by analyzing the current systems environment, leveraging proven practices, applications, technology, tools and platforms to support and enhance the information landscape.
Revenue generated
Budget responsibilities
Leads the delivery, support and maintenance of solutions with one or more business and technology areas.
Organizational impact results from mid-large sized projects
Required Job Qualifications
Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field
5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years prior lead experience.
Advanced in-depth knowledge of data integration concepts and tools
Strong organizational, analytical, critical thinking and leadership skills
Demonstrated leadership on mid-large-scale project impacting strategic partners
Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color, sex, gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state, or federal law. This policy applies to all employees and job applicants.

Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation, please let us know by sending an email to human.resources@thrivent.com or call 800-847-4836 and request Human Resources.",3.5,"Thrivent
3.5","Chicago, IL",5001 to 10000 Employees,1902,Nonprofit Organization,Insurance Carriers,Insurance,$5 to $10 billion (USD)
Data Engineer,-1,"Are you interested in building the future of healthcare and transforming the patient experience? Are you hopeful about what data and medical research can do to improve medicine? We’re looking for a Data Engineer to ensure PatientIQ remains on the forefront of using data to drive positive healthcare outcomes.

As a core member of the Analytics department, you will be in a very dynamic environment that works cross-functionally with all other departments, such Engineering, Sales, and Product. You will work on a broad array of problems that rely heavily on solid data engineering principles being in place: business intelligence, data science, and software engineering. We heavily value diligence, curiosity, and initiative, as those are key to unlocking the value of PatientIQ's data for our users and our decision-making. Your work will be impactful across the entire organization.

Role Responsibilities
Develop and maintain ETL infrastructure to support the ingestion of external data sources
Migrate client data into PatientIQ's platform per established service level agreements (SLA)
Define and implement key metrics for PatientIQ's data warehouse
Perform data quality assurance checks
Help scale PatientIQ's data strategy as the platform and business grows
Requirements

Ideal Qualifications
BS/MS in Computer Science, Engineering, Mathematics, or related field
Deep knowledge of SQL and at least one database technology
Proficient in Python
Experience with version control systems (e.g. git) and writing reusable and extensible code
Highly self-motivated with strong analytical problem-solving skills and attention to detail
Nice to Haves
Experience with workflow management systems such as luigi or airflow
Experience designing, building, and maintaining ETL infrastructure in a production setting
Experience in machine learning and/or business intelligence
Experience with ETL tools like Apache Kafka, Logstash, Segment, Informatica
Experience with cloud technologies such as AWS, Google Cloud Platform, or Azure
Experience working in Healthcare, Finance or another regulated industry
Benefits
Great Benefits - top-notch health, dental and vision insurance. Additional perks available including 401K.
We are Mission Driven - our team is motivated to solve complex problems, drive medicine forward, and ultimately improve patient outcomes.
True Idea Meritocracy - great ideas win out. We encourage all team members to challenge the status quo because our mission demands this.
Flexible Time Off - we trust you to take the time you need when you feel it is appropriate, given your workload and responsibilities. No need to track it or save up.
World-Class Team - we’re at the top of our industry because of our employees. They’re the best investment we can make, and we never forget that.
Fast Growing - we are building the largest platform for healthcare providers, industry partners, researchers, and others to collaborate on the mission to improve patient outcomes.",-1,PatientIQ,"Chicago, IL",-1,-1,-1,-1,-1,-1
People Analytics Data Engineer (Talent Insights Consultant Lead) - PS,"$86K-$144K
(Glassdoor Est.)","Your Talent. Our Vision. At Anthem, Inc., it’s a powerful combination, and the foundation upon which we’re creating greater access to care for our members, greater value for our customers, and greater health for our communities. Join us and together we will drive the future of health care.

This is an exceptional opportunity to do innovative work that means more to you and those we serve at one of America's leading health benefits companies and a Fortune Top 50 Company.

Do you love data? Do you enjoy the challenge of wrangling data and figuring out innovative data solutions to automate, combine, transform and model data? Then we’d love to talk to you about applying your skills to solve data challenges in on the Talent Insights team. This role is crucial to leveraging data (Inclusion & Diversity, Culture & Engagement, Productivity, Recognition, Performance, Talent, Attraction, Learning and Surveys) to develop strategy to attract, develop and retain Anthem’s workforce of the future.
People Analytics Data Engineer (Talent Insights Consultant Lead)

The preferred locations for this position are

Indianapolis, IN, Chicago, IL and Mason, OH

and is eligible for a remote schedule.
We are looking for a savvy Data Engineer to join our team of people analytics experts. The Data Engineer will be responsible for expanding our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing the HR data architecture to support critical people strategies that impact our associates and HR policies.

Responsibilities for People Analytics Data Engineer
Create and maintain optimal HR data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the HR data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using API, SQL and AWS technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with IT and HR stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Ensure associate and HR data is protected and secure.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Proven
ability to find innovative solutions to “figure things out.”
BA/BS
in computer science, business, math, industrial management/engineering or
related field.
Master’s
degree in related field preferred
10+
years of data collection and analysis experience; or any combination of
education and experience which would provide an equivalent background.
Advanced
knowledge of data tools including or similar to: SQL, Python, R, AWS, EC2, Redshift,
Alteryx, REST API, Java
Ability
to design and develop complex mappings, session, workflows, and identify areas
of optimizations.
A
successful history of manipulating, processing and extracting value from large
disconnected datasets.
Strong
analytic skills related to working with unstructured datasets.
Build
processes supporting data transformation, data structures, metadata, dependency
and workload management.
Strong
verbal/written communication, with ability to interact effectively with
individuals at all levels of responsibility and authority.
Strong
trouble-shooting and organizational skills and ability to work on multiple
projects simultaneously.
Strong
project management and organizational skills.
Experience
supporting and working with cross-functional teams in a dynamic environment.
Preferred
knowledge of HR processes and related data.
Preferred
knowledge of Peoplesoft, Oracle Analytics Cloud, Workday, Prism or similar HR
systems, business intelligence and analytics tools.
Anthem,
Inc. is ranked as one of America’s Most Admired Companies among health insurers
by Fortune magazine and is a 2018 Diversity Inc magazine Top 50 Company for
Diversity. To learn more about our company and apply, please visit us at
antheminc.com/careers. An Equal Opportunity Employer/Disability/Veteran",3.4,"Anthem
3.4","Chicago, IL",10000+ Employees,2004,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD)
Senior Data Engineer,"$77K-$147K
(Glassdoor Est.)","The Team: Morningstar’s mission is to create great products that help investors achieve their financial goals. For the Workplace group, that means building products and solutions that help employers maximize the value of their workplace retirement plans and put individuals on the path to better retirement outcomes. Workplace is a high-growth area for Morningstar that houses a diverse suite of technology and investment-based solutions. Our unique client base includes retirement plan providers, plan sponsors, plan consultants, and retirement plan advisors. By constantly evolving our solutions and solving our clients’ problems, we are well-positioned to help individuals achieve a better retirement. The workplace technology team is critical to achieving this mission and bringing it to life.

Responsibilities:
Develop efficient, high throughput data pipelines to push transactional data to the cloud
Build computation frameworks to get analytical insights from cloud-based data stores
Optimize storage to best serve business use cases
Define and implement the data life cycle per compliance requirements
Work with product managers and data scientists to understand the objectives of the data platform
Play an active role in data governance in collaboration with other Database Administrators and Applications/ Business teams
Design and develop for quick deployment with assistance from the Devops team
Requirements:
Bachelor’s degree in MIS, Computer Science, or a related field
Hands on ETL experience on Apache Spark or AWS Glue
Hands on experience with an AWS database, preferably Athena or RedShift
Experience using Python for data science
Strong knowledge of database design principles
Strong knowledge of serverless big data offerings on AWS
Very good understanding of CI/CD pipelines and infrastructure as code
Knowledge/experience adding quality checks to data pipelines
7+ years of experience in design, development, and maintenance of cloud-based data systems
3+ years of experience on Microsoft SQL server
Good communication skills
Ability to work independently, communicate effectively, and produce superior results
Experience working in Scrum-based methodologies Ability to write clean code and provide insights in code reviews
002_MIMLLC Morningstar Investment Management LLC Legal Entity",4.1,"Morningstar
4.1","Chicago, IL",5001 to 10000 Employees,1984,Company - Public,Financial Analytics & Research,Finance,$1 to $2 billion (USD)
Data Engineer,"$48K-$94K
(Glassdoor Est.)","Job Description
Health Data & Management Solutions, Inc. (HDMS), a subsidiary of CVS/ Aetna, is a software development company on the cutting edge of health IT data solutions. Offering data warehouse, management and analysis tools for the healthcare industry, HDMS strives to improve and enhance its product suite for health plans, employers and providers through constant innovation. HDMS' web-based products and services provide flexible, high-value reporting tools that empower users to maximize the value of their health care data and support benefit decisions.

The Data Engineer supports the HDMS client use of ART, DART and Enlight data reporting applications by managing internal and external client issues toward resolution. Involve in monthly data load activities.
And tableau reporting

Participates and collaborates with subject matter experts and works with cross-functional teams to address problems using various technologies available within HDMS.

#LI-TS1

Fundamental Components
Responsible for refreshing the database on a monthly basis
Responsible for meeting 100% database refresh SLA
Maintaining the reporting environment using Tableau
Responsible for handling Support tickets with respect to Data Enquiry and for any Issue reporting
Responsible for working with current support resources to setup JIRA workflows for DART, Enlight & ART
Partner with lead and other teams to develop process and on-boarding documentation for Operations Support team using Confluence
Responsible for handling deployment activities
Help create and maintain communication/documentation repository for the JIRA application (confluence), where users can access generally available information about access, contents, and documentation
Perform data analysis support and work collaborate with current Ops support team
Communicate with end users and business stakeholders to take support incidents to closure, maintain SLAs, status reporting
Exposure to Tableau reporting tool to gain insight into the operations
Background Experience
Required
3+ years of experience with Relational Database Management Systems- RDBMS (ex. SQL, Oracle databases, etc.), data systems and data warehouses
3+ years of experience with Tableau development
3+ years of experience with bash shell scripts, Informatica, JIRA, Mongo DB, MySQL, Python, HIVE and/or Hadoop
Preferred:
Healthcare experience
Experience with the Software Development and Product Development Lifecycles
Experience with the software support ticketing systems and processes
Experience communicating statistical and technical ideas and results to non-technical clients
Experience with perform ETL data load job execution and monitoring in Spark/Scala
Experience in Exasol and AppDynamics is good to have
Experience using complex systems and solve challenging analytical
Strong reporting and experience using Excel, Access, Word and/or PowerPoint
Education
Bachelor's degree or equivalent experience

Percent of Travel Required
0 - 10%

Business Overview
Aetna, a CVS Health company, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We are committed to maintaining a diverse and inclusive workplace. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, gender, gender identity, age, disability or protected veteran status. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.",2.9,"CVS Health
2.9","Chicago, IL",10000+ Employees,1963,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
"AI/ML , Data Engineer",-1,"Job Title: AI/ML , Data Engineer

Location: Chicago, IL

Duration: 12 months

Job Description:

Mandatory Skills:

Knowledge and experience in API development, AI/ML, SageMaker, Data Lake, Data Analytics, Cloud Monitoring and Analytics,

Strong cloud programming skill with experience in API and AWS Lambda functions or any other scripting languages like Python / Bash using Python & Node.js

Good understanding in using AWS CLI, Cloud formation, Terraform, Ansible with troubleshooting experiences

Strong knowledge of Cloud Security practices and IAM Policy preparation for AWS

Good to have:

Knowledge on Experience with implementing containers using AWS container services cloud native container orchestrators in AWS

Strong working experience with AWS services as EC2, RDS, API Gateway, Lambda, DynamoDB, Elastic Cache, ECS, ALB/NLB Load Balancers, S3, EBS, VPC Networking , Secret Manager, Parameter Store âetc.

Ability to participate in fast-paced DevOps and System Engineering teams within Scrum agile processes

Experience with DevOps tools will be an added advantage

Know-how of working with Python / Bash scripting will help",-1,softsnippets,"Chicago, IL",-1,-1,-1,-1,-1,-1
Environmental Scientist or Engineer/Project Manager (Mid Level),"$38K-$59K
(Glassdoor Est.)","Are you ready to take the next step in your career? Do you want to do meaningful work that improves quality of life? At Tetra Tech, you will work with high-performing teams who are passionate about using their expertise to find solutions to complex problems in water, environment, infrastructure, resource management, energy, and international development. Tetra Tech is a leading provider of high-end consulting and engineering services for projects worldwide. We combine the resources of a global, multibillion dollar company with local, client-focused delivery in more than 400 locations around the world. We are Leading with Science® to provide sustainable and resilient solutions for our clients.

Tetra Tech is seeking a Mid-Level Environmental Scientist or Engineer/Project Manager for our Chicago, IL office. This is a full-time position for an individual with a strong technical background in environmental site investigation and remediation who is interested in career growth and business development opportunities while managing and supporting a variety of public and private sector environmental projects.
Qualified candidates evaluated will have about 5-10 years of environmental consulting or related experience. Knowledge of federal, state, and local regulations and previous experience with hazardous waste site investigations and remediation is required. Previous private or public sector client management and business development success and project management experience is desirable. Applicable experience, training, and certifications with asbestos, lead-based paint, air quality, low-level radioactive waste, GIS, hydraulic and hydrologic modeling, or emergency response (e.g., ICS) is preferred. Candidate must possess strong analytical, organizational, client management, and communication skills (both written and verbal). Must also be highly motivated, customer focused and work well in a team environment. Proficiency with MS Word and Excel also required. Hydraulic and hydrologic modeling, GIS data analysis and geostatistics, coding (VBA, Python, etc.), and data management skills preferred. Must be able to drive a vehicle, and pass a motor vehicle records check.

B.S. or M.S. degree in engineering, science, or related environmental field required. 40-hr HAZWOPER training certification with 8-hr refresher required. Heavy lifting of field sampling and other equipment will be required. Candidate must also meet physical demands of hazardous waste site work. Travel is required and varies based on project requirements; may include weekend travel and work. Candidate may be exposed to various weather conditions while performing field work outside.

At Tetra Tech, we provide a collaborative environment that supports individual performance, innovation, and creativity. We are proud to offer competitive compensation and benefits. Learn more by visiting http://www.tetratech.com/en/benefits. For more information on our company, please visit our website at www.tetratech.com. To apply, please submit your resume and cover letter on the Careers portion of our website at www.tetratech.com/careers.

We thank all applicants for their interest; however only those selected for an interview will be contacted. Tetra Tech is committed to creating a diverse environment and is proud to be an Equal Opportunity Employer. We invite resumes from all interested parties including women, minorities, veterans and persons with disabilities.

Tetra Tech is a VEVRAA federal contractor and we request priority referral of veterans for available positions. EOE AA M/F/Vet/Disability - No calls or agencies

Additional Information



Organization: 103 EMI",3.6,"Tetra Tech
3.6","Chicago, IL",10000+ Employees,1966,Company - Public,Architectural & Engineering Services,Business Services,$2 to $5 billion (USD)
Director of Data Science,-1,"Role: Director of Data Science

Reporting to: COO

About Us:

We deliver the most advanced and flexible learning experience for certification, credentialing, test prep, continuing education, and training. Our cloud-based learning platform is designed to help education and training organizations deliver a highly engaging and effective learning experience for users who are trying to advance their careers. We incorporate the latest in learner-centered technology, including personalization, gamification, data science, usability and omni-channel delivery.

We're sitting in a pivotal time in the BenchPrep history, having achieved significant growth year-over-year and nearly doubling in employee size! The number of learners on our cloud-based learning platform has reached 6 million in 2019, up 30 percent versus the prior year.

We're committed to helping students learn better, and that starts in our own office.

About the role:

We are looking for a dynamic and talented Director of Data Science to build a new function here at BenchPrep, leading all of our Data Science and R&D efforts, creating a strategy to discover new insights hidden in the vast amounts of data we collect. You will work across the company with our product team, engineers, and strategy team; working toward a common goal of solving problems and finding creative solutions through data-driven decisions.

As our Director of Data Science, you will:
Oversee all of BenchPrep's data research and analytics efforts, including data strategy, data governance, and outcome modeling.
Build a brand new data science team from scratch, with the responsibility of identifying and developing talent on your team
Lead the discovery process with customers to begin identifying and solving business problems
Identify opportunities within the organization to increase efficiency and quality of our product using data-driven solutions, applying sound business judgement to quantify the impact of potential solutions
Conceptualize and plan leading-edge analytic and quantitative tools and modeling techniques to support our clients, helping them gain insight and improve decision-making
Drive customer impact by building out, operationalizing and managing scalable data science projects
Review internal and external analytical techniques, identifying what data is available and relevant and source the necessary data
Partner with our Product Management and Technology team to integrate prototypes and solutions into production systems
You should have:
Masters in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)
6+ years of experience working in data science
3+ years of experience managing, Data Scientists
Universal data outcome modeling experience and usage of python, R, spark and corresponding packages
Proven data literacy the ability to describe use cases and outcomes, data sources and management concepts across business and technology domains
Deep experience in integrating complex processes and information strategies, including technology planning and execution and policy development and maintenance
Life at BenchPrep:

We work at BenchPrep because we're dedicated to the mission and each day have an opportunity to be challenged and learn. We work hard, eat well, and have lots of fun. Culture is our lifeline at BenchPrep. We celebrate our people, both professionally and personally. We focus on flexibility - both in work/life balance, but also everyday in operating with agility. We care about professional development so much that we offer employees $1,200 annually to build their skills. And of course, even though we're currently remote, our inclusive work culture has been built to withstand challenges, as we stay connected and ensure all of our employees have the resources and tools they need to stay successful in this new environment. It's no wonder we were selected in Inc's Best Workplaces of 2020 and Crain's 2020 Best Places to Work in Chicago lists.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We are looking for high performing and motivated professionals who are excited about the chance to leverage technology to impact the lives of millions of learners.",4.5,"BenchPrep
4.5","Chicago, IL",51 to 200 Employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable
Bi Data Engineer,-1,"COMPANY OVERVIEW


Recently named one of Entrepreneur magazine's Top 100 Cannabis Leaders, Cresco Labs is one of the largest vertically-integrated multi-state cannabis operators in the United States. Cresco is built to become the most important company in the cannabis industry by combining the most strategic geographic footprint with one of the leading distribution platforms in North America. Employing a consumer-packaged goods (""CPG"") approach to cannabis, Cresco's house of brands is designed to meet the needs of all consumer segments and includes some of the most recognized and trusted national brands including Cresco, Remedi and Mindy's, a line of edibles created by James Beard Award-winning chef Mindy Segal. Sunnyside*, Cresco's national dispensary brand is a wellness-focused retailer designed to build trust, education and convenience for both existing and new cannabis consumers. Recognizing that the cannabis industry is poised to become one of the leading job creators in the country, Cresco has launched the industry's first national comprehensive Social Equity and Educational Development (SEED) initiative designed to ensure that all members of society have the skills, knowledge and opportunity to work in and own businesses in the cannabis industry.

MISSION STATEMENT


At Cresco, we aim to lead the nation's cannabis industry with a focus on regulatory compliance, product consistency, and customer satisfaction. Our operations bring legitimacy to the cannabis industry by acting with the highest level of integrity, strictly adhering to regulations, and promoting the clinical efficacy of cannabis. As Cresco grows, we will operate with the same level of professionalism and precision in each new market we move in to.

JOB SUMMARY

Cresco Labs is looking for a BI Data Engineer to join our corporate team. This individual will focus on designing and building data infrastructure, data visualization, and analytics services. The BI Data Engineer will develop data pipelines, manage tables and data sets, and other objects to house the data.

CORE JOB DUTIES
Design and build dynamic dashboards to support our unique requirements for visualization, security, data access, etc.
Collect, manage analyze and visualize large data sets while maintaining ETL pipelines
Implement data parsing and data cleansing to improve overall data quality and productivity
Collaborate with business stakeholders and other BI Engineers in identifying opportunities to build and analyze metrics
Manage progress, goals, and insights with business leadership
Stay up to data on data science trends and developments
Support the VP of Software Engineering through data analysis and reporting
Automate and document processes to ensure efficiency
REQUIRED EXPERIENCE, EDUCATION AND SKILLS
4+ years in a strong analytical background with a bachelor's degree in computer science or a similar field
Practical experience buildings out and implementing dashboards with Tableau or other business intelligence and analytics software
Expert knowledge in database technologies and web technologies
Excellent written and verbal communication skills
High level organization and structure
ADDITIONAL REQUIREMENTS
Must be 21 years of age or older to apply
Must comply with all legal or company regulations for working in the industry
Cresco Labs is an Equal Opportunity Employer and all applicants will be considered without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran, or disability status.",2.0,"Cresco Labs
2.0","Chicago, IL",501 to 1000 Employees,2013,Company - Public,"Health, Beauty, & Fitness",Consumer Services,Less than $1 million (USD)
DATA ENGINEER,"$69K-$122K
(Glassdoor Est.)","Job Overview

We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities for Data Engineer:

- Create and maintain optimal data pipeline architecture,

- Assemble large, complex data sets that meet functional / non-functional business requirements.

- Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.

- Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.

- Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.

- Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.

- Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.

- Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.

- Work with data and analytics experts to strive for greater functionality in our data systems.

Qualifications for Data Engineer:

- Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.

- Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.

- Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.

- Strong analytic skills related to working with unstructured datasets.

- Build processes supporting data transformation, data structures, metadata, dependency and workload management.

- A successful history of manipulating, processing and extracting value from large disconnected datasets.

- Working knowledge of message queuing, stream processing and highly scalable ‘big data’ data stores.

- Strong project management and organizational skills.

- Experience supporting and working with cross-functional teams in a dynamic environment.

Knowledge, Skills, Abilities, and other Characteristics:

Qualifications:
5+ years of experience in a Data Engineer role, who has attained a Master’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Industry-recognized certifications in data engineering, data architecture, informatics, machine learning, SQL
Experience with health care data, claim data, EMR systems (Meditech preferred), X.12 data formats, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with Microsoft and AWS cloud services: Azure, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience with statistical programming languages: R, Stata, SAS, etc.
Experience with architectural concepts and schemas: TOGAF, MITA, Star schema, etc.
Skilled in problem-solving with strong attention to detail.
Excellent customer service skills and the ability to react diplomatically and patiently to internal and external customers.
Excellent follow-up skills paired with the ability to multi-task and determine root causes.
Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures.
Strong response time to phone calls, emails and customer requests.
Adhere to department policies and standards.
Ability to work independently under minimal supervision in stressful situations and meet deadlines.
Ability to prioritize, plan, and organize tasks based upon user requirements.
Ability to multi-manage multiple projects utilizing best practices based on departmental priorities.
Ability to multi-manage multiple projects utilizing best practices based on departmental priorities.
MINIMUM WORK EXPERIENCE:

Bachelors Degree, 5 years of relevant experience including leading projects or 8 years of relevant experience including leading projects and developing teams .

REQUIRED LICENSES, CERTIFICATES, REGISTRATIONS:

MCSE or equivalent is strongly desired but not required",3.1,"Sinai Health System
3.1","Chicago, IL",1001 to 5000 Employees,1918,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD)
Translational Bioinformatics Scientist,"$59K-$80K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

We are seeking an independent and motivated Translational Bioinformatics Scientist to join our Research group.

What You'll Do:

You will work on an interdisciplinary team to develop new computational and statistical approaches to support precision medicine applications. The successful candidate will work in an interdisciplinary team, carry out data analysis, apply and develop best-in class algorithms that directly address important biological and clinical questions, and provide strategy and input on new products and services.

Qualifications:
Advanced degree (Masters or PhD) in bioinformatics, statistics, biostatistics, epidemiology, oncology, genomics, human genetics, computer science, mathematics or a related field, or 5+ years experience working with genomic and clinical data
Experience working with electronic health information and related software systems
Experience in genetic analysis of complex disease and familiarity with common bioinformatics software and file formats
Experience with statistical modeling, data mining and/or machine learning
Experience with Python, R, or other modern programming language
Excellent communications skills
A collaborative mindset
Nice-to-haves:
Experience with polygenic risk scores and population genetics
Experience with clinical risk modeling and implementation
Experience with version control (Git) and collaborative software development and testing
Experience with AWS technical stack (EC2, S3, Redshift, etc.)
Experience with Real World Evidence (RWE) and Real World Data (RWD) topics and techniques
Experience with relational databases
Record of meaningful scientific publications",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Research Data Engineer,"$71K-$96K
(Glassdoor Est.)","Title: Research Data Engineer

Location: Chicago, NYC, London

Company Overview:

Our client is a leading global market maker across a broad array of fixed income and equity securities. Their world-class capabilities position them to meet the liquidity demands of their diverse group of institutional clients in all market conditions. In partnering, their clients, including asset managers, banks, broker-dealers, hedge funds, government agencies and public pension programs are able to gain a powerful trading advantage and are better positioned to meet investment goals.

Our client stands among the most trusted and impactful financial firms of our time, and the best and brightest are drawn to this culture of meritocracy that prizes insightful research and analytical rigor.

The team makes its mark every day from offices around the world.

Data Engineers are tasked with building next generation data analysis platforms. Our data analysis methods evolve on a daily basis and we empower our engineers to make bold decisions that support critical functions across the business.

Key Responsibilities:
Design, develop, test, and deploy elegant software solutions across the firm to support critical investment decisions
Partner with business leaders, quantitative researchers and technologists to define priorities and deliver custom solutions
Skillset Requirements:
A deep passion for working with data and developing software to address data processing challenges
Minimum of a bachelor’s degree in Computer Science or equivalent experience with good software design and engineering skills
Proficiency within one or more programming languages including Python, C, C++, R and/or JavaScript is a plus
Proficiency with multiple data platforms including RDBMS, NoSQL, MongoDB, Spark, Hadoop
Experience with some of the following areas: Distributed Computing, Natural Language Processing, Machine Learning, Cloud Platform Development, Networking, and/or REST Service Development
Good analytical and quantitative abilities
Demonstrated ability to quickly learn new technologies and skills
Ability to manage multiple tasks and thrive in a fast-paced team environment",-1,Galaxy Technology Hires LLC,"Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Data Engineer,-1,"Immediate remote opportunities for Senior Data Engineers to leverage your expertise delivering large-scale Azure data systems to upskill in the Adobe Experience Platform.

As a Senior Data Engineer, you will be part of a data transformation program to support a well known retail organization responsible for the following:

Leading, designing, developing, and delivering large-scale Azure data systems, data processing, and data transformation projects.

Executing technical feasibility assessments and project estimates for moving databases and data processing to Azure.

Designing and advocating solutions using modern cloud technologies, design principles, integration points, and automation methods.

Mentoring and sharing knowledge with customers as well as providing architecture reviews, discussions, and prototypes.

Participating in overall engagement from strategy, assessment, migration, and implementations.

Working with customers to deploy, manage, and audit best practices for cloud products.

Expertise we need you to bring:

Demonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements.

Experience with Databricks and using Spark for data processing.

Experience with Azure Data Factory – ADF.

Advanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL).

Experience designing and building data marts, warehouses, customer profile databases, etc.

Experience with data modeling, table design, and mapping business needs to data structures.

Experience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus.

Experience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.

Experience with other cloud-based big data architectures is a plus.

Experience guidelines:

5 to 10 years of professional experience in the information technology industry.

BS in Computer Science or equivalent education/professional experience is required.

Strong and innovative approach to problem solving and finding solutions.

Excellent communicator (written and verbal, formal, and informal).

Flexible and proactive/self-motivated working style with strong personal ownership.

Ability to multi-task and prioritize under pressure.

Ability to work independently with minimal supervision as well as in a team environment.",-1,The Talent Source Inc,"Chicago, IL",1 to 50 Employees,-1,Unknown,-1,-1,Less than $1 million (USD)
Senior Data Scientist,-1,"Senior Data Scientist Job Title: Senior Data Scientist Job Location: Buffalo Grove, IL or Downtown Chicago, IL (NO OUT OF STATE CANDIDATES WILL BE CONSIDERED) Job Duration: Full-time, Direct Hire Requirements: Python, SQL, R, e-commerce knowledge, Data Science methodologies, Problem solving with Data Science Currently fully-remote due to COVID, On-premise work to resume when back to ""normal"" We are an e-commerce company specializing in business supplies and equipment. While other companies around the US are slowing down and hurting, we are proud to say that we are growing! And as such, we need more people to help us grow even more. We are looking for a Senior Data Scientist to join our team and help us take our data usage to the next level. If you have the skills we need, apply now! What You Will Be Doing - Lead data science projections from idea to completion (develop the idea, create a plan, layout the methodology, collaborate with other departments, execute the plan, and provide recommendations based on results) - Work closely with other data science team members to build algorithms, codes, evaluate research, deliver new outputs - Build predictive statistical models to support business initiatives - Document data science processes and codes, and develop strategies to ensure they are safe and secure - Use presentations and data visualizations to communicate results and findings to various levels of the company's leadership What You Need for this Position Must have skills/background: - 5+ years in data mining, database marketing, marketing analytics, or statistical modeling - Experience using analytics or data science at an E-commerce or internet retailer - Deep understanding of problem solving with Data Science methodologies - Experience taking complex problems and breaking them down into actionable tasks (idea to completion) - 5+ years of programming in Python - 3+ years experience in SQL Bonus skills: - 3+ years programming in R - Deploying models in the cloud (Google Cloud Platform, AWS) - Online marketing models, Google Analytics - Strong business acumen and understanding of how departments interact - Experience with BI visualization tools like Looker or Tableau - Experience in Machine Learning or Natural Language Processing What's In It for You - Strong starting salary ($110-130k) - Healthy year-end bonus - Top tier health benefits - Generous PTO - 401k safe harbor - Work from home opportunities So, if you are a Senior Data Scientist with the required experience, apply today! - Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",4.2,"CyberCoders
4.2","Chicago, IL",201 to 500 Employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Data Science Manager,"$110K-$176K
(Glassdoor Est.)","About the Job:
The Kenshoo Data Science team is hiring!
The role of the Data Science team is to empower customers to leverage Kenshoo's suite of algorithmic products such as bid optimizers and to identify/validate new directions for these algorithmic products.
The ideal candidate has mentored data scientists and has a strong grasp of statistical models, excellent analytical skills and the ability to coherently describe complex mathematical concepts to a layman audience. This role will report to the Senior Director of Data Science.
Responsibilities:
Develop and mentor a team of data scientists who use a variety of statistical and machine learning tools to effectively address client needs and foster a culture of constructive engagement across the company.
Represent Kenshoo Data Science in conversations with clients and partners. Advocate for our algorithmic solutions, data driven approaches and view of digital marketing; and provide consultation how to best set up and leverage these products.
Be part of our broader Product team to provide both client feedback and analysis to help guide data driven decisions to improve our products.
Build and guide the building of POCs ( proofs of concept ) to solve for clients needs using machine learning tools.
Perform analysis of customer/publisher data using ML and statistical methods.

Skills/Attributes Required:
Good working knowledge of statistical modeling.
Strong analytical and problem solving capabilities.
Strong SQL capabilities - experience querying data from relational DB engines.
Extensive knowledge of Python and its various packages.
Strong written and verbal communication skills - be able to take complex math and analytical concepts and explain to working teams and client executives.
Strong teamwork - internally with our teams as well as with clients.
Knowledge in machine learning algorithms such as linear/logistic-regression, Neural-Networks and others would be a strong plus.
Education/Experience:
BS/BA, ideally in a relevant field to data science.
5+ years in consulting/analytical roles.
2+ years in leading/supporting analytical teams.
MS/PhD in Machine Learning, Data Science, Statistics, Information Systems, Business Intelligence a plus but not required.
Having worked in internet marketing analytics at a top advertiser a plus.
Equal Employment Opportunity:
Kenshoo, Inc. is an equal opportunity employer. We strongly encourage and seek applications from women, people of color, and bilingual and bicultural individuals, as well as members of the lesbian, gay, bisexual, and transgender communities. Applicants shall not be discriminated against because of race, religion, sex, national origin, ethnicity, age, disability, political affiliation, sexual orientation, gender identity, color, marital status, or medical condition including acquired immune deficiency syndrome (AIDS) and AIDS-related conditions. Also pursuant to the San Francisco Fair Chance Ordinance, we encourage and will consider for employment qualified applicants with arrest and conviction records.
Kenshoo, Inc is an E-Verify employer.
Applicants with Disabilities:
Reasonable accommodation will be made so that qualified disabled applicants may participate in the application process. Please advise in writing of special needs at the time of application.


Region:
USA",3.8,"Kenshoo
3.8","Chicago, IL",501 to 1000 Employees,2006,Company - Private,Internet,Information Technology,Unknown / Non-Applicable
"Software/Data Engineer (Python, Static Data, OOP)",-1,"Software/Data Engineer (Python, Static Data, OOP)

Location: Chicago, Illinois, United States

Salary: competitive

Sectors: Finance and Operations

Job Type: Permanent

Apply for this Job
This top growing financial firm in Chicago is looking for Software/Data Engineer to join their growing team and who will work with cutting edge tech! This team is responsible for the collecting and transformation of the data for analytics.

Responsibilities include:
A Python and SQL technologies expert
Building out data pipelines
Designing and developing programs and systems daily
Able to work efficiently and collaborate with systems operations
Conduct research and provide technology solutions
Plans and executes unit tests to ensure the developed code is free of functional defects
Skills needed:
At least 3+ or more years of related experience
Excellent organization and communication skills
Extensive skills in building out data pipelines
A degree in a Computer Science/Computer Engineering related field
At least two years of Capital Markets experience is preferred
What's in it for you?!
Competitive Compensation base + Cash Bonus 10-15%
Take ownership of project and initiatives right away
Ability to collaborate with leadership and make an impact immediately
If you are interested in this Senior Software Engineer role for a top firm in Chicago, IL, please respond to me directly, and feel free to share with your network!

Sthree US is acting as an Employment Agency in relation to this vacancy.

Apply for this Job",3.1,"Huxley
3.1","Chicago, IL",201 to 500 Employees,1995,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Computational Scientist-Text Analysis,"$32K-$60K
(Glassdoor Est.)","Please make sure to read the job posting in its entirety as it reflects both the University roles and responsibilities, followed by the specific description.
Department
86755 Research Computing Center
About the Unit
The University of Chicago Research Computing Center (RCC), a unit in the Office of Research and National Laboratories (RNL), provides high-end research computing resources to researchers at the University of Chicago. It is dedicated to enabling research by providing access to centrally managed High Performance Computing (HPC), storage, and visualization resources. These resources include hardware, software, high-level scientific and technical user support, and the education and training required to help researchers make full use of modern HPC technology and local and national supercomputing resources. The Office of Research and National Laboratories oversees the conduct of sponsored research, research program development, multi-institutional research institutes, national laboratory board, and contract management functions. RNL supports the development and coordination of research-related communications and educational programs at The University of Chicago. RNL oversees the management of two Department of Energy contracts for Argonne National Laboratory and Fermi National Accelerator Laboratory. When combined with the Lab R&D budgets, the office oversees approximately $1.4 billion in sponsored research. RNL works closely with individual scholars, departments, and divisions to encourage, seed, and coalesce research across the University, Argonne, and Fermilab campuses.
Job Family
ResearchResponsible for all aspects of research projects and research facilities. Plans and conducts clinical and non-clinical research; facilitates and monitors daily activities of clinical trials or research projects. Directs engineering and technical support activities to develop and maintain tools and computational methods needed to gather and analyze data.
Career Track and Job Level
Research ComputingCreates research focused user interfaces web front-ends, back-end services that scale, and integrate scientific workflows that automate and accelerate the scientific output of multi-institutional collaborative projects. This role involves software development in support of research projects involving data acquisition, ingestion, and integration from heterogeneous sources (metadata extraction from a corpus of diverse data sets, both structured and unstructured data).P2: Requires knowledge and experience in own discipline; still acquiring higher-level knowledge and skills. Builds knowledge of the organization, processes and customers. Solves a range of straightforward problems. Analyzes possible solutions using standard procedures. Receives a moderate level of guidance and direction.
Role Impact
Individual Contributor
Responsibilities
The job develops software to support the data acquisition, ingestion, and integration for research projects. Assists in the development of user interfaces and scalable back-end services to automate and accelerate the scientific output of multi-institutional research projects.1) Participates in the product development life cycle, providing professional assistance to the design of front-end applications and database systems back-end schema. Analyzes high-level system specifications and makes sure that all application development standards are met., 2) Develops and presents technical training materials and web-based documentation. Ensures timely systems support and updates. Assists in conducting information security assessments and risk analysis of computing environment., 3) Evaluates past and present technologies to help develop new tools. Ensures all the new tools have been through quality control reviews., 4) With a moderate level of guidance, provides hardware, user and application level authentication and authorization. Implements modern web authentication methods such as XACML, SAML, OAuth2, Shibboleth, and LDAP directory server administration. Applies theoretical expertise and innovation to create or apply new technology, such as adapting principles for applying computers to new uses., 5) Performs other related work as needed.

Job Summary

1) The Research Computing Center (RCC) is partnering with the Harris School of Public Policy to hire a highly motivated Computational Scientist, Text Analysis to work closely with faculty and researchers at The University of Chicago. The person in this position serves as a technical domain expert supporting and advising faculty on text analysis, including natural language processing. The Computational Scientist may also hold a concurrent Lecturer appointment in an academic department and teach up to two courses per year. The successful candidate will join a team of Computational Scientists who are playing a key role in scientific computing support at the University of Chicago.

Unit-Specific Responsibilities

1) Develop, maintain and support text analysis pipelines that include data collection, data management, data digitization, data analysis and documentation.

2) Implement NLP algorithms, summarize findings and generate study results and plots for research projects.

3) Independently propose and execute practical solutions to research challenges; develop, install and test scientific software in support of research goals.

4) Prepare and contribute contents to manuscripts and presentations; create and present tutorials, hands-on workshops and documentation.

5) Communicate with various agencies and partners to apply for and manage data access; manage data collection and storage.

6) Work closely with faculty to identify, develop, and implement useful computational methods and resources that support or advance their research.

7) Keep abreast of new developments in High Performance Computing, data science, Machine Learning and deep learning; and be proactive in introducing them to the faculty.

8) May teach up to 2 academic courses per year.

9) Assist researchers with grant proposals with strong HPC or AI component to describe the interplay between their research and computation and data science.

10) Work with faculty and their research groups to enable them to fully utilize the University and national computational resources for their research.

Unit-Specific Competencies

1) Excellent interpersonal and communication (verbal and written) skills.

2) Understand and translate researchers' scientific goals into computational requirements.

3) Mentor and technical lead of a small team of students and/or Research Assistants.

4) Work well with faculty and researchers.

5) Identify and gain expertise in appropriate new technologies and/or software tools.

6) Function as part of an interactive team while demonstrating self-initiative to achieve project's goals and Research Computing Center's mission.

7) Strong analytical skills and problem-solving ability.

8) Work collaboratively with a diverse group of research scientists with different skills and expertise.

Education, Experience, and Certifications
Minimum requirements include a college or university degree in related field.Minimum requirements include knowledge and skills developed through 2-5 years of work experience in a related job discipline.

Preferred Qualifications

Education

1) PhD in Computer Science, Social Sciences, or related fields.

Technical Knowledge or Skills

1) Understanding of key natural language processing, data mining, machine learning and statistical methods.

2) Proficiency in one or more programming languages (such as C++, C, etc.).

3) Proficiency in a scripting language such as Python.

4) Knowledge of text analysis, including natural language processing.

5) Experience with Linux/Unix.

6) Knowledge of SQL.

7) Research experience in Natural Language processing, Machine Learning and Deep Learning frameworks.

8) Experience with running computational jobs on high-end computing systems.

Required Documents

1) Resume/CV

2) Cover letter

3) A solo-authored research-oriented writing sample (e.g. from a thesis) preferred.

NOTE: When applying, all required documents MUST be uploaded under the Resume/CV section of the application.

FLSA Status
Exempt
Pay Frequency
Monthly
Pay Grade
Depends on Qualifications
Scheduled Weekly Hours
37.5
Benefits Eligible
Yes
Drug Test Required
No
Health Screen Required
No
Motor Vehicle Record Inquiry Required
No
Posting Date
2020-08-14-07:00
Remove from Posting On or Before
2021-02-14-08:00
Posting Statement


The University of Chicago is an Affirmative Action/Equal Opportunity/Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.

Staff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via Applicant Inquiry Form.

The University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: http://securityreport.uchicago.edu. Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637.",4.0,"University of Chicago
4.0","Chicago, IL",10000+ Employees,1890,College / University,Colleges & Universities,Education,$2 to $5 billion (USD)
Senior Data Science Architect,"$72K-$120K
(Glassdoor Est.)","At West Monroe, our people are our business. We pride ourselves on bringing a different mindset to consulting—and that takes a different approach: highly collaborative, flexible, and tenacious.
Our people-first, highly collaborative culture is core to our identity. It’s something we care about, and something we strive to enrich and preserve. No hierarchies. No silos. No egos. Just smart ideas, and the drive to make an impact for our clients.
Every day our clients rely on us to help them tackle their greatest challenges, by strategically deploying technology through a business-focused and industry-specific lens. We bring together both the right knowledge and the right approach, so that they can capitalize on opportunities and deliver real results. That takes the right team. And that’s where you come in.
Ready for the next step on your career journey?West Monroe is seeking a Data Scientist to join and help build our emerging Advanced Analytics practice in the Chicago office. We’re looking for you to be a thought-leader building solutions for clients from the ground up on a daily basis. You will be engaging in developing and marketing analytics platforms-as-as-service solutions and collaborating with our client analytics SMEs and implementing predictive models in a variety of industries. Level Responsibilities: Practice DevelopmentEngage in developing and marketing analytics platforms-as-a-service solutionsCollaborate with top leadership within the various practices to develop applicable client projectsContribute to the development/enhancement of WMP’s advanced analytics methodologies, best practices, and approaches to client delivery.Contribute to growth of knowledge in service line through training and KTS sessionsComplete case studies for all engagementsDevelop talented individuals who are delivering client workAttract talent to continue to build the practice from top tier analytics firms and or schools
Client DeliveryOversee advanced analytics work for quality assuranceBe a thought-leader in providing solutions to clients on a daily basisAble to engage with client analytics SMEs to collaborateLead engagements or the analytics portion of engagements by communicating and reporting project status to key client stakeholders, including budget, risks, issues, etc.Make decisions regarding aspects of project, including tools, approach and methodologyDefine detailed responsibilities, work tasks and targets for each team member according to the technical work planManage multiple projects simultaneouslyAssess stakeholder interests and plan and execute strategies to address their needs while quickly responding to client requests for immediate issues and driving projects to completion.
Business Development (Desired)Drive new business with existing clients by identifying and communicating potential opportunities to account managerUnderstand client business needs and requirements and help turn those goals into concrete projects and detailed proposalsCreate work plans, pricing estimates, and risk assessments for prospectsActively build a professional network and affiliate network in the local communitySo, if you’re looking for an opportunity to flex your technical muscles in a high-energy, team-oriented environment where you own your career, we’d love to hear from you.

Qualifications:

MS or Bachelor with equivalent experience required in related Mathematics, Statistics, Econometrics, or similar quantitative degree preferred. PhD a plus
A minimum of 2+ years of experience working in a quantitative analysis/data analytics, managing and/or coaching one or more analysts
Experience working with relational databases, such as SQL
Strong communication skills to be able to work with clients and present to C-level executives.
Solid project management methodology background, including schedule, scope, issue and risk management experience, change management, strategic planning and analysis
Present experience or proficiency with data related projects
Proficient analytical, problem solving and quality delivery experience, preferable 3-5 projects and programs with Fortune 200.
Ability to work well in a team of 2 – 5 consultants
Ability to travel minimum 50%.

Requirements:

Proven expertise with advanced analytics and data mining tools and programming languages such as SAS, IBM/SPSS, R, Python, and SQLFamiliarity with BI/data visualization tools such as Tableau and Qlikview
Hands-on experience with multivariate analytic techniques such as linear and logistic regression, decision tree, cluster and factor analysis, time-series forecasting methods, SVM models, and neural nets.
NoSQL a plus: HBase, Cassandra, Accumulo, Mongo, Neo4j, etc.
Experience with ETL, data warehouse and reporting a plus
Experience with MapReduce: Hadoop, Hive, PIG, Mahout, etc. is a plus

Ready to get started? Join our team and make an impact.

Senior Data Science Architect

222 W Adams St, 11th Floor
Chicago, Illinois, 60606
United States
At West Monroe, our people are our business.
We pride ourselves on bringing a different mindset to consulting—and that takes a different approach: highly collaborative, flexible, and tenacious.

Our people-first, highly collaborative culture is core to our identity. It’s something we care about, and something we strive to enrich and preserve. No hierarchies. No silos. No egos. Just smart ideas, and the drive to make an impact for our clients.

Every day our clients rely on us to help them tackle their greatest challenges, by strategically deploying technology through a business-focused and industry-specific lens. We bring together both the right knowledge and the right approach, so that they can capitalize on opportunities and deliver real results. That takes the right team. And that’s where you come in.

Ready for the next step on your career journey?
West Monroe is seeking a Data Scientist to join and help build our emerging Advanced Analytics practice in the Chicago office. We’re looking for you to be a thought-leader building solutions for clients from the ground up on a daily basis. You will be engaging in developing and marketing analytics platforms-as-as-service solutions and collaborating with our client analytics SMEs and implementing predictive models in a variety of industries.

Level Responsibilities:
Practice Development
Engage in developing and marketing analytics platforms-as-a-service solutions
Collaborate with top leadership within the various practices to develop applicable client projects
Contribute to the development/enhancement of WMP’s advanced analytics methodologies, best practices, and approaches to client delivery.
Contribute to growth of knowledge in service line through training and KTS sessions
Complete case studies for all engagements
Develop talented individuals who are delivering client work
Attract talent to continue to build the practice from top tier analytics firms and or schools

Client Delivery
Oversee advanced analytics work for quality assurance
Be a thought-leader in providing solutions to clients on a daily basis
Able to engage with client analytics SMEs to collaborate
Lead engagements or the analytics portion of engagements by communicating and reporting project status to key client stakeholders, including budget, risks, issues, etc.
Make decisions regarding aspects of project, including tools, approach and methodology
Define detailed responsibilities, work tasks and targets for each team member according to the technical work plan
Manage multiple projects simultaneously
Assess stakeholder interests and plan and execute strategies to address their needs while quickly responding to client requests for immediate issues and driving projects to completion.

Business Development (Desired)
Drive new business with existing clients by identifying and communicating potential opportunities to account manager
Understand client business needs and requirements and help turn those goals into concrete projects and detailed proposals
Create work plans, pricing estimates, and risk assessments for prospects
Actively build a professional network and affiliate network in the local community
So, if you’re looking for an opportunity to flex your technical muscles in a high-energy, team-oriented environment where you own your career, we’d love to hear from you.
Qualifications:
MS or Bachelor with equivalent experience required in related Mathematics, Statistics, Econometrics, or similar quantitative degree preferred. PhD a plus
A minimum of 2+ years of experience working in a quantitative analysis/data analytics, managing and/or coaching one or more analysts
Experience working with relational databases, such as SQL
Strong communication skills to be able to work with clients and present to C-level executives.
Solid project management methodology background, including schedule, scope, issue and risk management experience, change management, strategic planning and analysis
Present experience or proficiency with data related projects
Proficient analytical, problem solving and quality delivery experience, preferable 3-5 projects and programs with Fortune 200.
Ability to work well in a team of 2 – 5 consultants
Ability to travel minimum 50%.
Requirements:
Proven expertise with advanced analytics and data mining tools and programming languages such as SAS, IBM/SPSS, R, Python, and SQL
Familiarity with BI/data visualization tools such as Tableau and Qlikview
Hands-on experience with multivariate analytic techniques such as linear and logistic regression, decision tree, cluster and factor analysis, time-series forecasting methods, SVM models, and neural nets.
NoSQL a plus: HBase, Cassandra, Accumulo, Mongo, Neo4j, etc.
Experience with ETL, data warehouse and reporting a plus
Experience with MapReduce: Hadoop, Hive, PIG, Mahout, etc. is a plus
Ready to get started? Join our team and make an impact.

.

West Monroe Partners is an Equal Employment Opportunity Employer -
We believe in treating each employee and applicant for employment fairly and with dignity. We base our employment decisions on merit, experience, and potential, without regard to race, color, national origin, sex, sexual orientation, gender identity, marital status, age, religion, disability, veteran status, or any other characteristic prohibited by federal, state or local law.",4.2,"West Monroe Partners
4.2","Chicago, IL",1001 to 5000 Employees,2002,Company - Private,Consulting,Business Services,$100 to $500 million (USD)
"Senior Analyst, Data & Analytics (Affinity)","$49K-$107K
(Glassdoor Est.)","Job Description


We’re hiring!

Aon is currently recruiting a Senior Analyst, Data & Analytics (Affinity) to join our team in Singapore.

About Aon's Center for Innovation & Analytics

Aon’s Centers for Innovation and Analytics in Dublin and Singapore are at the heart of delivering Aon’s Data & Analytic Services team’s mission to:
accelerate the rate of innovation through digital solutions to help better respond to clients’ evolving needs
provide foundational data and analytics capabilities in one place for 50,000 Aon colleagues and our global clients who use our risk and people solutions
Established in 2012, there are over 100 colleagues in Singapore’s Centre today including actuaries, software developers, data scientists, financial analysts and accountants. We are expanding rapidly and looking for dedicated individuals who can leverage emerging technologies and collaborate across Aon’s solution lines to help clients and colleagues make better, data-driven decisions today and tomorrow.

The Opportunity
The opportunity is within a newly formed team which is part of Aon’s B2B2C and B2C business in the US (also referred to as Affinity) focusing on marketing analytics.
The scope will eventually expand to include analytics that will serve the core Affinity business. It is an exciting time to join this team since you will get to shape the nature of analytics for this business
Responsibilities
Aggregate, combine, normalize and cleanse data from a variety of internal, public or proprietary data sources to create internal data sets
Work with data engineers and or carry out data ingestion activities as required.
Perform data exploration and analysis on these internally developed data sets to come up with insights
Collaborate with teams of experienced analysts, developers and business experts to implement the insights
Go beyond current tools to deliver the best solution to the problem and assist/advise on the most appropriate analytical methods to apply to a given problem
Provide support in communication of results to business leaders and in designing fully functional products
Requirements
Degree in Computer science, Engineering or Business analytics preferred
3+ years of working experience with data & analytics
A good working knowledge of databases; structured & unstructured with a view to obtaining internal & external data and troubleshooting data issues as necessary
Software developers (C#- backend development) will be considered for this role as long as they have an interest in working on data visualization using a BI toolset alongside software development (60/40 split)
Experience in Python & exposure to ETL scripting is desired if the background is not in software development.
Proven experience with a BI tool
A proven ability to work in a fast-paced unstructured environment
Familiarity with marketing or insurance concepts is a bonus
How to Apply

Your opportunity to empower results could start right here. Make your mark and apply online today with a brief covering letter and your resume, sharing relevant achievements for this position.

We Offer You

A competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.

Our Colleague Experience

Every day, our colleagues make a difference, work with the best, own their potential, and value one another. Together, we share this one purpose: to empower economic and human possibility around the world. This unifying goal is at the heart of our identity, and it lives in everything we do. To learn more about our colleague experience, visit Aon Colleague Experience.

Aon is an equal opportunities employer. We are committed to creating a winning and inclusive culture where everyone feels valued and has opportunities for growth and development.

2477248",3.6,"Aon
3.6","Chicago, IL",10000+ Employees,1892,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD)
Senior Big Data Engineer- Data Warehouse,"$102K-$126K
(Glassdoor Est.)","We're looking for a Senior Data Engineer for our Chicago to join us in building our next generation data processing platform. As part of the platform team you will work in multiple areas including campaign performance measurement and reporting, ad fraud, and botnet detection.

Are you someone who likes to have fun at work? Are you passionate about picking problems apart, driving results, and making an impact? Do you enjoy working in a fast-paced, dynamic environment where no two days are the same? If so, we want to speak with you!

About our team:

Quite simply our platform is the engine that powers the verification, optimization, and analytics solutions we provide. It has the power to handle hundreds of thousands of transactions per second; collect tens of billions of events each day and evaluate thousands of data-points in real-time all while responding in just a few milliseconds.

What you'll do:
Work on Big Data technologies, lead the design, coding and maintenance of highly scalable backend data processing platform for large throughput
Work on the data modelling for the MPP columnar databases to handle high volume of queries with sub-second response times
Lead the entire software lifecycle including hands-on development, code reviews, testing, continuous integration, continuous deployment and documentation using modern programming languages (such as Java, Scala, Python)
Perform tuning of systems for optimal performance
Mentor junior team members
You should apply if you have most of this:
5+ years of recent hands-on experience in one or more of the modern programming languages (Java, Scala, Python)
Good understanding of collections, multi-threading, JVM memory model, algorithms, scalability and various tradeoffs in a Big Data setting.
Experience developing and maintaining ETL applications and data pipelines using big data technologies
Strong SQL knowledge (OLAP) and experience working with mpp columnar databases (Vertica, SnowFlake,etc)
Excellent interpersonal and communication skills
Understanding of full software development life cycle, agile development and continuous integration
What puts you over the top:
Data warehouse experience in SnowFlake and experience writing ETL pipelines in SnowFlake
Experience working with AWS technologies such EMR, step functions, data pipeline, cloudformation, etc.
Experience working with hadoop mapreduce, spark, pig, hive, etc.
About Integral Ad Science

Integral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 18 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit integralads.com.

Equal Opportunity Employer:

IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.

California Applicant Pre-Collection Notice:

We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.

To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN

Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.",3.5,"Integral Ad Science
3.5","Chicago, IL",501 to 1000 Employees,2009,Company - Private,Internet,Information Technology,$100 to $500 million (USD)
Data Architect,"$77K-$128K
(Glassdoor Est.)","About our teams: Tempus is executing on the mission to create the world's largest, integrated dataset of molecular and clinical data. At Tempus, products are owned and developed by small, autonomous teams composed of developers, designers, data scientists, and product managers. You and your team set the goals, build the software, deploy the code, and contribute to a growing software platform that will make a lasting impact in the field of cancer research and treatment.

Tempus builds software as nimble as our teams. Our modern tech stack - React, NodeJS, and Python on AWS - allows our teams to iterate rapidly and lead our industry in innovation. Our decentralized, microservice architecture and emphasis on automation allow us to deliver advanced solutions with confidence, and at scale.

What You'll Do
Manage an enterprise data model in collaboration with engineers, product managers, scientists, and operators to integrate structured data from source systems in multiple complex domains (clinical records, genomics, NGS lab, radiology, et al.).
Author and maintain entity-relationship diagrams, data dictionaries, API specs, and data translation documentation at multiple levels of abstraction (conceptual, logical, physical) and across multiple data store technologies (relational, NoSQL).
Advocate and educate engineering team members on data modeling rules, standards, and best practices.
Evaluate completeness of source system data models and data by profiling partner data.
Implement solutions to proactively monitor data quality with traceability to source systems.
Why we're looking for you:
You have strong experience and knowledge of 3NF, dimensional (star schema), and data vault modeling techniques.
You have applied exceptional SQL skills in an enterprise data warehouse environment.
You have knowledge of ETL/ELT and BI architectures, concepts and frameworks.
You understand and can clearly articulate the long-term impacts of key decisions between database technologies (relational, MPP, NoSQL) and have experience architecting solutions across multiple technologies.
You have experience with data modeling tools like Erwin, Vertabelo or SQLDBM.
You have domain knowledge in healthcare.
Bonus points for:
Experience with AWS architecture
Experience working with clinical and/or genomic data
Experience writing and debugging Python
Chairing a data governance board for a complex organization
Implementing master, reference, or metadata management solutions",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Data Engineer,-1,"The Data Engineer will collaborate with various other IT groups, business partners and external service providers and play a key role in the design, development and operations of our new analytics platform.
Responsibilities Include:

Participate in Requirements Gathering: work with key business partner groups (e.g. Product Mgt) and other Data Engineering personnel to understand department-level data requirements.
Design Data Pipelines: work with other Data Engineering personnel on an overall design for flowing data from various internal and external sources into the platform.
Build Data Pipelines: leverage standard toolset and develop ETL/ELT code to move data from various internal and external sources into the platform.
Support Data Quality Program: work with Data QA Engineer to identify automated QA checks and associated monitoring & alerting to ensure consistently high-quality data.
Support Operations: triage alerts channeled to you and remediate as necessary.
Technical Documentation: leverage templates provided and create clear, simple and comprehensive documentation for your development.
Key contributor to defining, implementing and supporting:
Data Services
Data Dictionary
Tool Standards
Best Practices
Data Lineage
User Training",4.5,"Green Key Resources
4.5","Chicago, IL",201 to 500 Employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable
"Director of Product, Data as a Service (DaaS)","$115K-$186K
(Glassdoor Est.)","Position Description:

The Climate Corporation is modernizing the agriculture industry with our Digital Farming Platform that is helping the world’s growers sustainably increase farm productivity with digital tools. We build hardware, platforms, and a suite of grower-facing applications that collect and process vast amounts of agronomic data. We then deliver insights that allow farmers to produce enough food to feed the ever-growing population.

In this role, you will report directly into the Chief Product Officer and lead our DaaS product vertical. You will define the future of our industry by identifying and prioritizing the highest-value agricultural data opportunities for not only Climate, but the broader agricultural industry. You will create the vision and product roadmap that catalyzes and drives our data flywheel, turning our data into actionable insights for all of our enterprise and farmer customers.

What You Will Do:
Lead a motivated and driven product team focused on realizing The Climate Corporation’s mission to help farmers sustainably increase food production with digital tools.
Set the DaaS product strategy and business plan by deeply analyzing the market; use strong business judgment and technical knowledge to inform an understanding of what is technically possible, and strategically critical to success.
Own the DaaS product roadmap – synthesize multiple inputs into a clear product strategy and manage ongoing feature prioritization.
Work closely with the R&D leadership and executive teams to define product requirements and ensure the roadmap is aligned with the company vision and strategy; clearly communicate your vision, requirements, and features across teams and throughout the organization.
Engage deeply with researchers, data scientists, engineers, and other technical leaders to evaluate new technologies and product concepts. Explore build-vs-buy initiatives to ensure we deliver the highest quality/value in line with the market opportunities.
Execute on your vision by defining clear milestones and deliverables, and partnering with Engineering, Science, and end-to-end teams to ensure your vision becomes reality.
Define the evolution & future requirements for agriculture data collection based on equipment and industry trends. Contribute towards standards and adoption for agricultural data across the industry.
Basic Qualifications:
BS in a technical field or equivalent experience.
10+ years of enterprise product development or product management experience.
5+ years of experience building and leading product management teams.
Experience working hands-on with hardware and/or software engineering teams to deliver new products and features in an agile development environment.
Experience defining and managing Platform/DaaS solutions.
Strong strategic and analytical skills.
Strong written and verbal communication skills.
High attention to detail and the ability to manage complex projects.
Preferred Qualifications:
Masters degree or MBA.
Experience jumpstarting and launching DaaS initiatives.
Background and experience with data security and audit compliance.
Product leadership demonstrated through shipping successful products.
Experience developing and negotiating partnerships for platforms and/or content development.
Passion for agriculture is a huge plus.
What We Offer:

Our teams are composed of industry experts, top scientists, and talented engineers. The environment is extremely engaging and fast-paced, with dozens of specialties coming together to provide the best possible products and experiences for our customers. We provide competitive salaries and some of the best perks in the industry, including:
Superb medical, dental, vision, life, disability benefits, and a 401k matching program
A stocked kitchen with a large assortment of snacks & drinks to get you through the day
Encouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used
We take part and offer various workshops, conferences, meet-up groups, tech-talks, and hackathons to encourage participation and growth in both community involvement and career development
We also hinge our cultural DNA on these five values:
Inspire one another
Innovate in all we do
Leave a mark on the world
Find the possible in the impossible
Be direct and transparent
Learn more about our team and our mission:

The Climate Corporation - The Technology Behind Making A Difference

https://youtu.be/c5TgbpE9UBI or visit https://climate.com/careers

Climate aims to create a welcoming and collaborative environment for our employees in which a diverse set of perspectives and voices are represented and celebrated.

As part of our dedication to the diversity of our workforce, The Climate Corporation is committed to Equal Employment Opportunity and does not discriminate based on race, religion, color, national origin, ethnicity, gender, sex (including pregnancy), protected veteran status, age, disability, sexual orientation, gender identity, gender expression, or any unlawful criterion existing under applicable federal, state, or local laws. If you need assistance or an accommodation due to a disability, you may contact us at accommodations@climate.com.

#SSLI",3.3,"The Climate Corporation
3.3","Chicago, IL",501 to 1000 Employees,2006,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable
Product Manager - Data Integrations and Infrastructure,"$47K-$90K
(Glassdoor Est.)","Passionate about making a difference in the world of cancer genomics?

With the advent of genomic sequencing, we can finally understand our genetic makeup. We now have more data than ever before but providers don't have the infrastructure or expertise to make sense of said data. Here at Tempus, we are building the infrastructure to modernize cancer treatment. By analyzing a patient's genetic data in the context of molecular therapies, We empower physicians to make real-time data-driven decisions in the clinic based on the comprehensive computational analysis of a patient's unique pathology.

As a Product Manager, Data Integrations and Infrastructure at Tempus, you'll be on the front lines of our battle to develop and deliver cutting-edge data and technology into the hands of researchers. The software we are developing is the culmination of input from scientists, clinicians, pathologists, engineers, data scientists, and some of the top academic oncology centers in the world. We're expanding the team of product managers who bring those inputs together to design, scope, and build solutions to some of the toughest problems in cancer care.

What You'll Do:
Immerse yourself in the tough problems were solving, and team with scientists, engineers, and designers to develop elegant software solutions to solve those problems
Own the product roadmap for a subset of Tempus products, and partner with otherProduct Managers and the Director of Product to find the best way to execute quarterly and sub-quarterly goals.
Work with developers, scientists, and operations teams to deliver product releases that are stable in production and satisfy scalability, reliability, and performance goals
Conduct deep product analysis and use the data to guide the short- and long-term roadmap for the team
Own stakeholder communication and expectation management around roadmap and delivery timelines for your products
Test release candidates and participate in the Product Management approval process for deployments
Serve as the direct line of communication with users of your products to maintain a constantly evolving backlog of future enhancements
Help create the internal and external playbook for implementing and supporting integrations with the Tempus product and hospital/industry partners clinical systems in a scalable and consistent manner
Work closely with on-site and off-site integration and informatics managers to prioritize product roadmaps in accordance with requirements in the field to accelerate, improve and optimize integrations with new health systems
Qualifications:
3+ years of technical product management or equivalent experience, ideally at a SaaS company
Experience working with agile software development teams
2+ years of relevant experience with SQL or Python
Experience with software development and project management tools (JIRA, Trello, etc.)
Ability and interest to quickly ramp up on new concepts in the fields of genomics, oncology, and health informatics systems
Ability to work directly with business and operations partners to generate consensus around a technical direction",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Data Engineer Solutions Lead,"$77K-$138K
(Glassdoor Est.)","Your Talent. Our Vision. At Anthem, Inc., it’s a powerful combination, and the foundation upon which we’re creating greater access to care for our members, greater value for our customers, and greater health for our communities. Join us and together we will drive the future of health care.

This is an exceptional opportunity to do innovative work that means more to you and those we serve at one of America's leading health benefits companies and a Fortune Top 50 Company.

Data Science Solutions Lead is responsible for design and development of analytic models, applications and supporting tools, which enable Data Scientists to create algorithms/models in a big data ecosystem.

Primary duties may include but are not limited to:
Lead the design and implementation of Machine Learning/Data Science model operationalization and related system integration
Lead the design, implementation and delivery of an insights data pipeline supporting analytic products across the organization.
Design and integrate data from different sources.
Forms analytics platform components and/or processing components required to provide a business solution.
Engage with business stakeholders to design and own end-to-end solutions to empower data driven decision making.
Leverage data, technology and quantitative methods to form products that inject analytics and insights into daily workflow of teams.
Defines application scope and objectives, including impact to interfaces.
Ensures appropriate data testing is completed and meets test plan requirements.
Coordinates integration actions to ensure successful implementation.
Mentors Data Science Sol Consultants/Sr. Lead analytical projects and pilots for upgrades or enhancements.
Lead analytical projects and pilots for upgrades or enhancements
Requires BA/BS in Computer Science, Mathematics, or related disciplines; 5-7 years’ experience in predictive analytics and experience with software such as Hadoop technologies; 5-7 years Teradata experience and complex SQL, or equivalent; or any combination of education and experience which would provide an equivalent background. Experience in the healthcare sector preferred. Experience with deployment techniques within an agile development methodology. Strong knowledge of BTEQ and multi database preferred.
Requires BA/BS in Computer Science, Mathematics, or related disciplines.
An ideal candidate will have significant experience in at least one area: Data Architecture, Real-Time Applications, or BI Tools.
5+ years’ experience in leveraging at least 4 of the following technologies – HDFS, Hive, Sqoop, Impala, Spark, distributed processing concepts, Hbase, MongoDB, J2EE/Spring, AWS, Node.js
Solid understanding and experience using at least one of the following programming languages — Java, Python, R, Scala.
5+ years’ experience in one of the following areas:
Database Strategy, Data Modeling, Data Pipelines and ETL Architecture
API & messaging architectures
BI development/design
Experience in public cloud environment and container technologies is preferred
Experience in Healthcare industry is preferred
Strong relational database SQL skills; including optimization techniques, with knowledge of NoSQL concepts
Solid experience with unix and shell scripting
Experience in defining project solution approach leveraging agile methodologies working with Product Owners and Scrum Masters.
Experience with source code management and application deployment techniques within an agile development methodology
Knowledge of the following Machine Learning Algorithms - Classification, Regression, Clustering, Dimensionality Reduction, Model Selection, Feature Extraction
Anthem, Inc. is ranked as one of America’s Most Admired Companies among health insurers by Fortune magazine and is a 2018 DiversityInc magazine Top 50 Company for Diversity. To learn more about our company and apply, please visit us at careers.antheminc.com. An Equal Opportunity Employer/Disability/Veteran.",3.4,"Anthem
3.4","Chicago, IL",10000+ Employees,2004,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD)
"Software/Data Engineer (C#, Python, Cloud)",-1,"Software/Data Engineer (C#, Python, Cloud)

Location: Chicago, Illinois, United States

Salary: competitive

Sectors: Development

Job Type: Permanent

Apply for this Job
One of my clients is a growing global fintech firm, looking to expand their data/software engineering team in Chicago with both a mid-level and senior software engineers. With a goal to drive efficiencies leveraging data and technology, they work with a modern stack to stay competitive (C#, Python, Kubernetes, Cloud - Azure, AWS, GCP).

They are looking for mid-level and senior engineers that have experience working on data problems, preferably leveraging cloud technologies such as Azure, AWS or GCP. Ideal candidates will be familiar with REST based APIs, Microservice frameworks, containerization - kubernetes and experienced working with C#, Python and SQL. An understanding of capital markets and financial services is a plus, but not required.

The team is WFH due to COVID-19, with the ability to interview and onboard remotely. Preferred candidates will be based in the Greater Chicago Area. There are no immediate plans to return to the office, and employee health and safety is their #1 priority in making any decisions around that.

Whether you are actively looking or keeping a passive eye on the market, I'm happy to have an open conversation with you - about this opportunity and/or the market holistically. Please submit your resume here!

Sthree US is acting as an Employment Agency in relation to this vacancy.

Apply for this Job",3.1,"Huxley
3.1","Chicago, IL",201 to 500 Employees,1995,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Senior Data Analyst Informatics,"$49K-$88K
(Glassdoor Est.)","We now have more healthcare data than ever before, but providers often do not have the systems or expertise to make sense of all of this valuable data. At Tempus, we are building the infrastructure to modernize and enhance cancer treatment. We are on a mission to connect an entire ecosystem to redefine how data is used to improve patient outcomes. The Clinical Informatics team is seeking a highly-motivated data analyst who enjoys working with complex datasets and building tools for data pipelines.

What you'll do:

As part of the informatics team, you'll play a key role in helping us aggregate data from many different sources to build the largest library of oncology clinical data in the world. You'll work with clinical data experts, engineers, data scientists, and informatics analysts to ensure the quality of our data for analysis downstream.

Responsibilities
Lead efforts to build an extensive toolkit for scaling the aggregation and normalization of disjoint data
Automate quality assurance to ensure that data adheres to a common set of standards
Identify and socialize improvements to data processing infrastructure and workflow
Analyze the quality of our data and insights that can be generated from it
Skills and Qualifications:
Bachelor's degree in Analytics, Computer Science, or Information Systems (Master's Preferred)
2+ years of Python, SQL, and Github experience
Experience working with disorganized data from various sources
Extremely high attention to detail and fast learner
Nice-to-haves:
Familiarity with Oncology and Cancer Genomics
Knowledge of Health Informatics
Experience with Standard Medical Terminologies (SNOMED-CT, ICD-9/10, LOINC, etc.)
Experience with NLP techniques",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Azure Data Modeler- eCommerce,"$50K-$88K
(Glassdoor Est.)","Here is a great opportunity to join a great company! Medline Industries has enjoyed DOUBLE DIGIT GROWTH for 53 of the past 54 years! We've again been named to the Chicago Tribune's Top Workplaces, and we're again on the list of Becker's Great Places to Work in Healthcare.

We have a great opportunity to show off your passion for data, reporting, analytics and data warehousing. Medline's BI team may have the perfect fit for you!

We are looking for a self-motivated Data Engineer to join our business intelligence team.
This data engineer will be responsible for developing and maintaining business intelligence, data warehousing and data engineering solutions for E-commerce department. This individual will also create and maintain detailed business requirements, outlining data problems, opportunities and solutions for our E-Commerce department.

Responsibilities include:
• Responsible for designing relational and non-relational data stores on Azure.
• Responsible for designing and developing solutions in Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, SQL Data Warehouse, HDInsight.
• Gather and process raw data at scale that meet functional / non-functional business requirements (including writing scripts, REST API calls, SQL Queries, etc.)
• Responsible for developing data set processes for data modeling, mining and production.
• Responsible for data modeling of multiple E-Commerce data marts.
• Responsible for building new Data Lake in Azure, expanding and optimizing our data platform and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
• Responsible for supporting our Software Developers, Data Analysts and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
• Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
• Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
• Develop complex SQL queries in TIBCO Data Virtualization tool.

Qualifications
• 3+ years of experience architecting and building Data Lake, Azure Big Data architecture, Enterprise Analytics Solutions, and optimizing ' big data' data pipelines, architectures and data sets.
• Advanced hands-on SQL, USQL, Python, C#, Java, pySpark (2+ of these) knowledge and experience working with relational databases for data querying and retrieval.
• Experience with Design and Architecture of Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure ML, SQL Data Warehouse, HDInsight.
• Experience with building processes supporting data transformation, data structures, metadata, dependency and workload management.
• Experience working with cross-functional teams in a dynamic environment.
• Experience building Big data pipeline with Java and/or Python a plus.
• Strong SQL skills on multiple platform
• Data Modeling tools (e.g. Erwin, Visio) knowledge a plus.
• Experience with SAP HANA a plus.
• Experience with Talend a plus.
• Experience with Alteryx a plus.

More About Medline:
Medline is the largest privately held manufacturer and distributor of healthcare supplies in the United States, providing more than 550,000 products that serve the entire continuum of care. Our innovative products and programs can be found in most hospitals, extended-care facilities, surgery centers, physician offices, home care dealers, home health agencies and retail outlets.

Founded in 1910, Medline has grown from a small manufacturer of aprons, surgical gowns and uniforms to a thriving $12 billion global enterprise because of our dedicated people, entrepreneurial spirit and honest values.

Again named one of the country’s ""Best and Brightest Companies to Work For,” and once again named to Chicago Tribune’s Top Workplaces, Medline has experienced fifty-plus years of consecutive annual growth, and is headquartered in Northfield, IL.",3.4,"Medline Industries
3.4","Northfield, IL",10000+ Employees,1966,Company - Private,Health Care Products Manufacturing,Manufacturing,$10+ billion (USD)
Jr. Clinical Trials Data Specialist,"$26K-$51K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

We are looking for a Jr. Clinical Trials Data Specialist who will work with our clinical and computational biology team on reports for clinical and research use.

Responsibilities:
Works collaboratively within cross-functional teams at Tempus (including but not limited to scientists, pathologists, product development) to create customized clinical reports.
Analyze patient clinical records and molecular testing results to identify potential clinical trials.
Perform critical quality control functions in clinical report workflow.
Support ongoing and future projects within the team.
Qualifications:
Minimum of a BS degree in Genetics, Molecular Genetics, Cancer Biology or Biological Sciences.
Willingness to be flexible and adapt quickly.
Strong critical-thinking and attention to detail.
Excellent communication skills with the ability to work both independently and in a group setting.
Excitement and drive to make a difference in a fast-paced energetic work environment!
0-3 years of working experience.
Preferred Qualifications:
Hematology/oncology knowledge.
Experience reading and evaluating clinical trials.",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Senior Integration Data Analyst,"$56K-$99K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

We are looking for a motivated Senior Integration Data Analyst who will work with our cross-functional teams and current hospital and industry partners to ensure a seamless Connectivity integration between Tempus and our customer's clinical systems. You'll work closely with customer's hospital EMR, EDW, and oncology data management teams to understand their workflows and goals in order to implement and support our cutting edge products and start making an impact very quickly for their cancer patients.

What you'll do
Work as part of the Clinical Data Connectivity team to execute and integrate data flows between the Tempus software system and the customer's current hospital IT systems and workflows
You'll play a key role in helping us aggregate data from many different sources to build the largest library of oncology clinical and genetic data in the world.
You'll work with clinical data experts, engineers, data scientists, and informatics analysts to ensure the quality of our data for analysis downstream and alignment with customer specific data specification pipelines.
Lead efforts to build an extensive toolkit for scaling the aggregation and normalization of customer data connections.
Automate quality assurance to ensure that data adheres to a common set of standards and customer specific data approved data schemas.
Identify and socialize improvements to data processing infrastructure and workflow, helping to provide continuous improvements in the architecture, process, and algorithms used to ingest and monitor data feeds.
Analyze the quality of our data and insights that can be generated from it.
Project Implementation Support:
Help support the successful execution of implementation project scope, timeline, objectives, and create a shared vision for the project execution as it relates to data deliveries, formats, schema, and structures.
Work directly with hospital data teams to execute flawlessly the integration project scope including validation, testing, and data profiling.
Assist with validation, monitoring, and troubleshooting of physical data delivery mechanisms, but more importantly assist with validation and remediation of data.
Integration Operations Support and post Go-Live Maintenance:
Develop and monitor day-to-day ""lights on"" operations of the Tempus integration layer
Partner with DevOps and Engineering teams to continuously optimize and improve the performance, scalability, and fault-tolerance of the integration layer
Qualifications
Bachelor's or Master's degree in an analytical or healthcare related field (or equivalent industry experience)
Familiarity with EMRs (electronic medical record)
2+ years of SQL required.
2+ years of Python recommended.
2+ years of data mining recommended
1+ years working with Apache Spark and/ or related NoSQL data architectures.
Expertise in working with common health care data semantic/ ontology/ vocabulary representation (e.g., ICD-9/10, SNOMED, LOINC, RxNorm, ICD-O, etc.)
Experience working with genomic data and genomic data terminology nice-to-have (e.g., HUGO, COSMIC standards, VCF/BAM files, etc.)
Experience working with AWS, Google Cloud, or similar cloud-based technologies
Ability to lead large scale implementations in a fast-paced, ever-changing environment with demonstrable ability to navigate successfully with hospital client data teams.
Demonstrate ability to establish strong client-trust and maintaining consistent and strong relationships with customers and vendor partners
Demonstrate ability to handle large data sets and relational databases
5 year's experience preferred
Work Location
Position available at our Tempus Chicago HQ, San Francisco, or New York office; or consideration for remote available.",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Data Engineer,-1,"Job Description:

Â
Exact Job Location/Work Address

Requirements are scattered across 4 main locations: Richmond VA, McLean, VA, Wilmington, DE, Chicago, IL
Required Technologies
Strong Programming experience with object-oriented/object function scripting languages: Python, PySpark, Scala, etc.
Experience with big data tools: Hadoop, Apache Spark, Kafka, etc.
Experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra.
Â
Job Description:ÂDetailed overview of functional and technical role expectations

Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have working experience using the following software/tools:

Â
Strong Programming experience with object-oriented/object function scripting languages: Python, PySpark, Scala, etc.
Experience with big data tools: Hadoop, Apache Spark, Kafka, etc.
Experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra.
Â

Responsibilities for Data Engineer:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements.
ÂIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.
ÂBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'Big data' technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
ÂWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Â

Â

Â

Rating table:
Skills

Rating Out Of 10

Experience in Years
Spark

Â

Â
Python

Â

Â
Scala

Â

Â
AWS

Â

Â
Object oriented Programming

Â

Â

Â

Â",-1,Clear Technology Consulting,"Chicago, IL",Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD)
Associate Director - Lead Data Engineer,"$109K-$190K
(Glassdoor Est.)","Job Description


We’re hiring!

Aon is currently recruiting an Associate Director, Data Engineer to join our team in Singapore.

About Aon's Center for Innovation and Analytics

Aon’s Centers for Innovation and Analytics (ACIA) in Dublin and Singapore are at the heart of delivering Aon’s Data & Analytic Services team’s mission to:
accelerate the rate of innovation through digital solutions to help better respond to clients’ evolving needs
provide foundational data and analytics capabilities in one place for 50,000 Aon colleagues and our global clients who use our risk and people solutions
Established in 2012, there are over 100 colleagues in Singapore’s Centre today including actuaries, software developers, data scientists, financial analysts and accountants. We are expanding rapidly and looking for dedicated individuals who can leverage emerging technologies and collaborate across Aon’s solution lines to help clients and colleagues make better, data-driven decisions today and tomorrow.

The Opportunity

You will work with business stakeholders and our Engineering team (mostly with Data Scientists, Data Analysts, Backend Engineers and SRE’s) to develop and have a real impact on the overall design of the data and data pipeline architecture to allow the growth of our business. As our Lead Data Engineer, you should be passionate about designing, building, and maintaining our growing big data platform.

Responsibilities:
Work with the Engineering team and in collaboration with Aon’s business teams to define and deliver data solutions that enable and enhance Aon’s analytical capabilities.
Design, build and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Design the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Work with stakeholders including the Product Owner, Data Science and Development teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Maintain up to date Technical and Operational documentation
Requirements
Bachelor’s Degree in Computer Science, Information Technology or equivalent.
5+ years’ experience in Big Data technology and developing data pipelines within a Hadoop-based / Apache Spark environment
Good knowledge of Hadoop ecosystem (HDFS, Hive, Impala, Kafka, Spark, Elasticsearch etc.) & associated tools and cloud-based technologies (AWS-based)
Highly proficient at reading, profiling, parsing, transforming, cleansing & integrating data from various sources (structured and unstructured)
Experience designing Horizontally Scalable Event-Driven Big Data Architecture
Experience with big data ingestion and workflow management tools: Hadoop, Spark, Kafka,Airflow, StreamSets, etc.
Experience with relational SQL and NoSQL databases (Postgres, MongoDB, Redis, etc.)
Experience developing data solutions with AWS cloud services: EC2, EMR, RDS, Redshift, Kinesis, Athena
Experience in programming (Python, Scala, Java) for automation and data processing.
Experience working with bash scripting, Docker, Kubernetes and Linux environments on a daily basis.
Experience with Cloudera CDP will be an added advantage
Awareness of Data Security, Data Governance and Service Operations processes, with an ability to deliver on these key non-functional requirements.
Excellent communication, sharp analytical abilities, able to think critically of the current system in terms of growth and stability
How to Apply

Your opportunity to empower results could start right here. Make your mark and apply online today with a brief covering letter and your resume, sharing relevant achievements for this position.

We Offer You

A competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.

Our Colleague Experience

Every day, our colleagues make a difference, work with the best, own their potential, and value one another. Together, we share this one purpose: to empower economic and human possibility around the world. This unifying goal is at the heart of our identity, and it lives in everything we do. To learn more about our colleague experience, visit Aon Colleague Experience.

Aon is an equal opportunities employer. We are committed to creating a winning and inclusive culture where everyone feels valued and has opportunities for growth and development.

2477268",3.6,"Aon
3.6","Chicago, IL",10000+ Employees,1892,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD)
Data Engineer,"$63K-$114K
(Glassdoor Est.)","Oak Street Health is a rapidly growing, innovative company of community-based healthcare centers delivering higher quality health and wellness care that improves outcomes, manages medical costs and provides an unmatched experience for adults on Medicare in medically underserved communities. By providing holistic, comprehensive and integrated care right in our patients’ communities, we can help keep them healthy and reinvest cost savings in further care for those same communities and others. Since 2013, Oak Street Health has brought its singular approach to tens of thousands of people across the nation. With an ambitious growth trajectory, Oak Street Health is attracting and cultivating team members who embody Oak Street values and are passionate about our mission to rebuild healthcare as it should be.

For more information, visit www.oakstreethealth.com.

Job Responsibilities
Design, Develop, and unit test new or existing ETL/Data Integration solutions to meet business requirements.
Daily production support for Enterprise Data Warehouse including ETL/ELT jobs.
Design and Develop data integration/engineering workflows on big data technologies and platforms
Develop data streams using Apache Kafka.
Develop workflows in the cloud environment using Cloud base architecture (Azure or AWS).
Develop dataflows and processes for the Data Warehouse using SQL (SQL Server).
Develop Data integration workflows using Web services in XML, JSON, flat file format, SOAP
Work with stakeholders including the Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Deliver increased productivity and effectiveness through rapid delivery of high-quality applications.
Create and maintain optimal data pipeline architecture.
Performs other duties as assigned.
What we’re looking for

We’re looking for motivated, experienced developers with:
Bachelor’s degree in Computer Science, Engineering, or related field from an accredited university
Proven experience in a data integration role with expert level SQL
Working knowledge of ETL change detection solutions such as change data capture (CDC)
Experience using Apache Kafka
Proven experience integrating enterprise software using ETL modules/Data Engineering tools
Knowledge of data architecture, structures and principles with the ability to critique data and system designs
Ability to integrate data from Web services in XML, JSON, flat file format, SOAP
Experience with Big Data technology a plus
Knowledge in DevOps practices and tools is a plus
U.S. Work Authorization
Someone who embodies being “Oaky”
What does being “Oaky” look like?
Radiating positive energy
Assuming good intentions
Creating an unmatched patient experience
Driving clinical excellence
Taking ownership and delivering results
Being scrappy
Why Oak Street?

Oak Street Health offers our coworkers the opportunity to be at the forefront of a revolution in healthcare, as well as:
Collaborative and energetic culture
High levels of responsibility and rapid advancement
Headquarters (the “Treehouse”) located in the heart of Downtown, close to many public transit options and great restaurants
Competitive benefits; including paid vacation/sick time, generous 401K match with immediate vesting, as well as health benefits
Oak Street Health is an equal opportunity employer. We embrace diversity and encourage all interested readers to apply to oakstreethealth.com/careers.",3.6,"Oak Street Health
3.6","Chicago, IL",1001 to 5000 Employees,2012,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
GCP Data Engineer,"$65K-$115K
(Glassdoor Est.)","Skills Needed
Â
Spark(PySpark preferred)
Spark Workload Tuning/Optimization
Python(focus on data engineering)
Apache Beam(Python preferred)
Airflow(Cloud Composer preferred)
BigQuery
Hive
Data Modeling/Data Warehouse/Analytics
Looker, Tableau
CICD(Cloud Build, Bazel, MonoRepo)
Jupyter Notebooks(Good to have but not required)
Â
Â
Please send resumes toÂsgottumukkula@esharpedge.com
Â",4.7,"Sharpedge Solutions Inc
4.7","Naperville, IL",Unknown,-1,Company - Private,Publishing,Media,Less than $1 million (USD)
Data Engineer,"$44K-$83K
(Glassdoor Est.)","Data Engineer

Our goal at Elkay is to inspire everyday – customers, employees…and the employees of tomorrow. We focus on doing the right thing so we can be in business forever. Our values-driven culture emphasizes investing in people and treating them like part of the family. We’re financially-stable and privately-owned with a solid reputation for ethics, integrity, giving back, and providing an engaging, inclusive environment where careers flourish and grow. Our people are proud to work for Elkay.

And the feeling is mutual – because it’s Elkay’s people who really give us our edge. We empower our employees to take the lead in delivering Elkay’s exceptional customer experience. Our commitment to our people and their professional development is a recipe for success that has fueled our growth from a three-person shop in 1920 to one of today’s leading international suppliers of plumbing, water delivery and branded commercial interiors. If you’re ready for a new career challenge where everything you do will make a difference, talk to us about joining the Elkay family.

The Data Engineer we hire will perform a variety of project and technical tasks supporting Elkay’s analytics infrastructure, including data integration and ETL, database architecture and design, data prep, and reporting. Contribute to all aspects of the project lifecycle, including requirements gathering, design, development, testing, and deployment. Become familiar with Elkay’s business model and the various business functions that utilize Elkay’s analytics infrastructure, including sales, marketing, supply chain, operations, pricing, finance, and customer care. Keep abreast of trends, architectures, and tools in the analytics landscape and evaluate them for incorporation into Elkay’s analytics landscape. Learn quickly and juggle multiple tasks for various customers. Communicate complex technical problems effectively to management and to the business. Collaborate with other technical team members on solutions. Effectively prioritize support tasks with project work.

Specific duties include:
Design, develop and maintain data models, database architectures, and associated database objects in Snowflake, Oracle, and other database solutions such as Azure.
Design, develop, and maintain data integrations using Informatica Power Center, Informatica Integrated Cloud Services, and data prep tools.
Participate in or drive project activities such as requirements gathering, design, develop, test, and deploy.
Assist in the set-up of, and administer, on premise and cloud tools used in the Elkay analytics infrastructure.
Create and maintain necessary technical documentation, including requirements, design, and test documents.
Identify emerging trends, processes, and techniques impacting Elkay’s analytics infrastructure and make suggestions for incorporation of these into the analytics infrastructure.
Must have's:
A Master’s or Bachelor’s degree in Computer Science, MIS, engineering, or a related technical discipline is required.
5+ years of experience in data engineering, data warehousing, business intelligence, ETL on databases such as Oracle or SQL Server, and/or big data is required.
3+ years of experience in ETL/ data integration is required with 2+ years of experience in Informatica PowerCenter, job scheduling tools is required.
Working experience in Python/R/Scala, Snowflake is required.
Hands on experience in writing and understanding complex SQL (e.g. CTE’s others).
Thorough understanding of relational database design and best practices, including dimensional (star, snowflake) models is required.
A collaborative working style and ability to work well within the team and with business consumers is required.
Ability to clearly communicate to technical and non-technical audience by written and verbal is required.
Independent analytical, critical thinking, and problem-solving ability in complex technical environments is required.
Nice to have's:
Production experience in OBIEE, Oracle Analytics Cloud (OAC) and Tableau is nice to have.
Familiarity with big data technologies such as Microsoft Azure Data or AWS is nice to have.
EOE/M/F/D/V/SO",2.6,"Interior Systems
2.6","Downers Grove, IL",201 to 500 Employees,-1,Company - Private,Architectural & Engineering Services,Business Services,$50 to $100 million (USD)
Data Engineer,-1,"Data Engineer



Naperville,
IL

60563
Posted: 06/01/2020

2020-06-01
2020-10-05

Category: Support

Job Number: 13130

Job Description

Data Engineer

As a Data Engineer, you are familiar with the data warehousing technical components,

infrastructure, and their integration. You’ ll analyze large amounts of data, discover and solve real world

problems. You love the idea of being able to provide insight as well as presenting those insights. You are

responsible for high level design/architecture. You are comfortable fostering relationships with internal

business partners and other members of the development team.

Key Responsibilities

• Design, develop, and maintain modular code base to solve “ real” world problems.

• Conduct regular peer code reviews to ensure code quality and compliance following best

practices in the industry.

• Work in cross-disciplinary teams to understand client needs and ingest rich data sources.

• Utilize Big Data technologies in AWS

• Participate in process for pursuing innovations, target solutions, and extendable platforms for the firm’ s products.

Required Skills and Experience

• Qualified individuals possess the firm’ s attributes of being smart, curious, committed to

vision, passionate, fun/pleasant, an achiever and having a sense of urgency

• Minimum of three years of big data experience with multiple programming languages and

technologies, three years as a lead / team manager.

• Bachelor' s degree or master’ s degree from an accredited college/university in Computer

Science, Computer Engineering, or related field (i.e. math and physics);

• Ability to manage established relationships internally as well as with clients.

• Ability to communicate complex technical concepts succinctly to non-technical colleagues,

understand & manage interdependencies between all facets of a project.

• Ability to interface with clients; Must have demonstrated advanced proficiency in complex,

mature and sophisticated Design & Analysis technologies and solutions.

• Skilled ability to rapidly ingest, transform, engineer, and visualize data, both for ad hoc and

product-level (e.g., automated) data & analytics solutions.

• Experience with large-scale, AWS big data methods such as EC2, S3, EMR, Kinesis,

DynamoDB, and Redshift.

• Ability to work efficiently under Unix/Linux environment, having experience with source code

management systems like GIT.

• Strong knowledge with programming methodologies (version control, testing, QA) and agile

development methodologies.

• 3-5 years’ experience


Meet Your Recruiter

Kelly Hallgren

Apply Now:

Apply Online

Continue with LinikedIn

Continue with Facebook

Continue with Twitter

Apply Later
Send an email reminder to:

Email Address

Share This Job:


Login to save this search and get notified of similar positions.",4.9,"Talution Group
4.9","Naperville, IL",1 to 50 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,$1 to $5 million (USD)
R & D Engineer/Scientist II,"$46K-$103K
(Glassdoor Est.)","Innovate to solve the world's most important challenges


The future is what you make it.
When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who
make the things that make the future.
That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings smart and safe and even
making it possible to breathe on Mars.
Working at Honeywell isnt just about developing cool things. Thats why all of our employees enjoy access to dynamic
career opportunities across different fields and industries.
Are you ready to help us make the future?

Honeywell Performance Materials and Technology is a global leader
in providing customers with high-performance solutions, including fluorine
products; specialty films and additives; advanced fibers and composites;
intermediates; specialty chemicals; electronic materials and chemicals; and
technologies and materials for petroleum refining.

UOP LLC, headquartered in Des Plaines, Illinois, USA, is a leading
international supplier and licensor of process technology, catalysts,
adsorbents, process plants, and consulting services to the petroleum refining,
petrochemical, and gas processing industries. UOP is a wholly-owned subsidiary
of Honeywell International, Inc. and is part of Honeywell's Performance
Materials and Technology strategic business group. For more information, go to
www.uop.com.

An excellent career opportunity is currently available for an R&D Engineer/Scientist II in
the Aromatics & Derivatives Development group within UOP's Research and
Development organization located in Des Plaines, IL. This position
affords a unique opportunity to develop new catalyst, adsorbent, process and
equipment technology from concept to commercialization.

Position Responsibilities:
Develop expertise
in aromatic separations, particularly Simulated Moving Bed (SMB) adsorption
and hybrid separation systems
Participate on
multi-functional teams focused on the development of novel process,
catalyst, adsorbent and equipment technology in UOPs Aromatics &
Derivatives product line.
Coordinate the
design, planning and execution of experimental programs for new product
development (NPD) and capability projects.Analyze results and deliver data packages that meet
quality standards.
Coordinate
the development of models by collaborating with modeling specialists and
other team members
Provide support to
Technical Service in troubleshooting and optimizing performance on
commercial units.
Provide support to
the Sales Support and Engineering functions to improve the competitiveness
of commercial offerings and designs.
Contribute to the
innovation effort at Honeywell UOP by identifying novel process, catalyst,
adsorbent and equipment technology and filing invention disclosures

You must have:
Must have completed PhD degree in Chemical
Engineering by time of hire.
5+ years industry experience in simulated
moving bed (SMB), membrane or adsorptive separation (preferably
hydrocarbon separation)

We Value:
Strong understanding of chemical
engineering, catalysis and/or adsorbent fundamentals and their application
in refining and petrochemical process technology.
Experience in developing and executing
experimental plans including the use of statistical tools for data
analysis
Demonstrated ability to work independently
with a strong focus on delivering results and identifying alternative
solutions when challenges arise.
Excellent written and verbal communication
skills with the ability to concisely report results to a variety of
audiences and ensure key results, conclusions and decisions are well
documented.
Knowledge of Six Sigma concepts and their
application in managing risk and uncertainty.
Additional Information
JOB ID: req238828
Category: Engineering
Location: 50 E Algonquin Rd,Des Plaines,Illinois,60017-5016,United States
Exempt
Engineering (EMEA)

Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, or veteran status.",3.7,"Honeywell
3.7","Des Plaines, IL",10000+ Employees,1885,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD)
Senior Principal Data Scientist / Principal Data Scientist,"$124K-$195K
(Glassdoor Est.)","Company Description

ISO, a Verisk business, has been a leading source of information about property/casualty insurance risk since 1971. For a broad spectrum of commercial and personal lines of insurance, ISO provides statistical, actuarial, underwriting, and claims information and analytics; compliance and fraud identification tools; policy language; information about specific locations; and technical services. ISO serves insurers, reinsurers, agents and brokers, insurance regulators, risk managers, and other participants in the property/casualty insurance marketplace. To learn more about ISO please visit us at:  www.verisk.com/iso. We are proud to be a part of the Verisk family of companies!

At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.

Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.

But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.

It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.

At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.

At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work® Certification for the fourth consecutive year. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce. Verisk’s Statement on Racial Equity and Diversity supports our commitment to these values and affecting positive and lasting change in the communities where we live and work.

Job Description

· Leads a team of diverse team of data scientists.

· Coaches team members and manages team development.

· Engages in knowledge transfer to team members.

· Partners with internal teams (e.g. data engineering, development teams).

· Partner with project managers, directors, and other internal project leaders.

· Execute and monitor project plans for timely project completion; supporting all

stages of the analytic pipeline.

· Actively supports innovation, and the integration of new methods and technologies.

· Supports and/or tests new methodologies, software and data sources for continual

improvement of quantitative solutions.

· Supports and/or implements techniques to create high-performing models that comply with regulatory and privacy requirements and address business objectives and client needs.

· Utilizes statistical, mathematical, and machine learning theory and methodologies to design analytic architecture and solutions.

· Supports and/or participates in the creation of lucid documentation and reports (technical and non-technical) for internal and external clients.

· Presents analysis ideas, progress reports and results to internal managers, project owners, and executives.

· Completes all responsibilities as outlined on annual Performance Plan.

· Completes all special projects and other duties as assigned.

· Must be able to perform duties with or without reasonable accommodation.

Qualifications

· Minimum 7 years of insurance experience, focusing on the personal lines.

· Team-oriented with a track record of building strong internal and external unit partnerships.

· Experience leading cross-functional projects using advanced data analysis techniques.

· Strong logical and evidence-based problem solving. Critical thinking skills that support innovative,

creative solutions.

· Proficient across the stages of the data analytic pipeline, from ETL to results communication, supporting

knowledge transfer for team growth.

· Breadth and/or depth in the areas of feature engineering and selection methodologies, and machine

learning methodologies.

· Experience using programming, statistical, or machine learning languages.

· Experience with the management of large, complex datasets.

· Excellent verbal and written communication, and presentation skills (technical and non-technical).

Preferred:

· Graduate-level degree with concentration in a quantitative discipline such as business analytics,

economics, statistics, mathematics, operations research, or aligned discipline.

· Insurance and analytics experience with a carrier.

· Experience with R or Python.

· Experience with cloud computing environments (e.g. AWS)

#LI-AO1

Additional Information

Verisk Analytics is an equal opportunity employer.

All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.

http://www.verisk.com/careers.html

Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.

Consumer Privacy Notice",3.4,"Insurance Services Office
3.4","Buffalo Grove, IL",5001 to 10000 Employees,1971,Subsidiary or Business Segment,Insurance Carriers,Insurance,$500 million to $1 billion (USD)
SR STAFF SCIENTIST,"$46K-$100K
(Glassdoor Est.)","Job Title SR STAFF SCIENTIST
Position Number 8150697
Job Category University Staff
Job Type Full-Time
FLSA Status Exempt
Campus Maywood-Health Sciences Campus
Department Name DEPARTMENT OF CANCER BIOLOGY
Location Code Dept of Cancer Biology (06311A)
Is this split and/or fully grant funded? Yes
Duties and Responsibilities

The senior scientist will conduct research on a cancer health disparity research project entitled “SELENOF is a determinant of aggressive breast cancer disease in African American women”.
The scientist will conduct in vitro/cell-based experiments and in vivo experiments using mouse models to examine the role of the seleno-protein, SELENOF, in aggressive breast cancer disease.
The senior scientist will design experiments, collect data, co-ordinate the research efforts with our collaborator, analyze and present findings, and drive new research directions stemming from this project.
Evaluates need for new technologies and train laboratory staff on proper use of equipment.
Collaborates with faculty and other researchers
Participates in the preparation and writing of grant applications and reports and co-authors scientific research manuscripts
Operates and maintains a variety of scientific instrumentation which is essential to conducting the appropriate laboratory work. This would include equipment such as laboratory microscopes, centrifuges, incubators and autoclaves.
Employs safety measures in working with hazardous chemicals, laboratory animals, and radioisotopes as applicable.
Performs proper recording of procedures related to research studies in the laboratory and for the systematic organization of experimental data including the adequate.
Performs other duties as required.
Minimum Education and/or Work Experience

Required: Doctoral Degree (MD or PhD) Molecular Biology, Biology, Biochemistry, Physiology, Pharmacology, Microbiology, Immunology, other biomedical sciences.

Minimum 2-5 years of completed mentored postdoctoral scientific training and/or 7+ years of work experience.
Qualifications

Required: Doctoral Degree (MD or PhD)
Molecular Biology, Biology, Biochemistry, Physiology, Pharmacology, Microbiology, Immunology, other biomedical sciences.

Minimum 2-5 years of completed mentored postdoctoral scientific training and/or 7+ years of work experience.
Certificates/Credentials/Licenses

MD or PhD
Computer Skills

Familiarity with the Microsoft Office suite of programs is required.
Supervisory Responsibilities No
Required operation of university owned vehicles No
Does this position require direct animal or patient contact? Yes
Physical Demands Lifting, Standing, Repetitive Motions
Working Conditions Irregular Hours
Open Date 08/26/2020
Close Date
Special Instructions to Applicants
Quick Link for Posting http://www.careers.luc.edu/postings/14205",4.1,"Loyola University Chicago
4.1","Chicago, IL",1001 to 5000 Employees,1870,College / University,Colleges & Universities,Education,$500 million to $1 billion (USD)
People Analytics Data Engineer (Talent Insights Consultant Lead) - PS,"$86K-$144K
(Glassdoor Est.)","Your Talent. Our Vision. At Anthem, Inc., it’s a powerful combination, and the foundation upon which we’re creating greater access to care for our members, greater value for our customers, and greater health for our communities. Join us and together we will drive the future of health care.

This is an exceptional opportunity to do innovative work that means more to you and those we serve at one of America's leading health benefits companies and a Fortune Top 50 Company.

Do you love data? Do you enjoy the challenge of wrangling data and figuring out innovative data solutions to automate, combine, transform and model data? Then we’d love to talk to you about applying your skills to solve data challenges in on the Talent Insights team. This role is crucial to leveraging data (Inclusion & Diversity, Culture & Engagement, Productivity, Recognition, Performance, Talent, Attraction, Learning and Surveys) to develop strategy to attract, develop and retain Anthem’s workforce of the future.
People Analytics Data Engineer (Talent Insights Consultant Lead)

The preferred locations for this position are

Indianapolis, IN, Chicago, IL and Mason, OH

and is eligible for a remote schedule.
We are looking for a savvy Data Engineer to join our team of people analytics experts. The Data Engineer will be responsible for expanding our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing the HR data architecture to support critical people strategies that impact our associates and HR policies.

Responsibilities for People Analytics Data Engineer
Create and maintain optimal HR data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the HR data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using API, SQL and AWS technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with IT and HR stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Ensure associate and HR data is protected and secure.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Proven
ability to find innovative solutions to “figure things out.”
BA/BS
in computer science, business, math, industrial management/engineering or
related field.
Master’s
degree in related field preferred
10+
years of data collection and analysis experience; or any combination of
education and experience which would provide an equivalent background.
Advanced
knowledge of data tools including or similar to: SQL, Python, R, AWS, EC2, Redshift,
Alteryx, REST API, Java
Ability
to design and develop complex mappings, session, workflows, and identify areas
of optimizations.
A
successful history of manipulating, processing and extracting value from large
disconnected datasets.
Strong
analytic skills related to working with unstructured datasets.
Build
processes supporting data transformation, data structures, metadata, dependency
and workload management.
Strong
verbal/written communication, with ability to interact effectively with
individuals at all levels of responsibility and authority.
Strong
trouble-shooting and organizational skills and ability to work on multiple
projects simultaneously.
Strong
project management and organizational skills.
Experience
supporting and working with cross-functional teams in a dynamic environment.
Preferred
knowledge of HR processes and related data.
Preferred
knowledge of Peoplesoft, Oracle Analytics Cloud, Workday, Prism or similar HR
systems, business intelligence and analytics tools.
Anthem,
Inc. is ranked as one of America’s Most Admired Companies among health insurers
by Fortune magazine and is a 2018 Diversity Inc magazine Top 50 Company for
Diversity. To learn more about our company and apply, please visit us at
antheminc.com/careers. An Equal Opportunity Employer/Disability/Veteran",3.4,"Anthem
3.4","Chicago, IL",10000+ Employees,2004,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD)
Snowflake Data Engineer (remote),"$62K-$114K
(Glassdoor Est.)","Summary
We exist to help people achieve financial clarity. At Thrivent, we believe money is a tool, not a goal. Driven by a higher purpose at our core, we are committed to providing financial advice, investments, insurance, banking and generosity programs to help people make the most of all they’ve been given.

At our heart, we are a membership-owned fraternal organization, as well as a holistic financial services organization, dedicated to serving the unique needs of our clients. We focus on their goals and priorities, guiding them toward financial choices that will help them live the life they want today—and tomorrow.

Join our newly created Data Office as a Cloud Data Engineer! We have two positions open for mid and senior level within the data warehouse implementation team. We are in the early stages of a Snowflake cloud data warehouse implementation. You will be responsible for general ETL development and implementing new solutions. You will have the opportunity to help Thrivent modernize our hybrid technology solutions including the opportunity to work on modern warehousing and integration technologies. This role will require in depth understanding of cloud data integration tools and cloud data warehousing (Snowflake experience is critical), the ability to lead and execute to help drive and see tangible result.
Job Description


Job Duties and Responsibilities
Lead the implementation, execution, and maintenance of Data Integration technology solutions
Lead work to advance and support information management practices within business processes, applications and technology that underpin the EIM discipline (e.g. establishing data quality processes, performing data analysis, participating in technology implementation planning and verification to ensure successful installation of software and/or projects, implementing data integration processes, administering content, etc.).
Provide leadership for Data Integration tasks supporting projects
Lead the Management and proactive improvement of Thrivent's data by analyzing the current systems environment, leveraging proven practices, applications, technology, tools and platforms to support and enhance the information landscape.
Revenue generated
Budget responsibilities
Leads the delivery, support and maintenance of solutions with one or more business and technology areas.
Organizational impact results from mid-large sized projects
Required Job Qualifications
Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field
5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years prior lead experience.
Advanced in-depth knowledge of data integration concepts and tools
Strong organizational, analytical, critical thinking and leadership skills
Demonstrated leadership on mid-large-scale project impacting strategic partners
Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color, sex, gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state, or federal law. This policy applies to all employees and job applicants.

Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation, please let us know by sending an email to human.resources@thrivent.com or call 800-847-4836 and request Human Resources.",3.5,"Thrivent
3.5","Chicago, IL",5001 to 10000 Employees,1902,Nonprofit Organization,Insurance Carriers,Insurance,$5 to $10 billion (USD)
Data Engineer,"$48K-$94K
(Glassdoor Est.)","Job Description
Health Data & Management Solutions, Inc. (HDMS), a subsidiary of CVS/ Aetna, is a software development company on the cutting edge of health IT data solutions. Offering data warehouse, management and analysis tools for the healthcare industry, HDMS strives to improve and enhance its product suite for health plans, employers and providers through constant innovation. HDMS' web-based products and services provide flexible, high-value reporting tools that empower users to maximize the value of their health care data and support benefit decisions.

The Data Engineer supports the HDMS client use of ART, DART and Enlight data reporting applications by managing internal and external client issues toward resolution. Involve in monthly data load activities.
And tableau reporting

Participates and collaborates with subject matter experts and works with cross-functional teams to address problems using various technologies available within HDMS.

#LI-TS1

Fundamental Components
Responsible for refreshing the database on a monthly basis
Responsible for meeting 100% database refresh SLA
Maintaining the reporting environment using Tableau
Responsible for handling Support tickets with respect to Data Enquiry and for any Issue reporting
Responsible for working with current support resources to setup JIRA workflows for DART, Enlight & ART
Partner with lead and other teams to develop process and on-boarding documentation for Operations Support team using Confluence
Responsible for handling deployment activities
Help create and maintain communication/documentation repository for the JIRA application (confluence), where users can access generally available information about access, contents, and documentation
Perform data analysis support and work collaborate with current Ops support team
Communicate with end users and business stakeholders to take support incidents to closure, maintain SLAs, status reporting
Exposure to Tableau reporting tool to gain insight into the operations
Background Experience
Required
3+ years of experience with Relational Database Management Systems- RDBMS (ex. SQL, Oracle databases, etc.), data systems and data warehouses
3+ years of experience with Tableau development
3+ years of experience with bash shell scripts, Informatica, JIRA, Mongo DB, MySQL, Python, HIVE and/or Hadoop
Preferred:
Healthcare experience
Experience with the Software Development and Product Development Lifecycles
Experience with the software support ticketing systems and processes
Experience communicating statistical and technical ideas and results to non-technical clients
Experience with perform ETL data load job execution and monitoring in Spark/Scala
Experience in Exasol and AppDynamics is good to have
Experience using complex systems and solve challenging analytical
Strong reporting and experience using Excel, Access, Word and/or PowerPoint
Education
Bachelor's degree or equivalent experience

Percent of Travel Required
0 - 10%

Business Overview
Aetna, a CVS Health company, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We are committed to maintaining a diverse and inclusive workplace. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, gender, gender identity, age, disability or protected veteran status. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.",2.9,"CVS Health
2.9","Chicago, IL",10000+ Employees,1963,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
Data Engineer,-1,"Are you interested in building the future of healthcare and transforming the patient experience? Are you hopeful about what data and medical research can do to improve medicine? We’re looking for a Data Engineer to ensure PatientIQ remains on the forefront of using data to drive positive healthcare outcomes.

As a core member of the Analytics department, you will be in a very dynamic environment that works cross-functionally with all other departments, such Engineering, Sales, and Product. You will work on a broad array of problems that rely heavily on solid data engineering principles being in place: business intelligence, data science, and software engineering. We heavily value diligence, curiosity, and initiative, as those are key to unlocking the value of PatientIQ's data for our users and our decision-making. Your work will be impactful across the entire organization.

Role Responsibilities
Develop and maintain ETL infrastructure to support the ingestion of external data sources
Migrate client data into PatientIQ's platform per established service level agreements (SLA)
Define and implement key metrics for PatientIQ's data warehouse
Perform data quality assurance checks
Help scale PatientIQ's data strategy as the platform and business grows
Requirements

Ideal Qualifications
BS/MS in Computer Science, Engineering, Mathematics, or related field
Deep knowledge of SQL and at least one database technology
Proficient in Python
Experience with version control systems (e.g. git) and writing reusable and extensible code
Highly self-motivated with strong analytical problem-solving skills and attention to detail
Nice to Haves
Experience with workflow management systems such as luigi or airflow
Experience designing, building, and maintaining ETL infrastructure in a production setting
Experience in machine learning and/or business intelligence
Experience with ETL tools like Apache Kafka, Logstash, Segment, Informatica
Experience with cloud technologies such as AWS, Google Cloud Platform, or Azure
Experience working in Healthcare, Finance or another regulated industry
Benefits
Great Benefits - top-notch health, dental and vision insurance. Additional perks available including 401K.
We are Mission Driven - our team is motivated to solve complex problems, drive medicine forward, and ultimately improve patient outcomes.
True Idea Meritocracy - great ideas win out. We encourage all team members to challenge the status quo because our mission demands this.
Flexible Time Off - we trust you to take the time you need when you feel it is appropriate, given your workload and responsibilities. No need to track it or save up.
World-Class Team - we’re at the top of our industry because of our employees. They’re the best investment we can make, and we never forget that.
Fast Growing - we are building the largest platform for healthcare providers, industry partners, researchers, and others to collaborate on the mission to improve patient outcomes.",-1,PatientIQ,"Chicago, IL",-1,-1,-1,-1,-1,-1
Senior Data Engineer,"$77K-$147K
(Glassdoor Est.)","The Team: Morningstar’s mission is to create great products that help investors achieve their financial goals. For the Workplace group, that means building products and solutions that help employers maximize the value of their workplace retirement plans and put individuals on the path to better retirement outcomes. Workplace is a high-growth area for Morningstar that houses a diverse suite of technology and investment-based solutions. Our unique client base includes retirement plan providers, plan sponsors, plan consultants, and retirement plan advisors. By constantly evolving our solutions and solving our clients’ problems, we are well-positioned to help individuals achieve a better retirement. The workplace technology team is critical to achieving this mission and bringing it to life.

Responsibilities:
Develop efficient, high throughput data pipelines to push transactional data to the cloud
Build computation frameworks to get analytical insights from cloud-based data stores
Optimize storage to best serve business use cases
Define and implement the data life cycle per compliance requirements
Work with product managers and data scientists to understand the objectives of the data platform
Play an active role in data governance in collaboration with other Database Administrators and Applications/ Business teams
Design and develop for quick deployment with assistance from the Devops team
Requirements:
Bachelor’s degree in MIS, Computer Science, or a related field
Hands on ETL experience on Apache Spark or AWS Glue
Hands on experience with an AWS database, preferably Athena or RedShift
Experience using Python for data science
Strong knowledge of database design principles
Strong knowledge of serverless big data offerings on AWS
Very good understanding of CI/CD pipelines and infrastructure as code
Knowledge/experience adding quality checks to data pipelines
7+ years of experience in design, development, and maintenance of cloud-based data systems
3+ years of experience on Microsoft SQL server
Good communication skills
Ability to work independently, communicate effectively, and produce superior results
Experience working in Scrum-based methodologies Ability to write clean code and provide insights in code reviews
002_MIMLLC Morningstar Investment Management LLC Legal Entity",4.1,"Morningstar
4.1","Chicago, IL",5001 to 10000 Employees,1984,Company - Public,Financial Analytics & Research,Finance,$1 to $2 billion (USD)
"Medical Laboratory Scientist - Immunology/Special Chemistry, Full-time, Evenings","$21-$30 Per Hour
(Glassdoor Est.)","Company Description

At Northwestern Medicine, every patient interaction makes a difference in cultivating a positive workplace. This patient-first approach is what sets us apart as a leader in the healthcare industry. As an integral part of our team, you'll have the opportunity to join our quest for better healthcare, no matter where you work within the Northwestern Medicine system. At Northwestern Medicine, we pride ourselves on providing competitive benefits: from tuition reimbursement and loan forgiveness to 401(k) matching and lifecycle benefits, we take care of our employees. Ready to join our quest for better?

Job Description

The Medical Laboratory Scientist reflects the mission, vision, and values of NM, adheres to the organization’s Code of Ethics and Corporate Compliance Program, and complies with all relevant policies, procedures, guidelines and all other regulatory and accreditation standards.

A Medical Laboratory Scientist performs test procedures in a clinical laboratory and conveys the results to the physician or designee in an accurate and timely manner for the purpose of patient diagnosis and treatment

Responsibilities:

Technical responsibilities:
Performs all aspects of pre-analytic workflow appropriate for the specific laboratory section to ensure orders are entered correctly, specimens collected are appropriate for the test ordered and are correctly processed/transported.
Verifies order where necessary
Verifies non-patient information (e.g., collection time) according to established protocol.
Handles unresolved orders, troubleshoots where needed.
Verifies with physicians and/or nurses prior to laboratory information system (LIS) order entry to resolve unclear, duplicate or otherwise ambiguous orders.
Verifies specimens for add-on tests are available and acceptable and generates add-on test orders.
Recognizes when fraud and abuse compliance issues require adjustments to the test order
Collecting, receiving and processing of specimens:
Verifies specimens are correctly and completely labeled upon receipt. Evaluates specimens for appropriateness and takes necessary corrective action. Appropriately documents unacceptable specimens and proper notifications as needed.
Prioritizes specimen processing based on established priorities.
Aliquots specimens according to established protocols.
Performs all aspects of analytical testing appropriate for the specific laboratory section, following established written protocols and standard operating procedures (SOP)
Maintains test system integrity:
Performs preventive maintenance on instruments/equipment in a timely fashion according to defined schedule.
Verifies reagents and supplies meet defined acceptability criteria upon receipt and prior to use; takes action to ensure unacceptable items are removed from use.
Ensures that sufficient reagents and supplies necessary for test performance are available. Notifies senior staff when minimum inventory level is encountered.
Performs and records all necessary quality control (QC) required for test system performance.
Evaluates QC results and takes necessary corrective actions according to established protocol.
Performs specimen preparation:
Performs any necessary pretest specimen preparation according to protocols (e.g., microbiology plating, cell cultures, filtering, extraction, separation, elution, absorption, etc.)
Transfers or ships specimens to approved testing locations according to SOPs
Performs tests:
Prioritizes testing based on assignment or established priorities, completes testing within defined turn-around-times (TAT).
Recognizes the need for and follows any age-specific protocols
Responds effectively to changes in the workflow by coordinating a simultaneous series of tests when needed or adjusting work to incorporate STAT tests or fluctuations in work volume.
Monitors daily workflow and priorities to assure meeting service levels.
Performs technical review and interpretation:
Reviews results for completeness, correctness, and consistency within defined test system
Evaluates test results/reactions and provides accurate interpretations as appropriate to include correlation with, and integration of, other patient data as necessary.
Performs visual interpretation/identifications as appropriate.
Recognizes unusual test results/interpretations and completes indicated reflex testing or other follow-up actions.
Follows established notification protocols for critical values, phone/fax/e-mail results requests, abnormalities.
Troubleshoots and solves problems:
Recognizes test system performance problems and takes necessary corrective actions
Recognizes when unresolved problems need to be escalated and takes necessary follow-up action.
Prints pending logs and follows-up to ensure pending tests are completed or cancelled when appropriate.
Post-test specimen storage:
Stores specimens and related materials (blood, slides, tissues, etc.) according to protocols for location and duration.
Retrieves specimen and related materials when needed
Post-analytical responsibilities:
Performs all aspects of the post-analytical workflow appropriate for the specific laboratory section to ensure accurate results are reported within established time frames, specimens are retained appropriately, test results and/or current status are available upon inquiry, and billed charges are correct for testing performed.
Verifies and reports results:
Verifies results according to procedure.
Performs computer functions necessary for releasing results.
Generates written reports according to established protocol.
Reviews electronic or printed reports when applicable, recognizes problems and escalates according to protocol.
Amends reports:
Corrects erroneous reports and amends reports according to procedure
Responds to inquiries:
Responds to requests for information according to established protocol for confidentiality and release of information
Recognizes when unresolved inquiries need to be escalated and takes action
Stores documents and records:
Stores documents and records according to established protocol.
Charge capture/billing:
Performs billing and/or enter credits for tests and services when applicable.
Recognizes billing problems and escalates accordingly
Universal responsibilities:
Ensures quality of operations:
Follows written standard operating procedures (SOP).
Operates instruments/equipment according to protocol.
Uses computers according to established protocol; follows downtime procedures as required.
Performs required quality system responsibilities
Meets proficiency and competency standards of the department.
Participates in the training of new employees and students
Performs operational review of new SOPs.
Participates in new test development, validations and implementation.
Attends at least one personal development session per year
Performs other duties as assigned, or as needed, to ensure continued quality operations
Ensures safety of operations:
Follows all required safety procedures, uses personal protective equipment (PPE) appropriate for tasks performed.
Maintains cleans and organized work area
Provides service excellence:
Answers telephone when needed, using NM telephone etiquette
Maintains patient confidentiality including protected health information (PHI)
Assists patients, visitors and other contacts whenever need occurs
Qualifications

Required:
Bachelor’s Degree in Medical Technology, Medical Laboratory Science, Clinical Laboratory Science, Chemistry, Biology, or Allied Health qualifying the applicant to take the American Society for Clinical Pathology (ASCP) certification examination.
General MLS or MT (ASCP) Certification or eligible or
Categorical BB, C, H or M (ASCP) Certification or eligible
If eligible, must be ASCP certified within one year of employment
Additional Information

All your information will be kept confidential according to EEO guidelines.",3.9,"Northwestern Memorial Healthcare
3.9","Chicago, IL",5001 to 10000 Employees,1965,Hospital,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD)
Environmental Scientist - Compliance,"$29K-$45K
(Glassdoor Est.)","Description

Burns & McDonnell’s regional office in Chicago is looking for an Environmental Scientist to facilitate construction permit compliance, stormwater compliance, environmental inspections and federal/state/local permitting on a variety of projects. Burns & McDonnell is a 100% employee-owned firm ranked on FORTUNE’s List of 100 Best Companies to Work For and voted as a Best Place to Work in numerous cities across the United States.

This position can sit in either our Downers Grove or downtown Chicago offices.

The Environmental Scientist – Compliance position will work with the office’s Natural & Cultural Resources group within our Environmental Services Global Practice to perform the following duties:
Conduct environmental compliance audits, prepare permitting applications and analyze environmental data for various types of projects, including renewable projects, high-voltage transmission line routing, oil and gas facilities, power generation construction activities and water treatment facilities.
Environmental compliance audits; stormwater pollution prevention plan (SWPPP) preparation and Best Management Practices (BMP) inspections, environmental site assessments; and report and permit writing.
Work includes a mix of field assessments, report/permit preparation and travel.
Ensure compliance with company and site safety policies
Other duties as assigned.
Qualifications
Bachelor's degree in Environmental Science or related natural science degree from an accredited program is required. Minimum of a 3.0 GPA.
2 years of relevant professional experience is preferred. Environmental consulting experience preferred.
Strong analytical and problem-solving skills.
Ability to clearly communicate both verbal and written technical information.
Basic knowledge of environmental site assessment methods, environmental compliance and compliance audits, environmental permitting process (i.e., basic knowledge of waters and wetland permitting, threatened and endangered species permitting and cultural resources), and work in the ArcGIS desktop environment.
Previous consulting experience related to environmental compliance inspections
Must be proficient in the use of computer software (i.e., Microsoft Word, Excel, PowerPoint). Experience with a GPS unit in the field is a plus.
Valid driver's license required. In addition, must meet standards to qualify for and maintain the Company's vehicle driving privileges as outlined in the Company's Motor Vehicle Safety Policy.
Ability to work 50% or more in the field, and overnight travel to field locations.
EEO/Minorities/Females/Disabled/Veterans

Job Environmental

Primary Location US-IL-Downers Grove

Other Locations US-IL-Chicago

Travel: Yes, 50 % of the Time

Req ID: 201004

#LI-JJ #ENS",3.8,"Burns & McDonnell
3.8","Chicago, IL",5001 to 10000 Employees,1898,Company - Private,Architectural & Engineering Services,Business Services,$2 to $5 billion (USD)
Assistant Staff Scientist/Botanist,"$30K-$70K
(Glassdoor Est.)","Cardno is seeking a Delineator/Botanist Assistant Staff Scientist.

Responsibilities include but are not limited to:

> Assisting technical specialists in the field with biological (wildlife/avian), wetland delineations and botanical surveys.
> Conducting wetlands and botanical studies and compiling/summarizing data and information under direction of project managers and/or technical specialists.
> Preconstruction botanical and wetland surveys and construction monitoring activities to ensure consistency with permit requirements
> Entering and managing technical data and preparing graphs and tables, as needed
> Assisting with preparation of technical reports, plans, and permit applications

Minimum Qualifications:

> Bachelor’s degree in botany preferred, other degrees are acceptable if it includes experience in plant identification including: environmental studies, natural resource management, planning or related field
> Excellent oral and written communication skills
> Strong proficiency in Microsoft Word and Microsoft Office Excel
> Willing and able to travel to field sites and other Cardno office locations
> Ability to work well independently and with a diverse, multi-disciplinary team in a fast-paced, team
oriented work environment
> Strong time management and follow-through skills, with the ability to simultaneously work on multiple tasks/projects and meet project deadlines
> Self-motivated with strong initiative
Skills with botanical identification in Midwest, preferably in Chicagoland area.

Desired Qualifications:

> Terrestrial biology, botanical, water quality, and/or geomorphic field experience
Wetland delineation experience
> Knowledge of, and experience with, Midwest flora and wildlife/avian species and habitats
> Experience with floristic quality assessments (FQA) preferred
> General knowledge of various environmental permitting processes, especially permits required under Section 401 and 404 of the Clean Water Act
> GIS experience
> Ability to carry 50 pounds, often in uneven terrain
> Ability to traverse wet and/or rugged terrain in diverse, sometimes inclement weather conditions
> Must be able to work in an environment where safety is at the forefront of all operations
>Positive and energetic attitude
> Flexible, and team-oriented
> Detail oriented and resourceful

Job Type: Full-time",3.1,"Cardno
3.1","Monee, IL",5001 to 10000 Employees,1945,Company - Public,Architectural & Engineering Services,Business Services,$500 million to $1 billion (USD)
Analytical Chemistry Scientist,"$35K-$57K
(Glassdoor Est.)","Company Description
Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.
In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.
In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description
Employee Responsibilities:
This position performs all assigned chemistry techniques with minimal supervision.
This position will demonstrate a good understanding of GMP and scientific principals and their cause and effect on scientific outcomes as practice of GMP/GLP is routine.
This position authors and may review other scientist's protocols, reports, specifications and test methods and will present results at team meetings with interpretation.
Qualifications
The Ideal Candidate would possess:
Experience in small molecule product development
Proficiency performing all assigned laboratory techniques.
Experience independently developing analytical methods on a variety of analytical techniques and instrumentation, primarily HPLC.
Experience independently performing method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Experience with notebook review
Experience generating, analyzing and presenting scientific data at team meetings. Explain cause and effect relationships and may propose additional experiments to prove/disprove hypotheses.
Experience assisting with leading projects from analytical/formulation/process development from lab scale to exhibit manufacture.
Experience authoring technical protocols, reports and specifications for raw materials, APIs, excipients, drug products as well as analytical test methods.
Ensure adherence to highest quality and efficiency standards in laboratory operations
Demonstrate strong communication skills and initiative
Minimum Qualifications:
M.S. in in Chemistry, analytical chemistry, Chemical Engineering or related field and 3 - 5 years of small molecule product development experience in analytical testing of pharmaceutical samples. OR BS in in Chemistry, analytical chemistry, Chemical Engineering or related field and 5 - 10 years of small molecule product development experience in analytical testing of pharmaceutical samples.
Excellent verbal and written technical communication skills.
Ability to work independently with minimal supervision
Experience in use of electronic laboratory notebooks is a plus
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information
Position is full-time, Monday - Friday 8:00am - 5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",3.4,"Eurofins
3.4","Lake Forest, IL",10000+ Employees,1987,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (USD)
Senior Research and Development Scientist,-1,"Working for Sara Lee:

Sara Lee Frozen Bakery became a stand- alone company in 2018 when it was purchased by Kohlberg and Company (private equity) from Tyson Foods. We have the feel of start up in many ways, though we are an established brand with a strong customer and consumer base. If you have an entrepreneurial spirit, continually seek process improvements and a strong sense of customer service, then this is the right type of environment for you.

Our vision is to be the world’s most beloved bakery by creating irresistible foods, growing with our customers, and delivering value for all. We believe that each of us has unique points of difference and experience to offer. We believe that there is always a better way, and we will never be satisfied with status quo. We believe simplicity enables speed. We believe in integrity above all. We live for food, and we “wow” consumers and customers through collaboration and innovation.

Summary

The Senior Research and Development Scientist plays a critical role in helping us become the world’s most beloved bakery by creating our new product solutions necessary to unlocking added value for our customers. This role has responsibility for developing new product formulations, portfolio renovation and customer product solutions across Foodservice, Retail and In-Store Bakery. The ideal candidate brings key skills, experience and knowledge necessary for the development of high quality bakery products. She/he must work from ideation to commercialization, from benchtop samples to final production, and from raw material to finished product specification. This role requires experience with ingredient functionality, formula design and ability to collaborate with other key internal and external business partners (Project Management, Marketing, Innovation, Supply Chain, Packaging, Food Safety and Quality, Procurement, Sales, and Finance).



Essential Duties and Responsibilities:

• Develop, plan, coordinate and conduct product development initiatives to meet timeline expectations

• Provide technical leadership to prepare formula design and bench development for new or renovated bakery products

• Develop understanding of ingredients, products, processes and packaging to support development of new product platforms

• Utilize ingredient and process knowledge, experimental design and data interpretation tools to make technically sound recommendations

• Lead product cuttings and plant trials to support sales samples, scale-ups, and other needs

• Create, implement and maintain final product specifications, recipes and production guides

• Support the development of capability expansion by recognizing process improvements or equipment needs

• Work closely with Marketing, Project Management (PMO), Innovation, Insights and Sales to problem solve new product solutions

• Build strong relationships and collaborate with suppliers, 3rd party partnerships, Technical Services, Engineering and other colleagues to optimize new product development processes

Qualifications:

• Bachelor’s or Master’s degree in Food Science or related field with at least 3 years of relevant product formulation experience

• Previous experience developing and manufacturing bakery products is highly preferred

• A self-starter and doer with a sense of urgency to work fast but not rush while managing multiple projects

• Good working knowledge of experimental design and product development protocols, including formulation, process development, regulatory requirements, systems/data entry, sensory and consumer testing methodology

• Basic computer skills required; competence in Microsoft Word, Excel, and PowerPoint

• Ability to communicate effectively (verbal and written) and collaborate with teams

• Ability to problem solve development obstacles

• Ability to work in food allergen areas (Nuts, Dairy, Egg, etc.)

• Ability to travel 25-35% of the time

Sara Lee Frozen Bakery provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",4.7,"Sara Lee Frozen Bakery,LLC
4.7","Oak Brook, IL",1001 to 5000 Employees,2018,Company - Private,Food & Beverage Manufacturing,Manufacturing,Unknown / Non-Applicable
"AI/ML , Data Engineer",-1,"Job Title: AI/ML , Data Engineer

Location: Chicago, IL

Duration: 12 months

Job Description:

Mandatory Skills:

Knowledge and experience in API development, AI/ML, SageMaker, Data Lake, Data Analytics, Cloud Monitoring and Analytics,

Strong cloud programming skill with experience in API and AWS Lambda functions or any other scripting languages like Python / Bash using Python & Node.js

Good understanding in using AWS CLI, Cloud formation, Terraform, Ansible with troubleshooting experiences

Strong knowledge of Cloud Security practices and IAM Policy preparation for AWS

Good to have:

Knowledge on Experience with implementing containers using AWS container services cloud native container orchestrators in AWS

Strong working experience with AWS services as EC2, RDS, API Gateway, Lambda, DynamoDB, Elastic Cache, ECS, ALB/NLB Load Balancers, S3, EBS, VPC Networking , Secret Manager, Parameter Store âetc.

Ability to participate in fast-paced DevOps and System Engineering teams within Scrum agile processes

Experience with DevOps tools will be an added advantage

Know-how of working with Python / Bash scripting will help",-1,softsnippets,"Chicago, IL",-1,-1,-1,-1,-1,-1
Environmental Scientist or Engineer/Project Manager (Mid Level),"$38K-$59K
(Glassdoor Est.)","Are you ready to take the next step in your career? Do you want to do meaningful work that improves quality of life? At Tetra Tech, you will work with high-performing teams who are passionate about using their expertise to find solutions to complex problems in water, environment, infrastructure, resource management, energy, and international development. Tetra Tech is a leading provider of high-end consulting and engineering services for projects worldwide. We combine the resources of a global, multibillion dollar company with local, client-focused delivery in more than 400 locations around the world. We are Leading with Science® to provide sustainable and resilient solutions for our clients.

Tetra Tech is seeking a Mid-Level Environmental Scientist or Engineer/Project Manager for our Chicago, IL office. This is a full-time position for an individual with a strong technical background in environmental site investigation and remediation who is interested in career growth and business development opportunities while managing and supporting a variety of public and private sector environmental projects.
Qualified candidates evaluated will have about 5-10 years of environmental consulting or related experience. Knowledge of federal, state, and local regulations and previous experience with hazardous waste site investigations and remediation is required. Previous private or public sector client management and business development success and project management experience is desirable. Applicable experience, training, and certifications with asbestos, lead-based paint, air quality, low-level radioactive waste, GIS, hydraulic and hydrologic modeling, or emergency response (e.g., ICS) is preferred. Candidate must possess strong analytical, organizational, client management, and communication skills (both written and verbal). Must also be highly motivated, customer focused and work well in a team environment. Proficiency with MS Word and Excel also required. Hydraulic and hydrologic modeling, GIS data analysis and geostatistics, coding (VBA, Python, etc.), and data management skills preferred. Must be able to drive a vehicle, and pass a motor vehicle records check.

B.S. or M.S. degree in engineering, science, or related environmental field required. 40-hr HAZWOPER training certification with 8-hr refresher required. Heavy lifting of field sampling and other equipment will be required. Candidate must also meet physical demands of hazardous waste site work. Travel is required and varies based on project requirements; may include weekend travel and work. Candidate may be exposed to various weather conditions while performing field work outside.

At Tetra Tech, we provide a collaborative environment that supports individual performance, innovation, and creativity. We are proud to offer competitive compensation and benefits. Learn more by visiting http://www.tetratech.com/en/benefits. For more information on our company, please visit our website at www.tetratech.com. To apply, please submit your resume and cover letter on the Careers portion of our website at www.tetratech.com/careers.

We thank all applicants for their interest; however only those selected for an interview will be contacted. Tetra Tech is committed to creating a diverse environment and is proud to be an Equal Opportunity Employer. We invite resumes from all interested parties including women, minorities, veterans and persons with disabilities.

Tetra Tech is a VEVRAA federal contractor and we request priority referral of veterans for available positions. EOE AA M/F/Vet/Disability - No calls or agencies

Additional Information



Organization: 103 EMI",3.6,"Tetra Tech
3.6","Chicago, IL",10000+ Employees,1966,Company - Public,Architectural & Engineering Services,Business Services,$2 to $5 billion (USD)
Data Engineer / Backend Developer - Validate Health,-1,"Interested in being part of a small founding team, so you can see your direct impact on improving the healthcare industry? Want to be one of the rockstars building an innovative product from the ground up?

COMPANY

Validate Health is an early stage healthcare analytics company on a mission to improve accessibility to healthcare and industry transition to value based care. Validate was founded by a prominent healthcare actuary advising on matters of health economics policy and the entrepreneur-in-residence at the U.S. Department of Health & Human Services. Validate is building its analytics platform that encompasses the accumulated wisdom of its experts and clients, in order to empower medical organizations to manage their financial risk, while improving the clinical outcomes of their patients. We're looking for talented and driven contributors to join our team and be a part of this important moment in the healthcare industry.

JOB DESCRIPTION

As a Data Engineer , you’ll get to play a key role in shaping the delivery of powerful data-driven products that enable sustainable value-based healthcare models.

▪ Leverage scalable data processing tools, open source data science ecosystem and cloud technologies: Python, Anaconda stack (Jupyter Notebook, NumPy, Pandas, Dask, MatPlotLib/Bokeh, SciPy, Scikit-Learn), Postgres, Airflow, TensorFlow, Spark and several AWS services (EC2, RDS, S3, Lambda, Redshift) to...

▪ Automate the processing of patient-level healthcare transactions, third party data sources and aggregated public health data

▪ Ingest, transform, cleanse and augment internal and external data assets. Build algorithms for fuzzy matching, de-duplication and rule-based de-identification.

▪ Implement mathematical models using Python data science tools. Generate automated simulations and forecasts of large number of scenarios. Fully indulge your love for math, statistics and logical problem solving.

▪ Generate insightful and innovative visualizations and output reports that tell a “data story” and support your findings.

▪ Perform data modeling and performance optimization on relational databases. Write SQL for defining database objects and performing manipulations.

▪ Continuously learn by investigating and adopting new technologies. We love to experiment with cool technologies!

The right candidates brings aptitude, attitude, curiosity and grit that's shines in a startup environment. If you're more into an established corporate environment, this is not the role for you.

Requirements

The ideal candidate would have:

▪ Computer Science and/or Mathematics degree with history of academic or independent accomplishments.

▪ Strong aptitude for the following subject areas and ideally a demonstrated portfolio of relevant projects:

— Python language and libraries (Knowledge of additional languages beneficial.)

— SQL and relational database concepts

— Linux command line and shell utilities

— Mathematics, statistics and data science concepts

▪ Understanding of scalable application development, object oriented development and test driven development is beneficial, but not required.

▪ Desire to be an expert in the healthcare industry is a strong plus.

PREFERENCES

FIELDS OF STUDY

All Statistics, Mathematics, Software Design, Data Science, Data Mining, Computer Science, and Computer Programming majors

WORK AUTHORIZATION REQUIREMENTS

US work authorization is required, but the employer is willing to sponsor the right candidate.

TO APPLY

(Currently accepting only alumni and recent graduates.)

Send your resume to careers+1871@ValidateHealth.com with “VH Data Engineer via 1871” as the subject line. Include a note explaining what makes you particularly interested in Validate Health and this position specifically. Feel free to include any links that you feel speak to who you are and your capabilities, such as to LinkedIn, GitHub, publications, or portfolio. Specify when you're available to start work and any visa sponsorship requirements. Doing these steps will improve your chances of being considered. Looking forward to talking!

Benefits

Fun team environment and gratifying work. Remote work friendly and no travel. Stock options.

Contact:

David Portnoy",-1,1871 Member Companies,"Chicago, IL",-1,-1,-1,-1,-1,-1
Senior Scientist - Ophthalmology,-1,"A Biotechnology company is looking to add a Senior Researcher to join their Ophthalmology team. This candidate will have the desire to manage projects, develop & execute experiments, & oversee the work of other scientists & technicians.

Day to Day:
Lead scientist on multiple preclinical ophthalmology drug discovery and development programs
Subject matter expert and internal resource regarding ocular diseases and disorders, eye anatomy and physiology, and ophthalmology clinical and preclinical assessment techniques
Optimize & create assays related to gene editing
Develop, validate and implement assays as required to accomplish research goals
Design & execute experiments related to ophthalmology
Analyze and present data within the organization
Cross train into different areas of R&D analysis regarding molecular biology
Requirements:
PhD in a relevant science
4+ years of of relevant experience in biotechnology or pharmaceutical environment
Doctorate or post-doctoral studies must be in the context of ophthalmology or vision
Strong expertise in mRNA and DNA isolation (cells/tissue) and quantification techniques
A strong understanding of the theory behind their research and experience
Excellent written and oral communication skills",4.3,"Momentum Staffing Group
4.3","Chicago, IL",51 to 200 Employees,2008,Private Practice / Firm,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$1 to $5 million (USD)
Director of Data Science,-1,"Role: Director of Data Science

Reporting to: COO

About Us:

We deliver the most advanced and flexible learning experience for certification, credentialing, test prep, continuing education, and training. Our cloud-based learning platform is designed to help education and training organizations deliver a highly engaging and effective learning experience for users who are trying to advance their careers. We incorporate the latest in learner-centered technology, including personalization, gamification, data science, usability and omni-channel delivery.

We're sitting in a pivotal time in the BenchPrep history, having achieved significant growth year-over-year and nearly doubling in employee size! The number of learners on our cloud-based learning platform has reached 6 million in 2019, up 30 percent versus the prior year.

We're committed to helping students learn better, and that starts in our own office.

About the role:

We are looking for a dynamic and talented Director of Data Science to build a new function here at BenchPrep, leading all of our Data Science and R&D efforts, creating a strategy to discover new insights hidden in the vast amounts of data we collect. You will work across the company with our product team, engineers, and strategy team; working toward a common goal of solving problems and finding creative solutions through data-driven decisions.

As our Director of Data Science, you will:
Oversee all of BenchPrep's data research and analytics efforts, including data strategy, data governance, and outcome modeling.
Build a brand new data science team from scratch, with the responsibility of identifying and developing talent on your team
Lead the discovery process with customers to begin identifying and solving business problems
Identify opportunities within the organization to increase efficiency and quality of our product using data-driven solutions, applying sound business judgement to quantify the impact of potential solutions
Conceptualize and plan leading-edge analytic and quantitative tools and modeling techniques to support our clients, helping them gain insight and improve decision-making
Drive customer impact by building out, operationalizing and managing scalable data science projects
Review internal and external analytical techniques, identifying what data is available and relevant and source the necessary data
Partner with our Product Management and Technology team to integrate prototypes and solutions into production systems
You should have:
Masters in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)
6+ years of experience working in data science
3+ years of experience managing, Data Scientists
Universal data outcome modeling experience and usage of python, R, spark and corresponding packages
Proven data literacy the ability to describe use cases and outcomes, data sources and management concepts across business and technology domains
Deep experience in integrating complex processes and information strategies, including technology planning and execution and policy development and maintenance
Life at BenchPrep:

We work at BenchPrep because we're dedicated to the mission and each day have an opportunity to be challenged and learn. We work hard, eat well, and have lots of fun. Culture is our lifeline at BenchPrep. We celebrate our people, both professionally and personally. We focus on flexibility - both in work/life balance, but also everyday in operating with agility. We care about professional development so much that we offer employees $1,200 annually to build their skills. And of course, even though we're currently remote, our inclusive work culture has been built to withstand challenges, as we stay connected and ensure all of our employees have the resources and tools they need to stay successful in this new environment. It's no wonder we were selected in Inc's Best Workplaces of 2020 and Crain's 2020 Best Places to Work in Chicago lists.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We are looking for high performing and motivated professionals who are excited about the chance to leverage technology to impact the lives of millions of learners.",4.5,"BenchPrep
4.5","Chicago, IL",51 to 200 Employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable
Bi Data Engineer,-1,"COMPANY OVERVIEW


Recently named one of Entrepreneur magazine's Top 100 Cannabis Leaders, Cresco Labs is one of the largest vertically-integrated multi-state cannabis operators in the United States. Cresco is built to become the most important company in the cannabis industry by combining the most strategic geographic footprint with one of the leading distribution platforms in North America. Employing a consumer-packaged goods (""CPG"") approach to cannabis, Cresco's house of brands is designed to meet the needs of all consumer segments and includes some of the most recognized and trusted national brands including Cresco, Remedi and Mindy's, a line of edibles created by James Beard Award-winning chef Mindy Segal. Sunnyside*, Cresco's national dispensary brand is a wellness-focused retailer designed to build trust, education and convenience for both existing and new cannabis consumers. Recognizing that the cannabis industry is poised to become one of the leading job creators in the country, Cresco has launched the industry's first national comprehensive Social Equity and Educational Development (SEED) initiative designed to ensure that all members of society have the skills, knowledge and opportunity to work in and own businesses in the cannabis industry.

MISSION STATEMENT


At Cresco, we aim to lead the nation's cannabis industry with a focus on regulatory compliance, product consistency, and customer satisfaction. Our operations bring legitimacy to the cannabis industry by acting with the highest level of integrity, strictly adhering to regulations, and promoting the clinical efficacy of cannabis. As Cresco grows, we will operate with the same level of professionalism and precision in each new market we move in to.

JOB SUMMARY

Cresco Labs is looking for a BI Data Engineer to join our corporate team. This individual will focus on designing and building data infrastructure, data visualization, and analytics services. The BI Data Engineer will develop data pipelines, manage tables and data sets, and other objects to house the data.

CORE JOB DUTIES
Design and build dynamic dashboards to support our unique requirements for visualization, security, data access, etc.
Collect, manage analyze and visualize large data sets while maintaining ETL pipelines
Implement data parsing and data cleansing to improve overall data quality and productivity
Collaborate with business stakeholders and other BI Engineers in identifying opportunities to build and analyze metrics
Manage progress, goals, and insights with business leadership
Stay up to data on data science trends and developments
Support the VP of Software Engineering through data analysis and reporting
Automate and document processes to ensure efficiency
REQUIRED EXPERIENCE, EDUCATION AND SKILLS
4+ years in a strong analytical background with a bachelor's degree in computer science or a similar field
Practical experience buildings out and implementing dashboards with Tableau or other business intelligence and analytics software
Expert knowledge in database technologies and web technologies
Excellent written and verbal communication skills
High level organization and structure
ADDITIONAL REQUIREMENTS
Must be 21 years of age or older to apply
Must comply with all legal or company regulations for working in the industry
Cresco Labs is an Equal Opportunity Employer and all applicants will be considered without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran, or disability status.",2.0,"Cresco Labs
2.0","Chicago, IL",501 to 1000 Employees,2013,Company - Public,"Health, Beauty, & Fitness",Consumer Services,Less than $1 million (USD)
"Medical Laboratory Scientist - Hematology, Full-time, Nights","$56K-$77K
(Glassdoor Est.)","Technical responsibilities: o Performs all aspects of pre-analytic workflow appropriate for the specific laboratory section to ensure orders are entered correctly, specimens collected are appropriate for the test ordered and are correctly processed/transported. o Verifies order where necessary o Verifies non-patient information (e.g., collection time) according to established protocol. o Handles unresolved orders, troubleshoots where needed. o Verifies with physicians and/or nurses prior to laboratory information system (LIS) order entry to resolve unclear, duplicate or otherwise ambiguous orders. o Verifies specimens for add-on tests are available and acceptable and generates add-on test orders. o Recognizes when fraud and abuse compliance issues require adjustments to the test order o Collecting, receiving and processing of specimens: Verifies specimens are correctly and completely labeled upon receipt. Evaluates specimens for appropriateness and takes necessary corrective action. Appropriately documents unacceptable specimens and proper notifications as needed. Prioritizes specimen processing based on established priorities. Aliquots specimens according to established protocols. o Performs all aspects of analytical testing appropriate for the specific laboratory section, Following established written protocols and standard operating procedures (SOP) o Maintains test system integrity: Performs preventive maintenance on instruments/equipment in a timely fashion according to defined schedule. Verifies reagents and supplies meet defined acceptability criteria upon receipt and prior to use; takes action to ensure unacceptable items are removed from use. Ensures that sufficient reagents and supplies necessary for test performance are available. Notifies senior staff when minimum inventory level is encountered. Performs and records all necessary quality control (QC) required for test system performance. Evaluates QC resultsand takes necessary corrective actions according to established protocol. o Performs specimen preparation: Performs any necessary pretest specimen preparation according to protocols (e.g., microbiology plating, cell cultures, filtering, extraction, separation, elution, absorption, etc.) Transfers or ships specimens to approved testing locations according to SOPs o Responsible for all aspects of analytical testing appropriate for the specific laboratory section o Maintains test system integrity: Examines preventative maintenance logs on instruments/equipment in a timely fashion and follows up as needed. Verifies reagents and supplies meet defined acceptability criteria upon receipt and prior to use; takes action to ensure unacceptable items are removed from use. Responsible for inventory maintenance and supply ordering in designated section. Performs and records all necessary quality control (QC) required for test system performance. Review and evaluates QC results in designated sections and take necessary corrective actions according to established protocol. o Performs tests: Prioritizes testing based on assignment or established priorities, completes testing within defined turn-around-times (TAT). Recognizes the need for and follows any age-specific protocols Responds effectively to changes in the workflow by coordinating a simultaneous series of tests when needed or adjusting work to incorporate STAT tests or fluctuations in work volume. Exercises independent judgement in the performance of technical responsibilities Monitors daily workflow and priorities to assure meeting service levels. o Performs technical review and interpretation: Develops and maintains a higher level of expertise in the specific areas of responsibilities. Reviews results for completeness, correctness, and consistency within defined test system Evaluates test results/reactions and provides accurate interpretations as appropriate to include correlation with, and integration of, other patient data as necessary. Performs visual interpretation/identifications as appropriate. Recognizes unusual test results/interpretations and completes indicated reflex testing or other follow-up actions. Follows established notification protocols for critical values, phone/fax/e-mail results requests, abnormalities. Evaluates instruments and test systems and makes recommendations for acquisition to senior management. o Troubleshoots and solves problems: Recognizes test system performance problems and takes necessary corrective actions. Recognizes when unresolved problems need to be escalated and takes necessary follow-up action. Reviews pending logs and follows-up to ensure pending tests are completed or cancelled when appropriate. Performs advanced troubleshooting and repair. Calls for field service when necessary and is familiar with contractual terms of maintenance agreements. o Post-test specimen storage: Ensures that specimens and related materials (blood, slides, tissues, etc.) are stored according to protocols for location and duration with necessary documentation Post-analytical responsibilities: o Performs all aspects of the post-analytical workflow appropriate for the specific laboratory section to ensure accurate results are reported within established time frames, specimens are retained appropriately, test results and/or current status are available upon inquiry, and billed charges are correct for testing performed. o Verifies and reports results: Verifies results according to procedure. Performs computer functions necessary for releasing results. Generates written reports according to established protocol. Reviews electronic or printed reports when applicable, recognizes problems and escalates according to protocol. o Amends reports: Corrects erroneous reports and amends reports according to procedure o Responds to inquiries: Responds to requests for information according to established protocol for confidentiality and release of information Recognizes when unresolved inquiries need to be escalated and takes action o Stores documents and records: Stores documents and records according to established protocol. o Charge capture/billing: Performs billing and/or enter credits for tests and services when applicable. Recognizes billing problems and escalates accordingly Universal responsibilities: o Ensures quality of operations: Assumes delegated responsibilities in the absence of a coordinator. Responsible for regulatory compliance in designated section. Follows written standard operating procedures (SOP). Operates instruments/equipment according to protocol. Uses computers according to established protocol; follows downtime procedures as required. Performs required quality system responsibilities including initiating Quality Investigation Reports. Meets proficiency and competency standards of the department and assists in the competency assessment of technical and support staff. Participates in the training of new employees and students Performs operational review of new SOPs. Presents continuing education programs Assists in new test development, validations and implementation. Attends at least one personal development session per year. Assists the coordinator and manager in monitoring the operations of designated areas to ensure service standards and financial goals are met. Contributes in developing and is responsible for implementation of technical goals and standards. Performs other duties as assigned, or as needed, to ensure continued quality operations o Information Systems: Ensures integrity of Laboratory Information Systems (LIS) by following established protocols and participates in the maintenance and enhancements of the LIS. May oversee/accomplish instrument computer software upgrades/updates Demonstrates expertise in Information Technology; uses application to streamline operations and facilitate service monitoring and data collection. o Ensures safety of operations: Follows all required safety procedures, uses personal protective equipment (PPE) appropriate for tasks performed, and assumes a proactive role in laboratory safety. Maintains cleans and organized work area o Provides service excellence: Answers telephone when needed, using NM telephone etiquette Maintains patient confidentiality including protected health information (PHI) Assists patients, visitors and other contacts whenever need occurs",3.9,"Northwestern Medicine
3.9","Chicago, IL",5001 to 10000 Employees,1965,Hospital,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD)
DATA ENGINEER,"$69K-$122K
(Glassdoor Est.)","Job Overview

We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities for Data Engineer:

- Create and maintain optimal data pipeline architecture,

- Assemble large, complex data sets that meet functional / non-functional business requirements.

- Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.

- Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.

- Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.

- Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.

- Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.

- Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.

- Work with data and analytics experts to strive for greater functionality in our data systems.

Qualifications for Data Engineer:

- Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.

- Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.

- Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.

- Strong analytic skills related to working with unstructured datasets.

- Build processes supporting data transformation, data structures, metadata, dependency and workload management.

- A successful history of manipulating, processing and extracting value from large disconnected datasets.

- Working knowledge of message queuing, stream processing and highly scalable ‘big data’ data stores.

- Strong project management and organizational skills.

- Experience supporting and working with cross-functional teams in a dynamic environment.

Knowledge, Skills, Abilities, and other Characteristics:

Qualifications:
5+ years of experience in a Data Engineer role, who has attained a Master’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Industry-recognized certifications in data engineering, data architecture, informatics, machine learning, SQL
Experience with health care data, claim data, EMR systems (Meditech preferred), X.12 data formats, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with Microsoft and AWS cloud services: Azure, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience with statistical programming languages: R, Stata, SAS, etc.
Experience with architectural concepts and schemas: TOGAF, MITA, Star schema, etc.
Skilled in problem-solving with strong attention to detail.
Excellent customer service skills and the ability to react diplomatically and patiently to internal and external customers.
Excellent follow-up skills paired with the ability to multi-task and determine root causes.
Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures.
Strong response time to phone calls, emails and customer requests.
Adhere to department policies and standards.
Ability to work independently under minimal supervision in stressful situations and meet deadlines.
Ability to prioritize, plan, and organize tasks based upon user requirements.
Ability to multi-manage multiple projects utilizing best practices based on departmental priorities.
Ability to multi-manage multiple projects utilizing best practices based on departmental priorities.
MINIMUM WORK EXPERIENCE:

Bachelors Degree, 5 years of relevant experience including leading projects or 8 years of relevant experience including leading projects and developing teams .

REQUIRED LICENSES, CERTIFICATES, REGISTRATIONS:

MCSE or equivalent is strongly desired but not required",3.1,"Sinai Health System
3.1","Chicago, IL",1001 to 5000 Employees,1918,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD)
"Associate Data Engineer, Zoro","$63K-$120K
(Glassdoor Est.)","Company Summary:
Zoro.com is an eCommerce company that sells business supplies, equipment, and tools—but we’re much more than just a website. We’re a team of people who win and lose together (we prefer winning!). Since 2011, Zoro has been working hard to make it easy for our customers to purchase everything they need to make their businesses go. Zoro currently offers over 3 million products, fast and free shipping, no-hassle returns, and exceptional customer service. We’ve grown quickly in a short time, recently surpassing 400 team members and reaching annual revenue of over $500 million. Add to that our award-winning culture—we were named a Great Place to Work for 2019-20, among other accolades—and we think Zoro is a pretty amazing place to work and grow.
Primary Function:
Imagine what you could help us achieve as an Associate Data Engineer!
The Associate Data Engineer will work under the guidance of other data professionals and collaborate with various IT groups, business partners and external service providers to design, develop, operationalize and support critical components of our cloud-native data platform, the “Zoro Data Platform (ZDP)”.
Duties and Responsibilities:
Participate in Requirements Gathering: work with key business partner groups (e.g. Product Mgt) and other Data Engineering personnel to understand department-level data requirements for ZDP
Design Data Pipelines: work with other Data Engineering personnel to design new data pipelines for flowing data from various internal and external sources into the ZDP using standard and other pre-established frameworks and interfaces
Build Data Pipelines: leverage standard toolset and ZDP-specific data frameworks to develop ETL/ELT code to move data from various internal and external sources into the ZDP
Support Data Quality Program: work with Data QA Engineer to identify automated QA checks and associated monitoring & alerting to ensure ZDP maintains consistently high quality data
Support Operations: triage alerts channeled to you and remediate as necessary
Technical Documentation: leverage templates provided and create clear, simple and comprehensive documentation for your development
Key contributor to defining, implementing, enhancing and supporting:
Data Services
Data Dictionary
Tool Standards
Best Practices
Data Lineage
User Training
Skills & Responsibilities:
Competent programmer with focus on ELT/ ETL design/development using Python
Intermediate-level proficiency in SQL with demonstrable expertise in analytical data management tasks using SQL
Familiarity with Cloud environment development & operations (e.g. AWS, GCP)
Preference for candidates with prior working knowledge in:
Google Cloud Platform (GCP) and associated services; e.g. BigQuery, GCS, Cloud Composer, Dataproc, Dataflow, Dataprep, Cloud Pub/Sub, Data Catalog, Datalab other
Other important Zoro tools: Apache Airflow (scheduler), Bitbucket and git (version control), Stackdriver (ops monitoring), Opsgenie (alert notification), Docker
Real-time data replication/streaming tools
Data Modeling
Excellent verbal and written communications
Strong team player
Success Criteria
Strong analytical thinking and problem solving skills
Superior communication and business-technical interaction skills
Positive, “get it done” attitude with a high degree of ownership and responsibility
Ability to work with a high level of autonomy on critical tasks within an agile framework
To qualify, you must possess the following skills:
Bachelor’s degree in computer science, management information systems, or a related discipline
2+ years hands-on ETL/ELT design/development experience or Masters degree on a related field
Key resource on team(s) / projects that have delivered successful analytics platforms / products

Final note: We share a commitment to our Zoro values – Win & Lose Together (We prefer winning!), Take Ownership, We Are Transparent, and Aspire to be Customer-Obsessed. Everything we do at Zoro is centered around delighting our customers. It's a natural extension of our company culture and how we care for each other. We believe when we act in ways that are consistent with these values, we can solve any technical challenge that lies ahead of us. As a Zoro employee, you can expect to work with smart, energetic people, learn something every day, and be valued for your perspective.

Zoro is an Equal Opportunity Workplace and an Affirmative Action Employer.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.


Apply Now",3.7,"Zoro Tools
3.7","Buffalo Grove, IL",10000+ Employees,1927,Company - Public,Wholesale,Business Services,$10+ billion (USD)
"Medical Laboratory Scientist - Hemostasis, Full-time, Evenings","$21-$30 Per Hour
(Glassdoor Est.)","TECHNICAL RESPONSIBILITIES
Performs all aspects of pre-analytic workflow appropriate for the specific laboratory section to ensure orders are entered correctly, specimens collected are appropriate for the test ordered and are correctly process/transported.
Verifies order where necessary.
Verifies non-patient information (e.g., collection time) according to established protocol.
Handles unresolved orders, troubleshoots where needed.
Verifies with physician and/or nurses prior to LIS order entry to resolve unclear, duplicate or otherwise ambiguous orders.
Verifies specimens for add-on tests are available and acceptable and generates add-on test orders.
Recognizes when fraud and abuse compliance issues require adjustments to the test order.
Collecting, receiving and processing of specimens
Verifies specimens are correctly and completely labeled upon receipt. Evaluates specimens for appropriateness and takes necessary corrective action. Appropriately documents unacceptable specimens.
Prioritizes specimen processing based on established priorities.
Aliquots specimens according to established protocols.
Recognizes when fraud and abuse compliance issues require adjustments to the test order.
Performs all aspects of analytical testing appropriate for the specific laboratory section.
Maintains test system integrity:
Performs preventative maintenance on instruments/equipment in a timely fashion according to defined schedule.
Verifies reagents and supplies meet defined acceptability criteria upon receipt and prior to use; takes action to ensure unacceptable items are removed from use.
Ensures that sufficient reagents and supplies necessary for test performance are available. Notifies senior staff when minimum inventory level is encountered.
Performs and records all necessary quality control (QC) required for test system performance.
Evaluates QC results and takes necessary corrective actions according to established protocol.
Performs specimen preparation:
Performs any necessary pretest specimen preparation according to protocols (e.g., microbiology plating, cell cultures, filtering, extraction, separation, elution absorption, etc.).
Performs tests:
Prioritizes testing based on assignment or established priorities, completes testing within defined turn-around-times.
Recognizes the need for and follows any age-specific protocols.
Responds effectively to changes in the workflow by coordinating a simultaneous series of tests when needed or adjusting work to incorporate STAT tests or fluctuations in work volume.
Monitors daily workflow, overseeing and adjusting staff assignments (e.g., breaks, tasks) and priorities, to meet service levels.
Performs technical review and interpretation:
Reviews results for completeness, correctness, and consistency within defined test system.
Evaluates test results/reactions and provides accurate interpretations as appropriate to include correlation with, and integration of, other patient data as necessary.
Performs visual interpretation/identifications as appropriate.
Recognizes unusual test results/interpretations and complete indicated reflex testing or other follow-up actions.
Follows established notification protocols for critical values, phone/fax results requests, abnormalities.
Troubleshoots and solves problems:
Recognizes test system performance problems and takes necessary corrective actions.
Recognizes when unresolved problems need to be escalated and takes necessary follow-up action.
Prints pending logs and follows-up to ensure pending tests are completed or cancelled when appropriate.
Post-test specimen storage:
Stores specimens and related materials (blood, slides, tissues, etc) according to protocols for location and duration.
Retrieves specimen and related materials when needed.
Performs all aspects of the post-analytic workflow appropriate for the specific laboratory section to ensure accurate results are reported within established time frames, specimens are retained appropriately, test results and/or current status are available upon inquiry, and billed charges are correct for testing performed.
Verifies and reports results:
Verifies results according to procedure.
Performs computer functions necessary for releasing results.
Generates written reports according to established protocol.
Reviews printed reports when applicable, recognizes problems and escalates according to protocol.
Amends reports:
Corrects erroneous reports and amends reports according to procedure.
Responds to inquiries:
Responds to requests for information according to established protocol for confidentiality and release of information.
Recognizes when unresolved inquiries need to be escalated and take action.
Stores documents and records:
Stores documents and records according to established protocol.
Charge capture/billing:
Performs billing and/or enters credits for tests and services when applicable.
Recognizes billing problems and escalates accordingly.
Universal responsibilities:
Ensures quality of operations:
Follows written standard operating procedures.
Operates instruments/equipment according to protocol.
Uses computers according to established protocol; follows downtime procedures as required.
Performs required Quality System responsibilities.
Meets competency standards of the department.
Participates in the training of new employees and students.
Performs operational review of new procedures.
Participates in new test development and implementation.
Attends at least one personal development session per year.
Performs other duties as assigned, or as needed, to ensure continued quality of operations.
Ensures safety of operations:
Follows all required safety procedures, uses personal protective equipment appropriate for tasks performed.
Maintains clean and organized work area.
Provides service excellence:
Answers telephones when needed, using NMH telephone etiquette.
Maintains patient confidentiality.
Assists patients and other contacts whenever need occurs.",3.9,"Northwestern Medicine
3.9","Chicago, IL",5001 to 10000 Employees,1965,Hospital,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD)
Translational Bioinformatics Scientist,"$59K-$80K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

We are seeking an independent and motivated Translational Bioinformatics Scientist to join our Research group.

What You'll Do:

You will work on an interdisciplinary team to develop new computational and statistical approaches to support precision medicine applications. The successful candidate will work in an interdisciplinary team, carry out data analysis, apply and develop best-in class algorithms that directly address important biological and clinical questions, and provide strategy and input on new products and services.

Qualifications:
Advanced degree (Masters or PhD) in bioinformatics, statistics, biostatistics, epidemiology, oncology, genomics, human genetics, computer science, mathematics or a related field, or 5+ years experience working with genomic and clinical data
Experience working with electronic health information and related software systems
Experience in genetic analysis of complex disease and familiarity with common bioinformatics software and file formats
Experience with statistical modeling, data mining and/or machine learning
Experience with Python, R, or other modern programming language
Excellent communications skills
A collaborative mindset
Nice-to-haves:
Experience with polygenic risk scores and population genetics
Experience with clinical risk modeling and implementation
Experience with version control (Git) and collaborative software development and testing
Experience with AWS technical stack (EC2, S3, Redshift, etc.)
Experience with Real World Evidence (RWE) and Real World Data (RWD) topics and techniques
Experience with relational databases
Record of meaningful scientific publications",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Research Data Engineer,"$71K-$96K
(Glassdoor Est.)","Title: Research Data Engineer

Location: Chicago, NYC, London

Company Overview:

Our client is a leading global market maker across a broad array of fixed income and equity securities. Their world-class capabilities position them to meet the liquidity demands of their diverse group of institutional clients in all market conditions. In partnering, their clients, including asset managers, banks, broker-dealers, hedge funds, government agencies and public pension programs are able to gain a powerful trading advantage and are better positioned to meet investment goals.

Our client stands among the most trusted and impactful financial firms of our time, and the best and brightest are drawn to this culture of meritocracy that prizes insightful research and analytical rigor.

The team makes its mark every day from offices around the world.

Data Engineers are tasked with building next generation data analysis platforms. Our data analysis methods evolve on a daily basis and we empower our engineers to make bold decisions that support critical functions across the business.

Key Responsibilities:
Design, develop, test, and deploy elegant software solutions across the firm to support critical investment decisions
Partner with business leaders, quantitative researchers and technologists to define priorities and deliver custom solutions
Skillset Requirements:
A deep passion for working with data and developing software to address data processing challenges
Minimum of a bachelor’s degree in Computer Science or equivalent experience with good software design and engineering skills
Proficiency within one or more programming languages including Python, C, C++, R and/or JavaScript is a plus
Proficiency with multiple data platforms including RDBMS, NoSQL, MongoDB, Spark, Hadoop
Experience with some of the following areas: Distributed Computing, Natural Language Processing, Machine Learning, Cloud Platform Development, Networking, and/or REST Service Development
Good analytical and quantitative abilities
Demonstrated ability to quickly learn new technologies and skills
Ability to manage multiple tasks and thrive in a fast-paced team environment",-1,Galaxy Technology Hires LLC,"Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Data Engineer,-1,"Immediate remote opportunities for Senior Data Engineers to leverage your expertise delivering large-scale Azure data systems to upskill in the Adobe Experience Platform.

As a Senior Data Engineer, you will be part of a data transformation program to support a well known retail organization responsible for the following:

Leading, designing, developing, and delivering large-scale Azure data systems, data processing, and data transformation projects.

Executing technical feasibility assessments and project estimates for moving databases and data processing to Azure.

Designing and advocating solutions using modern cloud technologies, design principles, integration points, and automation methods.

Mentoring and sharing knowledge with customers as well as providing architecture reviews, discussions, and prototypes.

Participating in overall engagement from strategy, assessment, migration, and implementations.

Working with customers to deploy, manage, and audit best practices for cloud products.

Expertise we need you to bring:

Demonstrated experience designing, implementing, and supporting enterprise-grade technical solutions in the cloud for meeting complex business data requirements.

Experience with Databricks and using Spark for data processing.

Experience with Azure Data Factory – ADF.

Advanced experience with different query languages (i.e. T-SQL, PostgreSQL, PL-SQL).

Experience designing and building data marts, warehouses, customer profile databases, etc.

Experience with data modeling, table design, and mapping business needs to data structures.

Experience with Azure Data Lake, Azure SQL Data Warehouse, and Cosmos DB are a plus.

Experience with Data Management Gateway, Azure Storage Options, Stream Analytics, and Event Hubs is a plus.

Experience with other cloud-based big data architectures is a plus.

Experience guidelines:

5 to 10 years of professional experience in the information technology industry.

BS in Computer Science or equivalent education/professional experience is required.

Strong and innovative approach to problem solving and finding solutions.

Excellent communicator (written and verbal, formal, and informal).

Flexible and proactive/self-motivated working style with strong personal ownership.

Ability to multi-task and prioritize under pressure.

Ability to work independently with minimal supervision as well as in a team environment.",-1,The Talent Source Inc,"Chicago, IL",1 to 50 Employees,-1,Unknown,-1,-1,Less than $1 million (USD)
"Director, Cloud Data Engineer","$142K-$242K
(Glassdoor Est.)","Director, Cloud Data Engineer
375 Hudson St, New York, NY 10014, USA
Full-time
Company Description
Positioned at Publicis Groupe's core, Epsilon is a leader in interaction management, empowering brands to transform ordinary customer experiences into meaningful, human experiences. Through a connected suite of products and services, Epsilon combines leading-edge identity management, industrial strength data and technology expertise with big brand acumen gained over five decades working with the industry’s top brands. Our human-powered, data-led marketing delivers unmatched depth, breadth and scale to help brands turn meaningful human interactions into exceptional business outcomes.
Job Description
Role Summary:

The Epsilon PeopleCloud Solutions team is responsible for developing Epsilon’s proprietary technology platform (Epsilon PeopleCloud) that brings technically robust, innovative and differentiable data solutions leveraging internal investments in data and technology. The team owns the development and maintenance of data science development environments, proprietary libraries and packages, and the development of machine intelligent services for product applications.

As a Director of Cloud Data Engineering, you will apply your technical knowledge and expertise as a lead member of the team, collaborating with our data science, data partnerships and product team leads to define then deliver cloud native data integrated solutions and services across the Epsilon PeopleCloud ecosystem. You will design and build highly dynamic, data-driven solutions while keeping current on the latest developments and trends in data technologies. You will have hands-on experience with cloud platforms and big data, combined with a working knowledge of data science and ML/AI trends.

Day-to-Day Responsibilities include:
Lead the design and development of technical solutions utilizing cloud data services that bridge data engineering best practices with data science ML/AI services
Provide thought leadership partnering with product and engineering teams to innovate future solutions
Contribute to the product development and platform engineering roadmaps
Design for then enforce data security and data privacy mandates in a global environment
Maintain expertise and develop team awareness and adoption of relevant emerging technologies
Mentor and lead a distributed data engineering team and leading peer-level design reviews
Manage and communicate project risks and challenges
Minimum Qualifications:
B.S. in Mathematics, Computer Science/Engineering or Statistics
5-10 years of data engineering, software development or cloud-based services experience
Minimum 3 years leading and mentoring distributed engineering teams
Applied experience with deploying cloud-based data solutions and utilizing cloud services
Applied experience working with a range of database and data integration technologies (e.g. MySQL, Hadoop distros, BigQuery, DataFlow, Redshift)
Applied experience architecting and developing micro services designs and API services
Applied experience working with DevOps frameworks and CI (e.g. Jenkins, Ansible, Docker, etc.)
Applied experience programming developing packages in Python, Java, Scala or R
Applied experience in designing ETL solutions leveraging open source, product or custom solutions
Experience working with cloud functions, micro-services and serverless designs
Experience in designing and deploying automated data validations solutions
Experience in designing data solutions leveraging enterprise identity and access management services
Applied knowledge of developing compliant solutions with global data security and privacy regulations
Proficiency in building Machine Learning data pipelines and automation
Demonstrated ability to communicate solutions in terms of technical and functional design documents.

Additional Information
Great People, Deserve Great Benefits
We know that we have some of the brightest and most talented associates in the world, and we believe in rewarding them accordingly. If you work here, expect competitive pay, comprehensive health coverage, and endless opportunities to advance your career.

Epsilon is an Equal Opportunity Employer. Epsilon’s policy is not to discriminate against any applicant or employee based on actual or perceived race, age, sex or gender (including pregnancy), marital status, national origin, ancestry, citizenship status, mental or physical disability, religion, creed, color, sexual orientation, gender identity or expression (including transgender status), veteran status, genetic information, or any other characteristic protected by applicable federal, state or local law. Epsilon also prohibits harassment of applicants and employees based on any of these protected categories.

Epsilon will provide accommodations to applicants needing accommodations to complete the application process.

#LI-AD1

REF17431X
Job Location
I'm interestedPrivacy PolicyCookies Settings",3.5,"Publicis Groupe
3.5","Chicago, IL",10000+ Employees,1926,Company - Public,Advertising & Marketing,Business Services,$5 to $10 billion (USD)
Senior Data Scientist,-1,"Senior Data Scientist
Job Title: Senior Data Scientist
Job Location: Buffalo Grove, IL or Downtown Chicago, IL (NO OUT OF STATE CANDIDATES WILL BE CONSIDERED)
Job Duration: Full-time, Direct Hire
Requirements: Python, SQL, R, e-commerce knowledge, Data Science methodologies, Problem solving with Data Science

Currently fully-remote due to COVID, On-premise work to resume when back to ""normal""

We are an e-commerce company specializing in business supplies and equipment. While other companies around the US are slowing down and hurting, we are proud to say that we are growing! And as such, we need more people to help us grow even more. We are looking for a Senior Data Scientist to join our team and help us take our data usage to the next level. If you have the skills we need, apply now!

What You Will Be Doing
Lead data science projections from idea to completion (develop the idea, create a plan, layout the methodology, collaborate with other departments, execute the plan, and provide recommendations based on results)
Work closely with other data science team members to build algorithms, codes, evaluate research, deliver new outputs
Build predictive statistical models to support business initiatives
Document data science processes and codes, and develop strategies to ensure they are safe and secure
Use presentations and data visualizations to communicate results and findings to various levels of the company's leadership
What You Need for this Position
Must have skills/background:
5+ years in data mining, database marketing, marketing analytics, or statistical modeling
Experience using analytics or data science at an E-commerce or internet retailer
Deep understanding of problem solving with Data Science methodologies
Experience taking complex problems and breaking them down into actionable tasks (idea to completion)
5+ years of programming in Python
3+ years experience in SQL
Bonus skills:
3+ years programming in R
Deploying models in the cloud (Google Cloud Platform, AWS)
Online marketing models, Google Analytics
Strong business acumen and understanding of how departments interact
Experience with BI visualization tools like Looker or Tableau
Experience in Machine Learning or Natural Language Processing
What's In It for You
Strong starting salary ($110-130k)
Healthy year-end bonus
Top tier health benefits
Generous PTO
401k safe harbor
Work from home opportunities
So, if you are a Senior Data Scientist with the required experience, apply today!
Applicants must be authorized to work in the U.S.

CyberCoders, Inc is proud to be an Equal Opportunity Employer
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",4.2,"CyberCoders
4.2","Chicago, IL",201 to 500 Employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Data Science Manager,"$110K-$176K
(Glassdoor Est.)","About the Job:
The Kenshoo Data Science team is hiring!
The role of the Data Science team is to empower customers to leverage Kenshoo's suite of algorithmic products such as bid optimizers and to identify/validate new directions for these algorithmic products.
The ideal candidate has mentored data scientists and has a strong grasp of statistical models, excellent analytical skills and the ability to coherently describe complex mathematical concepts to a layman audience. This role will report to the Senior Director of Data Science.
Responsibilities:
Develop and mentor a team of data scientists who use a variety of statistical and machine learning tools to effectively address client needs and foster a culture of constructive engagement across the company.
Represent Kenshoo Data Science in conversations with clients and partners. Advocate for our algorithmic solutions, data driven approaches and view of digital marketing; and provide consultation how to best set up and leverage these products.
Be part of our broader Product team to provide both client feedback and analysis to help guide data driven decisions to improve our products.
Build and guide the building of POCs ( proofs of concept ) to solve for clients needs using machine learning tools.
Perform analysis of customer/publisher data using ML and statistical methods.

Skills/Attributes Required:
Good working knowledge of statistical modeling.
Strong analytical and problem solving capabilities.
Strong SQL capabilities - experience querying data from relational DB engines.
Extensive knowledge of Python and its various packages.
Strong written and verbal communication skills - be able to take complex math and analytical concepts and explain to working teams and client executives.
Strong teamwork - internally with our teams as well as with clients.
Knowledge in machine learning algorithms such as linear/logistic-regression, Neural-Networks and others would be a strong plus.
Education/Experience:
BS/BA, ideally in a relevant field to data science.
5+ years in consulting/analytical roles.
2+ years in leading/supporting analytical teams.
MS/PhD in Machine Learning, Data Science, Statistics, Information Systems, Business Intelligence a plus but not required.
Having worked in internet marketing analytics at a top advertiser a plus.
Equal Employment Opportunity:
Kenshoo, Inc. is an equal opportunity employer. We strongly encourage and seek applications from women, people of color, and bilingual and bicultural individuals, as well as members of the lesbian, gay, bisexual, and transgender communities. Applicants shall not be discriminated against because of race, religion, sex, national origin, ethnicity, age, disability, political affiliation, sexual orientation, gender identity, color, marital status, or medical condition including acquired immune deficiency syndrome (AIDS) and AIDS-related conditions. Also pursuant to the San Francisco Fair Chance Ordinance, we encourage and will consider for employment qualified applicants with arrest and conviction records.
Kenshoo, Inc is an E-Verify employer.
Applicants with Disabilities:
Reasonable accommodation will be made so that qualified disabled applicants may participate in the application process. Please advise in writing of special needs at the time of application.


Region:
USA",3.8,"Kenshoo
3.8","Chicago, IL",501 to 1000 Employees,2006,Company - Private,Internet,Information Technology,Unknown / Non-Applicable
Computational Scientist-Text Analysis,"$32K-$60K
(Glassdoor Est.)","Please make sure to read the job posting in its entirety as it reflects both the University roles and responsibilities, followed by the specific description.
Department
86755 Research Computing Center
About the Unit
The University of Chicago Research Computing Center (RCC), a unit in the Office of Research and National Laboratories (RNL), provides high-end research computing resources to researchers at the University of Chicago. It is dedicated to enabling research by providing access to centrally managed High Performance Computing (HPC), storage, and visualization resources. These resources include hardware, software, high-level scientific and technical user support, and the education and training required to help researchers make full use of modern HPC technology and local and national supercomputing resources. The Office of Research and National Laboratories oversees the conduct of sponsored research, research program development, multi-institutional research institutes, national laboratory board, and contract management functions. RNL supports the development and coordination of research-related communications and educational programs at The University of Chicago. RNL oversees the management of two Department of Energy contracts for Argonne National Laboratory and Fermi National Accelerator Laboratory. When combined with the Lab R&D budgets, the office oversees approximately $1.4 billion in sponsored research. RNL works closely with individual scholars, departments, and divisions to encourage, seed, and coalesce research across the University, Argonne, and Fermilab campuses.
Job Family
ResearchResponsible for all aspects of research projects and research facilities. Plans and conducts clinical and non-clinical research; facilitates and monitors daily activities of clinical trials or research projects. Directs engineering and technical support activities to develop and maintain tools and computational methods needed to gather and analyze data.
Career Track and Job Level
Research ComputingCreates research focused user interfaces web front-ends, back-end services that scale, and integrate scientific workflows that automate and accelerate the scientific output of multi-institutional collaborative projects. This role involves software development in support of research projects involving data acquisition, ingestion, and integration from heterogeneous sources (metadata extraction from a corpus of diverse data sets, both structured and unstructured data).P2: Requires knowledge and experience in own discipline; still acquiring higher-level knowledge and skills. Builds knowledge of the organization, processes and customers. Solves a range of straightforward problems. Analyzes possible solutions using standard procedures. Receives a moderate level of guidance and direction.
Role Impact
Individual Contributor
Responsibilities
The job develops software to support the data acquisition, ingestion, and integration for research projects. Assists in the development of user interfaces and scalable back-end services to automate and accelerate the scientific output of multi-institutional research projects.1) Participates in the product development life cycle, providing professional assistance to the design of front-end applications and database systems back-end schema. Analyzes high-level system specifications and makes sure that all application development standards are met., 2) Develops and presents technical training materials and web-based documentation. Ensures timely systems support and updates. Assists in conducting information security assessments and risk analysis of computing environment., 3) Evaluates past and present technologies to help develop new tools. Ensures all the new tools have been through quality control reviews., 4) With a moderate level of guidance, provides hardware, user and application level authentication and authorization. Implements modern web authentication methods such as XACML, SAML, OAuth2, Shibboleth, and LDAP directory server administration. Applies theoretical expertise and innovation to create or apply new technology, such as adapting principles for applying computers to new uses., 5) Performs other related work as needed.

Job Summary

1) The Research Computing Center (RCC) is partnering with the Harris School of Public Policy to hire a highly motivated Computational Scientist, Text Analysis to work closely with faculty and researchers at The University of Chicago. The person in this position serves as a technical domain expert supporting and advising faculty on text analysis, including natural language processing. The Computational Scientist may also hold a concurrent Lecturer appointment in an academic department and teach up to two courses per year. The successful candidate will join a team of Computational Scientists who are playing a key role in scientific computing support at the University of Chicago.

Unit-Specific Responsibilities

1) Develop, maintain and support text analysis pipelines that include data collection, data management, data digitization, data analysis and documentation.

2) Implement NLP algorithms, summarize findings and generate study results and plots for research projects.

3) Independently propose and execute practical solutions to research challenges; develop, install and test scientific software in support of research goals.

4) Prepare and contribute contents to manuscripts and presentations; create and present tutorials, hands-on workshops and documentation.

5) Communicate with various agencies and partners to apply for and manage data access; manage data collection and storage.

6) Work closely with faculty to identify, develop, and implement useful computational methods and resources that support or advance their research.

7) Keep abreast of new developments in High Performance Computing, data science, Machine Learning and deep learning; and be proactive in introducing them to the faculty.

8) May teach up to 2 academic courses per year.

9) Assist researchers with grant proposals with strong HPC or AI component to describe the interplay between their research and computation and data science.

10) Work with faculty and their research groups to enable them to fully utilize the University and national computational resources for their research.

Unit-Specific Competencies

1) Excellent interpersonal and communication (verbal and written) skills.

2) Understand and translate researchers' scientific goals into computational requirements.

3) Mentor and technical lead of a small team of students and/or Research Assistants.

4) Work well with faculty and researchers.

5) Identify and gain expertise in appropriate new technologies and/or software tools.

6) Function as part of an interactive team while demonstrating self-initiative to achieve project's goals and Research Computing Center's mission.

7) Strong analytical skills and problem-solving ability.

8) Work collaboratively with a diverse group of research scientists with different skills and expertise.

Education, Experience, and Certifications
Minimum requirements include a college or university degree in related field.Minimum requirements include knowledge and skills developed through 2-5 years of work experience in a related job discipline.

Preferred Qualifications

Education

1) PhD in Computer Science, Social Sciences, or related fields.

Technical Knowledge or Skills

1) Understanding of key natural language processing, data mining, machine learning and statistical methods.

2) Proficiency in one or more programming languages (such as C++, C, etc.).

3) Proficiency in a scripting language such as Python.

4) Knowledge of text analysis, including natural language processing.

5) Experience with Linux/Unix.

6) Knowledge of SQL.

7) Research experience in Natural Language processing, Machine Learning and Deep Learning frameworks.

8) Experience with running computational jobs on high-end computing systems.

Required Documents

1) Resume/CV

2) Cover letter

3) A solo-authored research-oriented writing sample (e.g. from a thesis) preferred.

NOTE: When applying, all required documents MUST be uploaded under the Resume/CV section of the application.

FLSA Status
Exempt
Pay Frequency
Monthly
Pay Grade
Depends on Qualifications
Scheduled Weekly Hours
37.5
Benefits Eligible
Yes
Drug Test Required
No
Health Screen Required
No
Motor Vehicle Record Inquiry Required
No
Posting Date
2020-08-14-07:00
Remove from Posting On or Before
2021-02-14-08:00
Posting Statement


The University of Chicago is an Affirmative Action/Equal Opportunity/Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.

Staff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via Applicant Inquiry Form.

The University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: http://securityreport.uchicago.edu. Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637.",4.0,"University of Chicago
4.0","Chicago, IL",10000+ Employees,1890,College / University,Colleges & Universities,Education,$2 to $5 billion (USD)
"Software/Data Engineer (Python, Static Data, OOP)",-1,"Software/Data Engineer (Python, Static Data, OOP)

Location: Chicago, Illinois, United States

Salary: competitive

Sectors: Finance and Operations

Job Type: Permanent

Apply for this Job
This top growing financial firm in Chicago is looking for Software/Data Engineer to join their growing team and who will work with cutting edge tech! This team is responsible for the collecting and transformation of the data for analytics.

Responsibilities include:
A Python and SQL technologies expert
Building out data pipelines
Designing and developing programs and systems daily
Able to work efficiently and collaborate with systems operations
Conduct research and provide technology solutions
Plans and executes unit tests to ensure the developed code is free of functional defects
Skills needed:
At least 3+ or more years of related experience
Excellent organization and communication skills
Extensive skills in building out data pipelines
A degree in a Computer Science/Computer Engineering related field
At least two years of Capital Markets experience is preferred
What's in it for you?!
Competitive Compensation base + Cash Bonus 10-15%
Take ownership of project and initiatives right away
Ability to collaborate with leadership and make an impact immediately
If you are interested in this Senior Software Engineer role for a top firm in Chicago, IL, please respond to me directly, and feel free to share with your network!

Sthree US is acting as an Employment Agency in relation to this vacancy.

Apply for this Job",3.1,"Huxley
3.1","Chicago, IL",201 to 500 Employees,1995,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Data Analyst,-1,"Role Type: Data Analyst *
Reports To: Data Scientist *
\*
About Us*
CareAdvisors is a technology company that helps patients get access to healthcare and social service benefits they need by automating the manual enrollment role taken on by hospitals.

Many patients who receive care at hospitals are eligible for Medicaid and other social service benefits, but some have barriers to enroll or re-enroll in their benefits. Using technology focused on automation, CareAdvisors remove barriers so that patients can get access to the benefits they need.

Our Customer Relationship Management tool empowers care navigators and social workers with a platform that is connected to a network of community resources and hospitals. We use the data gathered across our network to power our analytics engine. Join us in building out our platform so we can connect people to the care they need!
About the Role*
As a Data Analyst, you will research and develop predictive models for population health. Overall, you will support our enterprise strategy and delivery of analytic services by performing various analyses and interpretations to support business needs for assigned functions. The analyst will collaborate across analytic teams, business partners, and customers to ensure a coordinated flow of information, documentation, and relationships to support the delivery of leading-edge analytics. Due to the dynamic nature of this role, we are looking for entrepreneurial candidates with the ability to derive analytical insights from a variety of business contexts.
Responsibilities*
Compile analytical and statistical reports.
Formulate, define, and recommend scope of reports.
Review information for accuracy and reconcile data.
Provide support and education to staff on how to access reports and interpret the data.
Synthesize raw data into digestible and actionable information.
Identify trends and make recommendations for quality and operational improvement.
Collaborate with leaders to understand key value drivers and challenges within their business units and determine the key metrics and insights that can help improve performance as a result.
Continually think of new ways that data-driven insights can help support Care Advisors.
We are looking for a team member with the following background*
Currently based in the Chicagoland area *(REQUIRED)*
Master's degree in business, economics, finance, accounting, marketing analytics, MIS, computer science, engineering, or equivalent work experience.
4+ years of related experience guiding strategic decision making using data and analytics.
2+ years of experience working in a healthcare environment.
Experience with topics in public health, population health, social determinants of health, data science, or social science, preferred.
Experience with report/dashboard development, data/report automation, self-service capabilities, data design and integration, data quality and governance, preferred.
SQL, Python, and/or Tableau skills are preferred.
Familiar with predictive programming in R and/or Python.
Proficiency in Microsoft Excel, Powerpoint and Word.
Ability to take insights and turn them into actionable steps that can drive business value.
At Care Advisors we value diversity and endeavor to treat everyone with respect, no matter their age, gender, race, ethnicity, or sexual, cultural or ideological preferences.

Due to the unprecedented situation of COVID-19, CareAdvisors has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding, and daily operations. Please consider that our roles will not be remote long-term and we will return to an office environment once it is deemed safe to do so following the guidance of local health authorities and the Centers for Disease Control.

\*

Job Type: Full-time

Benefits:
Dental Insurance
Employee Assistance Program
Health Insurance
Paid Time Off
Parental Leave
Professional Development Assistance
Schedule:
Monday to Friday
Experience:
healthcare : 2 years (Required)
data and analytics: 4 years (Required)
Education:
Master's (Required)
Location:
Chicago, IL 60654 (Required)
Work Location:
One location
This Job Is Ideal for Someone Who Is:
Innovative -- prefers working in unconventional ways or on tasks that require creativity
High stress tolerance -- thrives in a high-pressure environment
Benefit Conditions:
Waiting period may apply
Work Remotely:
No",3.4,"Care Advisors Inc
3.4","Chicago, IL",1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable
Scientist - Tech Transfer,"$32K-$69K
(Glassdoor Est.)","Company Description
Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.
In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.
In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description
This position provides technical leadership and is a primary point of contact for CMOs (Contract Manufacturing Organizations) for PSS Client. The role is involved in the collaborative development of products for the client division and works directly to provide guidance for CMO groups that are supporting client products. This position is focused on global product development through commercial launch.
The role oversees and manages the tech transfer and scale-up of sterile injectable (includes solutions, lyophilized products, suspensions and emulsions) and ophthalmic pharmaceutical dosage forms (includes solutions, suspensions) and must have a fundamental understanding of cGMP, sterile operations, etc.
The individual will be expected to provide detailed technical, process understanding and expertise in support of complex technical investigations, process troubleshooting, technical transfer, scale up, as well as engineering and exhibit batch manufacturing. The individual will be instrumental in facilitating project and technical ownership to client prior to process validation/commercial batch manufacturing.
The individual will be expected to leverage collaboration across multiple groups and competing priorities and should have extensive understanding and experience dealing with large technical group of engineers, scientist and technicians in large multi-product contract manufacturing facilities. The role serves as the operations point of contact for technology transfer and manufacturing and should be knowledgeable of the documentation necessary for tech transfer of new products, including tech transfer plans and risk assessments.

Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development/tech transfer/manufacturing experience. Preferred education background in Pharmaceutics, Engineering or similar discipline, however, extensive experience with tech transfer processes may be substituted for education.
Significant experience with tech transfer of drug products in or out of manufacturing sites
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Working knowledge of project management concepts and tools
Working knowledge of Computer Aided Design (CAD) and/or Visio tools for Equipment/Process design
Working knowledge of DOE and MiniTab tools for experimental design and data analysis.
Significant experience in process development and scale-up
Experience fostering relationships with CMOs
Detailed knowledge of technology transfer and scale up.
Ability to trouble shoot/recommend the solutions to resolve the technical issues with manufacturing equipment.
Ability to handle multiple projects simultaneously at different CMOs.
Ability to travel globally, up to 30 % to CMOs for technical meetings, technology transfer, demonstration /engineering / exhibit batches.
Experience authoring, reviewing, and/or approving site technology documents such as tech transfer plans, risk assessments, validation protocols, reports, batch records, sampling protocols, CAPAs, change controls, procedures, policy and instructions, etc.
Experience collaborating with R & D colleagues for required process development and analytical support needed to address process issues and solutions.
Experience participating as needed in reviewing/authoring relevant regulatory and/or technical documents in support of implemented technologies or changes in the manufacturing process and evaluate the impact on the quality of the product
Requires understanding of scientific principles, operational aspects of production equipment, automation control systems, processing requirements and any related procedural requirements with emphasis on sterile injectable pharmaceutical dosage forms.
Experience participating in cross-functional teams in the evaluation and implementation of novel manufacturing technology and processes in commercial processes that increase process robustness and promote a culture of innovation and continuous improvement.
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information
Position is full-time, Monday - Friday 8:00am - 5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",3.4,"Eurofins
3.4","Lake Forest, IL",10000+ Employees,1987,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (USD)
Assistant Computer Scientist,"$71K-$124K
(Glassdoor Est.)","Position Description

Math and Computer Sciences at Argonne National Laboratory provides intellectual and technical leadership in the computing sciences, applied mathematics, computer science, and computational science. To this end, we pursue the most important scientific problems of our nation, problems that require innovative computational tools and technology for transformative science during the next several decades.

The Mathematics and Computer Science Division at Argonne National Laboratory seeks well-prepared candidates for an Assistant Computer Scientist position in scientific machine learning. The successful candidate will be performing machine learning research and development for scientific discovery on some of the world’s fastest supercomputers. This work will include development of scalable supervised, unsupervised, reinforcement, transfer, meta, continual, and automated learning methods with flexibility on the class of methods pursued based on wide range of DOE relevant scientific applications such as nuclear physics, computational chemistry, materials science, high performance computing, weather modeling, and transportation. You will actively collaborate with computer scientists, mathematicians, and domain scientists and will have the opportunity to build an independent research program.

This is an Evergreen job posting which allows candidates to apply once to be considered for multiple job requisitions; you may be asked to apply to a specific job posting in the future.

Position Requirements

Ideal Candidates are expected to have:
Bachelor’s degree and 5+ years; Master’s and 3+ years; Doctorate and 0 years, or equivalent.
Experience in machine/deep learning, high-performance computing, scientific computing or mathematical optimization
Programming experience in C, C++, and/or Python
Experience in Keras, Tensorflow, Pytorch
Good communication skills both verbal and written
Software development practices and techniques for computational and data-intensive science problems.
Desirable knowledge and skills:
Ability to understand and implement methods from latest machine learning articles
Experience and skills in interdisciplinary research involving computer scientists and discipline scientists
Experience with parallel programming such as MPI
Ability to provide project leadership
Collaborative skills including the ability to work well with other laboratories and universities, supercomputer centers and industry.
As an equal employment opportunity and affirmative action employer, and in accordance with our core values of impact, safety, respect, integrity and teamwork, Argonne National Laboratory is committed to a diverse and inclusive workplace that fosters collaborative scientific discovery and innovation. In support of this commitment, Argonne encourages minorities, women, veterans and individuals with disabilities to apply for employment. Argonne considers all qualified applicants for employment without regard to age, ancestry, citizenship status, color, disability, gender, gender identity, genetic information, marital status, national origin, pregnancy, race, religion, sexual orientation, veteran status or any other characteristic protected by law.

Argonne employees, and certain guest researchers and contractors, are subject to particular restrictions related to participation in Foreign Government Talent Recruitment Programs, as defined and detailed in United States Department of Energy Order 486.1. You will be asked to disclose any such participation in the application phase for review by Argonne’s Legal Department.
Back to top",4.5,"Argonne National Laboratory
4.5","Lemont, IL",1001 to 5000 Employees,1946,Nonprofit Organization,Federal Agencies,Government,Unknown / Non-Applicable
"Staff Software Scientist, Reproductive Health","$57K-$132K
(Glassdoor Est.)","When you're part of the team at Thermo Fisher Scientific, you'll do important work, like helping customers in finding cures for cancer, protecting the environment or making sure our food is safe. Your work will have real-world impact, and you'll be supported in achieving your career goals.

Genetic Sciences Division
This is a Remote position that can be based anywhere in the U.S.

How will you make an impact?
As a Staff Software Scientist, Reproductive Health, you will work as an integral member of a cross functional team in the product development process. This position represents scientists in charge of running and analyzing genetic data. You will play an important role in creating stream-lined data interpretation software solutions across multiple genetic analysis platforms. Responsibilities also include producing, editing, and maintaining software requirement documents for Thermo Fisher Scientific's applications for genetic analysis / Reproductive Health applications at a software-industry best practices level.

What will you do?
Engage with scientists, cytogeneticists, and field teams in discussing data analysis using various genetic platforms.
You will be directly accountable for planning and prioritizing functionality in both instrumentation and analysis software. This includes creation of customer requirements documents and the development of test cases and data sets for use by the development team
Coordinate reviews of specifications with internal and external stakeholders in the context of broader customer scientific objectives and business requirements
Documentation focuses on use cases, storyboards, data-flow diagrams, UI mock ups and other tools representing how scientists interact with Thermo Fisher Scientific software applications for data analysis.
Handle escalated technical support issues.
Assist in educating and supporting customers, partners, tech support and field personnel with various written and recorded communications and external meetings as needed
Prioritize and schedule customer contacts and evaluations
How will you get here?
Education
Minimally, possess a Bachelor's degree in a Biomedical discipline. PhD/MD degree is preferred

Experience
Six years of experience in Life Sciences (graduate work qualifies) with hands-on experience with microarray, next-generation sequencing and accompanying instrumentation
Hands-on experience with SNP, copy number, and/or gene expression studies
Broad understanding of the experimental design. This should include familiarity with the technical details from a laboratory operations and an IT perspective, and experience with downstream analysis applications
Excellent verbal and written communication skills
Prior customer interfacing experience is ideal
Experience with Thermo Fisher Scientific products and/or bioinformatics preferred
Knowledge, Skills, Abilities
Knowledge and experience with applications in the genetic sciences field (i.e. qPCR, NGS, microarray, etc,)
Strong initiative and ability to take ownership of challenging problems involving a range of audiences
Demonstrated problem solving skills in situations involving conflicting constraints and pressure
Ability to speak Mandarin a big plus
Our global team of more than 75,000 colleagues delivers an unrivaled combination of innovative technologies, purchasing convenience and pharmaceutical services through our industry-leading brands, including Thermo Scientific, Applied Biosystems, Invitrogen, Fisher Scientific, Unity Lab Services and Patheon. For more information, please visit www.thermofisher.com.

Thermo Fisher Scientific is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status.",3.5,"Thermo Fisher Scientific
3.5","Chicago, IL",10000+ Employees,1902,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (USD)
"Senior Analyst, Data & Analytics (Affinity)","$49K-$107K
(Glassdoor Est.)","Job Description


We’re hiring!

Aon is currently recruiting a Senior Analyst, Data & Analytics (Affinity) to join our team in Singapore.

About Aon's Center for Innovation & Analytics

Aon’s Centers for Innovation and Analytics in Dublin and Singapore are at the heart of delivering Aon’s Data & Analytic Services team’s mission to:
accelerate the rate of innovation through digital solutions to help better respond to clients’ evolving needs
provide foundational data and analytics capabilities in one place for 50,000 Aon colleagues and our global clients who use our risk and people solutions
Established in 2012, there are over 100 colleagues in Singapore’s Centre today including actuaries, software developers, data scientists, financial analysts and accountants. We are expanding rapidly and looking for dedicated individuals who can leverage emerging technologies and collaborate across Aon’s solution lines to help clients and colleagues make better, data-driven decisions today and tomorrow.

The Opportunity
The opportunity is within a newly formed team which is part of Aon’s B2B2C and B2C business in the US (also referred to as Affinity) focusing on marketing analytics.
The scope will eventually expand to include analytics that will serve the core Affinity business. It is an exciting time to join this team since you will get to shape the nature of analytics for this business
Responsibilities
Aggregate, combine, normalize and cleanse data from a variety of internal, public or proprietary data sources to create internal data sets
Work with data engineers and or carry out data ingestion activities as required.
Perform data exploration and analysis on these internally developed data sets to come up with insights
Collaborate with teams of experienced analysts, developers and business experts to implement the insights
Go beyond current tools to deliver the best solution to the problem and assist/advise on the most appropriate analytical methods to apply to a given problem
Provide support in communication of results to business leaders and in designing fully functional products
Requirements
Degree in Computer science, Engineering or Business analytics preferred
3+ years of working experience with data & analytics
A good working knowledge of databases; structured & unstructured with a view to obtaining internal & external data and troubleshooting data issues as necessary
Software developers (C#- backend development) will be considered for this role as long as they have an interest in working on data visualization using a BI toolset alongside software development (60/40 split)
Experience in Python & exposure to ETL scripting is desired if the background is not in software development.
Proven experience with a BI tool
A proven ability to work in a fast-paced unstructured environment
Familiarity with marketing or insurance concepts is a bonus
How to Apply

Your opportunity to empower results could start right here. Make your mark and apply online today with a brief covering letter and your resume, sharing relevant achievements for this position.

We Offer You

A competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.

Our Colleague Experience

Every day, our colleagues make a difference, work with the best, own their potential, and value one another. Together, we share this one purpose: to empower economic and human possibility around the world. This unifying goal is at the heart of our identity, and it lives in everything we do. To learn more about our colleague experience, visit Aon Colleague Experience.

Aon is an equal opportunities employer. We are committed to creating a winning and inclusive culture where everyone feels valued and has opportunities for growth and development.

2477248",3.6,"Aon
3.6","Chicago, IL",10000+ Employees,1892,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD)
Senior Data Science Architect,"$72K-$120K
(Glassdoor Est.)","At West Monroe, our people are our business. We pride ourselves on bringing a different mindset to consulting—and that takes a different approach: highly collaborative, flexible, and tenacious.
Our people-first, highly collaborative culture is core to our identity. It’s something we care about, and something we strive to enrich and preserve. No hierarchies. No silos. No egos. Just smart ideas, and the drive to make an impact for our clients.
Every day our clients rely on us to help them tackle their greatest challenges, by strategically deploying technology through a business-focused and industry-specific lens. We bring together both the right knowledge and the right approach, so that they can capitalize on opportunities and deliver real results. That takes the right team. And that’s where you come in.
Ready for the next step on your career journey?West Monroe is seeking a Data Scientist to join and help build our emerging Advanced Analytics practice in the Chicago office. We’re looking for you to be a thought-leader building solutions for clients from the ground up on a daily basis. You will be engaging in developing and marketing analytics platforms-as-as-service solutions and collaborating with our client analytics SMEs and implementing predictive models in a variety of industries. Level Responsibilities: Practice DevelopmentEngage in developing and marketing analytics platforms-as-a-service solutionsCollaborate with top leadership within the various practices to develop applicable client projectsContribute to the development/enhancement of WMP’s advanced analytics methodologies, best practices, and approaches to client delivery.Contribute to growth of knowledge in service line through training and KTS sessionsComplete case studies for all engagementsDevelop talented individuals who are delivering client workAttract talent to continue to build the practice from top tier analytics firms and or schools
Client DeliveryOversee advanced analytics work for quality assuranceBe a thought-leader in providing solutions to clients on a daily basisAble to engage with client analytics SMEs to collaborateLead engagements or the analytics portion of engagements by communicating and reporting project status to key client stakeholders, including budget, risks, issues, etc.Make decisions regarding aspects of project, including tools, approach and methodologyDefine detailed responsibilities, work tasks and targets for each team member according to the technical work planManage multiple projects simultaneouslyAssess stakeholder interests and plan and execute strategies to address their needs while quickly responding to client requests for immediate issues and driving projects to completion.
Business Development (Desired)Drive new business with existing clients by identifying and communicating potential opportunities to account managerUnderstand client business needs and requirements and help turn those goals into concrete projects and detailed proposalsCreate work plans, pricing estimates, and risk assessments for prospectsActively build a professional network and affiliate network in the local communitySo, if you’re looking for an opportunity to flex your technical muscles in a high-energy, team-oriented environment where you own your career, we’d love to hear from you.

Qualifications:

MS or Bachelor with equivalent experience required in related Mathematics, Statistics, Econometrics, or similar quantitative degree preferred. PhD a plus
A minimum of 2+ years of experience working in a quantitative analysis/data analytics, managing and/or coaching one or more analysts
Experience working with relational databases, such as SQL
Strong communication skills to be able to work with clients and present to C-level executives.
Solid project management methodology background, including schedule, scope, issue and risk management experience, change management, strategic planning and analysis
Present experience or proficiency with data related projects
Proficient analytical, problem solving and quality delivery experience, preferable 3-5 projects and programs with Fortune 200.
Ability to work well in a team of 2 – 5 consultants
Ability to travel minimum 50%.

Requirements:

Proven expertise with advanced analytics and data mining tools and programming languages such as SAS, IBM/SPSS, R, Python, and SQLFamiliarity with BI/data visualization tools such as Tableau and Qlikview
Hands-on experience with multivariate analytic techniques such as linear and logistic regression, decision tree, cluster and factor analysis, time-series forecasting methods, SVM models, and neural nets.
NoSQL a plus: HBase, Cassandra, Accumulo, Mongo, Neo4j, etc.
Experience with ETL, data warehouse and reporting a plus
Experience with MapReduce: Hadoop, Hive, PIG, Mahout, etc. is a plus

Ready to get started? Join our team and make an impact.

Senior Data Science Architect

222 W Adams St, 11th Floor
Chicago, Illinois, 60606
United States
At West Monroe, our people are our business.
We pride ourselves on bringing a different mindset to consulting—and that takes a different approach: highly collaborative, flexible, and tenacious.

Our people-first, highly collaborative culture is core to our identity. It’s something we care about, and something we strive to enrich and preserve. No hierarchies. No silos. No egos. Just smart ideas, and the drive to make an impact for our clients.

Every day our clients rely on us to help them tackle their greatest challenges, by strategically deploying technology through a business-focused and industry-specific lens. We bring together both the right knowledge and the right approach, so that they can capitalize on opportunities and deliver real results. That takes the right team. And that’s where you come in.

Ready for the next step on your career journey?
West Monroe is seeking a Data Scientist to join and help build our emerging Advanced Analytics practice in the Chicago office. We’re looking for you to be a thought-leader building solutions for clients from the ground up on a daily basis. You will be engaging in developing and marketing analytics platforms-as-as-service solutions and collaborating with our client analytics SMEs and implementing predictive models in a variety of industries.

Level Responsibilities:
Practice Development
Engage in developing and marketing analytics platforms-as-a-service solutions
Collaborate with top leadership within the various practices to develop applicable client projects
Contribute to the development/enhancement of WMP’s advanced analytics methodologies, best practices, and approaches to client delivery.
Contribute to growth of knowledge in service line through training and KTS sessions
Complete case studies for all engagements
Develop talented individuals who are delivering client work
Attract talent to continue to build the practice from top tier analytics firms and or schools

Client Delivery
Oversee advanced analytics work for quality assurance
Be a thought-leader in providing solutions to clients on a daily basis
Able to engage with client analytics SMEs to collaborate
Lead engagements or the analytics portion of engagements by communicating and reporting project status to key client stakeholders, including budget, risks, issues, etc.
Make decisions regarding aspects of project, including tools, approach and methodology
Define detailed responsibilities, work tasks and targets for each team member according to the technical work plan
Manage multiple projects simultaneously
Assess stakeholder interests and plan and execute strategies to address their needs while quickly responding to client requests for immediate issues and driving projects to completion.

Business Development (Desired)
Drive new business with existing clients by identifying and communicating potential opportunities to account manager
Understand client business needs and requirements and help turn those goals into concrete projects and detailed proposals
Create work plans, pricing estimates, and risk assessments for prospects
Actively build a professional network and affiliate network in the local community
So, if you’re looking for an opportunity to flex your technical muscles in a high-energy, team-oriented environment where you own your career, we’d love to hear from you.
Qualifications:
MS or Bachelor with equivalent experience required in related Mathematics, Statistics, Econometrics, or similar quantitative degree preferred. PhD a plus
A minimum of 2+ years of experience working in a quantitative analysis/data analytics, managing and/or coaching one or more analysts
Experience working with relational databases, such as SQL
Strong communication skills to be able to work with clients and present to C-level executives.
Solid project management methodology background, including schedule, scope, issue and risk management experience, change management, strategic planning and analysis
Present experience or proficiency with data related projects
Proficient analytical, problem solving and quality delivery experience, preferable 3-5 projects and programs with Fortune 200.
Ability to work well in a team of 2 – 5 consultants
Ability to travel minimum 50%.
Requirements:
Proven expertise with advanced analytics and data mining tools and programming languages such as SAS, IBM/SPSS, R, Python, and SQL
Familiarity with BI/data visualization tools such as Tableau and Qlikview
Hands-on experience with multivariate analytic techniques such as linear and logistic regression, decision tree, cluster and factor analysis, time-series forecasting methods, SVM models, and neural nets.
NoSQL a plus: HBase, Cassandra, Accumulo, Mongo, Neo4j, etc.
Experience with ETL, data warehouse and reporting a plus
Experience with MapReduce: Hadoop, Hive, PIG, Mahout, etc. is a plus
Ready to get started? Join our team and make an impact.

.

West Monroe Partners is an Equal Employment Opportunity Employer -
We believe in treating each employee and applicant for employment fairly and with dignity. We base our employment decisions on merit, experience, and potential, without regard to race, color, national origin, sex, sexual orientation, gender identity, marital status, age, religion, disability, veteran status, or any other characteristic prohibited by federal, state or local law.",4.2,"West Monroe Partners
4.2","Chicago, IL",1001 to 5000 Employees,2002,Company - Private,Consulting,Business Services,$100 to $500 million (USD)
Senior Big Data Engineer- Data Warehouse,"$102K-$126K
(Glassdoor Est.)","We're looking for a Senior Data Engineer for our Chicago to join us in building our next generation data processing platform. As part of the platform team you will work in multiple areas including campaign performance measurement and reporting, ad fraud, and botnet detection.

Are you someone who likes to have fun at work? Are you passionate about picking problems apart, driving results, and making an impact? Do you enjoy working in a fast-paced, dynamic environment where no two days are the same? If so, we want to speak with you!

About our team:

Quite simply our platform is the engine that powers the verification, optimization, and analytics solutions we provide. It has the power to handle hundreds of thousands of transactions per second; collect tens of billions of events each day and evaluate thousands of data-points in real-time all while responding in just a few milliseconds.

What you'll do:
Work on Big Data technologies, lead the design, coding and maintenance of highly scalable backend data processing platform for large throughput
Work on the data modelling for the MPP columnar databases to handle high volume of queries with sub-second response times
Lead the entire software lifecycle including hands-on development, code reviews, testing, continuous integration, continuous deployment and documentation using modern programming languages (such as Java, Scala, Python)
Perform tuning of systems for optimal performance
Mentor junior team members
You should apply if you have most of this:
5+ years of recent hands-on experience in one or more of the modern programming languages (Java, Scala, Python)
Good understanding of collections, multi-threading, JVM memory model, algorithms, scalability and various tradeoffs in a Big Data setting.
Experience developing and maintaining ETL applications and data pipelines using big data technologies
Strong SQL knowledge (OLAP) and experience working with mpp columnar databases (Vertica, SnowFlake,etc)
Excellent interpersonal and communication skills
Understanding of full software development life cycle, agile development and continuous integration
What puts you over the top:
Data warehouse experience in SnowFlake and experience writing ETL pipelines in SnowFlake
Experience working with AWS technologies such EMR, step functions, data pipeline, cloudformation, etc.
Experience working with hadoop mapreduce, spark, pig, hive, etc.
About Integral Ad Science

Integral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 18 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit integralads.com.

Equal Opportunity Employer:

IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.

California Applicant Pre-Collection Notice:

We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.

To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN

Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.",3.5,"Integral Ad Science
3.5","Chicago, IL",501 to 1000 Employees,2009,Company - Private,Internet,Information Technology,$100 to $500 million (USD)
Data Architect,"$77K-$128K
(Glassdoor Est.)","About our teams: Tempus is executing on the mission to create the world's largest, integrated dataset of molecular and clinical data. At Tempus, products are owned and developed by small, autonomous teams composed of developers, designers, data scientists, and product managers. You and your team set the goals, build the software, deploy the code, and contribute to a growing software platform that will make a lasting impact in the field of cancer research and treatment.

Tempus builds software as nimble as our teams. Our modern tech stack - React, NodeJS, and Python on AWS - allows our teams to iterate rapidly and lead our industry in innovation. Our decentralized, microservice architecture and emphasis on automation allow us to deliver advanced solutions with confidence, and at scale.

What You'll Do
Manage an enterprise data model in collaboration with engineers, product managers, scientists, and operators to integrate structured data from source systems in multiple complex domains (clinical records, genomics, NGS lab, radiology, et al.).
Author and maintain entity-relationship diagrams, data dictionaries, API specs, and data translation documentation at multiple levels of abstraction (conceptual, logical, physical) and across multiple data store technologies (relational, NoSQL).
Advocate and educate engineering team members on data modeling rules, standards, and best practices.
Evaluate completeness of source system data models and data by profiling partner data.
Implement solutions to proactively monitor data quality with traceability to source systems.
Why we're looking for you:
You have strong experience and knowledge of 3NF, dimensional (star schema), and data vault modeling techniques.
You have applied exceptional SQL skills in an enterprise data warehouse environment.
You have knowledge of ETL/ELT and BI architectures, concepts and frameworks.
You understand and can clearly articulate the long-term impacts of key decisions between database technologies (relational, MPP, NoSQL) and have experience architecting solutions across multiple technologies.
You have experience with data modeling tools like Erwin, Vertabelo or SQLDBM.
You have domain knowledge in healthcare.
Bonus points for:
Experience with AWS architecture
Experience working with clinical and/or genomic data
Experience writing and debugging Python
Chairing a data governance board for a complex organization
Implementing master, reference, or metadata management solutions",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
"Director of Product, Data as a Service (DaaS)","$115K-$186K
(Glassdoor Est.)","Position Description:

The Climate Corporation is modernizing the agriculture industry with our Digital Farming Platform that is helping the world’s growers sustainably increase farm productivity with digital tools. We build hardware, platforms, and a suite of grower-facing applications that collect and process vast amounts of agronomic data. We then deliver insights that allow farmers to produce enough food to feed the ever-growing population.

In this role, you will report directly into the Chief Product Officer and lead our DaaS product vertical. You will define the future of our industry by identifying and prioritizing the highest-value agricultural data opportunities for not only Climate, but the broader agricultural industry. You will create the vision and product roadmap that catalyzes and drives our data flywheel, turning our data into actionable insights for all of our enterprise and farmer customers.

What You Will Do:
Lead a motivated and driven product team focused on realizing The Climate Corporation’s mission to help farmers sustainably increase food production with digital tools.
Set the DaaS product strategy and business plan by deeply analyzing the market; use strong business judgment and technical knowledge to inform an understanding of what is technically possible, and strategically critical to success.
Own the DaaS product roadmap – synthesize multiple inputs into a clear product strategy and manage ongoing feature prioritization.
Work closely with the R&D leadership and executive teams to define product requirements and ensure the roadmap is aligned with the company vision and strategy; clearly communicate your vision, requirements, and features across teams and throughout the organization.
Engage deeply with researchers, data scientists, engineers, and other technical leaders to evaluate new technologies and product concepts. Explore build-vs-buy initiatives to ensure we deliver the highest quality/value in line with the market opportunities.
Execute on your vision by defining clear milestones and deliverables, and partnering with Engineering, Science, and end-to-end teams to ensure your vision becomes reality.
Define the evolution & future requirements for agriculture data collection based on equipment and industry trends. Contribute towards standards and adoption for agricultural data across the industry.
Basic Qualifications:
BS in a technical field or equivalent experience.
10+ years of enterprise product development or product management experience.
5+ years of experience building and leading product management teams.
Experience working hands-on with hardware and/or software engineering teams to deliver new products and features in an agile development environment.
Experience defining and managing Platform/DaaS solutions.
Strong strategic and analytical skills.
Strong written and verbal communication skills.
High attention to detail and the ability to manage complex projects.
Preferred Qualifications:
Masters degree or MBA.
Experience jumpstarting and launching DaaS initiatives.
Background and experience with data security and audit compliance.
Product leadership demonstrated through shipping successful products.
Experience developing and negotiating partnerships for platforms and/or content development.
Passion for agriculture is a huge plus.
What We Offer:

Our teams are composed of industry experts, top scientists, and talented engineers. The environment is extremely engaging and fast-paced, with dozens of specialties coming together to provide the best possible products and experiences for our customers. We provide competitive salaries and some of the best perks in the industry, including:
Superb medical, dental, vision, life, disability benefits, and a 401k matching program
A stocked kitchen with a large assortment of snacks & drinks to get you through the day
Encouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used
We take part and offer various workshops, conferences, meet-up groups, tech-talks, and hackathons to encourage participation and growth in both community involvement and career development
We also hinge our cultural DNA on these five values:
Inspire one another
Innovate in all we do
Leave a mark on the world
Find the possible in the impossible
Be direct and transparent
Learn more about our team and our mission:

The Climate Corporation - The Technology Behind Making A Difference

https://youtu.be/c5TgbpE9UBI or visit https://climate.com/careers

Climate aims to create a welcoming and collaborative environment for our employees in which a diverse set of perspectives and voices are represented and celebrated.

As part of our dedication to the diversity of our workforce, The Climate Corporation is committed to Equal Employment Opportunity and does not discriminate based on race, religion, color, national origin, ethnicity, gender, sex (including pregnancy), protected veteran status, age, disability, sexual orientation, gender identity, gender expression, or any unlawful criterion existing under applicable federal, state, or local laws. If you need assistance or an accommodation due to a disability, you may contact us at accommodations@climate.com.

#SSLI",3.3,"The Climate Corporation
3.3","Chicago, IL",501 to 1000 Employees,2006,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable
Data Engineer,-1,"The Data Engineer will collaborate with various other IT groups, business partners and external service providers and play a key role in the design, development and operations of our new analytics platform.
Responsibilities Include:

Participate in Requirements Gathering: work with key business partner groups (e.g. Product Mgt) and other Data Engineering personnel to understand department-level data requirements.
Design Data Pipelines: work with other Data Engineering personnel on an overall design for flowing data from various internal and external sources into the platform.
Build Data Pipelines: leverage standard toolset and develop ETL/ELT code to move data from various internal and external sources into the platform.
Support Data Quality Program: work with Data QA Engineer to identify automated QA checks and associated monitoring & alerting to ensure consistently high-quality data.
Support Operations: triage alerts channeled to you and remediate as necessary.
Technical Documentation: leverage templates provided and create clear, simple and comprehensive documentation for your development.
Key contributor to defining, implementing and supporting:
Data Services
Data Dictionary
Tool Standards
Best Practices
Data Lineage
User Training",4.5,"Green Key Resources
4.5","Chicago, IL",201 to 500 Employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable
Product Manager - Data Integrations and Infrastructure,"$47K-$90K
(Glassdoor Est.)","Passionate about making a difference in the world of cancer genomics?

With the advent of genomic sequencing, we can finally understand our genetic makeup. We now have more data than ever before but providers don't have the infrastructure or expertise to make sense of said data. Here at Tempus, we are building the infrastructure to modernize cancer treatment. By analyzing a patient's genetic data in the context of molecular therapies, We empower physicians to make real-time data-driven decisions in the clinic based on the comprehensive computational analysis of a patient's unique pathology.

As a Product Manager, Data Integrations and Infrastructure at Tempus, you'll be on the front lines of our battle to develop and deliver cutting-edge data and technology into the hands of researchers. The software we are developing is the culmination of input from scientists, clinicians, pathologists, engineers, data scientists, and some of the top academic oncology centers in the world. We're expanding the team of product managers who bring those inputs together to design, scope, and build solutions to some of the toughest problems in cancer care.

What You'll Do:
Immerse yourself in the tough problems were solving, and team with scientists, engineers, and designers to develop elegant software solutions to solve those problems
Own the product roadmap for a subset of Tempus products, and partner with otherProduct Managers and the Director of Product to find the best way to execute quarterly and sub-quarterly goals.
Work with developers, scientists, and operations teams to deliver product releases that are stable in production and satisfy scalability, reliability, and performance goals
Conduct deep product analysis and use the data to guide the short- and long-term roadmap for the team
Own stakeholder communication and expectation management around roadmap and delivery timelines for your products
Test release candidates and participate in the Product Management approval process for deployments
Serve as the direct line of communication with users of your products to maintain a constantly evolving backlog of future enhancements
Help create the internal and external playbook for implementing and supporting integrations with the Tempus product and hospital/industry partners clinical systems in a scalable and consistent manner
Work closely with on-site and off-site integration and informatics managers to prioritize product roadmaps in accordance with requirements in the field to accelerate, improve and optimize integrations with new health systems
Qualifications:
3+ years of technical product management or equivalent experience, ideally at a SaaS company
Experience working with agile software development teams
2+ years of relevant experience with SQL or Python
Experience with software development and project management tools (JIRA, Trello, etc.)
Ability and interest to quickly ramp up on new concepts in the fields of genomics, oncology, and health informatics systems
Ability to work directly with business and operations partners to generate consensus around a technical direction",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Data Engineer Solutions Lead,"$77K-$138K
(Glassdoor Est.)","Your Talent. Our Vision. At Anthem, Inc., it’s a powerful combination, and the foundation upon which we’re creating greater access to care for our members, greater value for our customers, and greater health for our communities. Join us and together we will drive the future of health care.

This is an exceptional opportunity to do innovative work that means more to you and those we serve at one of America's leading health benefits companies and a Fortune Top 50 Company.

Data Science Solutions Lead is responsible for design and development of analytic models, applications and supporting tools, which enable Data Scientists to create algorithms/models in a big data ecosystem.

Primary duties may include but are not limited to:
Lead the design and implementation of Machine Learning/Data Science model operationalization and related system integration
Lead the design, implementation and delivery of an insights data pipeline supporting analytic products across the organization.
Design and integrate data from different sources.
Forms analytics platform components and/or processing components required to provide a business solution.
Engage with business stakeholders to design and own end-to-end solutions to empower data driven decision making.
Leverage data, technology and quantitative methods to form products that inject analytics and insights into daily workflow of teams.
Defines application scope and objectives, including impact to interfaces.
Ensures appropriate data testing is completed and meets test plan requirements.
Coordinates integration actions to ensure successful implementation.
Mentors Data Science Sol Consultants/Sr. Lead analytical projects and pilots for upgrades or enhancements.
Lead analytical projects and pilots for upgrades or enhancements
Requires BA/BS in Computer Science, Mathematics, or related disciplines; 5-7 years’ experience in predictive analytics and experience with software such as Hadoop technologies; 5-7 years Teradata experience and complex SQL, or equivalent; or any combination of education and experience which would provide an equivalent background. Experience in the healthcare sector preferred. Experience with deployment techniques within an agile development methodology. Strong knowledge of BTEQ and multi database preferred.
Requires BA/BS in Computer Science, Mathematics, or related disciplines.
An ideal candidate will have significant experience in at least one area: Data Architecture, Real-Time Applications, or BI Tools.
5+ years’ experience in leveraging at least 4 of the following technologies – HDFS, Hive, Sqoop, Impala, Spark, distributed processing concepts, Hbase, MongoDB, J2EE/Spring, AWS, Node.js
Solid understanding and experience using at least one of the following programming languages — Java, Python, R, Scala.
5+ years’ experience in one of the following areas:
Database Strategy, Data Modeling, Data Pipelines and ETL Architecture
API & messaging architectures
BI development/design
Experience in public cloud environment and container technologies is preferred
Experience in Healthcare industry is preferred
Strong relational database SQL skills; including optimization techniques, with knowledge of NoSQL concepts
Solid experience with unix and shell scripting
Experience in defining project solution approach leveraging agile methodologies working with Product Owners and Scrum Masters.
Experience with source code management and application deployment techniques within an agile development methodology
Knowledge of the following Machine Learning Algorithms - Classification, Regression, Clustering, Dimensionality Reduction, Model Selection, Feature Extraction
Anthem, Inc. is ranked as one of America’s Most Admired Companies among health insurers by Fortune magazine and is a 2018 DiversityInc magazine Top 50 Company for Diversity. To learn more about our company and apply, please visit us at careers.antheminc.com. An Equal Opportunity Employer/Disability/Veteran.",3.4,"Anthem
3.4","Chicago, IL",10000+ Employees,2004,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD)
Senior Formulation Scientist,-1,"The Sr. Formulation Scientist will provide technical leadership for the development of pre-clinical and early clinical stage candidates using our proprietary technology for the delivery of small molecule and peptide/protein therapeutic agents. The successful candidate will be expected to drive programs from inception through preclinical manufacture/screening, technology transfer to selected CDMO’s, early cGMP manufacture working closely with Quality and CMC counterparts as well as any necessary analytical method development, specification development, and assessment of stability data/programs.

Develop and refine Xeris’ XeriJect technology platform (sterile suspension/paste in oil), including formulation, process and scaleup.
Develop robust phase appropriate preclinical formulations to screen commercial opportunities
Prepare and supply finished drug product (non-GLP, GLP) for internal and external studies
Conduct formulation optimization through Design of Experiments
Oversee the development of analytical methods to support the formulation development activities and early phase specifications for pre-clinical and clinical supplies.
Design stability studies, analyze and summarize analytical data, contribute to storage condition recommendations and product expiry/shelf life
Contribute to the identification/qualification of sterile fill-finish CDMO’s and facilitate technology transfer activities for non-GMP and cGMP drug product manufacture
CDMO management for early phase CTM manufacture
Write, review and approve technical protocols and reports
Write, review and edit appropriate sections of Regulatory submissions
Represent Product Development at cross functional Core Team interactions
Perform other duties as required
Up to 25% travel required

Ph.D. in Chemistry or related scientific field with a minimum of 9 years of experience working within formulation development, analytical method development and CMC
Experience with the development of sterile parenteral products
Experience in particle engineering and sterile suspension and paste manufacturing preferred.
Demonstrated experience in preclinical and early clinical development
Solid understanding of GLP and GMP regulations with a working understanding of ICH and FDA guidelines
Experience managing CDMO’s at all stages of development
Working understanding of analytical method development activities, HPLC/UPLC experience, experience using compendial methods for the characterization of parenteral products
Direct experience with the development of early phase clinical CTM specifications
Experience writing NDA, IND and other regulatory submissions
Preferred Combination product experience
Solid written and oral presentation skills
Communicates clearly and effectively across multiple functions and levels to foster a friendly collaborative work environment
Excellent problem-solving skills
Ability to be flexible and thrive in a fast-paced environment
Proactive team player who can also work independently",4.5,"Xeris Pharmaceuticals, Inc.
4.5","Chicago, IL",51 to 200 Employees,-1,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
"Software/Data Engineer (C#, Python, Cloud)",-1,"Software/Data Engineer (C#, Python, Cloud)

Location: Chicago, Illinois, United States

Salary: competitive

Sectors: Development

Job Type: Permanent

Apply for this Job
One of my clients is a growing global fintech firm, looking to expand their data/software engineering team in Chicago with both a mid-level and senior software engineers. With a goal to drive efficiencies leveraging data and technology, they work with a modern stack to stay competitive (C#, Python, Kubernetes, Cloud - Azure, AWS, GCP).

They are looking for mid-level and senior engineers that have experience working on data problems, preferably leveraging cloud technologies such as Azure, AWS or GCP. Ideal candidates will be familiar with REST based APIs, Microservice frameworks, containerization - kubernetes and experienced working with C#, Python and SQL. An understanding of capital markets and financial services is a plus, but not required.

The team is WFH due to COVID-19, with the ability to interview and onboard remotely. Preferred candidates will be based in the Greater Chicago Area. There are no immediate plans to return to the office, and employee health and safety is their #1 priority in making any decisions around that.

Whether you are actively looking or keeping a passive eye on the market, I'm happy to have an open conversation with you - about this opportunity and/or the market holistically. Please submit your resume here!

Sthree US is acting as an Employment Agency in relation to this vacancy.

Apply for this Job",3.1,"Huxley
3.1","Chicago, IL",201 to 500 Employees,1995,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Senior Data Analyst Informatics,"$49K-$88K
(Glassdoor Est.)","We now have more healthcare data than ever before, but providers often do not have the systems or expertise to make sense of all of this valuable data. At Tempus, we are building the infrastructure to modernize and enhance cancer treatment. We are on a mission to connect an entire ecosystem to redefine how data is used to improve patient outcomes. The Clinical Informatics team is seeking a highly-motivated data analyst who enjoys working with complex datasets and building tools for data pipelines.

What you'll do:

As part of the informatics team, you'll play a key role in helping us aggregate data from many different sources to build the largest library of oncology clinical data in the world. You'll work with clinical data experts, engineers, data scientists, and informatics analysts to ensure the quality of our data for analysis downstream.

Responsibilities
Lead efforts to build an extensive toolkit for scaling the aggregation and normalization of disjoint data
Automate quality assurance to ensure that data adheres to a common set of standards
Identify and socialize improvements to data processing infrastructure and workflow
Analyze the quality of our data and insights that can be generated from it
Skills and Qualifications:
Bachelor's degree in Analytics, Computer Science, or Information Systems (Master's Preferred)
2+ years of Python, SQL, and Github experience
Experience working with disorganized data from various sources
Extremely high attention to detail and fast learner
Nice-to-haves:
Familiarity with Oncology and Cancer Genomics
Knowledge of Health Informatics
Experience with Standard Medical Terminologies (SNOMED-CT, ICD-9/10, LOINC, etc.)
Experience with NLP techniques",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Jr. Clinical Trials Data Specialist,"$26K-$51K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

We are looking for a Jr. Clinical Trials Data Specialist who will work with our clinical and computational biology team on reports for clinical and research use.

Responsibilities:
Works collaboratively within cross-functional teams at Tempus (including but not limited to scientists, pathologists, product development) to create customized clinical reports.
Analyze patient clinical records and molecular testing results to identify potential clinical trials.
Perform critical quality control functions in clinical report workflow.
Support ongoing and future projects within the team.
Qualifications:
Minimum of a BS degree in Genetics, Molecular Genetics, Cancer Biology or Biological Sciences.
Willingness to be flexible and adapt quickly.
Strong critical-thinking and attention to detail.
Excellent communication skills with the ability to work both independently and in a group setting.
Excitement and drive to make a difference in a fast-paced energetic work environment!
0-3 years of working experience.
Preferred Qualifications:
Hematology/oncology knowledge.
Experience reading and evaluating clinical trials.",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Senior Integration Data Analyst,"$56K-$99K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

We are looking for a motivated Senior Integration Data Analyst who will work with our cross-functional teams and current hospital and industry partners to ensure a seamless Connectivity integration between Tempus and our customer's clinical systems. You'll work closely with customer's hospital EMR, EDW, and oncology data management teams to understand their workflows and goals in order to implement and support our cutting edge products and start making an impact very quickly for their cancer patients.

What you'll do
Work as part of the Clinical Data Connectivity team to execute and integrate data flows between the Tempus software system and the customer's current hospital IT systems and workflows
You'll play a key role in helping us aggregate data from many different sources to build the largest library of oncology clinical and genetic data in the world.
You'll work with clinical data experts, engineers, data scientists, and informatics analysts to ensure the quality of our data for analysis downstream and alignment with customer specific data specification pipelines.
Lead efforts to build an extensive toolkit for scaling the aggregation and normalization of customer data connections.
Automate quality assurance to ensure that data adheres to a common set of standards and customer specific data approved data schemas.
Identify and socialize improvements to data processing infrastructure and workflow, helping to provide continuous improvements in the architecture, process, and algorithms used to ingest and monitor data feeds.
Analyze the quality of our data and insights that can be generated from it.
Project Implementation Support:
Help support the successful execution of implementation project scope, timeline, objectives, and create a shared vision for the project execution as it relates to data deliveries, formats, schema, and structures.
Work directly with hospital data teams to execute flawlessly the integration project scope including validation, testing, and data profiling.
Assist with validation, monitoring, and troubleshooting of physical data delivery mechanisms, but more importantly assist with validation and remediation of data.
Integration Operations Support and post Go-Live Maintenance:
Develop and monitor day-to-day ""lights on"" operations of the Tempus integration layer
Partner with DevOps and Engineering teams to continuously optimize and improve the performance, scalability, and fault-tolerance of the integration layer
Qualifications
Bachelor's or Master's degree in an analytical or healthcare related field (or equivalent industry experience)
Familiarity with EMRs (electronic medical record)
2+ years of SQL required.
2+ years of Python recommended.
2+ years of data mining recommended
1+ years working with Apache Spark and/ or related NoSQL data architectures.
Expertise in working with common health care data semantic/ ontology/ vocabulary representation (e.g., ICD-9/10, SNOMED, LOINC, RxNorm, ICD-O, etc.)
Experience working with genomic data and genomic data terminology nice-to-have (e.g., HUGO, COSMIC standards, VCF/BAM files, etc.)
Experience working with AWS, Google Cloud, or similar cloud-based technologies
Ability to lead large scale implementations in a fast-paced, ever-changing environment with demonstrable ability to navigate successfully with hospital client data teams.
Demonstrate ability to establish strong client-trust and maintaining consistent and strong relationships with customers and vendor partners
Demonstrate ability to handle large data sets and relational databases
5 year's experience preferred
Work Location
Position available at our Tempus Chicago HQ, San Francisco, or New York office; or consideration for remote available.",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Azure Data Modeler- eCommerce,"$50K-$88K
(Glassdoor Est.)","Here is a great opportunity to join a great company! Medline Industries has enjoyed DOUBLE DIGIT GROWTH for 53 of the past 54 years! We've again been named to the Chicago Tribune's Top Workplaces, and we're again on the list of Becker's Great Places to Work in Healthcare.

We have a great opportunity to show off your passion for data, reporting, analytics and data warehousing. Medline's BI team may have the perfect fit for you!

We are looking for a self-motivated Data Engineer to join our business intelligence team.
This data engineer will be responsible for developing and maintaining business intelligence, data warehousing and data engineering solutions for E-commerce department. This individual will also create and maintain detailed business requirements, outlining data problems, opportunities and solutions for our E-Commerce department.

Responsibilities include:
• Responsible for designing relational and non-relational data stores on Azure.
• Responsible for designing and developing solutions in Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, SQL Data Warehouse, HDInsight.
• Gather and process raw data at scale that meet functional / non-functional business requirements (including writing scripts, REST API calls, SQL Queries, etc.)
• Responsible for developing data set processes for data modeling, mining and production.
• Responsible for data modeling of multiple E-Commerce data marts.
• Responsible for building new Data Lake in Azure, expanding and optimizing our data platform and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
• Responsible for supporting our Software Developers, Data Analysts and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
• Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
• Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
• Develop complex SQL queries in TIBCO Data Virtualization tool.

Qualifications
• 3+ years of experience architecting and building Data Lake, Azure Big Data architecture, Enterprise Analytics Solutions, and optimizing ' big data' data pipelines, architectures and data sets.
• Advanced hands-on SQL, USQL, Python, C#, Java, pySpark (2+ of these) knowledge and experience working with relational databases for data querying and retrieval.
• Experience with Design and Architecture of Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure ML, SQL Data Warehouse, HDInsight.
• Experience with building processes supporting data transformation, data structures, metadata, dependency and workload management.
• Experience working with cross-functional teams in a dynamic environment.
• Experience building Big data pipeline with Java and/or Python a plus.
• Strong SQL skills on multiple platform
• Data Modeling tools (e.g. Erwin, Visio) knowledge a plus.
• Experience with SAP HANA a plus.
• Experience with Talend a plus.
• Experience with Alteryx a plus.

More About Medline:
Medline is the largest privately held manufacturer and distributor of healthcare supplies in the United States, providing more than 550,000 products that serve the entire continuum of care. Our innovative products and programs can be found in most hospitals, extended-care facilities, surgery centers, physician offices, home care dealers, home health agencies and retail outlets.

Founded in 1910, Medline has grown from a small manufacturer of aprons, surgical gowns and uniforms to a thriving $12 billion global enterprise because of our dedicated people, entrepreneurial spirit and honest values.

Again named one of the country’s ""Best and Brightest Companies to Work For,” and once again named to Chicago Tribune’s Top Workplaces, Medline has experienced fifty-plus years of consecutive annual growth, and is headquartered in Northfield, IL.",3.4,"Medline Industries
3.4","Northfield, IL",10000+ Employees,1966,Company - Private,Health Care Products Manufacturing,Manufacturing,$10+ billion (USD)
Lead Data Engineer - IHM,"$90K-$168K
(Glassdoor Est.)","Discover. A brighter future.

With Discover, you’ll have the chance to make a difference at one of the world’s leading digital banking and payments companies. From Day 1, you’ll do meaningful work you’re passionate about, with the support and resources you need for success. We value what makes each employee unique and provide a collaborative, team-based culture that gives everyone an opportunity to shine. Be the reason millions of people find a brighter financial future, while building the future you want, here at Discover.

Job Description


TITLE: Lead Data Engineer

DUTIES: DFS Corporate Services LLC seeks Lead Data Engineer in Riverwoods, IL to develop data driven solutions utilizing current and next generation technologies to meet evolving business needs. Ability to quickly identify an opportunity and recommend possible technical solutions. Develop application systems that comply with the standard system development methodology and concepts for design, programming, backup, and recovery to deliver solutions that have superior performance and integrity. Contribute to determining programming approach, tools, and techniques that best meet the business requirements. Understand and follow the PDP process to develop, deploy and deliver the solutions. Be pro-active and diligent in identifying and communicating design and development issues. Provide business analysis and develop ETL code and scripting to meet all technical specifications and business requirements according to the established designs. Offer system support as part of a support rotation with other team members. Operationalize open source data-analytic tools for enterprise use. Work heavily within the Cloud ecosystem and migrate data from Teradata to Cloud based platform. Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution with partner Data Engineers and source data providers. Provide subject matter expertise in the analysis, preparation of specifications and plans for the development of data processes. Ensure proper data governance policies are followed by implementing or validating Data Lineage, quality checks, and classifications. Promote a risk-aware culture to ensure efficient and effective risk and compliance management practices by adhering to required standards and processes.

REQUIREMENTS: Bachelor’s degree or foreign equivalent in Information Technology, Communications Engineering, Computer Science, or a related field and four (4) years of experience in job offered or related position: utilizing development tools including Python, Abinitio, Hadoop, and Hive; developing real time ingestion and streaming applications leveraging Abinitio; migrating ETL processes from relational databases like Teradata to Cloud-based platforms; utilizing programming languages including Shell Scripting, Python, SQL, and Microservices; utilizing Google Cloud Solutions including Jenkins, Github, Hadoop, and Teradata; building and utilizing tools and frameworks within the Big Data ecosystem including Hadoop, Hive, Scoop, HBase, and Hue; utilizing database technologies including Oracle and DB2; and scheduling and monitoring jobs using Maestro and Tivoli work load scheduler.

QUALIFIED APPLICANTS: Please apply directly through our website https://jobs.discover.com/ for Job ID R1776 by clicking on “Apply Now.” No calls. Equal Opportunity Employer/disability/vet.

What are you waiting for? Apply today!

The same way we treat our employees is how we treat all applicants – with respect. Discover Financial Services is an equal opportunity employer (EEO is the law). We thrive on diversity & inclusion. You will be treated fairly throughout our recruiting process and without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status in consideration for a career at Discover.",3.9,"Discover
3.9","Riverwoods, IL",10000+ Employees,1985,Company - Public,Financial Transaction Processing,Finance,$5 to $10 billion (USD)
Data Engineer,-1,"Job Description:

Â
Exact Job Location/Work Address

Requirements are scattered across 4 main locations: Richmond VA, McLean, VA, Wilmington, DE, Chicago, IL
Required Technologies
Strong Programming experience with object-oriented/object function scripting languages: Python, PySpark, Scala, etc.
Experience with big data tools: Hadoop, Apache Spark, Kafka, etc.
Experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra.
Â
Job Description:ÂDetailed overview of functional and technical role expectations

Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have working experience using the following software/tools:

Â
Strong Programming experience with object-oriented/object function scripting languages: Python, PySpark, Scala, etc.
Experience with big data tools: Hadoop, Apache Spark, Kafka, etc.
Experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra.
Â

Responsibilities for Data Engineer:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements.
ÂIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.
ÂBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'Big data' technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
ÂWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Â

Â

Â

Rating table:
Skills

Rating Out Of 10

Experience in Years
Spark

Â

Â
Python

Â

Â
Scala

Â

Â
AWS

Â

Â
Object oriented Programming

Â

Â

Â

Â",-1,Clear Technology Consulting,"Chicago, IL",Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD)
Data Engineer,"$63K-$114K
(Glassdoor Est.)","Oak Street Health is a rapidly growing, innovative company of community-based healthcare centers delivering higher quality health and wellness care that improves outcomes, manages medical costs and provides an unmatched experience for adults on Medicare in medically underserved communities. By providing holistic, comprehensive and integrated care right in our patients’ communities, we can help keep them healthy and reinvest cost savings in further care for those same communities and others. Since 2013, Oak Street Health has brought its singular approach to tens of thousands of people across the nation. With an ambitious growth trajectory, Oak Street Health is attracting and cultivating team members who embody Oak Street values and are passionate about our mission to rebuild healthcare as it should be.

For more information, visit www.oakstreethealth.com.

Job Responsibilities
Design, Develop, and unit test new or existing ETL/Data Integration solutions to meet business requirements.
Daily production support for Enterprise Data Warehouse including ETL/ELT jobs.
Design and Develop data integration/engineering workflows on big data technologies and platforms
Develop data streams using Apache Kafka.
Develop workflows in the cloud environment using Cloud base architecture (Azure or AWS).
Develop dataflows and processes for the Data Warehouse using SQL (SQL Server).
Develop Data integration workflows using Web services in XML, JSON, flat file format, SOAP
Work with stakeholders including the Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Deliver increased productivity and effectiveness through rapid delivery of high-quality applications.
Create and maintain optimal data pipeline architecture.
Performs other duties as assigned.
What we’re looking for

We’re looking for motivated, experienced developers with:
Bachelor’s degree in Computer Science, Engineering, or related field from an accredited university
Proven experience in a data integration role with expert level SQL
Working knowledge of ETL change detection solutions such as change data capture (CDC)
Experience using Apache Kafka
Proven experience integrating enterprise software using ETL modules/Data Engineering tools
Knowledge of data architecture, structures and principles with the ability to critique data and system designs
Ability to integrate data from Web services in XML, JSON, flat file format, SOAP
Experience with Big Data technology a plus
Knowledge in DevOps practices and tools is a plus
U.S. Work Authorization
Someone who embodies being “Oaky”
What does being “Oaky” look like?
Radiating positive energy
Assuming good intentions
Creating an unmatched patient experience
Driving clinical excellence
Taking ownership and delivering results
Being scrappy
Why Oak Street?

Oak Street Health offers our coworkers the opportunity to be at the forefront of a revolution in healthcare, as well as:
Collaborative and energetic culture
High levels of responsibility and rapid advancement
Headquarters (the “Treehouse”) located in the heart of Downtown, close to many public transit options and great restaurants
Competitive benefits; including paid vacation/sick time, generous 401K match with immediate vesting, as well as health benefits
Oak Street Health is an equal opportunity employer. We embrace diversity and encourage all interested readers to apply to oakstreethealth.com/careers.",3.6,"Oak Street Health
3.6","Chicago, IL",1001 to 5000 Employees,2012,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Principal Environmental Scientist,"$74K-$115K
(Glassdoor Est.)","General Statement

Under general direction, carries out or supervises applied research projects of varied scope in relation to wastewater treatment processes and oversees environmental monitoring activities.

Essential Job Functions

Essential job functions are fundamental, core functions common to positions in a classification. They are not intended to be an exhaustive list of all job duties for any one position in the class. Since class specifications are designed to be descriptive and not restrictive, incumbents may complete one or all of the job duties listed or tasks of similar kind not specifically listed here.
Conducts complex research assignments on new technologies related to wastewater, sludge processing, biosolids management and water quality improvements in the fields of environmental chemistry, wastewater microbiology, soil science, environmental engineering and aquatic ecology.
Manages programs/projects as a team leader, supervises technical staff, develops work plans and advises on the proper conduct of studies.
Oversees environmental monitoring activities related to District’s operations (biosolids, aquatic ecology, surface water and groundwater quality and wastewater microbiology).
Prepares interim and final reports on research projects and monitoring programs and technical manuscripts for publication; prepares comprehensive technical reports.
Reviews and prepares comments on technical documents from other District Departments or regulatory agencies or other outside organizations; assists in the preparation of position papers related to District activities.
Assists Maintenance and Operations in solving plant problems such as sludge dewatering, odor problems and plant upsets.
Reviews plans and specifications and design criteria prepared by Engineering Department; collaborates with Analytical Laboratories and Industrial Waste Sections to solve problems related to the District water reclamation plants.
Assigns, supervises and reviews work; ensures staff compliance with District policies and procedures including Personnel Rules and Administrative Procedures; completes performance reviews; addresses employee complaints and grievances; may recommend employment actions such as hiring, transfer, suspension, promotion or discharge.

Other Job Functions

Prepares or participates in seminar and lecture presentations related to research projects.
Performs administrative duties such as coordination of weekly progress reports, work plans, time sheets, purchasing and reimbursements, and assisting with the annual budget.
Manages field and laboratory environmental activities.
Oversees laboratories, NPDES permit-required toxicity testing, bacterial and virological analyses, biological collections and analyses, and soil and plant analyses.
Establishes and maintains effective relationships with other public agencies and the general public.
Coordinates review of monitoring reports required by regulators.
Performs other duties as assigned.

Environmental Conditions

May involve exposure to a variety of chemical and biological materials, some of which may be hazardous or toxic. May involve exposure to fumes and noxious odors.

Desirable Knowledge, Skills and Abilities


Thorough knowledge of the principles, practices, procedures and related environmental regulations in at least one of the following technical areas:
Analytical microbiology, molecular microbiology, virology and bioassay;
Aquatic biology, biological indices related to environmental perturbations, water and sediment quality monitoring, and ecology of freshwater aquatic systems;
Environmental engineering, wastewater treatment and biosolids processing; and/or
Soil science and agronomy, biosolids land application and groundwater monitoring.
Thorough knowledge of project and program management.
Thorough knowledge of the methods and techniques for planning and executing applied research and environmental monitoring projects.
Considerable knowledge of statistical techniques used in project planning and analyzing data.
Considerable knowledge of District Administrative Procedures and other policies.
Ability to supervise and coordinate the work of professional, technical and support personnel engaged in research and related activities.
Ability to coordinate and manage technical and scientific activities.
Ability to consistently deliver quality project deliverables on schedule.
Ability to communicate effectively, orally and in writing.

Minimum Qualification Requirements

A master's degree in water resources sciences, environmental engineering, environmental sciences, microbiology, bacteriology, biology, soil science, or agronomy from an accredited college or university. Ten years of experience in the fields of wastewater and sludge treatment technologies, biosolids management, analytical microbiology or water quality monitoring, including one year at a supervisory level.

Substitution

Related graduate study above the master's degree may be substituted for the required non-supervisory experience on a year-for-year basis.

Promotional Requirement

Two years of service with the District as a Senior Environmental Research Scientist, Senior Environmental Soil Scientist, Senior Environmental Microbiologist, or Senior Aquatic Biologist.
Civil service status in one of the foregoing classes.",4.1,"MWRD of Greater Chicago
4.1","Chicago, IL",1001 to 5000 Employees,-1,Government,Federal Agencies,Government,Less than $1 million (USD)
Associate Director - Lead Data Engineer,"$109K-$190K
(Glassdoor Est.)","Job Description


We’re hiring!

Aon is currently recruiting an Associate Director, Data Engineer to join our team in Singapore.

About Aon's Center for Innovation and Analytics

Aon’s Centers for Innovation and Analytics (ACIA) in Dublin and Singapore are at the heart of delivering Aon’s Data & Analytic Services team’s mission to:
accelerate the rate of innovation through digital solutions to help better respond to clients’ evolving needs
provide foundational data and analytics capabilities in one place for 50,000 Aon colleagues and our global clients who use our risk and people solutions
Established in 2012, there are over 100 colleagues in Singapore’s Centre today including actuaries, software developers, data scientists, financial analysts and accountants. We are expanding rapidly and looking for dedicated individuals who can leverage emerging technologies and collaborate across Aon’s solution lines to help clients and colleagues make better, data-driven decisions today and tomorrow.

The Opportunity

You will work with business stakeholders and our Engineering team (mostly with Data Scientists, Data Analysts, Backend Engineers and SRE’s) to develop and have a real impact on the overall design of the data and data pipeline architecture to allow the growth of our business. As our Lead Data Engineer, you should be passionate about designing, building, and maintaining our growing big data platform.

Responsibilities:
Work with the Engineering team and in collaboration with Aon’s business teams to define and deliver data solutions that enable and enhance Aon’s analytical capabilities.
Design, build and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Design the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Work with stakeholders including the Product Owner, Data Science and Development teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Maintain up to date Technical and Operational documentation
Requirements
Bachelor’s Degree in Computer Science, Information Technology or equivalent.
5+ years’ experience in Big Data technology and developing data pipelines within a Hadoop-based / Apache Spark environment
Good knowledge of Hadoop ecosystem (HDFS, Hive, Impala, Kafka, Spark, Elasticsearch etc.) & associated tools and cloud-based technologies (AWS-based)
Highly proficient at reading, profiling, parsing, transforming, cleansing & integrating data from various sources (structured and unstructured)
Experience designing Horizontally Scalable Event-Driven Big Data Architecture
Experience with big data ingestion and workflow management tools: Hadoop, Spark, Kafka,Airflow, StreamSets, etc.
Experience with relational SQL and NoSQL databases (Postgres, MongoDB, Redis, etc.)
Experience developing data solutions with AWS cloud services: EC2, EMR, RDS, Redshift, Kinesis, Athena
Experience in programming (Python, Scala, Java) for automation and data processing.
Experience working with bash scripting, Docker, Kubernetes and Linux environments on a daily basis.
Experience with Cloudera CDP will be an added advantage
Awareness of Data Security, Data Governance and Service Operations processes, with an ability to deliver on these key non-functional requirements.
Excellent communication, sharp analytical abilities, able to think critically of the current system in terms of growth and stability
How to Apply

Your opportunity to empower results could start right here. Make your mark and apply online today with a brief covering letter and your resume, sharing relevant achievements for this position.

We Offer You

A competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.

Our Colleague Experience

Every day, our colleagues make a difference, work with the best, own their potential, and value one another. Together, we share this one purpose: to empower economic and human possibility around the world. This unifying goal is at the heart of our identity, and it lives in everything we do. To learn more about our colleague experience, visit Aon Colleague Experience.

Aon is an equal opportunities employer. We are committed to creating a winning and inclusive culture where everyone feels valued and has opportunities for growth and development.

2477268",3.6,"Aon
3.6","Chicago, IL",10000+ Employees,1892,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD)
"Principal Research Scientist/ Statistician, Real World Evidence/ Late Phase","$85K-$166K
(Glassdoor Est.)","Principal Research Scientist/ Statistician, Real World Evidence (RWE)/ Late Phase

Job Purpose / Summary:
Responsible for planning, implementing and reporting RWE or health economics and outcomes research projects within CTI. This includes working closely with pharmaceutical, medical device, and diagnostics clients, among others, in partnership with CTI business development personnel in the development of project-specific methods and project deliverables. The person in this role may conduct face-to-face client meetings, teleconference calls, and publication strategies autonomously and may serve as mentor for other Research Scientists.

What You'll Do
Provide leadership or management for Real-World Evidence (RWE) programs with responsibilities to include: business development, client interactions, developing research objectives and statistical methodology for clients, participating in and overseeing projects
Consult and design of RWE study protocols, to include retrospective studies (EMR, chart reviews, cohort) and cross-sectional and prospective observational studies
Apply knowledge of statistical theory, techniques and methods encompassing such areas as sampling, ratios and proportions, measures of dispersion and central tendency, reliability, validity, correlations, survival, trends, index numbers, forecasting, categorical data analysis, non-parametric methods
Design and conduct analyses of large- and small-scale healthcare databases, registries, and non-regulatory clinical study data including EMR, EPIC, marketscan or other large scale databases
Write statistical analysis plans for studies and work with programmers and analysts to create the necessary analyzable datasets
Effectively communicate with clients to develop and report RWE solutions during the course of business development or within the context of a project
Required Education/Experience
Bachelors in biostatistics, health services research, pharmacy, nursing, natural science, epidemiology, biostatistics, or closely related discipline
10 years experience in working in outcomes research design, epidemiology, or biostatistics
Master of Public Health (MPH), or PhD (or DrPH, ScD/PharmD/MD) level scientist in health services research, pharmacy, nursing, natural science, epidemiology, biostatistics, or closely related discipline preferred
Pharmaceutical / biotech and/or contract research organization (CRO) experience preferred
Knowledge of statistical software packages including SAS preferred
Data visualization software (e.g. Tableau) and other advanced data presentation methodology preferred
Economic modeling building experience preferred
Significant demonstrated experience with developing peer-reviewed publications in relevant medical/pharmacy journals
Why CTI?
We support career progression 25% of our global staff is promoted annually and we have a structured mentoring program to provide the support you need to move forward
We value education and training We provide tuition reimbursement, partner with universities and colleges to create programs in our field, and have a dedicated training department
We value our people - We have never had a layoff in our 20-year history, support a work-life balance with flexible schedules, and have provided cash bonuses every year for the past decade
Our culture is unparalleled Click here to learn more about The CTI Way
We think globally and act locally We have a global philanthropic program supporting our teams efforts to improve their local communities (Click here to learn more about our CTI Cares program)
We are looking toward the future We have had a consistent 15% growth rate over the last decade, invest in cutting-edge technology, and pride ourselves on our average 95% annual retention rate
Our work makes a difference We focus our work on treatments for chronically and critically-ill patients, who are depending on us to bring these life-changing therapies to market",4.0,"CTI Clinical Trial Services, Inc
4.0","Chicago, IL",501 to 1000 Employees,1999,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Food Scientist,-1,"Employee Type:

Full time

Location:

NE Omaha R&D Center

Job Type:

Research and Development

Job Posting Title:

Food Scientist

Job Description:

Under limited supervision, leads the design, planning, validation, and implementation of new products, line extensions, product improvement and technical service for TreeHouse Foods that meet product offering requirements within our Baked Goods Division.

Position Responsibilities:
Under limited supervision, works collaboratively in the execution of development from bench to production scale for new products, product improvements and cost savings projects.
Defines the formulation, nutritional and process parameters needed to develop a product which meets the project objective(s). Understands the impact of these parameters to overall project.
Defines raw material and corresponding process and finished product specifications and set-ups through corresponding systems.
Applies sound scientific methods in all stages of development. Including planning and executing trials, analyzing data and defining solutions to achieve project goals.
Identifies opportunities for competitive market advantage
Provide judgement and experience to assure that an appropriate level of technical knowledge and discipline are being applied and utilized in business decisions
Partner and communicate effectively with cross-functional groups: Marketing, Sales, QA, Procurement, Finance, Operations and Engineering
Ensure the transfer of technology to the operations team when commercializing products. Provide technical oversight of internal and external manufacturing start-ups and ongoing technical service
Contribute significantly and continually to attain results through the generation and application of advanced, specialized knowledge
Generate and support pipeline work to drive cost optimization through formulation and processing efficiencies
Participates in customer presentations and/or preparing product, content for customer meetings
Ensure all activities follow established safety standards, regulatory requirements (FDA, UDSA & Kosher) and Good Manufacturing Procedures (GMP)
Qualifications and Requirements:
Three years’ experience in Food Science Product Development OR No experience required if holding a PhD in Food Science/Engineering or Related Field
Dough and Baked Goods experience preferred
Understanding of ingredient interactions/functionality
Communicate effectively and openly while working in a cross-functional team.
Must be a self-starter, independent, energetic and resourceful
Excellent written and verbal communications skills
Solid Project Management skills and experience
Aptitude for technical leadership and project management
Education: Bachelor’s Degree Required – Type: Food Science/Engineering or Related Field

Preferred Attributes, Qualifications & Working Conditions: Travel - Up to 35%

Disability Assistance
TreeHouse Foods is an Equal Employment Opportunity Employer and offers opportunities to all job seekers, including those with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to disability-accommodations@treehousefoods.com. In your email please include a description of the specific accommodation you are requesting and a description of the position for which you are applying.

EEO Considerations

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, citizenship, disability or protected veteran status.",3.4,"Flagstone Foods
3.4","Downers Grove, IL",501 to 1000 Employees,-1,Company - Public,Catering & Food Service Contractors,"Restaurants, Bars & Food Services",$50 to $100 million (USD)
Sr. Scientist - Biologics,"$72K-$149K
(Glassdoor Est.)","Company Description

SGS is the world’s leading inspection, verification, testing and certification company. SGS is recognized as the global benchmark for quality and integrity. With more than 94,000 employees, SGS operates a network of over 2,600 offices and laboratories around the world.

Job Description

PRIMARY RESPONSIBILITIES

The Senior Scientist position is responsible for method development, validation and transfer of methods used in testing of biopharmaceutical products or raw materials. Responsible for complex decision making and re-evaluation, optimisation and troubleshooting of methodologies as required by clients. Responsible for providing guidance to and overseeing analysts within the Analytical Operations regarding the performance of their activities related to department. Responsible for leading technical discussions with clients and managing small to mid-sized projects to ensure completion in a timely manner to the satisfaction of both SGS and client management. With aid from the Department head and/or Group Leader, managing performance of group, resource allocation and scheduling. Overall, the Scientist role presents the employee with an opportunity to contribute in many ways to the long-term success of both the Biologics Services Laboratory and the company as a whole.

Follow Training SOP for training and training records.

REPORTING LINE

The Senior Scientist of the Biologics Services Laboratory at SGS reports to the Department Head and/or Group Leader.

SPECIFIC RESPONSIBILITIES

OUR PROMISE TO OUR CUSTOMERS

· At all times, comply with SGS Code of Integrity and Professional Conduct, and to conduct all our testing to to the highest level of cGMP compliance.

SERVICE RESPONSIBILITIES TO CLIENTS

· Develop, implement, and maintain systems to ensure that SGS clients receive top-notch customer service.

· Ensure that all client requests for analytical testing information or time and materials estimates for quotation purposes (or information regarding any of SGS other services) are met in a timely and effective manner.

· Develop, implement, and maintain systems to ensure that established parameters governing turnaround time and quality expectations are met on a consistent basis in the Analytical Services Laboratory.

· Ensure that client requests pertaining to the development and completion of specialized studies are met in a timely and effective manner.

· Ensure that client complaints are dealt with effectively according to applicable SGS SOPs.

· Play a lead role in departmental and/or company-wide projects designed to improve the nature of SGS client services.

· Represent Company and Company policies as needed during client visits and regulatory agency inspections.

SERVICE RESPONSIBILITIES TO INTERNAL CUSTOMERS

· Provide technical support and feedback to clients and other SGS groups.

· Liaise with clients to establish project timelines and with SGS management to assess resource requirements.

· Coordinate method transfers between clients, the Research and Development group, and the RM/Finished Products departments

· Assist in the failure investigations within other SGS groups and design investigation protocols and suggest corrective actions.

· Utilizes advanced analytical techniques to identify root causes and determine courses of action

· Perform evaluation of sophisticated analytical equipment or software, providing expert opinion on quality and feasibility with respect to their use in the Laboratory

· Ensure that equipment are maintained in a good order, calibrated and qualified as required.

· Ensure all work areas are clean and organized.

· Oversee, train, mentor and guide Analysts in their work

· Participate in departmental or company-wide projects designed to improve the internal efficiency and overall quality of work performed at the laboratory.

· Act as a specialised technical resource to the team members around potential courses of action to resolve complex problems.

· Knowledgeable in all regulatory guides impacting their specialized field, such as ICH, FDA, TPP, pharmacopeias.

· The incumbent must be capable of incorporating scientific rigor into work activities, multi-tasking, and appropriately interpreting/trending scientific results in order to meet the required expectations and timelines while working together with department management and clients on a regular basis.

· The incumbent must possess very strong communication skills allowing them to navigate sensitive and often complex matters with both clients and SGS staff.

· Organizes and schedules the testing with the Group Leader/Department Head.

· Feedback to Scientific Leader/Department Head and client to support the decision making on any technical and procedure issues

· Perform other assigned lab duties as requested.

TECHNICAL RESPONSIBILITIES

· Perform the development and validation of analytical testing procedures for drug substances and drug products

· Write protocols, drafts methods and technical reports.

· Coordinate method transfers between clients and SGS.

· Provide expert technical support to clients, internal and othe SGS groups.

· Make complex decisions and perform activities relating to method development and validation of analytical testing procedures.

· Ensure that equipment is maintained properly. Also perform calibrations and qualifications as required.

· Participate in and lead investigations for OOS, OOT, and deviations. Participate and execute CAPA.

· Executes experiments, following the company’s Standard Operating Procedures, Deviations and Change Control programs and cGMP guidelines.

· Keep all records and lab notebooks in good order. Analyze testing data, enter the testing results into the company’s electronic system for a certificate of analysis and prepare reports, if required, in timely manner.

· Duties here include preparation for testing by using good time management skills for each assigned task, adequacy of testing documentation, proper application of test procedures, proper techniques for data capture and recording and preparation of the final report of analysis.

· Write and Review technical data, documents, SOPs and proposals as required.

· In case of a testing failure, immediately report to the Department Head or the designee before proceeding further with the test, lead/assist failure investigations to identify the cause of failure and prepare a deviation report and/or Corrective Preventative Actions (CAPA) if it is appropriate.

· Ensure that work order documentation is complete in every respect and all results are entered into the Electronic Laboratory Information System or client’s Certificate of Analysis before submission to the QA reviewer.

· Keep the work area clean and organized; immediately clean up spills, dispose of waste according to laboratory procedures and place used glassware in designated locations for cleaning.

· Perform other assigned lab duties as requested.

· Utilizes advanced analytical techniques to identify root causes and determine courses of action

· Inform the Department Head if the assigned work order cannot be satisfactorily completed within established scheduled time and quality-of-work expectations.

ADMINISTRATIVE RESPONSIBILITIES

· Adherence to all SGS personnel policies.

· Adherence to relevant SGS SOPs governing documentation and reporting.

· Compliance with applicable SGS SOPs related to the handling of client complaints.

· Participation in general staff training sessions as these are scheduled.

Qualifications

· Education: B.S., M.S or PhD in Biochemistry, Chemistry, Biology (depending on experience and training).

· Experience: 2-5 years’ relevant previous laboratory experience in a regulated industry with demonstrated ability to complete more complex role/duties.

REQUIRED SKILLS

Specific technical skills:

· Ability to stand out, think outside the box.

· Demonstrated understanding of cGMP/GLP

· Ability to coordinate and manage a group and its workload.

· Ability to critically interpret and analyze data

· Able to read, understand, communicate and follow work instructions in a safe, accurate and timely manner.

· Capable of interacting with all levels of management, suppliers and clients.

· Must be proficient in using various types of computer software (Word, Excel. PowerPoint & Outlook).

· Proven ability to manage and coordinate multiple projects in a fast-paced, highly professional environment.

· Demonstrates excellent verbal and written communication skills.

· Ability to work well with others & independently.

· Proven time management skills and a strong attention to detail.

· Works well under pressure.

· Extended hours and shift work may be required from time to time.

· Travel to other SGS locations or client location may be required from time to time or lead a group of individuals at Client’s site.

· Ensures full compliance with the company’s Health & Safety, Code of Integrity, and Professional Conduct policies.

Appropriate attitude, constant vigilance, attention to detail and following Training SOP for training and training records

Additional Information

SGS is an Equal Opportunity Employer, and as such we recruit, hire, train, and promote persons in all job classifications without regard to race, color, religion, sex, national origin, disability, age, marital status, sexual orientation, gender identity or expression, genetics, status as a protected veteran, or any other characteristics protected by law.

Perform this job successfully, an individual must be able to perform each essential duty satisfactorily with or without reasonable accommodations. The requirements listed above are representative of the knowledge, skills, and/or abilities required.

This job description should not be construed as an exhaustive statement of duties, responsibilities or requirements, but a general description of the job. Nothing contained herein restricts the company’s rights to assign or reassign duties and responsibilities to this job at any time.

If you are applying for a position within the United States and you have difficulty completing the on-line employment application because of a disability, please call 201-508-3149 for assistance and leave a message. You will receive a call back. Please note, this phone number is not for general employment information, but is only for individuals who are experiencing difficulty applying for a position due to a disability

All your information will be kept confidential according to EEO guidelines.",3.0,"SGS
3.0","Lincolnshire, IL",10000+ Employees,1878,Company - Public,Consulting,Business Services,$5 to $10 billion (USD)
"Medical Laboratory Scientist - Hematology, Full-time, Evenings",-1,"Technical responsibilities: o Performs all aspects of pre-analytic workflow appropriate for the specific laboratory section to ensure orders are entered correctly, specimens collected are appropriate for the test ordered and are correctly processed/transported. o Verifies order where necessary o Verifies non-patient information (e.g., collection time) according to established protocol. o Handles unresolved orders, troubleshoots where needed. o Verifies with physicians and/or nurses prior to laboratory information system (LIS) order entry to resolve unclear, duplicate or otherwise ambiguous orders. o Verifies specimens for add-on tests are available and acceptable and generates add-on test orders. o Recognizes when fraud and abuse compliance issues require adjustments to the test order o Collecting, receiving and processing of specimens: Verifies specimens are correctly and completely labeled upon receipt. Evaluates specimens for appropriateness and takes necessary corrective action. Appropriately documents unacceptable specimens and proper notifications as needed. Prioritizes specimen processing based on established priorities. Aliquots specimens according to established protocols. o Performs all aspects of analytical testing appropriate for the specific laboratory section, Following established written protocols and standard operating procedures (SOP) o Maintains test system integrity: Performs preventive maintenance on instruments/equipment in a timely fashion according to defined schedule. Verifies reagents and supplies meet defined acceptability criteria upon receipt and prior to use; takes action to ensure unacceptable items are removed from use. Ensures that sufficient reagents and supplies necessary for test performance are available. Notifies senior staff when minimum inventory level is encountered. Performs and records all necessary quality control (QC) required for test system performance. Evaluates QC resultsand takes necessary corrective actions according to established protocol. o Performs specimen preparation: Performs any necessary pretest specimen preparation according to protocols (e.g., microbiology plating, cell cultures, filtering, extraction, separation, elution, absorption, etc.) Transfers or ships specimens to approved testing locations according to SOPs o Responsible for all aspects of analytical testing appropriate for the specific laboratory section o Maintains test system integrity: Examines preventative maintenance logs on instruments/equipment in a timely fashion and follows up as needed. Verifies reagents and supplies meet defined acceptability criteria upon receipt and prior to use; takes action to ensure unacceptable items are removed from use. Responsible for inventory maintenance and supply ordering in designated section. Performs and records all necessary quality control (QC) required for test system performance. Review and evaluates QC results in designated sections and take necessary corrective actions according to established protocol. o Performs tests: Prioritizes testing based on assignment or established priorities, completes testing within defined turn-around-times (TAT). Recognizes the need for and follows any age-specific protocols Responds effectively to changes in the workflow by coordinating a simultaneous series of tests when needed or adjusting work to incorporate STAT tests or fluctuations in work volume. Exercises independent judgement in the performance of technical responsibilities Monitors daily workflow and priorities to assure meeting service levels. o Performs technical review and interpretation: Develops and maintains a higher level of expertise in the specific areas of responsibilities. Reviews results for completeness, correctness, and consistency within defined test system Evaluates test results/reactions and provides accurate interpretations as appropriate to include correlation with, and integration of, other patient data as necessary. Performs visual interpretation/identifications as appropriate. Recognizes unusual test results/interpretations and completes indicated reflex testing or other follow-up actions. Follows established notification protocols for critical values, phone/fax/e-mail results requests, abnormalities. Evaluates instruments and test systems and makes recommendations for acquisition to senior management. o Troubleshoots and solves problems: Recognizes test system performance problems and takes necessary corrective actions. Recognizes when unresolved problems need to be escalated and takes necessary follow-up action. Reviews pending logs and follows-up to ensure pending tests are completed or cancelled when appropriate. Performs advanced troubleshooting and repair. Calls for field service when necessary and is familiar with contractual terms of maintenance agreements. o Post-test specimen storage: Ensures that specimens and related materials (blood, slides, tissues, etc.) are stored according to protocols for location and duration with necessary documentation Post-analytical responsibilities: o Performs all aspects of the post-analytical workflow appropriate for the specific laboratory section to ensure accurate results are reported within established time frames, specimens are retained appropriately, test results and/or current status are available upon inquiry, and billed charges are correct for testing performed. o Verifies and reports results: Verifies results according to procedure. Performs computer functions necessary for releasing results. Generates written reports according to established protocol. Reviews electronic or printed reports when applicable, recognizes problems and escalates according to protocol. o Amends reports: Corrects erroneous reports and amends reports according to procedure o Responds to inquiries: Responds to requests for information according to established protocol for confidentiality and release of information Recognizes when unresolved inquiries need to be escalated and takes action o Stores documents and records: Stores documents and records according to established protocol. o Charge capture/billing: Performs billing and/or enter credits for tests and services when applicable. Recognizes billing problems and escalates accordingly Universal responsibilities: o Ensures quality of operations: Assumes delegated responsibilities in the absence of a coordinator. Responsible for regulatory compliance in designated section. Follows written standard operating procedures (SOP). Operates instruments/equipment according to protocol. Uses computers according to established protocol; follows downtime procedures as required. Performs required quality system responsibilities including initiating Quality Investigation Reports. Meets proficiency and competency standards of the department and assists in the competency assessment of technical and support staff. Participates in the training of new employees and students Performs operational review of new SOPs. Presents continuing education programs Assists in new test development, validations and implementation. Attends at least one personal development session per year. Assists the coordinator and manager in monitoring the operations of designated areas to ensure service standards and financial goals are met. Contributes in developing and is responsible for implementation of technical goals and standards. Performs other duties as assigned, or as needed, to ensure continued quality operations o Information Systems: Ensures integrity of Laboratory Information Systems (LIS) by following established protocols and participates in the maintenance and enhancements of the LIS. May oversee/accomplish instrument computer software upgrades/updates Demonstrates expertise in Information Technology; uses application to streamline operations and facilitate service monitoring and data collection. o Ensures safety of operations: Follows all required safety procedures, uses personal protective equipment (PPE) appropriate for tasks performed, and assumes a proactive role in laboratory safety. Maintains cleans and organized work area o Provides service excellence: Answers telephone when needed, using NM telephone etiquette Maintains patient confidentiality including protected health information (PHI) Assists patients, visitors and other contacts whenever need occurs",3.9,"Northwestern Medicine
3.9","Chicago, IL",5001 to 10000 Employees,1965,Hospital,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD)
GCP Data Engineer,"$65K-$115K
(Glassdoor Est.)","Skills Needed
Â
Spark(PySpark preferred)
Spark Workload Tuning/Optimization
Python(focus on data engineering)
Apache Beam(Python preferred)
Airflow(Cloud Composer preferred)
BigQuery
Hive
Data Modeling/Data Warehouse/Analytics
Looker, Tableau
CICD(Cloud Build, Bazel, MonoRepo)
Jupyter Notebooks(Good to have but not required)
Â
Â
Please send resumes toÂsgottumukkula@esharpedge.com
Â",4.7,"Sharpedge Solutions Inc
4.7","Naperville, IL",Unknown,-1,Company - Private,Publishing,Media,Less than $1 million (USD)
Data Engineer,"$51K-$98K
(Glassdoor Est.)","Hello Associates,

***Greetings from Conch Technologies***

Position: Data Engineer

Location: Rolling Meadows, IL

Â

Basic Qualifications:

- 1+ years experience Spark

- 2+ years experience with AWS

- At least 2 years of SDLC experience using Java technologies

- At least 2 years' experience with leading big data technologies like Cassandra, Accumulo, Python, HBase,ÂScala,ÂHadoop

- At least 1 years' experience in one of the following Cloud technologies: AWS and Docker, or Ansible or Chef or Terraform

Â

You will:

- Work with product owners to understand desired application capabilities and testing scenarios

- Continuously improve software engineering practices

- Work within and across Agile teams to design, develop, test, implement, and support technical solutions across a full-stack of development tools and technologies

- Lead the craftsmanship, availability, resilience, and scalability of your solutions

- Bring a passion to stay on top of tech trends, experiment with and learn new technologies, participate in internal & external technology communities, and mentor other members of the engineering community

- Encourage innovation, implementation of cutting-edge technologies, inclusion, outside-of-the-box thinking, teamwork, self-organization, and diversity

Â

Preferred Qualifications:

- Master's Degree

- 3+ years' experience developing software solutions to solve complex business problems

Thank you

Balu Yetukuri |Recruiting Manager|Â

Desk:Â+1 901-444-3149 // (T) +1 901-249-1904

E-mail:Âbalu@conchtech.com

6750 Poplar Ave # 711, Memphis, TN.Â
web:Âwww.conchtech.com

""A Certified MBE Company""",4.6,"Conch Technologies, Inc
4.6","Rolling Meadows, IL",51 to 200 Employees,-1,Company - Private,Consulting,Business Services,$5 to $10 million (USD)
SENIOR/PRINCIPAL FORMULATION SCIENTIST,"$77K-$140K
(Glassdoor Est.)","Job Summary
We currently have an opportunity for a Senior or Principal Scientist to complete developmental studies and ensure that products can be manufactured to generate acceptable stability data for FDA drug application.

This position is located in our in our Innovation and Development Center in Skokie, IL
Responsibilities
All stages of product development including on-site monitoring of stability lot manufacturing.
Plans, develops, and implements scientifically well-designed experimental designs to meet project objectives as well as meeting corporate and GMP requirements.
Identifies the multidimensional aspects of complex problems and applies novel and creative solutions to problems; handles complex projects with only general guidance.
Participates in the orientation and training of new lab employees in the proper execution of research and development experiments and supervising one to two lab staffs at Principal level.
Product and process improvement as well as for ideas for new products, line-extension, product stability improvement and novel drug delivery systems.
Scales up the manufacturing process and transfers the technology accurately to the production plant.
Sets product specifications based on stability results and according to FDA and ICH guidelines.
Writes Chemistry, Manufacturing and Control (CMC) section for Regulatory submission.
Establishes work priorities for assignments within his/her authority and keeps assignment completion on schedule and is further accountable for the use of his/ her time for creative, self-initiated research.
Requirements:
Bachelors or Masters Degree in Pharmaceutical Sciences, Chemistry, Biological Sciences with 5+ years of related experience or a PhD in Pharmaceutical Sciences, Chemistry, Biological Sciences, Polymer Sciences, Chemical/Biomedical Engineering with 0-3 years of related experience. (Sr. Scientist level)
Ph.D. plus 3+ years of related experience, or MS degree with 7+ years related experience, or BS degree with 10+years related experience. (Principal level)
Skills in designing and executing experiments, analyzing experimental results, and solving problems.
Knowledge of statistic and analysis/interpretation, and pharmaceutical dosage forms.
Concepts in developing novel drug delivery systems.
Willing to perform drug product development for potent compounds, cytotoxic substances and/or controlled substances while following and observing all safety procedures in place, which include the use of engineering controls, administrative controls, Standard Operating Procedures (SOPs), training, and Personal Protective Equipment (PPE).
Ability to travel domestically and internationally to production plant to support batch manufacturing, etc.
IND-1

Additional Information


We offer an excellent salary and benefits package including medical, dental and vision coverage, as well as life insurance, disability, 401K with company match, and wellness program.

Fresenius Kabi is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disabilities, or protected veteran status.",2.3,"Fresenius Kabi USA
2.3","Skokie, IL",1001 to 5000 Employees,-1,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$500 million to $1 billion (USD)
Senior Scientist --Analytics,"$69K-$138K
(Glassdoor Est.)","Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 103,000 colleagues serve people in more than 160 countries.

Diagnostic testing is a compass, providing information that helps in the prevention, diagnosis and treatment of a range of health conditions.

Abbotts life-changing tests and diagnostic tools give you accurate, timely information to better manage your health. Were empowering smarter medical and economic decision making to help transform the way people manage their health at all stages of life. Every day, more than 10 million tests are run on Abbotts diagnostics instruments, providing lab results for millions of people.

Our location in Des Plaines, IL, currently has an opportunity for a Senior Scientist-Analytics.

WHAT YOULL DO:

Position Summary:
Analyzes large data sets and effectively communicates insights
Conceives, plans, designs, and conducts advanced independent research.
Investigates and develops new procedures. on direction provided by project goals and experimental design.
May act as project leader, lead scientist, or independent reviewer.
Provides technical direction and feedback to others, Interacts with other groups and shares information; participates in team
Position Responsibilities:
Defines project goals and is responsible for timely project completion.
Responsible for own Redbook documentation, and for the accuracy, quality, and timeliness of experimental results.
Summarizes data and analyzes results, independently formulates conclusions, and determines future experiments.
Actively participates in routine maintenance, lab safety; may assume roles of responsibility, such as training or document control.


Position Accountabilities
Writes and maintains scripts to automate data analyses
Responsible for implementing and maintaining the effectiveness of the quality system.
Understands and consistently follows documented procedures.
Determines priorities for experiments.
Applies quantitative methods: analyzes data, evaluates results, forms conclusions, and provides/implements process or document improvements.
Independently designs and executes a series of experiments to test hypotheses related to project outcomes.
Applies advance scientific knowledge to projects.
Utilizes DOE where appropriate.
May assist in the design of experiments for others.
Identifies technical alternatives from literature review.
Applies basic computer skills (includes word processing, spreadsheets,
instrumentation-related and Abbott network systems).
Produces reports and documents utilizing advanced writing skills.
Utilizes multiple analytical instruments; trains others in their operation.
Recognizes and resolves technical problems.
Education/ Skills/ Experience:
PhD. in a life or physical science with 2+ years research or industrial Or B.S./M.S. degree with research experience sufficient to demonstrate
Proficient in Python coding; SQL experience is a plus
Demonstrated experience with data visualization techniques
Experience with AWS or Azure is a plus
Prepares results of projects internally and may present externally.
Reviews, evaluates, and critiques presentations for others.
Presents complex technical data to large and diverse groups.
Trains others on the theoretical and practical basis of techniques, processes and assays.
Participates in project planning, updates, and process improvements.
May coach lower-level scientists (e.g., presentation skills, negotiation skills, decision-making, and contingency planning).
Influences decision-making through negotiation, addressing conflict, and by building (productive) working relationships across functional areas.
Knowledge of regulations and standards affecting IVDs and Biologics.
WHAT WE OFFER

At Abbott, you can have a good job that can grow into a great career. We offer:
Training and career development, with on boarding programs for new employees and tuition assistance
Financial security through competitive compensation, incentives and retirement plans
Health care and well-being programs including medical, dental, vision, wellness and occupational health programs
Paid time off
401(k) retirement savings with a generous company match
The stability of a company with a record of strong financial performance and history of being actively involved in local communities
Learn more about our benefits that add real value to your life to help you live fully: www.abbottbenefits.com

Follow your career aspirations to Abbott for diverse opportunities with a company that provides the growth and strength to build your future. Abbott is an Equal Opportunity Employer, committed to employee diversity.

Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.",3.6,"Abbott Laboratories
3.6","Des Plaines, IL",10000+ Employees,1888,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
Data Engineer,-1,"Data Engineer



Naperville,
IL

60563
Posted: 06/01/2020

2020-06-01
2020-10-05

Category: Support

Job Number: 13130

Job Description

Data Engineer

As a Data Engineer, you are familiar with the data warehousing technical components,

infrastructure, and their integration. You’ ll analyze large amounts of data, discover and solve real world

problems. You love the idea of being able to provide insight as well as presenting those insights. You are

responsible for high level design/architecture. You are comfortable fostering relationships with internal

business partners and other members of the development team.

Key Responsibilities

• Design, develop, and maintain modular code base to solve “ real” world problems.

• Conduct regular peer code reviews to ensure code quality and compliance following best

practices in the industry.

• Work in cross-disciplinary teams to understand client needs and ingest rich data sources.

• Utilize Big Data technologies in AWS

• Participate in process for pursuing innovations, target solutions, and extendable platforms for the firm’ s products.

Required Skills and Experience

• Qualified individuals possess the firm’ s attributes of being smart, curious, committed to

vision, passionate, fun/pleasant, an achiever and having a sense of urgency

• Minimum of three years of big data experience with multiple programming languages and

technologies, three years as a lead / team manager.

• Bachelor' s degree or master’ s degree from an accredited college/university in Computer

Science, Computer Engineering, or related field (i.e. math and physics);

• Ability to manage established relationships internally as well as with clients.

• Ability to communicate complex technical concepts succinctly to non-technical colleagues,

understand & manage interdependencies between all facets of a project.

• Ability to interface with clients; Must have demonstrated advanced proficiency in complex,

mature and sophisticated Design & Analysis technologies and solutions.

• Skilled ability to rapidly ingest, transform, engineer, and visualize data, both for ad hoc and

product-level (e.g., automated) data & analytics solutions.

• Experience with large-scale, AWS big data methods such as EC2, S3, EMR, Kinesis,

DynamoDB, and Redshift.

• Ability to work efficiently under Unix/Linux environment, having experience with source code

management systems like GIT.

• Strong knowledge with programming methodologies (version control, testing, QA) and agile

development methodologies.

• 3-5 years’ experience


Meet Your Recruiter

Kelly Hallgren

Apply Now:

Apply Online

Continue with LinikedIn

Continue with Facebook

Continue with Twitter

Apply Later
Send an email reminder to:

Email Address

Share This Job:


Login to save this search and get notified of similar positions.",4.9,"Talution Group
4.9","Naperville, IL",1 to 50 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,$1 to $5 million (USD)
Clinical Lab Scientist-GENERALIST SIGN ON BONUS,"$21-$34 Per Hour
(Glassdoor Est.)","$2000.00 SIGN ON BONUS
(Bonus program parameters apply)

Edward-Elmhurst Health includes three hospitals — Edward Hospital, Elmhurst Hospital, and Linden Oaks Behavioral Health — and an extensive ambulatory care network that provides comprehensive healthcare to residents of the west and southwest suburbs of Chicago.
Edward-Elmhurst Health provides comprehensive healthcare at more than 60 locations in the suburbs of Chicago. Our success has always been — and always will be — driven by our most talented, reliable, compassionate and skilled people, who genuinely believe in delivering top quality care to our patients and their families. At Edward-Elmhurst Health, you will also experience a vibrant culture and an atmosphere of nurturing support and leadership.

Be DRIVEN to join our over 8,000 employees, 1,700 staff physicians and 1,800 volunteers who want to provide safe, seamless and personalized care every day for our patients, our families and our communities.

Job Summary: Performs various clinical laboratory tests in one or more sections of the Laboratory in order to obtain data for use in diagnosis and treatment of disease.

Hours: Full-time NIGHTS 10 pm-6:30 am various days during the week; Includes weekend and holiday rotation

Required:
Associate's degree in Medical Technology or Clinical Laboratory Science
Ability to accurately collect and analyze test results, and to perceive similarities and differences in color
Registration with the American Society of Clinical Pathology (ASCP), National Credentialing Agency (NCA) or equivalent
Preferred:
Bachelor’s Degree
*Benefits offered by Edward-Elmhurst Health include:
Medical, dental, and vision
401K
Tuition reimbursement
Paid time off
Fitness center membership
Plus many other Employee Perks",-1,Edward Hospital,"Elmhurst, IL",1001 to 5000 Employees,-1,Hospital,Health Care Services & Hospitals,Health Care,$500 million to $1 billion (USD)
Sr Scientist III Abbott Molecular R&D,"$69K-$138K
(Glassdoor Est.)","Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 103,000 colleagues serve people in more than 160 countries.

Senior Scientist III

Diagnostic testing is a compass, providing information that helps in the prevention, diagnosis and treatment of a range of health conditions.

Abbotts life-changing tests and diagnostic tools give you accurate, timely information to better manage your health. Were empowering smarter medical and economic decision making to help transform the way people manage their health at all stages of life. Every day, more than 10 million tests are run on Abbotts diagnostics instruments, providing lab results for millions of people.

Position Overview:
Conceives, plans, designs, and conducts advanced independent research.
Investigates and develops new procedures.
Direction provided by project goals and experimental design.
May act as project leader, lead scientist, or independent reviewer.
Provides technical direction and feedback to others.
Interacts with other groups and shares information; participates in team
Position Responsibilities:
Defines project goals and is responsible for timely project completion.
Responsible for own Redbook documentation, and for the accuracy, quality, and timeliness of experimental results.
Summarizes data and analyzes results, independently formulates conclusions, and determines future experiments.
Actively participates in routine maintenance, lab safety; may assume roles of responsibility, such as training or document control.
Position Accountabilities
Responsible for implementing and maintaining the effectiveness of the quality system.
Understands and consistently follows documented procedures.
Determines priorities for experiments.
Applies quantitative methods: analyzes data, evaluates results, forms
conclusions, and provides/implements process or document improvements.
Independently designs and executes a series of experiments to test hypotheses related to project outcomes.
Applies advance scientific knowledge to projects.
Utilizes DOE where appropriate.
May assist in the design of experiments for others.
Identifies technical alternatives from literature review.
Applies basic computer skills (includes word processing, spreadsheets, instrumentation-related and Abbott network systems).
Produces reports and documents utilizing advanced writing skills.
Utilizes multiple analytical instruments; trains others in their operation.
Recognizes and resolves technical problems.
Education/ Skills/ Experience:
Knowledge of regulations and standards affecting IVDs and Biologics.
Ph.D. in a life or physical science with 2+ years research or industrial
Or B.S./M.S. degree with research experience sufficient to demonstrate
Prepares results of projects internally and may present externally.
Reviews, evaluates, and critiques presentations for others.
Presents complex technical data to large and diverse groups.
Trains others on the theoretical and practical basis of techniques, processes and assays.
Participates in project planning, updates, and process improvements.
May generate new product ideas consistent with division strategy.
Prepares and aligns goals with manager's goals.
May coach lower-level scientists (e.g., presentation skills, negotiation skills,decision-making, and contingency planning).
Influences decision-making through negotiation, addressing conflict, and by
building (productive) working relationships across functional areas.
WHAT WE OFFER

At Abbott, you can have a good job that can grow into a great career. We offer:
Training and career development, with on-boarding programs for new employees and tuition assistance
Financial security through competitive compensation, incentives and retirement plans
Health care and well-being programs including medical, dental, vision, wellness and occupational health programs
Paid time off
401(k) retirement savings with a generous company match
The stability of a company with a record of strong financial performance and history of being actively involved in local communities
Learn more about our benefits that add real value to your life to help you live fully: www.abbottbenefits.com

Follow your career aspirations to Abbott for diverse opportunities with a company that provides the growth and strength to build your future. Abbott is an Equal Opportunity Employer, committed to employee diversity.

Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.",3.6,"Abbott Laboratories
3.6","Des Plaines, IL",10000+ Employees,1888,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
Principal Data Engineer - IHM,"$75K-$144K
(Glassdoor Est.)","Discover. A brighter future.

With Discover, you’ll have the chance to make a difference at one of the world’s leading digital banking and payments companies. From Day 1, you’ll do meaningful work you’re passionate about, with the support and resources you need for success. We value what makes each employee unique and provide a collaborative, team-based culture that gives everyone an opportunity to shine. Be the reason millions of people find a brighter financial future, while building the future you want, here at Discover.

Job Description


TITLE: Principal Data Engineer

DUTIES: DFS Corporate Services LLC seeks Principal Data Engineer in Riverwoods, IL to develop data driven solutions utilizing current and next generation technologies to meet evolving business needs. Identifies opportunities and recommends possible technical solutions. Works extensively with AWS ecosystem using AWS services as well as Hadoop ecosystems to migrate data from Teradata to Hadoop. Operationalize open source data-analytic tools for enterprise use. Develops real time data ingestion and stream-analytic solutions leveraging technologies such as Kafka, Apache Spark, NIFI, Python, HBase Kinesis and EMR. Supports custom Data pipeline development. Provides support for deployed data application and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution with partner Data Engineers and source data providers. Provide subject matter expertise in the analysis, preparation of specifications and plans for development of data processes. Ensures proper data governance policies are followed by implementing or validating Data Lineage, Quality Checks and Classification. Promote a risk-aware culture, ensure efficient and effective risk and compliance management practices by adhering to required standards and processes.

REQUIREMENTS: Bachelor’s degree or foreign equivalent in Electrical Engineering, Electronic Engineering, Database Administrations, Information Technology or a related field and eight (8) years of progressively responsible experience in job offered or related position: designing and developing ETL jobs to load business related data into the Enterprise Data Warehouse; developing data ingestion and stream-analytic solutions; supporting custom data pipeline developments; participating within a Hadoop ecosystem and migrating data from Teradata to Hadoop; utilizing development language and technologies including ETL tools such as Microsoft R, Java and Ab Initio to build prototypes. Five (5) years of experience must include using technologies including C++, Kafka, Apache Spark, NIFI, Python, Hive, HBase Kinesis and EMR.

QUALIFIED APPLICANTS: Please apply directly through our website jobs.discover.com for Job ID R2136 by clicking on “Apply Now.” No calls. Equal Opportunity Employer/disability/vet.

What are you waiting for? Apply today!

The same way we treat our employees is how we treat all applicants – with respect. Discover Financial Services is an equal opportunity employer (EEO is the law). We thrive on diversity & inclusion. You will be treated fairly throughout our recruiting process and without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status in consideration for a career at Discover.",3.9,"Discover
3.9","Riverwoods, IL",10000+ Employees,1985,Company - Public,Financial Transaction Processing,Finance,$5 to $10 billion (USD)
Clinical Lab Scientist-BLOOD BANK SIGN ON BONUS,"$20-$32 Per Hour
(Glassdoor Est.)","Edward-Elmhurst Health includes three hospitals — Edward Hospital, Elmhurst Hospital, and Linden Oaks Behavioral Health — and an extensive ambulatory care network that provides comprehensive healthcare to residents of the west and southwest suburbs of Chicago. Edward-Elmhurst Health provides comprehensive healthcare at more than 60 locations in the suburbs of Chicago. Our success has always been — and always will be — driven by our most talented, reliable, compassionate and skilled people, who genuinely believe in delivering top quality care to our patients and their families. At Edward-Elmhurst Health, you will also experience a vibrant culture and an atmosphere of nurturing support and leadership.

Be DRIVEN to join our over 8,000 employees, 1,700 staff physicians and 1,800 volunteers who want to provide safe, seamless and personalized care every day for our patients, our families and our communities.

Job Summary: Performs various clinical laboratory tests in the Blood Bank section of the Laboratory in order to obtain data for use in diagnosis and treatment of disease.

Hours: Part-time (0.5 FTE 20 hrs/week) 2pm-10:30pm various evenings during the week including weekend and holiday rotation

Required:
Associate's degree in Medical Technology or Clinical Laboratory Science
Ability to accurately collect and analyze test results, and to perceive similarities and differences in color
Registration with the American Society of Clinical Pathology (ASCP), National Credentialing Agency (NCA) or equivalent
Preferred
Bachelor’s Degree
*Benefits offered by Edward-Elmhurst Health include: (eligibility varies by FTE)
Medical, dental, and vision
401K
Tuition reimbursement
Paid time off
Fitness center membership
Plus many other Employee Perks",3.8,"Elmhurst Memorial Healthcare
3.8","Elmhurst, IL",5001 to 10000 Employees,-1,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Clinical Lab Scientist-MICROBIOLOGY SIGN ON BONUS,"$20-$32 Per Hour
(Glassdoor Est.)","$2000.00 SIGN ON BONUS
(Bonus program parameters apply)

Edward-Elmhurst Health includes three hospitals — Edward Hospital, Elmhurst Hospital, and Linden Oaks Behavioral Health — and an extensive ambulatory care network that provides comprehensive healthcare to residents of the west and southwest suburbs of Chicago.

Edward-Elmhurst Health provides comprehensive healthcare at more than 60 locations in the suburbs of Chicago. Our success has always been — and always will be — driven by our most talented, reliable, compassionate and skilled people, who genuinely believe in delivering top quality care to our patients and their families. At Edward-Elmhurst Health, you will also experience a vibrant culture and an atmosphere of nurturing support and leadership.

Be DRIVEN to join our over 8,000 employees, 1,700 staff physicians and 1,800 volunteers who want to provide safe, seamless and personalized care every day for our patients, our families and our communities.

Job Summary: Performs various clinical laboratory tests in one or more sections of the Laboratory in order to obtain data for use in diagnosis and treatment of disease Will work in a high volume, dynamic and state of the art laboratory and performing some molecular testing and plate reading as well as microbiology set ups.

Hours: Part-time (0.5 FTE/20 hrs. week-BENEFIT ELIGIBLE) 3pm-11:30pm; Includes weekend/holiday rotation

Required:
Associate's degree or higher in Medical Technology or Clinical Laboratory Science
Ability to accurately collect and analyze test results, and to perceive similarities and differences in color
Registration with the American Society of Clinical Pathology (ASCP), National Credentialing Agency (NCA) or equivalent
Preferred:
Bachelor’s Degree
Microbiology experience
*Benefits offered by Edward-Elmhurst Health include:
Medical, dental, and vision
401K
Tuition reimbursement
Paid time off
Fitness center membership
Plus many other Employee Perks",3.8,"Elmhurst Memorial Healthcare
3.8","Elmhurst, IL",5001 to 10000 Employees,-1,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
R & D Engineer/Scientist II,"$46K-$103K
(Glassdoor Est.)","Innovate to solve the world's most important challenges


The future is what you make it.
When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who
make the things that make the future.
That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings smart and safe and even
making it possible to breathe on Mars.
Working at Honeywell isnt just about developing cool things. Thats why all of our employees enjoy access to dynamic
career opportunities across different fields and industries.
Are you ready to help us make the future?

Honeywell Performance Materials and Technology is a global leader
in providing customers with high-performance solutions, including fluorine
products; specialty films and additives; advanced fibers and composites;
intermediates; specialty chemicals; electronic materials and chemicals; and
technologies and materials for petroleum refining.

UOP LLC, headquartered in Des Plaines, Illinois, USA, is a leading
international supplier and licensor of process technology, catalysts,
adsorbents, process plants, and consulting services to the petroleum refining,
petrochemical, and gas processing industries. UOP is a wholly-owned subsidiary
of Honeywell International, Inc. and is part of Honeywell's Performance
Materials and Technology strategic business group. For more information, go to
www.uop.com.

An excellent career opportunity is currently available for an R&D Engineer/Scientist II in
the Aromatics & Derivatives Development group within UOP's Research and
Development organization located in Des Plaines, IL. This position
affords a unique opportunity to develop new catalyst, adsorbent, process and
equipment technology from concept to commercialization.

Position Responsibilities:
Develop expertise
in aromatic separations, particularly Simulated Moving Bed (SMB) adsorption
and hybrid separation systems
Participate on
multi-functional teams focused on the development of novel process,
catalyst, adsorbent and equipment technology in UOPs Aromatics &
Derivatives product line.
Coordinate the
design, planning and execution of experimental programs for new product
development (NPD) and capability projects.Analyze results and deliver data packages that meet
quality standards.
Coordinate
the development of models by collaborating with modeling specialists and
other team members
Provide support to
Technical Service in troubleshooting and optimizing performance on
commercial units.
Provide support to
the Sales Support and Engineering functions to improve the competitiveness
of commercial offerings and designs.
Contribute to the
innovation effort at Honeywell UOP by identifying novel process, catalyst,
adsorbent and equipment technology and filing invention disclosures

You must have:
Must have completed PhD degree in Chemical
Engineering by time of hire.
5+ years industry experience in simulated
moving bed (SMB), membrane or adsorptive separation (preferably
hydrocarbon separation)

We Value:
Strong understanding of chemical
engineering, catalysis and/or adsorbent fundamentals and their application
in refining and petrochemical process technology.
Experience in developing and executing
experimental plans including the use of statistical tools for data
analysis
Demonstrated ability to work independently
with a strong focus on delivering results and identifying alternative
solutions when challenges arise.
Excellent written and verbal communication
skills with the ability to concisely report results to a variety of
audiences and ensure key results, conclusions and decisions are well
documented.
Knowledge of Six Sigma concepts and their
application in managing risk and uncertainty.
Additional Information
JOB ID: req238828
Category: Engineering
Location: 50 E Algonquin Rd,Des Plaines,Illinois,60017-5016,United States
Exempt
Engineering (EMEA)

Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, or veteran status.",3.7,"Honeywell
3.7","Des Plaines, IL",10000+ Employees,1885,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD)
Environmental Scientist - Permitting,"$32K-$51K
(Glassdoor Est.)","Description

Burns & McDonnell’s regional office in Chicago is looking for an Environmental Scientist to complete field work, permit applications and task management for a variety of market sectors, including transmission, oil and gas, renewable, and transportation. Burns & McDonnell is a 100% employee-owned firm ranked on FORTUNE’s List of 100 Best Companies to Work For and voted as a Best Place to Work in numerous cities across the United States.

This position can sit in either our Downers Grove or downtown Chicago offices.

The Environmental Scientist - Permitting will work with the office’s Natural & Cultural Resources group within our Environmental Services Global Practice to perform the following duties:
Perform wetland delineations with strict adherence to the U.S. Army Corps of Engineers protocol and procedures
Assist with completing field investigations that may include habitat evaluations for threatened and endangered species and/or evaluation of other potentially sensitive resources
Compose technical reports presenting results from field investigations and develop appropriate applications/consultations necessary for various regulatory approvals.
Conduct permit compliance tasks, federal/state/local permit applications, agency consultations
Assist project manager with field-oriented tasks, project permit tracking, agency consultations
Office related tasks would include report writing, QA/QC review, assistance with compliance related tasks
Frequent overnight travel to field locations may be required (50-70%)

All other duties as assigned.
Qualifications
Bachelor’s degree in Biology, Environmental Science, Botany, Soil Science or a related accredited program is required
4 years of relevant professional experience is highly preferred. Environmental consulting experience is preferred.
Experience in completing field investigations, wetland assessments, associated permitting, analyzing GIS data; preparing environmental assessments and permitting documents, technical writing
Demonstrated knowledge of wetlands and aquatic resources
Demonstrated knowledge of Section 404, 401 and Section 10 permitting required
Knowledge of state and local permitting processes in the Midwest
Knowledge of the agencies that govern waters of the U.S.
Knowledge of erosion and sediment control permitting and site restoration practices
Demonstrated proficiency operating GPS equipment
Working knowledge of GIS support software and analysis
Ability to clearly communicate both verbal and written technical information
Ability to work under pressure and meet tight deadlines
Proficient in computer software (Microsoft Office-Word, Excel, Powerpoint, Project)
Ability to work 50% or more in the field

EEO/Minorities/Females/Disabled/Veterans
Job Environmental

Primary Location US-IL-Downers Grove

Other Locations US-IL-Chicago

Travel: Yes, 50 % of the Time

Req ID: 201003

#LI-JJ #ENS",3.8,"Burns & McDonnell
3.8","Downers Grove, IL",5001 to 10000 Employees,1898,Company - Private,Architectural & Engineering Services,Business Services,$2 to $5 billion (USD)
GCP Data Engineer with Strong Scala,"$65K-$115K
(Glassdoor Est.)","Skills Needed

Â

GCP Experience is Must

hard code coder

coding and debugging -- data flow pipelines

implemented in Scala utilizing beam

data is pulled from BQ and results are stored in BQ

Python and bash

Scio is a spotify lib in Scala -- is a must

Â

Â

Â
Please send resumes toÂsgottumukkula@esharpedge.com

Â",4.7,"Sharpedge Solutions Inc
4.7","Naperville, IL",Unknown,-1,Company - Private,Publishing,Media,Less than $1 million (USD)
Data Engineer,"$69K-$121K
(Glassdoor Est.)","Join a passionate and purpose-driven team of colleagues who contribute to Trustmark’s mission of helping people increase wellbeing through better health and greater financial security. At Trustmark, you’ll work collaboratively to transform lives and help people, communities and businesses thrive. Flourish in a culture where appreciation, mutual respect and trust are constants, not just for our customers but for ourselves.

Position Overview: Our IT team is growing and currently looking for a Data Engineer to design, lead, and prototype various data solutions in the direction to a newly formed enterprise data team. The Enterprise Data team works closely with our IT leadership team, business stakeholders and vendors to oversee the delivery of enterprise data, analytics and digital capabilities and services to support key initiatives of the organization. This position will assist in defining and executing enterprise data strategy which includes several foundational capabilities like data ingestion, integration frameworks, data quality, master data management, data consumption patterns, cloud data lake enablement and supporting build of advanced analytics platform at Trustmark.

You should be highly technical with a strong data engineering background, extremely service oriented, and able to navigate project obstacles in a timely fashion to enable successful execution. You should have a good understanding of modern data platform architecture, cloud data processing capabilities, data modeling best practices, and exposure to various advance analytics and reporting technologies.

Responsibilities:

Modern data platform engineering
Develop, prototype and test data processing systems leveraging large volumes of data from internal and external data sources.
Explore and analyze complex data structures to find answers to business problems. Recommend ways to improve overall quality of enterprise data assets.
Lead implementation of Master data management capability by working closely with business stakeholders, data stewards and IT teams.
Build and operationalize data processing frameworks including re-usable data ingestion processes, metadata layer, enterprise data structures for key data domains, data consumption frameworks for various consumption patterns (reporting, data science, visualization and digital micro services)
Develop and maintain formal documentation describing enterprise data flows, data processing and security frameworks, data models and consumption patterns.
Business stakeholder management
Work closely with business stakeholders to understand data needs to support analytics and reporting.
Prepare data to support various predictive modeling and data visualization use cases
Help business find hidden patterns using existing data
Deliver updates to stakeholders based on analytics demand
Partner with multiple lines of business stakeholders to provide technical guidance related to data structures, data models, data processing pipelines and related infrastructure.
Solution Delivery and Operations Management
Foster and maintain productive working relationship with business and IT stakeholders
Effectively participate in project execution, identify and escalate issues with IT stakeholders in a proactive manner
Plan for and minimize unplanned business disruptions due to outage of enterprise integration technologies
Ensure successful project and service delivery
Track and report metrics for operational efficiency and plan for continuous improvements
Qualifications:
Strong intellectual curiosity
Bachelor’s degree in Computer Science or equivalent
8+ years of industry experience with 5+ years in the data and analytics space.
Technologically savvy specifically in large scale enterprise data initiatives including data warehouse, Master data management, Data Lake, data quality, Business Intelligence and Visualization implementations.
Prior experience working on cloud data processing technologies such as Azure data lake, SQL data warehouse, data factory, Cosmos DB, Stream Analytics, Azure DevOps, Spark, Data bricks, Snowflake or similar cloud data engineering background is must.
High degree of business aptitude and the ability to articulate technology solutions to business audience.
Ability to lead data platform innovation roadmap by conducting tool research and proof of concepts with an eye to the future of enterprise data including creation of data science platform.
Ability to prioritize multiple tasks and deadlines simultaneously, while collaborating with various cross functional IT and business teams.
Experience in collaborating, working with and leading onsite and offshore resources.
Familiarity with ETL/ELT concepts and market leading tools like Datastage, Informatica or Talend.
Knowledge of Integration technologies like Kafka, RabbitMQ or similar
Insurance industry background
Experience working in an Agile/Iterative environment with Scrum knowledge",3.2,"Trustmark Companies
3.2","Lake Forest, IL",1001 to 5000 Employees,1913,Company - Private,Insurance Carriers,Insurance,$500 million to $1 billion (USD)
NGS Field Application Scientist - Chicago - Remote,-1,"Employment Status: Exempt
Location: Remote

Department: Sales

Purpose statement:

The NGS Application Scientist will provide technical field support for IDTs xGen/NGS customers, regarding product design and end use. This position will assist Sales to identify, convert and support potential/existing customers. This position will also collaborate with internal departments to prioritize customer requirements for future NGS product development activities.

The ideal candidate will have 3-5 years of hands-on NGS Workflow Experience.

Essential Functions:
Provides technical field support for IDT NGS customers, including experimental design and troubleshooting
Represents IDTs products to molecular biology community at large, including presentations of established technologies at industry trade shows
Collaborates with Product Management, Applications Support, Customer Care and Sales to identify key customer requirements for future product development efforts
Works closely with Marketing and Sales to ensure the value of the NGS product line is communicated clearly and effectively to customers
Maintains strong working relationships within Research, Manufacturing, Marketing, Product Management and Product Development, Customer Support and Sales
Maintains positive existing key customer interactions by providing support on new emerging NGS applications in which xGen products may be employed
Retains knowledge base via literature and personal communications with newer trends in the NGS field
Ensure customer is setup for success in bake-off
Partner with potential customers in their evaluations (or proof-of-principle studies) of IDT products by reviewing /walking through data
Ensure customers scale as planned
Troubleshoot technical challenges to provide white-glove support as customers use products
Demonstrates behavior consistent with the Integrated DNA Technologies Core Values.
Performs other duties as assigned.
Education:
Bachelors degree (in Molecular Biology, Biochemistry, Genetics, Biology, Chemistry, Bioinformatics) or equivalent experience with demonstrated performance required
Masters degree or PhD (in Molecular Biology, Biochemistry, Genetics, Biology, Chemistry, Bioinformatics) preferred
Professional Experience:
Minimum of five years of experimental design and troubleshooting required
Expert background in NGS bench techniques (library prep and enrichment) required
Previous hands-on experience with qPCR and NGS technologies required
Other Job Qualifications:
Extreme craving to learn more applications and techniques in NGS workflows
Ability to cultivate and maintain cross-functional relationships within a larger organization
Self-motivated and driven
High Customer Satisfaction Level Drive
Strong organizational and presentation skills
Superior communication skills, both oral and written
Adaptability to performing a variety of duties, often changing from one task to another without loss of efficiency or composure.
Ability to maintain both a high standard of courtesy and cooperation in dealing with co-workers.
Adaptability to accepting responsibility for the direction, control or planning of an activity
Present scientific data generated from R&D or other customers that technically position the products
Provide technical consultation to sales specialist

What We Offer:
Generous Paid Time Off Accruals
16 Hours PAID Volunteer Time Off
10 Paid Holidays
Up to eight (8) weeks of 100% paid parental leave to eligible U.S. associates
401(k) with Company Match
Medical, Dental, and Vision Insurance Options
Integrated DNA Technologies (IDT) conducts drug screens and background checks on applicants who accept employment offers.

Danaher Corporation and all Danaher Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity, or other characteristics protected by law. The EEO is the Law poster is available here.",-1,Integrated DNA Technologies (IDT),"Chicago, IL",-1,-1,-1,-1,-1,-1
"Medical Laboratory Scientist - Flow Cytometry, Full-time, Evenings","$56K-$77K
(Glassdoor Est.)","Technical responsibilities: o Performs all aspects of pre-analytic workflow appropriate for the specific laboratory section to ensure orders are entered correctly, specimens collected are appropriate for the test ordered and are correctly processed/transported. o Verifies order where necessary o Verifies non-patient information (e.g., collection time) according to established protocol. o Handles unresolved orders, troubleshoots where needed. o Verifies with physicians and/or nurses prior to laboratory information system (LIS) order entry to resolve unclear, duplicate or otherwise ambiguous orders. o Verifies specimens for add-on tests are available and acceptable and generates add-on test orders. o Recognizes when fraud and abuse compliance issues require adjustments to the test order o Collecting, receiving and processing of specimens: Verifies specimens are correctly and completely labeled upon receipt. Evaluates specimens for appropriateness and takes necessary corrective action. Appropriately documents unacceptable specimens and proper notifications as needed. Prioritizes specimen processing based on established priorities. Aliquots specimens according to established protocols. o Performs all aspects of analytical testing appropriate for the specific laboratory section, Following established written protocols and standard operating procedures (SOP) o Maintains test system integrity: Performs preventive maintenance on instruments/equipment in a timely fashion according to defined schedule. Verifies reagents and supplies meet defined acceptability criteria upon receipt and prior to use; takes action to ensure unacceptable items are removed from use. Ensures that sufficient reagents and supplies necessary for test performance are available. Notifies senior staff when minimum inventory level is encountered. Performs and records all necessary quality control (QC) required for test system performance. Evaluates QC resultsand takes necessary corrective actions according to established protocol. o Performs specimen preparation: Performs any necessary pretest specimen preparation according to protocols (e.g., microbiology plating, cell cultures, filtering, extraction, separation, elution, absorption, etc.) Transfers or ships specimens to approved testing locations according to SOPs o Responsible for all aspects of analytical testing appropriate for the specific laboratory section o Maintains test system integrity: Examines preventative maintenance logs on instruments/equipment in a timely fashion and follows up as needed. Verifies reagents and supplies meet defined acceptability criteria upon receipt and prior to use; takes action to ensure unacceptable items are removed from use. Responsible for inventory maintenance and supply ordering in designated section. Performs and records all necessary quality control (QC) required for test system performance. Review and evaluates QC results in designated sections and take necessary corrective actions according to established protocol. o Performs tests: Prioritizes testing based on assignment or established priorities, completes testing within defined turn-around-times (TAT). Recognizes the need for and follows any age-specific protocols Responds effectively to changes in the workflow by coordinating a simultaneous series of tests when needed or adjusting work to incorporate STAT tests or fluctuations in work volume. Exercises independent judgement in the performance of technical responsibilities Monitors daily workflow and priorities to assure meeting service levels. o Performs technical review and interpretation: Develops and maintains a higher level of expertise in the specific areas of responsibilities. Reviews results for completeness, correctness, and consistency within defined test system Evaluates test results/reactions and provides accurate interpretations as appropriate to include correlation with, and integration of, other patient data as necessary. Performs visual interpretation/identifications as appropriate. Recognizes unusual test results/interpretations and completes indicated reflex testing or other follow-up actions. Follows established notification protocols for critical values, phone/fax/e-mail results requests, abnormalities. Evaluates instruments and test systems and makes recommendations for acquisition to senior management. o Troubleshoots and solves problems: Recognizes test system performance problems and takes necessary corrective actions. Recognizes when unresolved problems need to be escalated and takes necessary follow-up action. Reviews pending logs and follows-up to ensure pending tests are completed or cancelled when appropriate. Performs advanced troubleshooting and repair. Calls for field service when necessary and is familiar with contractual terms of maintenance agreements. o Post-test specimen storage: Ensures that specimens and related materials (blood, slides, tissues, etc.) are stored according to protocols for location and duration with necessary documentation Post-analytical responsibilities: o Performs all aspects of the post-analytical workflow appropriate for the specific laboratory section to ensure accurate results are reported within established time frames, specimens are retained appropriately, test results and/or current status are available upon inquiry, and billed charges are correct for testing performed. o Verifies and reports results: Verifies results according to procedure. Performs computer functions necessary for releasing results. Generates written reports according to established protocol. Reviews electronic or printed reports when applicable, recognizes problems and escalates according to protocol. o Amends reports: Corrects erroneous reports and amends reports according to procedure o Responds to inquiries: Responds to requests for information according to established protocol for confidentiality and release of information Recognizes when unresolved inquiries need to be escalated and takes action o Stores documents and records: Stores documents and records according to established protocol. o Charge capture/billing: Performs billing and/or enter credits for tests and services when applicable. Recognizes billing problems and escalates accordingly Universal responsibilities: o Ensures quality of operations: Assumes delegated responsibilities in the absence of a coordinator. Responsible for regulatory compliance in designated section. Follows written standard operating procedures (SOP). Operates instruments/equipment according to protocol. Uses computers according to established protocol; follows downtime procedures as required. Performs required quality system responsibilities including initiating Quality Investigation Reports. Meets proficiency and competency standards of the department and assists in the competency assessment of technical and support staff. Participates in the training of new employees and students Performs operational review of new SOPs. Presents continuing education programs Assists in new test development, validations and implementation. Attends at least one personal development session per year. Assists the coordinator and manager in monitoring the operations of designated areas to ensure service standards and financial goals are met. Contributes in developing and is responsible for implementation of technical goals and standards. Performs other duties as assigned, or as needed, to ensure continued quality operations o Information Systems: Ensures integrity of Laboratory Information Systems (LIS) by following established protocols and participates in the maintenance and enhancements of the LIS. May oversee/accomplish instrument computer software upgrades/updates Demonstrates expertise in Information Technology; uses application to streamline operations and facilitate service monitoring and data collection. o Ensures safety of operations: Follows all required safety procedures, uses personal protective equipment (PPE) appropriate for tasks performed, and assumes a proactive role in laboratory safety. Maintains cleans and organized work area o Provides service excellence: Answers telephone when needed, using NM telephone etiquette Maintains patient confidentiality including protected health information (PHI) Assists patients, visitors and other contacts whenever need occurs",3.9,"Northwestern Medicine
3.9","Chicago, IL",5001 to 10000 Employees,1965,Hospital,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD)
Data Engineer - RBD,"$59K-$88K
(Glassdoor Est.)","Position Summary:

The Data Engineer is responsible for designing, developing, and supporting data management solutions. The position will develop data models, perform data analysis, construct technical designs, develop data integration solutions, collaborate with team members and business stakeholders, and support existing data solutions. This position will also lead and coordinate the work activities of offshore development and support resources.

Position Responsibilities may include, but not limited to:
Responsible for the solution architecture, design, development, and support of data management applications
Drive data sourcing and integration solution design and development on hybrid (cloud & on-prem) data solutions
Perform data analysis and architect data models for analytics
Providing guidance and direction to offshore ETL support/development resources
Collaborate with cross functional teams such as Infrastructure, Support, DBA and Business team
Assist with task identification and effort estimates for ETL development
Assist with risk and issue identification and resolution
Provide off-hour/weekend ETL support (on a rotating basis)
Other duties as assigned",3.3,"Reyes Beer Division
3.3","Rosemont, IL",1001 to 5000 Employees,1976,Company - Private,Wholesale,Business Services,Unknown / Non-Applicable
GCP Data Engineer (Contract),"$58K-$109K
(Glassdoor Est.)","Duration: 6+ months

Requirements:
Very good understand of GCP Architecture. Strong GCP Data Engineering experience and background.
4+ years' experience as a software engineering using Python, C+ and have data engineering experience in Python
1+ experience on GCP platform on IAM roles, migration of applications, using Cloud storage, BigQuery, dataflow, dataProc
Google Cloud Data Engineer Certification is a plus.
Experience with Data Migration / Data Warehouse.
2+ experience using Big data echo system Hadoop, Hive, HDFS, Spark, Hbase,
Must have hands on experience in Advanced SQL skillset - preference on using BigQuey, Snowflake or Redshift
Minimum 2 year experience in using Python in data engineering, Cloudformation or as Object oriented ( Pandas, Spark library, NumPy or SciPy library)
Good understanding of developer tools, CICD etc.
The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.",3.8,"Capgemini
3.8","Arlington Heights, IL",10000+ Employees,1967,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (USD)
Sr Advanced R&D Engineer/Scientist,"$69K-$134K
(Glassdoor Est.)","Innovate to solve the world's most important challenges


The future is what you make it. When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who make the things that make the future. That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings smart and safe and even making it possible to breathe on Mars. Working at Honeywell isnt just about developing cool things. Thats why all of our employees enjoy access to dynamic career opportunities across different fields and industries. Are you ready to help us make the future?

Contribute to team that applies its expertise and knowledge to engineering, research and development projects focused on the development, testing, and deployment of an innovative electrochemical technology enabling large-scale production of an energy storage solution. You will initiate new product concepts and ideas and work collaboratively within a multidisciplinary team and will participate in the complete development life cycle and analyze current R&D programs including performance, diagnosis and troubleshooting of issues to provide solutions.

Key Responsibilities:
Conceptualize and implement novel concepts for electrochemically enabled R&D programs
Develop new and improved analysis methods to support both existing and potential future products.
Apply your knowledge of design principles and engineering techniques to development efforts
Thrive in a fast paced, entrepreneurial environment with rapidly changing priorities that require quick adaptation

YOU MUST HAVE

• Bachelors Degree in Chemistry or Chemical Engineering and a minimum of 10 years experience working with energy storage solutions
OR
• A Ph.D. in Chemistry or Chemical Engineering and a minimum of 3 years experience working with energy storage solutions

WE VALUE

• Practical experience with flow battery construction, flow cell/stack design at various scales
• Experience with Battery Management Systems and algorithm development
• Data regression
• Depth of knowledge in electrochemistry fundamentals
• Prior experience producing coin and/or pouch cells at research scale
• Industrial design talent
• Global mindset, cross cultural agility and resourcefulness
• Willingness to learn new technologies
• Demonstrated ability to work in a team environment
• Eagerness to get involved in hands-on work
• Creativity
• Additional experience in electrochemistry or energy storage related fields
• Excellent project management and prioritization skills
• Technology development and converting needs into a solution

Additional Information
JOB ID: req238827
Category: Engineering
Location: 50 E Algonquin Rd,Des Plaines,Illinois,60017-5016,United States
Exempt
Marketing (GLOBAL)

Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, or veteran status.",3.7,"Honeywell
3.7","Des Plaines, IL",10000+ Employees,1885,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD)
Bioinformatics Scientist,-1,"EmeraldAI has partnered with a leading science-based biopharmaceutical company that discovers, invents, develops, manufactures, and commercializes medicines for the treatment of serious medical conditions. This position can be based in North Chicago Suburbs or Greater Boston area.

The role of the bioinformatics leader is to broadly enable the genomics data capability across Research and Preclinical Development. This role will also help drive the genomics data strategy for R&D IT, as well as provide internal technology and genomic data expertise to key business functions, focusing on data capture, processing, reporting, and analysis.

Responsibilities:
Oversee the development and maintenance of genomics information services providing genome and genotype data by working closely with Research Biologists and Bioinformaticists.
Integrate public and proprietary genome (including genomic sequence) and genotype data into a common framework.
This is an onsite in-office position in Northern IL suburbs, or greater Boston area
Facilitate comparisons of human and non-human genomes and genotypes
Facilitate genotype-phenotype correlation studies
Leverage public and internal ontologies (e.g. Gene Ontology, Genotype Ontology, Sequence Ontology) for linking information
You will be partnering with agile extreme programming (XP) developers or quantitative specialists in extreme machine learning (XL) as a business expert, guiding the strategies behind the development
Highly effective in collaborating with other agile technical experts, agile coaches, product Owners and business stakeholders
Experience with agile software and terminology such as: backlogs, iterations, user stories, and agile backlog management tools such as Jira
Scientific Technology Execution
Provide creative solutions to genomic data challenges, working closely with scientists, bioinformaticians, and IT teams
Ensure conceptual, functional, and technical designs will meet functional and non-functional requirements for projects and enhancements
Understands the business processes associated with genomic data and ensures the solutions are designed and built to meet scientists’ requirements and long term single source of truth and supportability
Understands agile principles and the ability to execute projects using methodologies such as XP, Kanban and Scrum
Minimum Requirements:
Bachelor's degree in bioinformatics, medical, data analytics, engineering or related field
3+ years of bio or genome or bio research work experience
3+ years with clinical data sources, standard Omics nomenclature including HUGO & HGNC.
You will partner with statistical analysis quants who write scripts in R, Python, SQL, and SPARQL to perform data manipulation
3+ years in a lab based environment using controlled clinical vocabularies like SNOMED-CT and ICD-10.
strong leadership, communication and collaboration skills.
Demonstrated proficiency in oncology data (including biomedical terminologies such as biomarkers, treatments, diagnosis and provider workflow).
3+ years experience integrating data from various clinical systems such as lab information systems, EHRs, pharmacy and claims
3+ years experience creating new oncology data/information models from scratch
Familiar bio research practices including:
Highly effective in working with other medical, scientific, technical experts, Product development and business stakeholders
Strong oral and written communication skills
Ability to multi-task and manage changing priorities in a fast paced environment
Strong teamwork and interpersonal skills
Ability to work independently and take initiative when solving unexpected problems
Job Type: Full-time

Pay: From $110,000.00 per year

Benefits:
401(k)
401(k) matching
Dental insurance
Disability insurance
Health insurance
Life insurance
Paid time off
Tuition reimbursement
Vision insurance
Schedule:
Monday to Friday
This Company Describes Its Culture as:
Detail-oriented -- quality and precision-focused
Innovative -- innovative and risk-taking
Outcome-oriented -- results-focused with strong performance culture
Company's website:
emeraldaitech.com
Benefit Conditions:
Waiting period may apply
Work Remotely:
No",-1,EmeraldAI,"Skokie, IL",-1,-1,-1,-1,-1,-1
Senior Data Engineer,"$54K-$106K
(Glassdoor Est.)","What we do:

Uptake is a Chicago-based predictive analytics SaaS platform provider that empowers major industry leaders to optimize performance, reduce asset failures and enhance safety. At Uptake, we combine our strengths—machine learning, analytics, data visualization and software development—with the expertise of our industrial partners. The result is enormous savings in development time and resources for Uptake’s partners and a proven industrial grade software platform that delivers value to partners and their end customers.

What we do:

Uptake helps industrial companies digitally transform with open, purpose-built software that delivers outcomes that matter. Built on a foundation of data science and machine learning, our vision is to create a world that always works — one where the machines and equipment we depend on daily don’t break, and industrial companies are once again the creators of economic growth and opportunity.

What you’ll do:

As a Data Engineer on the Data Science team, you’ll work with Uptake’s data scientists and product team to design and build data infrastructure in support of Uptake’s Data Science. The tools you create will have lasting impact on model development and deployment, performance and outcomes reporting, as well as data monitoring. The ideal candidate has strong analytic and technical abilities, as well as the ability to be flexible and adaptive to rapidly evolving needs of the team.

Responsibilities:
Design and implement data warehouses, real-time ETL, and batch processing of data to support modeling and reporting needs
Work with data ingestion teams to develop data expertise and resolve upstream issues relating to data quality
Define best practices and design for the management of data
Partner with Data Scientists to build and maintain internal data processing and visualization tools
Translate requests into replicable analytic reports using varying applications
Create tools to serve data such as APIs and packages
What we hope you’ll bring to the table:
Bachelor’s degree in computer science, information technology/information systems, or a field related to a computational science or 2+ years experience working as a data engineer
Ability to write efficient SQL queries
Experience managing data ETL processes and making data available through service applications and databases.
1+ years experience with NoSQL databases (Cassandra or Elasticsearch preferred)
3+ years experience with programming languages (Python, Java, R, and/or Scala preferred)
Familiarity with a variety of data processing technologies (e.g. Spark, Kafka, Hadoop)
Excellent communication skills, including a knack for clear documentation
Experience with or knowledge of REST APIs and making data available through microservices.
Experience using version control (Git, Mercurial, SVN, etc.) for collaborative code development.
These are not required but are preferred skills:
MS or PhD in Computer Science or other technical field
Ability to architect data solutions
Some knowledge of machine learning and data science processes
Experience supporting data science and analytical efforts is preferred
Some experience with frontend web-development
Experience defining and implementing APIs
Experience working with Docker
Applicants must be authorized to work in the U.S.

Uptake welcomes and encourages applications from all individuals, without regard to any prohibited ground of discrimination, including from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.",2.2,"Uptake
2.2","Chicago, IL",501 to 1000 Employees,2014,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable
Senior AWS Big Data Engineer,"$104K-$133K
(Glassdoor Est.)","About Us

Would you like to be part of a team focused on helping customers in a ""once in a generation"" shift to the cloud and AWS. NorthBay is a 300 person fast growing AWS Cloud-based Professional Services firm helping customers build solutions for data platforms and analytics, ML/Ai, DevOps, Database Migrations and custom application development and modernization. Do you have the business savvy and the technical background necessary to help grow NorthBay as a key technology provider to the Enterprise?

NorthBay is seeking technically savvy Senior Big Data Engineer to implement solutions for our customers working with our offshore engineering team. In this role, you will collaborate with NorthBay customers, some working onsite, understand requirements and needs, translate into specifications to develop solutions, drive work with offshore engineering teams, and deliver solutions and results to the customer. This includes assessing customer needs, re-engineering business intelligence processes, designing and developing data models, and sharing your expertise throughout the deployment process.
Responsibilities Include but Not Limited to:
Possess In depth knowledge and hands on development experience in building Distributed Big Data Solutions including ingestion, caching, processing, consumption, logging & monitoring) (Must Have)
Strong Development Experience in either one of the Distributed Big Data processing (bulk) engines preferably using Spark on EMR or related (Must Have)
Strong Development Experience on at least one or more event driven streaming platforms prefer Kinesis, Firehose, Kafka or related (Must Have)
Strong Data Orchestration experience using tools such has AWS Step Functions, Lambda, AWS Data Pipeline, Apache Airflow or related (Must Have)
Assess use cases for various teams within the client company and evaluate pros and cons and justify recommended tooling and component solution options using AWS native services, 3rd party and open source solutions (Must Have)
Strong experience on either one or more MPP Data Warehouse Platforms prefer AWS RedShift, PostgreSQL, Teradata or similar (Must Have)
Strong understanding and experience with Cloud Storage infrastructure and operationalizing AWS based storage services & solutions prefer S3 or related (Must Have)
Strong technical communication skills and ability to engage a variety of business and technical audiences explaining features, metrics of Big Data technologies based on experience with previous solutions (Must Have)
Strong Data Cataloging experience preferably using AWS Glue (Nice to Have)
Strong Development Experience on at least one NoSQL OR Document databases (Nice to Have)
Experience on at least one or More Ingestion Integration tools Like Apache NIFI or Streamset or related (Nice to Have)
Strong Development Experience on at least one Caching Tools like Redis, Lucene, Memcached (Nice to Have)
Strong Understanding and experience in Big Data Audit Logging and Monitoring solutions (Nice to Have)
Strong Understanding of at least one or more Cluster Managers (Yarn, Hive, Pig, etc) (Nice to Have)Interface with client project sponsors to gather, assess and interpret client needs and requirements
Advising on database performance, altering the ETL process, providing SQL transformations, discussing API integration, and deriving business and technical KPIs
Develop a data model around stated use cases to capture client’s KPIs and data transformations
Assess, document and translate goals, objectives, problem statements, etc. to our offshore team and onshore management
Document and communicate product feedback in order to improve user experience

Qualifications:

5+ years of AWS Solutions implementation, professional services experience, prefer Data Analytics space.
A passion for exploring data and extracting valuable insights.
Proven analytical, problem solving, and troubleshooting expertise.
Proficiency in SQL, preferably across a number of dialects (we commonly write MySQL, PostgreSQL, Redshift, SQL Server, and Oracle).
Exposure to developer tools/workflow (e.g., git/github, *nix, SSH)Experience optimizing database/query performance.
Experience with AWS ecosystem (EC2, S3, RDS, Redshift).Experience with business intelligence tools with a physical model (e.g., MicroStrategy, Business Objects, Cognos).Experience with data warehousing.
Exposure to NoSQL-based, SQL-like technologies (e.g., Hive, Pig, Spark SQL/Shark, Impala, BigQuery)
Excellent verbal and written communication skills
Ability to travel up to 70-80%

Education and Experience:

Bachelor’s Degree in Computer Science or Equivalent
Minimum five years of Big Data Engineering on AWS experience
This position can be located in Columbus or Cincinnati, OH or Detroit or Chicago.",3.5,"NorthBay Solutions
3.5","Chicago, IL",201 to 500 Employees,2011,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable
Senior Data Engineer,"$96K-$167K
(Glassdoor Est.)","GoHealth is looking for Data Engineers who will be responsible for the design, development, and delivery of its various batch and streaming data pipelines. We are seeking candidates who have experience in building large batch pipelines, as well as experiencing building stable, high throughput streaming systems. In this role, you will work with other members of Engineering, Product and Project Management, and various business groups to ensure timely availability of usable data to all parts of the business that need it.

Due to the unprecedented situation of COVID-19, GoHealth has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities' and the CDC.

Responsibilities:
Design, develop and deploy batch and streaming data pipelines.
Monitor and ensure operational stability of data pipelines.
Create and maintain documentation of the technical detail design, operational support and maintenance procedures for all data pipelines.
Ensure data quality and compliance with development, architecture, reporting, and regulatory standards throughout entire data pipeline.
Collaborate with the rest of the Engineering Team, subject matter experts and department leaders to understand, analyze, build and deliver new data-related processes and/or reports.
Skills and Experience:
Bachelor's Degree in computer science or equivalent experience required.
4+ years of experience in the design and development of data pipelines and tasks.
Strong analytical and problem solving ability with strong attention to detail and accuracy.
Understanding of data warehousing concepts and dimensional data modeling.
Hands-on experience with troubleshooting performance issues and fine tuning queries.
Experience extracting data from relational and document databases.
Experience consuming data over HTTP and in formats such as HTML, XML, and JSON.
Knowledge of and experience with a version control system (such as Git, Mercurial, SVN, etc).
Proficiency in Java or Python programming languages.
Familiarity with data warehousing platforms, such as Redshift, Snowflake, SQL Server, etc.
Benefits and Perks:
Open vacation policy
401k program with company match
Medical, dental, vision, and life insurance benefits
Flexible spending accounts
Commuter and transit benefits
Professional growth opportunities
Casual dress code
Generous employee referral bonuses
Happy hours, ping-pong tournaments, and more company-sponsored events
Subsidized gym memberships
GoHealth is an Equal Opportunity Employer
*LI-JC1",3.1,"GoHealth
3.1","Chicago, IL",501 to 1000 Employees,2001,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Senior Data Engineer,"$74K-$138K
(Glassdoor Est.)","Job Description


We’re hiring!

Aon is currently recruiting a Senior Data Engineer to join our team in Singpore.

About Aon's Center for Innovation & Analytics

Aon’s Centers for Innovation and Analytics in Dublin and Singapore are at the heart of delivering Aon’s Data & Analytic Services team’s mission to:
accelerate the rate of innovation through digital solutions to help better respond to clients’ evolving needs
provide foundational data and analytics capabilities in one place for 50,000 Aon colleagues and our global clients who use our risk and people solutions
Established in 2012, there are over 100 colleagues in Singapore’s Centre today including actuaries, software developers, data scientists, financial analysts and accountants. We are expanding rapidly and looking for dedicated individuals who can leverage emerging technologies and collaborate across Aon’s solution lines to help clients and colleagues make better, data-driven decisions today and tomorrow

The Opportunity

We are seeking a senior data engineer who is a team player and extremely keen in pushing themselves to learn new skills on the job or off the job. The right individual for this role will need to have a meticulous eye for data and appreciates the process of manipulating, storing and understanding data. This person will work with a team of experienced actuarial analysts, developers and business resources to build databases, warehouses and ETL/ELT pipelines to fuel modern web applications and visualizations that deliver insightful analytics to the users.

As a senior data engineer in the Singapore Aon Innovation Centre, you will be the expert that specialises in areas of ETL/ELT, modern data pipelines and data warehousing that spans both the traditional OLTP/OLAP databases, warehouses and modern big data database systems. You will have an opportunity to work with newer modern technologies as well as tried and tested traditional technologies in the data ingestion/wrangling/storage toolchain. In addition to the training and hands on opportunities, this is a role that will be part of the talent growth strategy of Aon. Being successful in this role would lead to technical and people leadership opportunities in the future as well.

Responsibilities
Collaborate with teams of experienced actuaries, developers and business experts to deliver projects
Design and propose end-to-end data flows for data projects as well as databases to support web-based applications
Design and implement data warehouses and data marts to serve data consumers
Execute implementation of the designs and bring it from design stages to implementation followed by operationalization to maintenance
Database design and modelling. To be able to organize data at both macro and micro level and provide logical data models for the consumers
Database performance tuning and data lifecycle management
Assist in support and enhancements of existing data pipelines and databases
Requirements
3+ years in-depth experience in working with MS SQL Server or any other relational database management system
Highly knowledgeable in ETL/ELT processes, both design and implementation via SSIS or some other ETL/ELT tool.
Skilled in both complex query performance tuning and database performance tuning for MS SQL Server
Have experience in data validation and data QA as data flows through
Have experience in building and designing data warehouses/data marts
Understand the importance of performance and able to implement best practices in ensuring performance for data-centric projects
This person is required to be dynamic and be a quick eager learner as knowledge about new technologies will need to be acquired on the spot
Some hands-on experience developing data pipelines within a Hadoop-based or Apache Spark environment (solution stack is preferably Cloudera, but similar stacks considered) will be an advantage
Some experience developing data solutions using native IaaS and PaaS solutions on AWS (EMR, Redshift, RDS, S3) is a big advantage.
Have very good and clear communication skills, as this person is required to present, propose and advise on data solutions to the management and technical team
How to Apply

Your opportunity to empower results could start right here. Make your mark and apply online today with a brief covering letter and your resume, sharing relevant achievements for this position.

We Offer You

A competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.

Our Colleague Experience

Every day, our colleagues make a difference, work with the best, own their potential, and value one another. Together, we share this one purpose: to empower economic and human possibility around the world. This unifying goal is at the heart of our identity, and it lives in everything we do. To learn more about our colleague experience, visit Aon Colleague Experience.

Aon is an equal opportunities employer. We are committed to creating a winning and inclusive culture where everyone feels valued and has opportunities for growth and development.

2477657",3.6,"Aon
3.6","Chicago, IL",10000+ Employees,1892,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD)
Lead Data Engineer,"$93K-$175K
(Glassdoor Est.)","Discover. A brighter future.

With Discover, you’ll have the chance to make a difference at one of the world’s leading digital banking and payments companies. From Day 1, you’ll do meaningful work you’re passionate about, with the support and resources you need for success. We value what makes each employee unique and provide a collaborative, team-based culture that gives everyone an opportunity to shine. Be the reason millions of people find a brighter financial future, while building the future you want, here at Discover.

Job Description


As an Engineer on our Finance Modernization team, you will provide technical (design & development) leadership in support of our migration from legacy technologies to cloud based solutions. You will be involved in the in development of ETL (Extract/Transform/Load) applications within an evolving AWS infrastructure and support the preparation and transmission of data between systems. This position requires excellent communication skills for understanding business vision and the ability to translate the vision into technical artifacts.

Responsibilities:
Designs and develops complex and critical data projects.
Creates and enhances data solutions that enable seamless integration and flow of data across the data ecosystem.
Designs and develops data ingestion frameworks, leveraging open-source tools and data-processing frameworks.
Identifies improvement opportunities and recommends possible technical solutions.
Provides subject matter expertise in the analysis, preparation of specifications and plans for the development of data processes.
Ensure proper data governance policies are followed by implementing or validating Data Lineage, Quality checks, classification, etc.
Utilize multiple development languages/tools such as Python, SPARK, Hive to build prototypes and evaluate results for effectiveness and feasibility.
Contribute to determining programming approach, tools, and techniques that best meet the business requirements.
Works with key stakeholders to design complex solutions and lead from inception to production
Creates and maintains devops processes, application infrastructure, and utilizes cloud services (including database systems and models)
Innovates on and advocates for best practices and improved team processes; mentors junior team members
Supports live systems to ensure business continuity
Minimum Qualifications
At a minimum, here’s what we need from you:
Bachelor’s degree in information technology or related field
6+ years of experience in computer science, information technology or related field
In lieu of degree, 8+ years of experience in computer science, information technology or related field
Preferred Qualifications:

Hands on experience with Amazon Web Services (AWS) based solutions such as RDS, Lambda, Snowflake and S3 or other cloud technologies
Experience in migrating ETL processes (not just data) from relational warehouse Databases to AWS based solutions
Experience with Spark and/or Python
Experienced in Agile methodologies.
Prior experience in Finance domain is a big plus.

What are you waiting for? Apply today!

The same way we treat our employees is how we treat all applicants – with respect. Discover Financial Services is an equal opportunity employer (EEO is the law). We thrive on diversity & inclusion. You will be treated fairly throughout our recruiting process and without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status in consideration for a career at Discover.",3.9,"Discover
3.9","Riverwoods, IL",10000+ Employees,1985,Company - Public,Financial Transaction Processing,Finance,$5 to $10 billion (USD)
Senior Data Engineer - 100% Remote,-1,"Remote Data Engineer needed for technology company that allows Online Media to achieve the most from their work.

This Jobot Job is hosted by: Patrick Murray
Are you a fit? Easy Apply now by clicking the ""Apply Now"" button and sending us your resume.
Salary: $100,000 - $150,000

A bit about us:

We are looking for a Data Engineer to help develop and own data solutions at our fast-paced Online Media and Ad Services and Revenue company. The Data Engineer role is an excellent opportunity for someone who wants to join a close-knit and smart team at a rapidly growing business. If you are a highly independent worker and have excellent organizational and problem-solving skills, this is the job for you.

If you are a Data Engineer that can work remote, please apply today!

Why join us?
Competitive salary
Great benefits
Career growth
Modern, startup culture
Friendly work environment
Remote employment
Long term learning opportunities


Job Details

The position will require extensive hands-on experience building and scaling data pipelines and corresponding data stores for reporting. We are looking for someone with experience using Airflow, AWS Glue, GCP Dataflow (Beam or Flink), Spark, and/or data stores like Snowflake, Cassandra (or ScyllaDB) to join our fast-paced Online Media and Ad Services and Revenue technology company! Our Expected language competency would be in Python, Java, Scala, or R, with Ruby and/or Go nice to have.

Responsibilities:

Develop and maintain ETL/ELT processes at scale, handling hundreds of millions of records per day
Write advanced SQL for data wrangling, as well as scheduled reporting and automated queries
Perform data exploration and analytics with the goal of developing new insights and business value
Help develop APIs and dashboards to surface data insights

Qualifications:

3+ years of experience
Hands-on implementation and maintenance of a large-scale, high-volume data pipeline
Knowledge of programming language(s) for data processing, such as Python, Scala, R, and libraries and tools, such as Dataflow
Experience with Ruby and/or Go is preferred
In-depth knowledge of relational databases (e.g. PostgreSQL, MySQL) and NoSQL databases (e.g. Druid, Cassandra), as well as analytics using BigQuery
Familiarity with containers and related technologies, such as Docker and Kubernetes, and working with public cloud (e.g. AWS or Google Cloud Platform)
Knowledge of machine learning and time-series forecasting methodologies


Interested in hearing more? Easy Apply now by clicking the ""Apply Now"" button.",5.0,"Jobot
5.0","Chicago, IL",51 to 200 Employees,2018,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Clinical Lab Scientist/MT,"$57K-$60K
(Glassdoor Est.)","Description
Performs various routine and complex clinical laboratory tests according to established policies and procedures in order to obtain data for use in the diagnosis and treatment of disease. Assess test results for accuracy. Performs routine scheduled preventative maintenance, calibration, and minor problem troubleshooting on laboratory instruments. May perform blood specimen collection, training personnel and students. Independent judgment and professional education and certification are required.

Qualifications

REQUIRED QUALIFICATIONS:

A bachelor’s degree in Clinical/Medical Laboratory Science.

Successful completion of the ASCP or AMT Board of Certification CLS exam within the first year of employment is also required.

Alternative bachelor’s degrees are acceptable with successful completion of ASCP or AMT CLS certification exam prior to employment.

Maintains current certification according to guidelines established by appropriate certifying agency.

Interpersonal skills sufficient to interact effectively and communicate with patients and other health care professionals.

http://www.osfcareers.orgHigh level of professionalism and skillful performance in stressful situations.

Must possess sufficient academic, technical, and clinical skills and knowledge to evaluate, troubleshoot, research, and resolve day-to-day problems that arise or special projects as assigned by the laboratory management.

PREFERRED QUALIFICATIONS:

Experience not required but 1-2 years preferred.

EOE/Minorities/Females/Vet/Disabled

Job seekers will be afforded equal opportunity regardless of their race, ethnicity, veteran status or disability status.

Experience the OSF culture and community by clicking here.",3.9,"OSF Healthcare System
3.9","Evergreen Park, IL",10000+ Employees,1877,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$2 to $5 billion (USD)
Sr. Data Visualization Developer,"$79K-$130K
(Glassdoor Est.)","AddThisShare

Sr. Data Visualization Developer / Sr. Data Visualization Engineer
Job Summary
This role is responsible for designing and creating compelling and insightful data and advanced analytics visualization applications for executive-level stakeholders. The successful candidate should have a natural curiosity about business questions and needs related to advanced analytics, knowledge of advanced analytic modeling approaches, and an outstanding ability to communicate advanced analytic model outputs through visually captivating and impactful interactive applications that drive business decisions and support CGI’s strategic priorities.
Essential Duties and Responsibilities
Design, develop, implement, and maintain complex interactive visualization applications using modern JavaScript libraries.
Engage with executive-level stakeholders to understand business strategies and needs related to advanced analytics, and translate requirements into captivating designs and sustainable applications
You’ll understand tools like D3.js, Angular, VUE, React, Semiotic and R Shiny etc – knowing the strengths and tradeoffs of each; and can guide the team on selecting the best tool for the task.
You’ll work with the data scientists to determine the best approach to communicating the analysis or model, then bring it all the way from design through development to production.
You’ll work with the data engineers to ensure the sustainable data pipelines you need are available to, and consumed by, your visualization tools in a robust, maintainable way.
Create documentation and deliver training to business users on the use of developed tools to drive user adoption
Establish subject matter expertise and strongly influence CGI’s data visualization strategy and enterprise tool selections
Maintain and advance professional and technical skills and knowledge
Provide leadership to third-party contractors
Protect CGI reputation by keeping information confidential
Minimum Qualifications

Education/Certifications:
Bachelor’s degree in computer science, information technology, design, or other quantitative field
Experience:
3+ years of hands-on professional design and development of complex interactive advanced data visualization applications
Experience implementing solutions using JavaScript-based data visualization libraries and tools, such D3.js, and building web and mobile interfaces for displaying applications across a range of devices
Proficiency with front end development tools such as HTML5, CSS3, and Node.js
Experience working with business stakeholders
Knowledge, Skills, and Abilities:
Demonstrated knowledge of core concepts in data visualization design
Familiar with connecting data to visualizations through RESTful APIs
Exceptional problem solving / analytical thinking and skills
Natural sense of urgency, teamwork, and collaboration reflected in daily work ethic
Must thrive in a dynamic and changing environment
Outstanding attention to detail
Strong communication skills
Preferred Qualifications

Education/Certifications:
Master’s degree in quantitative field
Experience:
5+ years of professional experience, with 2+ years of experience using data and visualization to influence executive-level decision making
Knowledge, Skills, and Abilities:
Familiarity with modern advanced analytics and Machine Learning techniques
Familiarity with business intelligence visualization tools such as Qlikview/QlikSense, Tableau, or Power BI a plus",3.2,"The Chamberlain Group
3.2","Oak Brook, IL",1001 to 5000 Employees,1954,Company - Private,Consumer Products Manufacturing,Manufacturing,Unknown / Non-Applicable
Clinical Lab Scientist/MT I,"$59K-$87K
(Employer Est.)","Description

Performs various routine and complex clinical laboratory tests according to established policies and procedures in order to obtain data for use in the diagnosis and treatment of disease. Assess test results for accuracy. Performs routine scheduled preventative maintenance, calibration, and minor problem troubleshooting on laboratory instruments. May perform blood specimen collection, training personnel and students. Independent judgment and professional education and certification are required.

Qualifications

REQUIRED QUALIFICATIONS:

A bachelor’s degree in Clinical/Medical Laboratory Science.

Successful completion of the ASCP or AMT Board of Certification CLS exam within the first year of employment is also required.

Alternative bachelor’s degrees are acceptable with successful completion of ASCP or AMT CLS certification exam prior to employment.

Maintains current certification according to guidelines established by appropriate certifying agency.

Interpersonal skills sufficient to interact effectively and communicate with patients and other health care professionals.

High level of professionalism and skillful performance in stressful situations.

Must possess sufficient academic, technical, and clinical skills and knowledge to evaluate, troubleshoot, research, and resolve day-to-day problems that arise or special projects as assigned by the laboratory management.

PREFERRED QUALIFICATIONS:

Experience not required but 1-2 years preferred.

EOE/Minorities/Females/Vet/Disabled

Job seekers will be afforded equal opportunity regardless of their race, ethnicity, veteran status or disability status.

Experience the OSF culture and community by clicking here.",3.9,"OSF Healthcare System
3.9","Evergreen Park, IL",10000+ Employees,1877,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$2 to $5 billion (USD)
Data engineer with Strong Scala,"$65K-$115K
(Glassdoor Est.)","Â

Job Spec:

Â

hard code coder

Â

coding and debugging -- data flow pipelines

implemented in Scala utilizing beam

data is pulled from BQ and results are stored in BQ

Python and bash

Good to have background on GKE

Scio is a spotify lib in Scala -- is a must

Â

prep data that will be sued to train ML models and validate for housing

predictions

Â
Please send resumes toÂbchitneedi@esharpedge.com",4.7,"Sharpedge Solutions Inc
4.7","Naperville, IL",Unknown,-1,Company - Private,Publishing,Media,Less than $1 million (USD)
Data Engineer,"$51K-$98K
(Glassdoor Est.)","Hello Associates,

*****Greetings from Conch Technologies*****

Â

Title: Data Engineer

Length: 12+ month's contract

Location:ÂRolling Meadows, IL

You will:
Work with product owners to understand desired application capabilities and testing scenarios
Continuously improve software engineering practices
Work within and across Agile teams to design, develop, test, implement, and support technical solutions across a full-stack of development tools and technologies
Lead the craftsmanship, availability, resilience, and scalability of your solutions
Bring a passion to stay on top of tech trends, experiment with and learn new technologies, participate in internal & external technology communities, and mentor other members of the engineering community
Encourage innovation, implementation of cutting-edge technologies, inclusion, outside-of-the-box thinking, teamwork, self-organization, and diversity
Basic Qualifications:
Bachelor's Degree
At least 2 years of SDLC experience using Java technologies
At least 2 years' experience with leading big data technologies like Cassandra, Accumulo, Python, HBase,ÂScala,ÂHadoop, HDFS, AVRO, MongoDB, or Zookeeper
At least 1 years' experience in one of the following Cloud technologies:AWS, Azure, OpenStack,ÂDocker, Ansible, Chef or Terraform
Preferred Qualifications:
Master's Degree
2+ year experience withÂSpark
3+ years' experience developing software solutions to solve complex business problems
With Regards,
Â
NageeshÂGÂ
Main:Â901-313-3066
Email:Ânagesh@conchtech.com
Web:Âwww.conchtech.comÂ",4.6,"Conch Technologies, Inc
4.6","Rolling Meadows, IL",51 to 200 Employees,-1,Company - Private,Consulting,Business Services,$5 to $10 million (USD)
Sensory Scientist,"$59K-$126K
(Glassdoor Est.)","WHO WE ARE:

Baldwin Richardson Foods (BRF) is a family-owned company located east of the city of Rochester, NY and just north of the beautiful Finger Lakes area. It is the leading manufacturer and beverage syrup supplier to the top three quick-service coffee franchises. They have long-standing partnerships with large consumer packaging companies, and national quick service food chains. BRF has been growing, year over year, since its inception in the mid-90's and is continuing to expand its footprint in the current market, and beyond.

WHAT WE NEED:

The primary function of this role is to lead the Innovation Sensory department for Baldwin Richardson Foods. The Sensory Scientist will lead sensory initiatives within all New Product Development and Brand Maintenance projects from Concept Development through Commercialization. As the product attribute expert, they will be responsible for collaborating with R&D, Marketing, and Sales to translate sensory insights to influence business decisions. The Sensory Scientist will be responsible for providing guidance on sensory studies needed to support key innovation priorities and cost savings initiatives for Baldwin.

WHAT YOU WILL DO:
Manage the Sensory program within R&D for Baldwin Richardson Foods
Supports internal R&D teams on New Product Development and Brand Maintenance projects from concept creation through commercialization
Lead the design and execution of all sensory tests including Descriptive, Discrimination, and Hedonic tests
Lead objective setting, research design and statistical data analysis for all required sensory tests
Leads setting up, sample prepping, and executing tasting panels with alignment on customer protocols for testing
Lead the interpretation of test results and generate recommendations to R&D on formulation requirements and changes needed
Responsible for sensory final report creation and result communication to internal and external customers
Creates and maintains product sensory profiles for all of Baldwin’s products
Responsible for generation and maintenance of product testing ballots
Leads the prescreening, training, and training maintenance of all internal panelists
Leads all communication and relationship management with external sensory support vendors
Leads the recruitment and training of external consumer panelists
Creates and maintains department SOPs for all sensory protocols
Orders and maintains all sensory equipment and sensory laboratory supplies
Attend internal team meetings to report out sensory updates
Attend external customer meetings as needed to report out sensory updates.
A SUCCESSFUL CANDIDATE WILL HAVE:
Bachelor's degree (B.A./B.S.) from four-year college or university in Nutrition, Chemistry, Biology, Microbiology, Engineering, or Food Science
Master’s degree in Sensory Science strongly preferred
5+ years of food industry experience in a sensory role
KNOWLEDGE, SKILLS AND ABILITY:
Strong food science fundamentals with a passion for food and Innovation
Excellent interpersonal skills with abilities to work directly with customers and internal cross functional counterparts
Strong fundamental with in depth experience on sensory principles, test design, and execution
Ability to conduct statistical design and calculations.
COMPUTER SKILLS:
To perform this job successfully, an individual should have knowledge of Microsoft Outlook, Excel, and Powerpoint
Preferred experience utilizing sensory software such as Computrac, SIMs, etc.
Strong abilities in Algebra, Geometry and Statistics
BRF offers a generous benefits package, including low premium and out-of-pocket medical/dental/vision costs, vacation, sick, 401k with matching, holiday, birthday off, designated holidays and floating holidays.",2.5,"Baldwin Richardson Foods Co.
2.5","Westmont, IL",201 to 500 Employees,1992,Company - Private,Food & Beverage Manufacturing,Manufacturing,$100 to $500 million (USD)
Sr. Field Applications Scientist-Inorganic,"$92K-$138K
(Glassdoor Est.)","Field Application Scientist, Inorganic

Job Overview

We are looking for someone with drive, passion, and a competitive spirit to help maximize PerkinElmers commercial success. This role will specialize in the use of our Inorganic portfolio in chemical, environmental, food, pharmaceutical and industrial applications. This role provides sales support for our Atomic Absorption, Inductively Coupled Plasma Optical Emission, and Inductively Coupled Plasma Mass Spectrometry products to include applications development, training and presales activities.

Our Team

The Discovery and Analytical Solutions group services the Environmental, Pharmaceutical, Manufacturing, Food and Beverage, Chemical, Agriculture, and Government markets. The Field Applications Scientists work closely with the sales team to provide solutions for the research scope and vision for our customers.

Job Responsibilities
Position is field based and covers significant portions if not all of the states of Illinois, Indiana, Missouri, and Ohio, as well as a small portion of western Kentucky with laboratory and Technical Center access in Downers Grove (near Chicago), IL.
Conduct customer demonstrations on the aforementioned products in conjunction with the associated geographical Sales team; perform sample analysis/method development on customer samples using the spectroscopy solutions mentioned above; prepare data packages and presentations summarizing the analysis via online meeting or in person.
Collaborate with all Field Team members to develop and deploy world-class systems and tools and provide front-line support to sales as the Field Applications Scientist.
Provide and deliver product training to field (marketing & sales) as new features/functionality is available for designated product and domain specialty.
Coordinate with Product Management to identify, communicate, and incorporate new product enhancements as well as with the Services team to insure we deliver competitive solutions that are differentiated through value as perceived by our customers.
Characterize the external market by performing pipeline analysis and competitive assessments for region and specific market segments.
Attend regional and national meetings presenting new applications and assisting sales with booth duty and customer inquiries.
Present a professional image at all times to customers, clients and other vendors.
Basic Qualifications:
Minimum BS in a scientific discipline.
5+ years in the atomic spectroscopy field.
Experience in AA, ICP-OES and ICP-MS including sample preparation requirements.
Preferred Qualifications:
PhD or MS in a scientific discipline with at least 3 years in the atomic spectroscopy field.
Current or previous scientific expertise and experience with a customer focus and excellent communication skills.
Willingness for 30% - 50% overnight travel.
What We Provide

PerkinElmer provides our customers with critical knowledge, expertise and innovative detection, software, and services solutions so that they can make better decisions for better outcomes. At PerkinElmer, we make a difference everyday helping scientists, clinicians and governments detect earlier and more accurately to improve the health and safety of people and the environment. Our solutions range from enabling the discovery of more effective diagnostics and therapies, to making sure that the food we eat, the water we drink, and our environment are safe from contaminants.

Nothing in this job description restricts managements right to assign or reassign duties and responsibilities of this job at any time",3.1,"Perkinelmer
3.1","Downers Grove, IL",10000+ Employees,1937,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (USD)
Senior Formulation Scientist,-1,"Senior Formulation Scientist

Full Time

Our Company
Nexus Pharmaceuticals, a US-based healthcare company, specializes in innovative processes to make difficult-to-manufacture specialty and generic drugs that are easier to use, less labor intensive, and more streamlined in practice. Nexus ensures that its high-quality FDA-approved drugs fulfill a critical unmet medical need and delivers dependable life-saving treatment options when and where theyre needed most.

Position Summary

Nexus Pharmaceuticals, Inc. is looking to recruit a Senior Formulation Scientist, Research and Development to join a growing team in Lincolnshire, IL.

You will play a critical role in formulation development for complex parenteral drug products such as Liposomes, Colloids, Suspensions, Emulsions, Extended Release etc. This entails literature search, material procuring, laboratory trials based on DOE (Design of Experiments), formulation optimization, laboratory stability studies, technology transfer preparedness, assistance for scale-up, close monitoring of ANDA/ NDA stability data, document preparations for ANDA/ NDA submissions (including Pharmaceutical Development Report and related study reports), preparation of related FDA Deficiency responses and trouble-shooting at any of the drug product development stages. This position requires a high level of formulation development skills, detail orientation, and analysis to provide recommendations to drive new product development strategies and results. Effective interpersonal skills to work through problems with cross-functional team members (Analytical R&D Team/ QC/ QA/ Regulatory) and external members (manufacturing/ outside testing laboratories/ vendors for API, raw materials, container/closures, etc.) are required.

Role Responsibilities
Develop formulations for complex parenteral drug products such as Liposomes, Colloids, Suspensions, Emulsions, Extended Release, etc. in a cost-effective and timely manner with a consideration of scale-up feasibility.
Initiate development with extensive literature search including but not limited to online resources, FDA websites, patents, etc. followed by material procuring required as per FDA standards.
Conduct laboratory studies based on DOE (Design of Experiments), as needed, for formulation optimization and stability confirmation.
Prepare documents for technology transfer, assist for scale-up, and provide input for initial technology transfer batches.
Monitor closely ANDA/NDA stability data for any issues with the drug product.
Provide documentation to Regulatory Affairs for ANDA/NDA submissions as required.
Lead proactive troubleshooting at any of the drug product development stages.
Work closely with Analytical R&D Team to assist analytical method development needs and data interpretation.
Involved in cross-functional team discussions with QC/QA/Regulatory departments on various tasks related to new product development projects and provide scientific and technical expertise.
Assist fellow formulation R&D team members on projects or ANDA/NDA documents (write-up/ review) being handled by R&D.
QA Compliance: Write or review SOPs and maintain lab practices as per QA/FDA compliance requirements.
Coordinate with external members (manufacturing/outside testing laboratories/vendors for API, raw materials, container/closures, etc.), as needed for product development.
Responsible for troubleshooting as needed by data compilation and presentation to members involved in the project and decision making. Perform document writing, data interpretation, presentation, statistical analysis, and trending.
Provide recommendations to leadership and cross-functional teams to streamline processes and flow of information. Establish practices to provide information and intelligence to drive continuous improvement process proactively.
Other duties as assigned
Required Qualifications
Extremely strong formulation development skills for complex injectables
Strong organizational and problem-solving skills
Strong communication skills, both written and verbal
Self-motivated, proactive, detail-oriented, and able to manage multiple tasks while still meeting deadlines
Ability to track assignments and follow through to completion with minimal supervision
Ability to successfully handle multiple, competing priorities in a fast-paced, changing team environment
Flexibility to adapt with project priority changes or project cancellations
Experience and Education
PhD in pharmaceutics, polymer chemistry, biochemical engineering, or similar disciplines with 2+ years related experience; expert knowledge of scientific principles and concepts preferred.
Masters Degree with 3-5 years relevant experience required.
Bachelors Degree with 5-7 years relevant experience required.
Demonstration of successful ANDA/NDA experience relevant to formulation development and regulatory document submissions required.
Extensive knowledge on Liposomes formulation development- a must.
Travel Requirements
0-15% Travel required for this role
Physical Demands and Work Environment:
Regular (0% - 25%) exertion including standing/walking for extended periods of time, lifting/carrying more than 15 and up to 25 pounds. At times low physical effort includes sitting, and operating computers or other small equipment.

DISCLAIMER: The list under Role Responsibilities are not exhaustive but are merely the most accurate lists for the current job. Management reserves the right to revise the job description and to require that other tasks be performed when the circumstances of the job change.

EEO Statement:


Nexus is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability status, genetic information, protected veteran status, or any other characteristic protected by law.",4.1,"Nexus Pharmaceuticals
4.1","Lincolnshire, IL",51 to 200 Employees,2003,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Sr. Field Applications Scientist-Inorganic,"$92K-$138K
(Glassdoor Est.)","Field Application Scientist, Inorganic

Job Overview

We are looking for someone with drive, passion, and a competitive spirit to help maximize PerkinElmers commercial success. This role will specialize in the use of our Inorganic portfolio in chemical, environmental, food, pharmaceutical and industrial applications. This role provides sales support for our Atomic Absorption, Inductively Coupled Plasma Optical Emission, and Inductively Coupled Plasma Mass Spectrometry products to include applications development, training and presales activities.

Our Team

The Discovery and Analytical Solutions group services the Environmental, Pharmaceutical, Manufacturing, Food and Beverage, Chemical, Agriculture, and Government markets. The Field Applications Scientists work closely with the sales team to provide solutions for the research scope and vision for our customers.

Job Responsibilities
Position is field based and covers significant portions if not all of the states of Illinois, Indiana, Missouri, and Ohio, as well as a small portion of western Kentucky with laboratory and Technical Center access in Downers Grove (near Chicago), IL.
Conduct customer demonstrations on the aforementioned products in conjunction with the associated geographical Sales team; perform sample analysis/method development on customer samples using the spectroscopy solutions mentioned above; prepare data packages and presentations summarizing the analysis via online meeting or in person.
Collaborate with all Field Team members to develop and deploy world-class systems and tools and provide front-line support to sales as the Field Applications Scientist.
Provide and deliver product training to field (marketing & sales) as new features/functionality is available for designated product and domain specialty.
Coordinate with Product Management to identify, communicate, and incorporate new product enhancements as well as with the Services team to insure we deliver competitive solutions that are differentiated through value as perceived by our customers.
Characterize the external market by performing pipeline analysis and competitive assessments for region and specific market segments.
Attend regional and national meetings presenting new applications and assisting sales with booth duty and customer inquiries.
Present a professional image at all times to customers, clients and other vendors.
Basic Qualifications:
Minimum BS in a scientific discipline.
5+ years in the atomic spectroscopy field.
Experience in AA, ICP-OES and ICP-MS including sample preparation requirements.
Preferred Qualifications:
PhD or MS in a scientific discipline with at least 3 years in the atomic spectroscopy field.
Current or previous scientific expertise and experience with a customer focus and excellent communication skills.
Willingness for 30% - 50% overnight travel.
What We Provide

PerkinElmer provides our customers with critical knowledge, expertise and innovative detection, software, and services solutions so that they can make better decisions for better outcomes. At PerkinElmer, we make a difference everyday helping scientists, clinicians and governments detect earlier and more accurately to improve the health and safety of people and the environment. Our solutions range from enabling the discovery of more effective diagnostics and therapies, to making sure that the food we eat, the water we drink, and our environment are safe from contaminants.

Nothing in this job description restricts managements right to assign or reassign duties and responsibilities of this job at any time",3.1,"Perkinelmer
3.1","Downers Grove, IL",10000+ Employees,1937,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (USD)
Data Engineer,"$55K-$107K
(Glassdoor Est.)","Data Engineer

Our goal at Elkay is to inspire everyday – customers, employees…and the employees of tomorrow. We focus on doing the right thing so we can be in business forever. Our values-driven culture emphasizes investing in people and treating them like part of the family. We’re financially-stable and privately-owned with a solid reputation for ethics, integrity, giving back, and providing an engaging, inclusive environment where careers flourish and grow. Our people are proud to work for Elkay.

And the feeling is mutual – because it’s Elkay’s people who really give us our edge. We empower our employees to take the lead in delivering Elkay’s exceptional customer experience. Our commitment to our people and their professional development is a recipe for success that has fueled our growth from a three-person shop in 1920 to one of today’s leading international suppliers of plumbing, water delivery and branded commercial interiors. If you’re ready for a new career challenge where everything you do will make a difference, talk to us about joining the Elkay family.

The Data Engineer we hire will perform a variety of project and technical tasks supporting Elkay’s analytics infrastructure, including data integration and ETL, database architecture and design, data prep, and reporting. Contribute to all aspects of the project lifecycle, including requirements gathering, design, development, testing, and deployment. Become familiar with Elkay’s business model and the various business functions that utilize Elkay’s analytics infrastructure, including sales, marketing, supply chain, operations, pricing, finance, and customer care. Keep abreast of trends, architectures, and tools in the analytics landscape and evaluate them for incorporation into Elkay’s analytics landscape. Learn quickly and juggle multiple tasks for various customers. Communicate complex technical problems effectively to management and to the business. Collaborate with other technical team members on solutions. Effectively prioritize support tasks with project work.

Specific duties include:
Design, develop and maintain data models, database architectures, and associated database objects in Snowflake, Oracle, and other database solutions such as Azure.
Design, develop, and maintain data integrations using Informatica Power Center, Informatica Integrated Cloud Services, and data prep tools.
Participate in or drive project activities such as requirements gathering, design, develop, test, and deploy.
Assist in the set-up of, and administer, on premise and cloud tools used in the Elkay analytics infrastructure.
Create and maintain necessary technical documentation, including requirements, design, and test documents.
Identify emerging trends, processes, and techniques impacting Elkay’s analytics infrastructure and make suggestions for incorporation of these into the analytics infrastructure.
Must have's:
A Master’s or Bachelor’s degree in Computer Science, MIS, engineering, or a related technical discipline is required.
5+ years of experience in data engineering, data warehousing, business intelligence, ETL on databases such as Oracle or SQL Server, and/or big data is required.
3+ years of experience in ETL/ data integration is required with 2+ years of experience in Informatica PowerCenter, job scheduling tools is required.
Working experience in Python/R/Scala, Snowflake is required.
Hands on experience in writing and understanding complex SQL (e.g. CTE’s others).
Thorough understanding of relational database design and best practices, including dimensional (star, snowflake) models is required.
A collaborative working style and ability to work well within the team and with business consumers is required.
Ability to clearly communicate to technical and non-technical audience by written and verbal is required.
Independent analytical, critical thinking, and problem-solving ability in complex technical environments is required.
Nice to have's:
Production experience in OBIEE, Oracle Analytics Cloud (OAC) and Tableau is nice to have.
Familiarity with big data technologies such as Microsoft Azure Data or AWS is nice to have.
EOE/M/F/D/V/SO",3.5,"Elkay Manufacturing
3.5","Downers Grove, IL",1001 to 5000 Employees,1920,Company - Private,Consumer Products Manufacturing,Manufacturing,$500 million to $1 billion (USD)
"AVP, Senior Data Scientist","$88K-$141K
(Glassdoor Est.)","Zurich North America is looking for a Senior Data Scientist to join the Data & Analytics team, supporting the United States Commercial Insurance (USCI) and Middle Market business units, based out of North American Headquarters in Schaumburg, Illinois or our New York/Jersey City offices.

In the Senior Data Scientist role you will lead one or more project teams responsible for using data and analytics to create business impact for the USCI and Middle Market business units. Data & Analytics at Zurich encompass data science, analytics, dashboards and data visualizations as well as data as a business asset.

In this role you will:
Lead one or more teams of data scientists to solve business problems and bring impact to the business units. This means:
Partnering with stakeholders to understand how data and analytics can help the business unit achieve their strategic priorities
Ensuring the quality of the data and analytics solution being built, and that it’s fit for purpose
Working with stakeholders to develop a strategy on how to use data and analytics to generate the desired impact
Continuing to work with stakeholders after deployment to ensure that impact is achieved
Broad ownership of a portfolio of 2-4 projects, each with a project lead and a project team
Establish and maintain collaborative relationships throughout the organization
Develop the team’s analytic and business problem-solving skillset.
Basic Qualifications:
Bachelor’s Degree in Computer Science or Engineering or Mathematics/Statistics or Technology and 8 or more years of experience in the Predictive Analytics area
AND
Experience applying data transformation techniques such as exact and probabilistic matching methods; fuzzy matching, text mining, and data reduction
Experience with programming and database mining tools such as Hadoop, Hive, Pig, Java, SQL, and Python.
Preferred Qualifications:
2 or more years of Project Management level experience for projects with management consulting
Experience in managing and developing people
Strong communication and presentation skills
Ability to craft and defend actionable solutions to business challenges
Experience in using data and analytics, including data science, to solve business challenges and drive business impact
Knowledge of statistical and data science models, e.g. GLMs, decision trees, clustering, association rules, ensemble methods
Experience leading, managing, and coaching an analytics team
Commercial property & casualty insurance knowledge and experience.
Imagine working for a company that truly cares about their employees, customers, stakeholders, and communities they serve.

Imagine working for a values-driven organization that has the ambition and desire to be the best global insurance provider in the world.

Zurich is that place where 55,000 employees across approximately 200 countries and territories are all focused on helping people and helping companies protect what is truly most important to them. We are a values-driven organization that takes pride in the work that we do every day and we have the ambition to be the best global insurer in the world.

EOE disability/vets

Zurich does not accept unsolicited resumes from search firms or employment agencies. Any unsolicited resume will become the property of Zurich American Insurance. If you are a preferred vendor, please use our Recruiting Agency Portal for resume submission.",3.2,"Zurich North America
3.2","Schaumburg, IL",10000+ Employees,1912,Company - Public,Insurance Carriers,Insurance,$500 million to $1 billion (USD)
Computational Scientist Team Lead,"$39K-$73K
(Glassdoor Est.)","Please make sure to read the job posting in its entirety as it reflects both the University roles and responsibilities, followed by the specific description.
Department
86755 Research Computing Center
About the Unit
The University of Chicago Research Computing Center (RCC), a unit in the Office of Research and National Laboratories (RNL), provides high-end research computing resources to researchers at the University of Chicago. It is dedicated to enabling research by providing access to centrally managed High Performance Computing (HPC), storage, and visualization resources. These resources include hardware, software, high-level scientific and technical user support, and the education and training required to help researchers make full use of modern HPC technology and local and national supercomputing resources. The Office of Research and National Laboratories oversees the conduct of sponsored research, research program development, multi-institutional research institutes, national laboratory board, and contract management functions. RNL supports the development and coordination of research-related communications and educational programs at The University of Chicago. RNL oversees the management of two Department of Energy contracts for Argonne National Laboratory and Fermi National Accelerator Laboratory. When combined with the Lab R&D budgets, the office oversees approximately $1.4 billion in sponsored research. RNL works closely with individual scholars, departments, and divisions to encourage, seed, and coalesce research across the University, Argonne, and Fermilab campuses.
Job Family
ResearchResponsible for all aspects of research projects and research facilities. Plans and conducts clinical and non-clinical research; facilitates and monitors daily activities of clinical trials or research projects. Directs engineering and technical support activities to develop and maintain tools and computational methods needed to gather and analyze data.
Career Track and Job Level
Research ComputingCreates research focused user interfaces web front-ends, back-end services that scale, and integrate scientific workflows that automate and accelerate the scientific output of multi-institutional collaborative projects. This role involves software development in support of research projects involving data acquisition, ingestion, and integration from heterogeneous sources (metadata extraction from a corpus of diverse data sets, both structured and unstructured data).P3: Requires in-depth knowledge and experience. Uses best practices and knowledge of internal or external University issues to improve products or services. Solves complex problems; takes a new perspective using existing solutions. Works independently, receives minimal guidance. Acts as a resource for colleagues with less experience.
Role Impact
Individual Contributor
Responsibilities
The job develops front and back-end software structures that scale and integrate scientific workflows in multi-institutional research projects. Uses in-depth knowledge of software development to facilitate solutions to data acquisition, ingestion and data integration from heterogeneous sources.1) Participates in the product development life cycle, providing professional assistance to the design of front-end applications and database systems back-end schema. Analyzes high-level system specifications and makes sure that all application development standards are met., 2) Develops and presents technical training materials and web-based documentation. Ensures timely systems support and updates. Assists in conducting information security assessments and risk analysis of computing environment., 3) Evaluates past and present technologies to help develop new tools. Ensures all the new tools have been through quality control reviews., 4) With a moderate level of guidance, provides hardware, user and application level authentication and authorization. Implements modern web authentication methods such as XACML, SAML, OAuth2, Shibboleth, and LDAP directory server administration. Applies theoretical expertise and innovation to create or apply new technology, such as adapting principles for applying computers to new uses., 5) Performs other related work as needed.

Unit-Specific Responsibilities

1) The Research Computing Center (RCC) is seeking a highly motivated Computational Scientist to work closely with faculty and researchers at The University of Chicago and to lead the Computational Scientist Team.

2) As part of the RCC senior leadership group, serve as a multi-disciplinary technical expert in supporting and advising faculty on using High Performance Computing (HPC) and related technologies for their research.

3) Assist with compiling, debugging, optimizing, profiling, and porting parallel codes on HPC and AI systems.

4) Assist with improvements of parallel scaling and load balancing of large-scale research codes; assist with maintaining parallel community codes.

5) Develop, install, and test scientific software in support of research goals.

6) Work with faculty and their research groups to enable them to fully utilize the University and national computational resources for their research.

7) Solve user problems quickly and professionally.

8) Work closely with faculty to identify, develop, and implement useful computational methods and resources that support or advance their research.

9) Keep abreast of new developments in High Performance Computing, data science and AI, and pro-active in introducing them to the faculty.

10) Create and present tutorials, hands-on workshops and documentation to educate the research community.

11) Assist researchers with grant proposals with strong HPC or AI component to describe the interplay between their research and computation and data science.

12) Serve as the lead of the Computational Scientists team.

Education, Experience, and Certifications
Minimum requirements include a college or university degree in related field.Minimum requirements include knowledge and skills developed through 5-7 years of work experience in a related job discipline.

Preferred Qualifications

Education

1) Ph.D. in Astronomy, Astrophysics, Computer Science, Physics, Chemistry or similar discipline.

Experience

1) Proficiency in one or more programming languages (such as C++, C, etc.).

2) Proficiency in a scripting language such as Python.

3) Parallelizing large scientific codes with MPI and Open MP and using such codes on parallel supercomputing platforms.

4) Linux/Unix.

5) Software design and development methodologies and best practices.

6) Installing and tuning scientific applications software strongly.

7) Compiler optimization techniques.

8) Machine Learning and Deep Learning frameworks.

Required Documents

1) Resume or CV

2) Cover Letter

NOTE: When applying, all required documents MUST be uploaded under the Resume/CV section of the application.

FLSA Status
Exempt
Pay Frequency
Monthly
Pay Grade
Depends on Qualifications
Scheduled Weekly Hours
37.5
Benefits Eligible
Yes
Drug Test Required
No
Health Screen Required
No
Motor Vehicle Record Inquiry Required
No
Posting Date
2020-06-26-07:00
Remove from Posting On or Before
2020-12-26-08:00
Posting Statement


The University of Chicago is an Affirmative Action/Equal Opportunity/Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.

Staff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via Applicant Inquiry Form.

The University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: http://securityreport.uchicago.edu. Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637.",4.0,"University of Chicago
4.0","Chicago, IL",10000+ Employees,1890,College / University,Colleges & Universities,Education,$2 to $5 billion (USD)
"Applied Data Science Lead, Commercial","$71K-$117K
(Glassdoor Est.)","What we do

At Civis, we take a science-first approach to solving problems. With a blend of proprietary technology and statistical advisory services, we help public and private sector organizations find, understand and connect with the people they care about, so they can stop guessing and start using mathematical proof to guide decisions. We know others use “data science” and “analytics” as buzzwords, but at Civis we don’t stand for fluff, and we will always deliver scalable products and technologies — not PowerPoints — to drive your business forward. Learn more about Civis at www.civisanalytics.com.

Our mission

To democratize data science so organizations can stop guessing and make decisions based on numbers and scientific fact.

What we are looking for

We are currently seeking an Applied Data Science Lead to play a pivotal role in powering Civis’ growth within the Commercial sector. You will lead end-to-end delivery of client solutions, including initial business development, problem scoping, and delivery. You will help grow Civis' business by delivering excellent work and identifying new strategic growth opportunities for the company.

The Applied Data Science (ADS) team is the consultancy arm of Civis Analytics, working closely with companies to help solve their toughest challenges with data science. ADS Leads manage, supervise and mentor a team of Applied Data Scientists to deliver analytic solutions to our commercial clients that help inform some of their biggest decisions.

ADS Leads work closely with teams across the company, including engineering, product, legal, finance, and sales, and often they find themselves managing cross-functional teams to advise, oversee, and communicate their work internally and externally. They lead the scoping of their projects as the face of Civis, and they help grow Civis' business through delivering excellent work and identifying new strategic growth opportunities for the company.

Due to the uncertainty of COVID-19, all Civis offices are closed and all employees are remote for the foreseeable future. This is being closely monitored as things change and it’s likely our offices will reopen. Because of this uncertainty, we want to ensure candidates for this role are open to relocating to our Chicago office in the future.

Responsibilities
Manage and lead a team of applied data scientists, as well as cross-functional client delivery teams, that provides analytics and survey research consulting to achieve our clients’ business goals through the usage of Civis’ services and technology.
Partner with technical, product and sales teams to establish a strategy that accomplishes a client's strategic goals.
Design the scope and analytics roadmap for clients. Manage a team through the process of solving some of our clients’ hardest problems; defining the client’s problem, designing a solution, and delivering high-quality work
Own engagements end-to-end for clients that may include Fortune 500 companies or high-profile startups
Grow Civis' business by delivering excellent work to existing clients, identify new strategic growth opportunities for the company, and developing expertise and credibility in commercial data science and quantitative survey research
Develop and manage relationships with senior clients and decision makers and is responsible for all client-facing communication and work product
Lead the research design of their projects, including statistical and data management methods, soliciting input from subject matter experts when needed
Ensure that all deliverables provide substantive value to clients, adhere to our standards, and further our mission
Manage and mentor teams of data scientists
Some limited travel required (typically
Minimum Qualifications
Bachelor’s degree in an analytical subject (e.g. statistics, math, social science, etc) or business (marketing, economics, etc.)
A strong foundation in statistics and data analytics expertise in survey research and statistical modeling. This will be demonstrated by having 5+ years of experience working with large data sets to solve real-world business challenges
Experience managing teams to complete products within scope and on time
Proficiency in SQL and/or statistical packages (R, Python, STATA, etc)
Excellent interpersonal and communication skills
Demonstrated history of delivering high-quality analytic work to decision-makers in a client services or internal consulting / research environment
Preferred Qualifications
Advanced degree in an analytical subject (e.g. statistics, math, social science, economics, etc.) or Masters in Business Administration
Experience with survey questionnaire design and other research deliverables and studies (customer segmentation, brand health tracking, marketing evaluation experience, etc.) a plus
Familiarity with machine learning, and causal inference a plus
Experience working for a consulting, services, or advisory firm
Experience writing proposals, building cost and pricing estimates of proposed work, and selling the work to new or existing clients
Experience presenting completed work or pitching new work to executive audiences
Who we are

At Civis, we have opportunities for applicants who are newcomers, seasoned professionals, and anywhere in between. Our teams are energized by complex challenges and value diversity of thought. Opportunities to stand out and inspire happen daily and we trust and encourage you to act on your ideas – no matter how big they are. We offer you the tools and community you need to do your best work. Each of us is committed to holding ourselves accountable for results, challenging the status quo and finding new ways to grow our company and each other.

Why join our team?
The opportunity to be part of a growing tech startup focused on solving interesting and meaningful problems, invested in internal promotion, and committed to fostering a diverse, equal and inclusive workplace.
Competitive benefits, including unlimited PTO, 401K match with immediate vesting, health, dental, and vision benefits, paid parental leave, breastfeeding support including breastmilk shipping services for traveling moms, flexible work from home policy, commuter benefits, wellness initiatives including weekly group meditations, monthly on-site massage therapy, and pet insurance.
Civis Analytics embraces the individuality of our employees and we celebrate each other's differences. Our products, services, and culture benefit from and thrive on the unique perspectives brought by each person in our community. We're proud to be an equal opportunity workplace, and we are committed to equal employment opportunity regardless of race, age, sex, color, ancestry, religion, national origin, sexual orientation, gender identity, citizenship, marital status, disability, or Veteran status. If you have a disability or special need that requires accommodation, please contact internalrecruiting@civisanalytics.com

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States.

EEO IS THE LAW

EEO Supplement

Pay Transparency",3.2,"Civis Analytics
3.2","Chicago, IL",51 to 200 Employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,$25 to $50 million (USD)
Clinical Lab Scientist-MICROBIOLOGY SIGN ON BONUS,"$21-$34 Per Hour
(Glassdoor Est.)","$2000.00 SIGN ON BONUS
(Bonus program parameters apply)

Edward-Elmhurst Health includes three hospitals — Edward Hospital, Elmhurst Hospital, and Linden Oaks Behavioral Health — and an extensive ambulatory care network that provides comprehensive healthcare to residents of the west and southwest suburbs of Chicago.

Edward-Elmhurst Health provides comprehensive healthcare at more than 60 locations in the suburbs of Chicago. Our success has always been — and always will be — driven by our most talented, reliable, compassionate and skilled people, who genuinely believe in delivering top quality care to our patients and their families. At Edward-Elmhurst Health, you will also experience a vibrant culture and an atmosphere of nurturing support and leadership.

Be DRIVEN to join our over 8,000 employees, 1,700 staff physicians and 1,800 volunteers who want to provide safe, seamless and personalized care every day for our patients, our families and our communities.

Job Summary: Performs various clinical laboratory tests in one or more sections of the Laboratory in order to obtain data for use in diagnosis and treatment of disease Will work in a high volume, dynamic and state of the art laboratory and performing some molecular testing and plate reading as well as microbiology set ups.

Hours: Part-time (0.5 FTE/20 hrs. week-BENEFIT ELIGIBLE) 3pm-11:30pm; Includes weekend/holiday rotation

Required:
Associate's degree or higher in Medical Technology or Clinical Laboratory Science
Ability to accurately collect and analyze test results, and to perceive similarities and differences in color
Registration with the American Society of Clinical Pathology (ASCP), National Credentialing Agency (NCA) or equivalent
Preferred:
Bachelor’s Degree
Microbiology experience
*Benefits offered by Edward-Elmhurst Health include:
Medical, dental, and vision
401K
Tuition reimbursement
Paid time off
Fitness center membership
Plus many other Employee Perks",-1,Edward Hospital,"Elmhurst, IL",1001 to 5000 Employees,-1,Hospital,Health Care Services & Hospitals,Health Care,$500 million to $1 billion (USD)
Senior Data Analyst,"$46K-$82K
(Glassdoor Est.)","Senior Data Analyst - Health Communication Research
Submit
#495803
/
Regular Full-Time
/
Chicago – 55 East Monroe Street, IL
/
Public Health
JOB DESCRIPTION:
NORC at the University of Chicago is seeking a Senior Data Analyst to support our public health data science team. This position can be located in either our Chicago, IL or Bethesda, MD office. At NORC, Data Analysts work with our Data Scientists, and play a strategic role in supporting our research teams to produce valuable insights for our clients. They work collaboratively and help break down silos and barriers across the company to help drive innovative work. A person in this position, under the leadership of Data Scientists, contributes to data acquisition and management of large volumes of data from various sources (including social media); the design and implementation of analyses, algorithms, models, and work flows to discover valuable information from structured and unstructured data; organizes, harmonizes, and analyzes data sets; uses various technologies to enable data visualization; and creates applications of general value to the company’s business.

NORC’s Public Health staff work closely with colleagues across the organization to offer program, policy, and research solutions. We are committed to building and maintaining long-term relationships among our staff, partners, and sponsors through collaboration, mutual respect, and a commitment to improving health and health care for all people.

Due to COVID-19, this position will initially be remote, but preferably applicants will be based in either or Chicago, IL or our Bethesda, MD office when it is safe to resume office work.
DEPARTMENT: Public Health
The Public Health Research team conducts work on a variety of public health topics including chronic disease prevention and health promotion, rural health, health disparities, and social determinants of health. NORC’s Social Data Collaboratory within Public Health Research collects, manages and analyzes social media data from multiple platforms, employing NLP and other machine learning approaches to understand how the amount, content, sources and diffusion of social media messages influence and reflect individuals’ behavior and opinions related to a wide range of topics. Our team includes prominent health policy experts, nationally recognized public health researchers with general and specialized expertise in areas such as health communications and substance abuse control, skilled methodologists, and leaders in the field of survey design and implementation. Our staff also brings expertise in populations of special interest and the intersection of public health and health care delivery. We offer broad, multidisciplinary experiences spanning public health, epidemiology, statistics, policy, developmental psychology, economics, sociology, social work, and political science.
RESPONSIBILITIES:
Responsibilities of a person in this position would include but not be limited to:
Supporting analytics, evaluation and technical assistance projects working with data from multiple sources;
Assisting with ingestion and interpretation of data from multiple sources;
Developing programs and scripts for data transformation, integration, or reduction; Enhancing previously developed in-house applications such as those for data coding;
Performing various types of quantitative and qualitative analysis and data visualizations involving multiple data sets;
REQUIRED SKILLS:
The successful candidate should have at least a Bachelor’s degree in one of the following fields: math, statistics, computer science, data science, or a social science or public policy related field. He/she should have a strong foundation in areas of statistics, mathematics, and computer programming with a strong interest in applying these skills in public health evaluation and program implementation.
At least 3 years’ experience in positions working with large datasets and conducting statistical and quantitative modeling, melding analytics with basic programming, data mining, clustering and segmentation. Domain expertise preferred.
Desired: experience or familiarity with data management, ETL processes, query, and aggregation tools such as MongoDB, ElasticSearch, and/or Spark a
Desired: experience or familiarity with data programming in statistical packages and database tools such as SQL, Python, R, and/or other large data systems
Preference will be given to those with additional expertise in areas of data mining such as topic modeling, natural language processing, and machine learning.
Strong skills in problem solving and quantitative/qualitative analysis are required.
The candidate should be able to organize and prioritize work assignments to meet project needs.
Some familiarity with the social science domain is also preferred.
The qualified candidate should have strong communication skills; able to quickly comprehend requirements and assignments and then explain his/her solutions in both writing and speech.
Qualified applicants must be eligible to work in the U.S. We regret that we are unable to offer visa sponsorship for this position.
WHAT WE DO:
NORC at the University of Chicago is an objective, non-partisan research institution that delivers reliable data and rigorous analysis to guide critical programmatic, business, and policy decisions. Since 1941, our teams have conducted groundbreaking studies, created and applied innovative methods and tools, and advanced principles of scientific integrity and collaboration. Today, government, corporate, and nonprofit clients around the world partner with us to transform increasingly complex information into useful knowledge.
WHO WE ARE:
For over 75 years, NORC has evolved in many ways, moving the needle with research methods, technical applications and groundbreaking research findings. But our tradition of excellence, passion for innovation, and commitment to collegiality have remained constant components of who we are as a brand, and who each of us is as a member of the NORC team. With world-class benefits, a business casual environment, and an emphasis on continuous learning, NORC is a place where people join for the stellar research and analysis work for which we’re known, and stay for the relationships they form with their colleagues who take pride in the impact their work is making on a global scale.
EEO STATEMENT:
NORC is an affirmative action, equal opportunity employer that values and actively seeks diversity in the workforce. NORC evaluates qualified applicants without regard to race, color, religion, sex, national origin, disability, veteran status, sexual orientation, gender identity, and other legally- protected characteristics.
9.4.2020
/
Back",3.1,"NORC at the University of Chicago
3.1","Chicago, IL",1001 to 5000 Employees,1941,Nonprofit Organization,Research & Development,Business Services,$100 to $500 million (USD)
Cloud Data Engineer,"$62K-$74K
(Glassdoor Est.)","Cloud Data Engineer

19-Feb-2020

Job Summary
BDO’s Core Purpose is Helping People Thrive Every Day. Our Core Values reflect how we manage our work, our relationships and ourselves. As an employee of the firm, you will live true to our Core Values of people first, being exceptional every day in every way, embracing change, feeling empowered through knowledge and choosing accountability. Our Core Values are the standards by which we conduct ourselves day in and day out, both internally and externally.

BDO Digital, LLC, a subsidiary of BDO USA, LLP, provides a holistic portfolio of technology, transformation services and solutions. We are an organization that values your time, talent, and contributions. Collaborate with BDO Digital’s cross-disciplinary team who work together to solve digital needs and unearth new opportunities to drive competitive advantage. Our commitment to each other is why BDO Digital is a recognized leader for our culture, employee satisfaction and career growth. We’re looking for people with the same drive; to combine teamwork with technology to produce amazing results.

The Cloud Data Engineer has advanced experience within Data Analytics (DA) using cloud massive scale data engineering tools such as Databricks or Spark. This position works closely with our clients to provide outstanding customized cloud data analytics solutions. This role is exposed to a wide range of cloud technologies, roles and client environments. This role will understand data analytics principles to guide implementation of Data Analytics (DA) projects both functionally and technically.
Responsibilities:
Leads clients and project team members to define and document project specifications
Designs, develops, tests, and implements cloud data solutions, both functionally and technically
Manages activities for existing software within the Data Analytics practice
Data visualization using PowerBI or Tableau for data analysis and reporting
Partakes in technology training to stay current on various cloud data engineering and data science technologies
Other duties as required
Supervisory Responsibilities:
Leads a team within projects to ensure that timelines and deliverables are met
Oversees time reporting accuracy and technical management of projects
Performs code reviews and ensures adherence to standards
Auto req ID
17589BR

Posting Title
Cloud Data Engineer

Multiple Locations
Indianapolis

State
Illinois

City
Oak Brook

Qualifications
Education:
Bachelor's degree from an accredited university, required
Bachelor’s degree in Computer Science or a related field from an accredited university, preferred
Experience:
Five (5) or more years of software development/engineer experience within data analytics, business intelligence or application development using Microsoft technologies, required
Two (2) or more years of experience using Spark, required
Two (2) or more years of experience technically leading development projects, required
Strong SQL Server skills along with SQL queries and stored procedures, required
Two (2) or more years with the following experience with some of these technologies: AWS, Azure, Data Lake, Databricks, Synapse, SQL Data Warehouse, Snowflake, Azure Data Factory, Python, or R, preferred
Two (2) or more years of experience producing technical designs (artifacts), preferred
Other Knowledge, Skills & Abilities:
Excellent organizational and time management skills
Strong written and verbal communication skills
Strong understanding of data modeling best practices
Must be open to local travel to client sites, if needed
Keywords: Spark, Engineering, Databricks, Software Developer, Data Analytics, Business Intelligence, BI Developer, BI, Data Engineer, Machine Learning, Data Lake Analytics, Stream, BI Stack, Cube, Microsoft, SQL Server, Tableau, Qlik, PowerBI, Azure Data Factory, Snowflake, Azure Synapse, , Python, R

#LI-AG1",3.6,"BDO USA
3.6","Oak Brook, IL",5001 to 10000 Employees,1910,Company - Private,Accounting,Accounting & Legal,$1 to $2 billion (USD)
Clinical Lab Scientist-BLOOD BANK SIGN ON BONUS,"$21-$34 Per Hour
(Glassdoor Est.)","Edward-Elmhurst Health includes three hospitals — Edward Hospital, Elmhurst Hospital, and Linden Oaks Behavioral Health — and an extensive ambulatory care network that provides comprehensive healthcare to residents of the west and southwest suburbs of Chicago. Edward-Elmhurst Health provides comprehensive healthcare at more than 60 locations in the suburbs of Chicago. Our success has always been — and always will be — driven by our most talented, reliable, compassionate and skilled people, who genuinely believe in delivering top quality care to our patients and their families. At Edward-Elmhurst Health, you will also experience a vibrant culture and an atmosphere of nurturing support and leadership.

Be DRIVEN to join our over 8,000 employees, 1,700 staff physicians and 1,800 volunteers who want to provide safe, seamless and personalized care every day for our patients, our families and our communities.

Job Summary: Performs various clinical laboratory tests in the Blood Bank section of the Laboratory in order to obtain data for use in diagnosis and treatment of disease.

Hours: Part-time (0.5 FTE 20 hrs/week) 2pm-10:30pm various evenings during the week including weekend and holiday rotation

Required:
Associate's degree in Medical Technology or Clinical Laboratory Science
Ability to accurately collect and analyze test results, and to perceive similarities and differences in color
Registration with the American Society of Clinical Pathology (ASCP), National Credentialing Agency (NCA) or equivalent
Preferred
Bachelor’s Degree
*Benefits offered by Edward-Elmhurst Health include: (eligibility varies by FTE)
Medical, dental, and vision
401K
Tuition reimbursement
Paid time off
Fitness center membership
Plus many other Employee Perks",-1,Edward Hospital,"Elmhurst, IL",1001 to 5000 Employees,-1,Hospital,Health Care Services & Hospitals,Health Care,$500 million to $1 billion (USD)
Data Engineer,"$76K-$130K
(Glassdoor Est.)","Working at Horizon is more than a job – it’s personal. For us, success is measured by the numbers that matter most – the number of lives we touch, the number we change and those we work tirelessly to help save. We’re a team of agile, out-of-the-box thinkers who are inspired to do more because we know we’re a part of something bigger. We strive to build meaningful careers at a company whose values we share because when we live up to our potential, we help others live up to theirs.

Position Summary:

The Data Engineer will help our analytics team provide the best possible insights to our business partners across the organization. They will be responsible for expanding and optimizing our data pipeline and pipeline architecture. As new analytics initiatives begin, the Data Engineer will help to create an ideal architecture for capturing, storing, and transforming the necessary data. This role is ideally suited for an intellectually curious and forward-thinking candidate with a strong technical background. The right candidate will be self-directed and able to handle multiple projects and deadlines. The Data Engineer should be enthusiastic about learning new technologies and applying them solve data problems efficiently.

Responsibilities:
Develop a deep understanding of available data sources, including capture methodologies and data limitations
Create automated data pipelines and ETL procedures to capture and curate data from many sources
Design and optimize data architecture to best answer business questions presented to the analytics team
Advise on how new technologies can improve current data processes
Support the data science and business insights teams with data queries and investigations on an ad-hoc basis
Qualifications and Skills Required:
BS in Software Engineering, Computer Science, Information Technology, or other technical discipline
Master’s degree in a related field preferred but not required
Extensive experience in modern data storage technologies, including relational SQL and NoSQL databases, graph databases, and cloud storage
Advanced programming knowledge related to data manipulation, extraction, and automation – python and Linux background strongly preferred
Ability to manage multiple projects in an ambiguous environment with shifting priorities and time-pressure
Ability to translate business questions into clearly documented data manipulation and ETL procedures
Excellent problem solving capabilities
Strong communication skills (verbal and written); proven ability to work cross functionally and liaise across a complex set of stakeholders
Experience generating data, including from APIs, web scraping, or behavior logging
Expert at: Microsoft Office (Word, Excel, PowerPoint, Outlook)
Horizon Core Values & Competencies:

Growth
Manages Ambiguity
Strategic Mindset
Demonstrates Self-awareness
Cultivates Innovation
Develops Talent
Accountability
Drives Results
Ensures Accountability
Decision Quality
Transparency
Courage
Collaboration
Instills Trust
Horizon Therapeutics plc does not discriminate on the basis of race, color, religion, gender, sexual orientation, national origin, age, disability, veteran status, or any other characteristic protected by law. It is our intention that all qualified applications are given equal opportunity and that selection decisions be based on job-related factors. Any individual, who, because of a disability, needs accommodation or assistance in completing this application or at any time during the application process, should contact the Human Resources Department.",3.7,"Horizon Therapeutics
3.7","Lake Forest, IL",1001 to 5000 Employees,2008,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$1 to $2 billion (USD)
Mid to Senior Level Environmental Scientist,-1,"Toeroek Associates, Inc. is seeking a motivatedMid to Senior Level Environmental Scientistto provide technical support reviewing and editing technical Comprehensive Environmental Response, Compensation, and Liability Act (CERCLA) and Resource Conservation and Recovery Act (RCRA) documents supporting environmental assessment and cleanups. Preferred locations include Kansas City, MO, Chicago, IL, St. Louis, MO, Cleveland OH, or San Francisco Bay Area, CA. The successful candidate will support a team of Toeroek engineers, geologists, environmental scientists, and risk assessors that assesses the nature and the extent of contamination, potential cleanup alternatives, remedial design, and operations and maintenance at CERCLA and RCRA Corrective Action sites. Periodic travel is required.

This is an excellent opportunity for a career professional to develop deep technical knowledge of complex environmental sites and grow a rewarding career path with Toeroek. Applicants should apply with a resume and cover letter at https://toeroek.applicantpool.com/jobs/. Toeroek is a small business headquartered in Colorado with satellite offices located in Chicago, Berkeley, Dallas, and Northern Virginia. Toeroek provides specialized support services to the Federal Government, including the U.S. Environmental Protection Agency (""EPA"").

Specific Responsibilities Include:
Technical reviews of reports such as Preliminary Assessments/Site Inspection (PA/SI) Reports, Remedial Investigation (RI)/Feasibility Studies (FS); Remedial Designs (RDs), Quality Assurance Project Plans (QAPPs), Operations and Maintenance (O&M) Plans, Treatability Study (TS), Corrective Measures Studies (CMS), Corrective Measures Implementation (CMI) Designs and Work Plans, RCRA Facility Investigations (RFIs)
Collecting and evaluating environmental data in field and office settings
Field activities will consist of soil, groundwater, sediment, and soil gas sample collection; geological logging and interpretation; and oversight of investigation and remediation subcontractors including laboratories and excavation and drilling companies
Support providing soil and groundwater assessments, soil gas sampling, asbestos inspections, lead-based paint assessments, geophysical surveys, and waste determinations
Preparing technical reports and other documents on topics associated with site characterization, remedial optimization, and remedy implementation
Recognizing technical discrepancies in analytical results and making appropriate corrections following standard procedures
Work within quality/budget/schedule expectations and scope-specific assignments
TECHNICAL REQUIREMENTS:
BS degree in Engineering, Geology, Environmental Science or related field
6+ years of practical experience related to contaminated site characterization and remediation at contaminated sites including Superfund, Brownfields, and RCRA Corrective Action sites
Strong knowledge of federal and state environmental laws and regulations under Federal (e.g., Superfund, RCRA, Brownfields), state, or other cleanup programs
Experience conducting quantitative analyses using Microsoft Excel
OTHER PREFERRED SKILL SETS AND CERTIFICATIONS:
Remedial system operations and maintenance
Targeted Brownfields Assessment experience (Phase I and Phase II ESAs)
40-Hour HAZWOPER, EPA Lead Inspector/Risk Assessor, AHERA accredited Building Inspector, Asbestos Inspector License in any of the following states: California, Arizona, Nevada, Missouri, Iowa


PROFESSIONAL SKILLS:
Demonstrated attributes to become a strong consultant team player, eagerness to learn and grow, self-starter who takes initiative, versatile, and service-oriented mentality
Effective written/verbal communication and organization/analytical skills; experience writing and compiling technical data and reports
Ability to multi-task, maintain flexibility, travel, and work independently with minimal supervision
Strong attention to detail with the ability to manage multiple priorities at once
Toeroek is proud to be an Affirmative Action / Equal Employment Opportunity employer.

Toeroek does not accept recruiting agency resumes.",3.7,"Toeroek Associates, Inc.
3.7","Chicago, IL",51 to 200 Employees,1993,Company - Private,Consulting,Business Services,$10 to $25 million (USD)
Scientist - Tech Transfer,-1,"Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description

This position provides technical leadership and is a primary point of contact for CMOs (Contract Manufacturing Organizations) for PSS Client. The role is involved in the collaborative development of products for the client division and works directly to provide guidance for CMO groups that are supporting client products. This position is focused on global product development through commercial launch.

The role oversees and manages the tech transfer and scale-up of sterile injectable (includes solutions, lyophilized products, suspensions and emulsions) and ophthalmic pharmaceutical dosage forms (includes solutions, suspensions) and must have a fundamental understanding of cGMP, sterile operations, etc.

The individual will be expected to provide detailed technical, process understanding and expertise in support of complex technical investigations, process troubleshooting, technical transfer, scale up, as well as engineering and exhibit batch manufacturing. The individual will be instrumental in facilitating project and technical ownership to client prior to process validation/commercial batch manufacturing.

The individual will be expected to leverage collaboration across multiple groups and competing priorities and should have extensive understanding and experience dealing with large technical group of engineers, scientist and technicians in large multi-product contract manufacturing facilities. The role serves as the operations point of contact for technology transfer and manufacturing and should be knowledgeable of the documentation necessary for tech transfer of new products, including tech transfer plans and risk assessments.

Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development/tech transfer/manufacturing experience. Preferred education background in Pharmaceutics, Engineering or similar discipline, however, extensive experience with tech transfer processes may be substituted for education.
Significant experience with tech transfer of drug products in or out of manufacturing sites
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Working knowledge of project management concepts and tools
Working knowledge of Computer Aided Design (CAD) and/or Visio tools for Equipment/Process design
Working knowledge of DOE and MiniTab tools for experimental design and data analysis.
Significant experience in process development and scale-up
Experience fostering relationships with CMOs
Detailed knowledge of technology transfer and scale up.
Ability to trouble shoot/recommend the solutions to resolve the technical issues with manufacturing equipment.
Ability to handle multiple projects simultaneously at different CMOs.
Ability to travel globally, up to 30 % to CMOs for technical meetings, technology transfer, demonstration /engineering / exhibit batches.
Experience authoring, reviewing, and/or approving site technology documents such as tech transfer plans, risk assessments, validation protocols, reports, batch records, sampling protocols, CAPAs, change controls, procedures, policy and instructions, etc.
Experience collaborating with R & D colleagues for required process development and analytical support needed to address process issues and solutions.
Experience participating as needed in reviewing/authoring relevant regulatory and/or technical documents in support of implemented technologies or changes in the manufacturing process and evaluate the impact on the quality of the product
Requires understanding of scientific principles, operational aspects of production equipment, automation control systems, processing requirements and any related procedural requirements with emphasis on sterile injectable pharmaceutical dosage forms.
Experience participating in cross-functional teams in the evaluation and implementation of novel manufacturing technology and processes in commercial processes that increase process robustness and promote a culture of innovation and continuous improvement.
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information

Position is full-time, Monday - Friday 8:00am - 5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",-1,Eurofins USA PSS Insourcing Solutions,"Lake Forest, IL",-1,-1,-1,-1,-1,-1
Clinical Lab Scientist-Generalist,"$20-$32 Per Hour
(Glassdoor Est.)","Edward-Elmhurst Health includes three hospitals — Edward Hospital, Elmhurst Hospital, and Linden Oaks Behavioral Health — and an extensive ambulatory care network that provides comprehensive healthcare to residents of the west and southwest suburbs of Chicago. Edward-Elmhurst Health provides comprehensive healthcare at more than 60 locations in the suburbs of Chicago. Our success has always been — and always will be — driven by our most talented, reliable, compassionate and skilled people, who genuinely believe in delivering top quality care to our patients and their families. At Edward-Elmhurst Health, you will also experience a vibrant culture and an atmosphere of nurturing support and leadership.

Be DRIVEN to join our over 8,000 employees, 1,700 staff physicians and 1,800 volunteers who want to provide safe, seamless and personalized care every day for our patients, our families and our communities.

Job Summary: Performs various clinical laboratory tests in one or more sections of the Laboratory in order to obtain data for use in diagnosis and treatment of disease.

Hours: Full-time 6am -2:30pm various shifts during the week; Includes weekend and holiday rotations

Required:
Associate's degree in Medical Technology or Clinical Laboratory Science
Ability to accurately collect and analyze test results, and to perceive similarities and differences in color
Registration with the American Society of Clinical Pathology (ASCP), National Credentialing Agency (NCA) or equivalent
Preferred:
Bachelor’s Degree
*Benefits offered by Edward-Elmhurst Health include:
Medical, dental, and vision
401K
Tuition reimbursement
Paid time off
Fitness center membership
Plus many other Employee Perks",3.8,"Elmhurst Memorial Healthcare
3.8","Naperville, IL",5001 to 10000 Employees,-1,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable
Big Data Engineer,-1,"Our client, a premier investment bank, is looking for a Big Data Engineer to join their growing team in Chicago, IL.

Currently our client spends a lot of time trying to answer client's questions by logging in to several disparate data sources. It is estimated each support analyst spends about an hour every day answering client's questions. The goal of the project is to provide clients access to the data so they can access the data themselves.

Role to be played by the consultant/contractor:
Work with the business, understand and review technical requirements
Design and develop end to end solution
Ability to pick right technology for the execution of project
Profile
Hands on experience working with tools in Big Data ecosystem
Hands on experience in building Kafka streaming application in Java
Hands on experience in building Spark applications in Java or Scala
Hands on experience in working with NoSQL databases
Full stack Java developer
Hands on experience in building production applications using Node.js and React
Environment History of Project:
Cross Asset Query Tool – will bring low latency query capabilities to our Cross Asset data",-1,LiniumIT,"Chicago, IL",-1,-1,-1,-1,-1,-1
Big Data Engineer,-1,"Our client, a premier investment bank, is looking for a Big Data Engineer to join their growing team in Chicago, IL.

Currently our client spends a lot of time trying to answer client's questions by logging in to several disparate data sources. It is estimated each support analyst spends about an hour every day answering client's questions. The goal of the project is to provide clients access to the data so they can access the data themselves.

Role to be played by the consultant/contractor:
Work with the business, understand and review technical requirements
Design and develop end to end solution
Ability to pick right technology for the execution of project
Profile
Hands on experience working with tools in Big Data ecosystem
Hands on experience in building Kafka streaming application in Java
Hands on experience in building Spark applications in Java or Scala
Hands on experience in working with NoSQL databases
Full stack Java developer
Hands on experience in building production applications using Node.js and React
Environment History of Project:
Cross Asset Query Tool – will bring low latency query capabilities to our Cross Asset data",-1,LiniumIT,"Chicago, IL",-1,-1,-1,-1,-1,-1
"Senior Manager - Data Engineering- Hanover, MD, Washington DC Metro Area; Atlanta, GA; Chicago,IL; Denver Metro","$138K-$230K
(Glassdoor Est.)","Arcadis
is looking for people with a passion to drive and execute Digital to the core
of everything we do. We firmly believe in “Everything Digital, Digital
Everything”. We are transforming, we are reimagining the industry and we are
reimagining how communities and nations can help becoming more sustainable
places to live for today and future generations.

Technology
is the core and integral part of what we do, all the way for empowering
Arcadians to harnessing power of data and AI/ML for sensors, IIOT and Advanced
Drones, the technology teams are Dreaming Big and Delivering on future. As part
of our Technology drive, we are looking for on-board talented and passionate
people (Full Stack Engineers, Product Leaders, Cyber Experts, Data Buffs,
Architects) across multiple locations including India, Romania, parts of Europe
and North America.
As the Senior Manager of Data Engineering, you will be working with a full
range of data technologies and architecture for a rapidly growing data services
/ platform on Microsoft Azure. You will be responsible for designing, building
and operating the latest cloud-based data technologies from data ingestion to
consumption. As part of a core data leadership team, you will provide deep
technical subject matter expertise for successfully deploying large scale data
solutions in the enterprise, using modern data and analytics technologies. This
position will both lead and work collaboratively with business and technology
stakeholders to establish and maintain the enterprise data architecture,
strategy and roadmap
Design,
develop, and test cloud solutions leveraging tools including Data Lakes, Data
Cubes, and Data Warehouses.
Lead
design, development and maintenance of scalable data pipelines that will
ingest, transform, and distribute numerous data streams for both machine
learning applications as well as business reports (Oracle eBS / ERP and Oracle
Analytics Cloud) using Power Build high-capacity data analytics systems using
On Prem and cloud services for storing, collecting, and analyzing data.
Design and
implement the management, monitoring, security, and privacy of data using the
full stack of Azure data services to satisfy business needs
Ensuring
non-functional system characteristics such as such as security,
maintainability, quality, performance, and reliability are captured,
prioritized, and incorporated into products.
Developing
reusable software components and systems based on requirements, architecture
and design specifications and organizational policies and standards.
Collaborating
with other data engineers, scientists, software architects, software engineers,
quality engineers, and other team members to design and build solutions that
best fit the requirements.
Leverage
Agile, CI/CD and DevOps methodologies to deliver high quality product
on-time Expose data to end users using
Power BI, Azure API Apps or other modern visualization platforms like RStudio.
Demonstrated
experience building data lakes and data warehouses in Azure
Experience with large scale data extract and data load
using Microsoft SQL server and Azure.
Understanding and experience developing reporting and
analytics systems using ETL tools or business intelligence platforms such as
MicroStrategy or other tools.
Experience on the Databricks, HD Insight,
Pig/Kafka/Hive/Spark, MangoDB, CosmosDB and SQL Data Warehouse
Solid working experience in Azure, data lake, data
factory, and Data bricks.
Experience with cloud computing services and
infrastructure in the data space (e.g. Azure ADLS, HD Insight, Databricks,
etc.) and awareness of considerations for building scalable, distributed
systems.
Working knowledge of Python, R.
Experience with BI and reporting tools like PowerBI
and Tableau.
Exposure to machine learning, data science, computer
vision, artificial intelligence, statistics, and/or applied mathematics,
Experience with construction industry specific
concepts like BIM and GIS.
Self-motivated with the ability to prioritize, meet
deadlines, and manage changing priorities,
Excellent interpersonal, problem-solving skills with
the ability to work independently and in a team environment,
Ability to independently solve problems and accomplish
tasks in a logical, methodical, and time-efficient manner when given high-level
tasks or objectives.

Basic Requirements:

· Bachelor’s degree or higher in a science or
engineering discipline

· Minimum of seven 7 years of ETL experience in data
acquisition, modeling, extraction, processing, transforming, and/or loading in
a private, public, government or military environment

· Minimum of five 5 years of experience in design and
development of operational data stores, data warehouses, and/or data marts in a
private, public, government or military environment
Why Choose Arcadis?

Arcadis is the leading
global design and consulting firm for natural and built assets, and we invite
you to join us in partnering with our clients to deliver truly exceptional and
sustainable outcomes. Contribute to the world’s most high-profile and transformative
projects, from shopping centers in Shanghai and improved traffic flow in
Atlanta to state-of-the-art rail systems in Doha, coastal defenses for
Manhattan and cleaner air in Los Angeles. Work alongside the industry’s
foremost thought leaders and accomplished professionals, generating effective,
real-world results. We are Arcadis: 27,000 people in more than 70 countries,
creating value by applying our collective wisdom to every challenge. Our
culture is collaborative, we believe in diversity and the power of global
teamwork, and we own the responsibility to sustain the Earth and its people in
a safe and balanced way. Arcadis. Improving quality of life.

Every day, our
Environment, Water, and Infrastructure experts apply their strengths and
collaborate across disciplines and geographies to create exceptional and
sustainable outcomes for our clients. Members of the Arcadis Corporate Services
teams, apply emerging technologies, foster innovation, and work
collaboratively. We create solutions that enable Arcadians to deliver the best
customer experience in the industry and achieve our client’s goals. We
continuously develop our skills and capabilities with global learning
opportunities and workshops. Join us and start improving quality of life
for clients and communities across North America today!
EEO statement

We are an equal
opportunity and affirmative action employer. Women, minorities, people with
disabilities and veterans are strongly encouraged to apply. We are dedicated to
a policy of non-discrimination in employment on any basis including race,
creed, color, religion, national origin, sex, age, disability, marital status,
sexual orientation, gender identity, citizenship status, disability, veteran
status, or any other basis prohibited by law.",3.7,"Arcadis UK
3.7","Chicago, IL",1001 to 5000 Employees,-1,Company - Public,Construction,"Construction, Repair & Maintenance",Unknown / Non-Applicable
People Analytics Data Engineer (Talent Insights Consultant Lead),-1,"Your Talent. Our Vision. At Anthem, Inc., it’s a powerful combination, and the foundation upon which we’re creating greater access to care for our members, greater value for our customers, and greater health for our communities. Join us and together we will drive the future of health care.

This is an exceptional opportunity to do innovative work that means more to you and those we serve at one of America's leading health benefits companies and a Fortune Top 50 Company.

Do you love data? Do you enjoy the challenge of wrangling data and figuring out innovative data solutions to automate, combine, transform and model data? Then we’d love to talk to you about applying your skills to solve data challenges in on the Talent Insights team. This role is crucial to leveraging data (Inclusion & Diversity, Culture & Engagement, Productivity, Recognition, Performance, Talent, Attraction, Learning and Surveys) to develop strategy to attract, develop and retain Anthem’s workforce of the future.
People Analytics Data Engineer (Talent Insights Consultant Lead)

The preferred locations for this position are

Indianapolis, IN, Chicago, IL and Mason, OH

and is eligible for a remote schedule.
We are looking for a savvy Data Engineer to join our team of people analytics experts. The Data Engineer will be responsible for expanding our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing the HR data architecture to support critical people strategies that impact our associates and HR policies.

Responsibilities for People Analytics Data Engineer
Create and maintain optimal HR data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the HR data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using API, SQL and AWS technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with IT and HR stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Ensure associate and HR data is protected and secure.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Proven
ability to find innovative solutions to “figure things out.”
BA/BS
in computer science, business, math, industrial management/engineering or
related field.
Master’s
degree in related field preferred
10+
years of data collection and analysis experience; or any combination of
education and experience which would provide an equivalent background.
Advanced
knowledge of data tools including or similar to: SQL, Python, R, AWS, EC2, Redshift,
Alteryx, REST API, Java
Ability
to design and develop complex mappings, session, workflows, and identify areas
of optimizations.
A
successful history of manipulating, processing and extracting value from large
disconnected datasets.
Strong
analytic skills related to working with unstructured datasets.
Build
processes supporting data transformation, data structures, metadata, dependency
and workload management.
Strong
verbal/written communication, with ability to interact effectively with
individuals at all levels of responsibility and authority.
Strong
trouble-shooting and organizational skills and ability to work on multiple
projects simultaneously.
Strong
project management and organizational skills.
Experience
supporting and working with cross-functional teams in a dynamic environment.
Preferred
knowledge of HR processes and related data.
Preferred
knowledge of Peoplesoft, Oracle Analytics Cloud, Workday, Prism or similar HR
systems, business intelligence and analytics tools.
Anthem,
Inc. is ranked as one of America’s Most Admired Companies among health insurers
by Fortune magazine and is a 2018 Diversity Inc magazine Top 50 Company for
Diversity. To learn more about our company and apply, please visit us at
antheminc.com/careers. An Equal Opportunity Employer/Disability/Veteran",4.0,"Anthem Health Plans of Virginia
4.0","Chicago, IL",1001 to 5000 Employees,1935,Subsidiary or Business Segment,Insurance Carriers,Insurance,$1 to $2 billion (USD)
E15 Senior Data Engineer--REMOTE,"$72K-$131K
(Glassdoor Est.)","Posted Date: Aug 4, 2020

Position Title: TECH, ENGINEER SR

Pay GRADE 16

Reports To:

A family of companies and experiences

As the leading foodservice and support services company, Compass Group USA is known for our great people, great service and our great results. If youve been hungry and away from home, chances are youve tasted Compass Groups delicious food and experienced our outstanding service. Our 225,000 associates work in award-winning restaurants, corporate cafes, hospitals, schools, arenas, museums, and more in all 50 states. Our reach is constantly expanding to shape the industry and create new opportunities for innovation. Join the Compass family today!

great people. great services. great results.

Each and every individual plays a key role in the growth and legacy of our company. We know the next big idea can come from anyone. We encourage developing and attracting expertise that differentiates us as a company as we continue to raise the bar.

This position is eligible for an Employee Referral Bonus! If you know someone that is qualified for this role, please use the job search in MyOpportunity to refer your referral and email them a link to apply. Your referral will be able to apply by clicking the link in the email then you can check the status under Careers in MyOpportunity by clicking on referral tracking. For Employee Referral guidelines, FAQs and the Compass Employee Referral Policy, email MyReferral@compass-usa.com. Click here to view the step-by-step instructions to refer a friend to this position.
Job Summary
At E15, we are the spark that ignites. Our team delivers next-generation insights based on data, not hunches, to drive business in healthcare, campus, corporate, sports, entertainment, hospitality, and retail industries to help companies make forward-looking decisions to benefit their business and their guests. In this role, you'll have the opportunity to make code decisions and build cloud infrastructure and pipelines that will deliver data solutions to our Food and Beverage and Sports industry clients.

Responsibilities:
Collaborate with our reporting, analytics, and data science teams to understand data sources and business requirements
Work within a collaborative team, adhering to Agile best practices, documentation, and knowledge sharing
Gather, clean, enrich, and transform data through data pipelines using Python and the AWS stack
Monitor pipeline performance and document infrastructure changes
Adhere to best practices for ETL and programming
Contribute to our overall architecture and pipeline design and make contributions to the product roadmap
Experience:
3-5 years of programming experience, Python strongly preferred
Solid understanding of data structures
Strong skills with SQL with the ability to write efficient queries
Familiarity microservices and event driven architecture
Familiarity with AWS big data services: S3, Redshift, Glue, EC2, Lambda, SageMaker

Apply to Compass Group today!

Click here to Learn More about the Compass Story

Compass Group is an equal opportunity employer. At Compass, we are committed to treating all Applicants and Associates fairly based on their abilities, achievements, and experience without regard to race, national origin, sex, age, disability, veteran status, sexual orientation, gender identity, or any other classification protected by law.

Req ID: 413680

Compass Corporate

HUNTER VANDUSEN

SALARIED EXEMPT",3.7,"Compass Group USA
3.7","Chicago, IL",10000+ Employees,1994,Subsidiary or Business Segment,Catering & Food Service Contractors,"Restaurants, Bars & Food Services",$10+ billion (USD)
Principal Bioinformatics Scientist,"$60K-$74K
(Glassdoor Est.)","Passionate about precision medicine and advancing the healthcare industry?

Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.

We are looking for a highly motivated and capable bioinformatics team lead with extensive experience and interest in translational cancer research and genomics algorithm development. This position requires experience with scientific programming, relational data systems, algorithms development, and statistical modeling. Top candidates will also have leadership experience in NGS pipeline development in a clinical setting.

Responsibilities:
Design and conduct analysis to improve variant calling, classification and analysis systems.
Translate insight from model systems into predictors and classifiers of therapeutic response and prognosis in clinical cancer care.
Collaborate with scientists, and clinicians to design and perform analyses on cancer clinical sequencing data in order to improve quality of care.
Lead an interdisciplinary groups of scientists and engineers to translate research into clinically actionable insights for our clients.
Develop algorithms used to gain insight into cancer variation through analysis of next generation sequencing data
Communicate with outside scientific teams as well as product and bioinformatics leadership
Produce high quality and detailed documentation for all projects.
Required Experience:
Must have completed a Ph.D. in Cancer Biology or Molecular Biology related to cancer.
5+ years of post-doc experience
Computational skills using R, Bioconductor, and/or Python.
Ideal candidates will possess:
Experience in cancer genetics, immunology, or molecular biology
Experience working with next-generation sequencing data
Leadership experience in NGS pipeline development in a clinical setting.
Self-driven and works well in interdisciplinary teams
Experience leading a team of scientists or software engineers
Experience with communicating insights and presenting concepts to a diverse audience
Demonstrated programming ability
Background in predictive or prognostic algorithm development
Strong background in the development of statistical models",3.2,"Tempus Labs
3.2","Chicago, IL",501 to 1000 Employees,2015,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable
Big Data Architect,"$98K-$124K
(Glassdoor Est.)","Job Description:

Cogensia is a leader in data-driven marketing, named as one of the top 20 data integrators to watch and grow with; we are dedicated to driving marketing results through insight. We deliver insight and results to our clients through marketing expertise, technical and analytic capabilities, and our relentless focus on the customer. We partner with clients to drive lasting customer relationships and incremental brand revenue through integrated systems, online and offline CRM, real time predictive modeling, and data management.

The Big Data Architect’s primary responsibilities are to create and develop solution designs to integrate and ingest data from various resources, supporting Cogensia’s big data ecosystem.

They will be responsible for defining the big data architectural blueprint under the supervision and collaboration with the Technology Solutions Director. The Architect will work closely with data engineers, cloud engineers, and data scientists to design and implement optimum solutions using best practices. They are responsible to ensure the data ecosystem is built to be highly scalable, responsive, and available.

The Big Data Architect oversees the implementation of data solutions by working with Cogensia’s onshore and offshore engineering teams to create ETL, batch, real-time, and automated processes. They are part of the core Technology Solutions team and heavily contribute to the team’s coding and programming standards and ensure other team members are following the guidelines and standards. They have a high standard for the quality of code and documentation they themselves produce.

Responsibilities:
Take ownership of data solutions from design and architecture perspective for projects in presales phase as well as on-going projects
Select and integrate any Big Data tools and frameworks required to provide requested capabilities. Can oversee the implementation by team members of said solutions
Design and implement ETL and automated processes
Monitor performance and advise of any necessary improvements and changes
Management of EMR clusters, Glue Jobs, Athena Tables, S3 data lakes; with all included services
Provide technical support to members of TS and SA team, as well as project support across client engagements
Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value
Stays current with relevant technology in order to maintain and/or improve functionality for authored applications
Assume other responsibilities as requested/required
Acts as a subject matter expert for systems worked on. Ensures Cogensia’s data solutions are using the latest versions and code base
Actively listen to and work with end users to gather feedback and input, and make suggestions and solutions based on said feedback
Required Experience:
(7 years of relevant experience) or (5 years of relevant experience and an advanced degree in Computer Science/IT or related field)
Keen understanding of distributed computing principles
Proficiency with Big Data frameworks such as Hadoop, Spark, MapReduce, HDFS.
Proven experience ingesting data from multiple data sources such as REST API, SFTP flat files, Streaming data etc.
Proven experience with Big Data querying tools such as Athena/Presto, Pig, Hive, and Impala
Proven experience with NoSQL databases, such as HBase, Cassandra, Redshift, DynamoDB
Proven experience with various ETL techniques and frameworks, such as Flume, Glue Jobs, Step Functions
Proven experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O
Proven experience with AWS Lambda and leveraging it in various solutions such as Glue, Step Functions, CloudWatch, S3 Events, etc.
Strong experience with using Python scripts & libraries
Experience desired with Database Warehousing Design Concepts; Dimensional.
Modeling, Star/Snowflake Schemas, ETL/ELT, Data Marts, Analytic Playgrounds, Reporting techniques
Experience working with Agile software development methodologies, namely Scrum
Proven experience with team collaboration, release management, system and performance monitoring
Ability to work well with people from many different disciplines and varying degrees of technical experience
Excellent analytical, problem resolution, organization and time management skills
Ability to handle multiple tasks at a time
Demonstrated ability to have successfully completed multiple, complex technical projects and create high-level design and architecture of the solution, including class, sequence and deployment infrastructure diagrams
Prior experience with application delivery using an Onshore/Offshore model
Experience with gathering end user requirements and writing technical documentation
Keyword: Hadoop, Spark, MapReduce, HDFS, REST, API, SFTP, Athena, Pig, Hive, Impala, NoSQL, HBase, Cassandra, Reddrift, DynamoDB
From: Cogensia
Apply now",3.4,"Cogensia
3.4","Schaumburg, IL",1 to 50 Employees,2002,Company - Private,Advertising & Marketing,Business Services,$5 to $10 million (USD)
"Sr Data Scientist, Zoro","$120K-$150K
(Glassdoor Est.)","Company Summary:
Zoro.com is an eCommerce company that sells business supplies, equipment, and tools—but we’re much more than just a website. We’re a team of people who win and lose together (we prefer winning!). Since 2011, Zoro has been working hard to make it easy for our customers to purchase everything they need to make their businesses go. Zoro currently offers 3 million products, fast and free shipping, no-hassle returns, and exceptional customer service. We’ve grown quickly in a short time, recently surpassing 400 team members and reaching annual revenue of over $500 million. Add to that our award-winning culture—we were named a Great Place to Work for 2019-20, among other accolades—and we think Zoro is a pretty amazing place to work and grow.
Primary Function:
Our Sr. Data Scientists are key contributors to the development of Zoro’s customer, product, eCommerce, and pricing plans. The Data Science team covers a broad scope of projects including customer segmentation, A/B testing, marketing investment optimization, predictive modeling, promotion forecasting, and pricing analysis. We are closely integrated with our business leaders and support their ability to make critical decisions. At Zoro, you will be challenged by new questions every day.
Duties and Responsibilities:
Lead data science projects from beginning to end: develop and refine the idea, create a project plan and methodology, collaborate with business partners, execute, and provide recommendations for the company
Collaborate with other data scientists to develop and implement algorithms, write code, evaluate relevant academic research, and deliver outputs
Advise the company about tools, data sources, and best practices to facilitate digital marketing, pricing, and web analytics
Build predictive and inference models using Python and R to support business initiatives in the areas of customer acquisition, activation, engagement, retention, or channel investment optimization
Document code and data science processes that are critical to the company, and develop strategies to ensure those processes are robust and fault-tolerant
Communicate findings to business leaders and colleagues using data visualizations, presentations, and written means
Qualifications:
Experience leading data science projects that have a direct impact on company objectives
Demonstrated ability to assist business decision-making through data mining and machine learning
Strong communication skills to collaborate effectively with business stakeholders. Must be able to interact cross-functionally and drive both business and technical discussions
5+ years’ progressive business experience in areas including marketing analytics, database marketing, data mining, or statistical modeling. Experience using data science or advanced analytics in an Internet retailer or a top-tier consumer-focused company is required
Ability to translate complex business problems into project plans and solve them by analyzing large amounts of data
Familiarity with Python or R for statistical modeling, clustering, classification, machine learning, and data mining
Demonstrated proficiency in SQL and cloud-hosted data platforms (Google Cloud Platform, AWS, etc)
Familiarity with BI tools such as Tableau or Looker, and ability to communicate results to business partners
Master’s degree preferred in quantitative fields such as Statistics, Engineering, Operational Research, or Economics
Knowledge of web tracking technology and web analytics tools (Google Analytics, Adobe Analytics, etc.) a definite plus

Final note: We share a commitment to our Zoro values – Win & Lose Together (We prefer winning!), Take Ownership, We Are Transparent, and Aspire to be Customer-Obsessed. Everything we do at Zoro is centered around delighting our customers. It's a natural extension of our company culture and how we care for each other. We believe when we act in ways that are consistent with these values, we can solve any technical challenge that lies ahead of us. As a Zoro employee, you can expect to work with smart, energetic people, learn something every day, and be valued for your perspective.

Zoro is an Equal Opportunity Workplace and an Affirmative Action Employer.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.",2.0,"Zoro Tools
2.0","Buffalo Grove, IL",Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD)
Senior Data Engineer,-1,"Data Engineering is the foundational layer of our Data & Analytics stack at Arrive. Data Engineers not only build and optimize data pipelines that transform and store data in a way that allows the rest of the organization (analysts, data scientists, other stakeholders) analyze and consume data. They are also in charge of building the systems and establishing the processes to enable the rest of the data team to develop, test, and deploy analyses and code in an efficient and scalable way.

We’re looking for a Senior Data Engineer to lead the scale and execution of our data infrastructure and platform. If you're seeking a role that is high impact and full of ownership....please read on.
What you'll tackle
Design new enterprise data models and ETL processes to populate them
Extract and transform data from production databases and 3rd party services to provide consumable data and support functions across the organization
Detect quality issues, track them to their root source, and implement fixes and preventative audits
Manage and optimize Redshift clusters/data lake to ensure current health and performance and future scaling needs
Help maintain the process we use to develop, test, and deploy good code
Become the “go to” expert of our data. Work closely with staff to understand all data from our core systems, partner services, and any other platforms we rely on
What you bring to the table
Experience with AWS; expertise in Redshift, Postgres or other RDBSs (preferably column-oriented)
Expertise in SQL and ability to write and optimize complex queries
Experience with Docker, Elastic Container Service, Lambda a plus
Ability to write customized software in Python, Bash, Go or other common open source languages. Experience with Airflow or similar scheduling service a plus
Experience with CI/CD tools like Jenkins or Drone
Creativity in approaching data organization challenges with an understanding of the end goal
A collaborative nature and entrepreneurial spirit. Prior startup experience a huge plus",-1,Arrive,"Chicago, IL",Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD)
Senior Market Data Engineer,"$109K-$123K
(Glassdoor Est.)","Job title: Senior Market Data Engineer
Job type: Permanent
Emp type: Full-time
Salary:
Negotiable
Location: Chicago, United States
Job published: 2020-01-10
Job ID: 41638

Job Description


Our client is looking for a Senior Market Data Engineer to join their Chicago office. In this dynamic role, you will work on systems and libraries that enable developers to build trading tools and order execution systems.

Responsibilities:
Building market data and distribution systems, specifically for stock and option market data feeds and high-throughput, low latency systems.
Participating in technical discussions and set technical vision on projects.
Working effectively in a fast-paced, constantly changing environment.
Building high quality, maintainable, readable code.
Thinking on your feet to support mission-critical production systems.
Getting the answers you need to solve a problem from Google, finding the right person to ask, or digging deep technically
Mentoring junior developers.
Learning new languages and technologies while continuously evolving your skill set.


Requirements:
Experience with C++
Good knowledge of data structures
Strong experience and knowledge of network programming required - TCP, UDP, and multicast, and other protocols
Experience with Linux
Strong experience and knowledge of systems programming
Experience building robust, fault-tolerant systems
Experience with multi-threaded programming
Experience with Go, Java, or Python preferred
Experience working with distributed systems strongly preferred
Experience with low-latency and high-throughput market data systems strongly preferred
Experience with financial markets and stock and option exchange feeds strongly preferred
Experience with binary and FIX connectivity protocols strongly preferred
Education:
A Bachelor’s degree in Computer Science or related field
If you would like to be considered for the position of Senior Market Data Engineer or wish to discuss the role further then please leave your details below. Your resume will be held in confidence until you connect with a member of our team",4.2,"NJF Global Holdings
4.2","Chicago, IL",51 to 200 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (USD)
Senior Data Engineer,"$67K-$129K
(Glassdoor Est.)","Join SADA as a Sr. Data Engineer!

Your Mission

As a Sr. Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data problems facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring batch or streaming data pipelines, data lakes and data warehouses.

You will be expected to run point on whole projects, end-to-end, and to mentor less experienced Data Engineers. You will be recognized as an expert within the team and will build a reputation with Google and our customers. You will demonstrate repeated delivery of project architectures and critical components that other engineers demur to you for lack of expertise. You will also participate in early-stage opportunity qualification calls, as well as lead client-facing technical discussions for established projects.

Pathway to Success

#BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage agility. This means that not only do our engineers know that change is inevitable, but they embrace this change to continuously expand their skills, preparing for future customer needs.

Your success starts by positively impacting the direction of a fast-growing practice with vision and passion. You will be measured quarterly by the breadth, magnitude, and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, how well you collaborate with your peers, and the consultative polish you bring to customer interactions.

As you continue to execute successfully, we will build a customized development plan together that leads you through the engineering or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events. Due to the COVID-19 pandemic, travel has been temporarily restricted.

Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.

Training - Ongoing with first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:
Google Professional Data Engineer Certified or able to complete within the first 45 days of employment
Required Qualifications:
Mastery in at least one of the following domain areas:
Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Experience writing software in one or more languages such as Python, Java, Scala, or Go
Experience building production-grade data solutions (relational and NoSQL)
Experience with systems monitoring/alerting, capacity planning and performance tuning
Experience in technical consulting or customer-facing role
Useful Qualifications:
Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)
Experience with IoT architectures and building real-time data streaming pipelines
Experience operationalizing machine learning models on large datasets
Demonstrated leadership and self-direction -- a willingness to teach others and learn new techniques
Demonstrated skills in selecting the right statistical tools given a data analysis problem
About SADA

Values: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA's values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.
Make them rave
Be data driven
Be one step ahead
Be a change agent
Do the right thing
Work with the best: SADA has been the largest partner in North America for GCP since 2016 and has been named the 2019 and 2018 Google Cloud Global Partner of the Year. SADA has also been awarded Best Place to Work by Inc. as well as LA Business Journal!

Benefits: Unlimited PTO, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match, professional development reimbursement program as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core:3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.",4.8,"SADA
4.8","Chicago, IL",201 to 500 Employees,2000,Company - Private,IT Services,Information Technology,$100 to $500 million (USD)
Principal Data Engineer,"$83K-$156K
(Glassdoor Est.)","Discover. A brighter future.

With Discover, you’ll have the chance to make a difference at one of the world’s leading digital banking and payments companies. From Day 1, you’ll do meaningful work you’re passionate about, with the support and resources you need for success. We value what makes each employee unique and provide a collaborative, team-based culture that gives everyone an opportunity to shine. Be the reason millions of people find a brighter financial future, while building the future you want, here at Discover.

Job Description


Discover Financial Services is seeking a Principal Data Engineer to join our Enterprise Technology organization. Successful candidates will partner with our business partners to understand their reporting & data needs, design and help the team build pipelines using Next-Gen tools & new capabilities. Additionally you will be responsible to achieve operational excellence and efficient ways to manage projects and Production support. The ideal candidate will be passionate about Discover Financial Service’s data and its mission.

***THIS ROLE HAS THE OPPORTUNITY TO WORK 100% REMOTE FROM HOME***

Responsibilities:
Provide senior-level technical consulting to peer & junior engineers during design and development for highly complex and critical data projects.
Provide engineering leadership to create and enhance data solutions enabling seamless integration and flow of data across the data ecosystem.
Design and develop data ingestion frameworks leveraging Open-Source tools such as NiFi, Kafka, Java, Pig, Spark, Python, as well as data processing/transformation frameworks leveraging Open-Source tools.
Building / Prototyping micro services based designs & solutions within the ETL data pipeline on Container Platforms (e.g Kubernetes & Open Shift)
Well verse with AWS, Cloud Platforms and experience on hybrid cloud data strategy solutions along with experience working with / in Data Warehouse teams that solve big data problems and challenges.
Create POC's of new ideas, scale them into Generic Patterns, and able to drive the team with technology thought leadership, bring in new ideas and bringing the engineering culture.
Provide support for deployed data applications and analytical models.
Working or conceptual knowledge of Ab Initio / ETL technologies, MPP Databases, Stream Data Platforms with knowledge on Qlik Replicate, Kafka, K-SQL
Develops and maintains complex front-ends with a focus on user experience
Develops and maintains backend systems
Uses holistic knowledge of all products in the team’s ecosystem to plan how new systems will be built and integrated
Innovates on and advocates for best practices and improved processes within the team and with internal partners; stays up to date with technology trends and innovations; mentors team members
Creates and maintains DevOps processes, application infrastructure, and utilizes cloud services (including database systems and models)
Supports live systems to ensure business continuity
Required Skills:
Bachelors degree in Information Technology, or related field
Minimum 8+ years of work experience in Information Technology, Computer Science, or equivalent work experience
In lieu of education experience, 10+ years of work experience in Information Technology, Computer Science, or equivalent work experience
Desired Skills:
AWS / Cloud / Data Warehouse Certification a big plus
Self-starter, Engineering Mindset, Innovator & Individual Contributor, Bring ideas to whiteboard and adopt with an agile mindset.
Bonus, if the candidates are experienced with Customers, Contact Preferences, Marketing and Financial domains.
#LI-KE

What are you waiting for? Apply today!

The same way we treat our employees is how we treat all applicants – with respect. Discover Financial Services is an equal opportunity employer (EEO is the law). We thrive on diversity & inclusion. You will be treated fairly throughout our recruiting process and without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status in consideration for a career at Discover.",3.9,"Discover
3.9","Riverwoods, IL",10000+ Employees,1985,Company - Public,Financial Transaction Processing,Finance,$5 to $10 billion (USD)
Azure Data Modeler,"$50K-$88K
(Glassdoor Est.)","Description

Great opportunity to show off your passion for data, reporting, analytics and data warehousing. Medline's BI team may have the perfect fit for you!

We are looking for a self-motivated Data modeler/Engineer to join our business intelligence team.

This individual will be responsible for developing and maintaining business intelligence, data warehousing and data engineering solutions for Enterprise data This individual will also create and maintain detailed business requirements, outlining data problems, opportunities and solutions.

Responsibilities include:
Responsible for designing relational and non-relational data stores on Azure.
Responsible for designing and developing solutions in Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, SQL Data Warehouse, HDInsight.
Gather and process raw data at scale that meet functional / non-functional business requirements (including writing scripts, REST API calls, SQL Queries, etc.)
Responsible for developing data set processes for data modeling, mining and production.
Responsible for building new Data Lake in Azure, expanding and optimizing our data platform and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
Responsible for supporting our Software Developers, Data Analysts and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Develop complex SQL queries in TIBCO Data Virtualization tool.
Qualifications
3+ Years of experience architecting and building Data Lake, Azure Big Data architecture, Enterprise Analytics Solutions, and optimizing ' big data' data pipelines, architectures and data sets.
Bachelor’s Degree in Computer Science, Information Systems, or related field
Advanced hands-on SQL, USQL, Python, C#, Java, pySpark (2+ of these) knowledge and experience working with relational databases for data querying and retrieval.
Experience with Design and Architecture of Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure ML, SQL Data Warehouse, HDInsight.
Experience with building processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience working with cross-functional teams in a dynamic environment.
Experience building Big data pipeline with Java and/or Python a plus.
Strong SQL skills on multiple platform
Data Modeling tools (e.g. Erwin, Visio) knowledge a plus.
Experience with SAP HANA a plus.
Experience with Talend a plus.",3.4,"Medline Industries
3.4","Northfield, IL",10000+ Employees,1966,Company - Private,Health Care Products Manufacturing,Manufacturing,$10+ billion (USD)
E15 Senior Data Engineer--REMOTE,"$75K-$136K
(Glassdoor Est.)","Position Title: TECH, ENGINEER SR

Pay GRADE 16

Reports To:

A family of companies and experiences

As the leading foodservice and support services company, Compass Group USA is known for our great people, great service and our great results. If you’ve been hungry and away from home, chances are you’ve tasted Compass Group’s delicious food and experienced our outstanding service. Our 225,000 associates work in award-winning restaurants, corporate cafes, hospitals, schools, arenas, museums, and more in all 50 states. Our reach is constantly expanding to shape the industry and create new opportunities for innovation. Join the Compass family today!

great people. great services. great results.

Each and every individual plays a key role in the growth and legacy of our company. We know the next big idea can come from anyone. We encourage developing and attracting expertise that differentiates us as a company as we continue to raise the bar.

This position is eligible for an Employee Referral Bonus! If you know someone that is qualified for this role, please use the ‘job search’ in MyOpportunity to refer your referral and email them a link to apply. Your referral will be able to apply by clicking the link in the email then you can check the status under Careers in MyOpportunity by clicking on ‘referral tracking.’ For Employee Referral guidelines, FAQs and the Compass Employee Referral Policy, email MyReferral@compass-usa.com. Click here to view the step-by-step instructions to refer a friend to this position.
Job Summary
At E15, we are the spark that ignites. Our team delivers next-generation insights based on data, not hunches, to drive business in healthcare, campus, corporate, sports, entertainment, hospitality, and retail industries to help companies make forward-looking decisions to benefit their business and their guests. In this role, you'll have the opportunity to make code decisions and build cloud infrastructure and pipelines that will deliver data solutions to our Food and Beverage and Sports industry clients.

Responsibilities:
Collaborate with our reporting, analytics, and data science teams to understand data sources and business requirements
Work within a collaborative team, adhering to Agile best practices, documentation, and knowledge sharing
Gather, clean, enrich, and transform data through data pipelines using Python and the AWS stack
Monitor pipeline performance and document infrastructure changes
Adhere to best practices for ETL and programming
Contribute to our overall architecture and pipeline design and make contributions to the product roadmap
Experience:
3-5 years of programming experience, Python strongly preferred
Solid understanding of data structures
Strong skills with SQL with the ability to write efficient queries
Familiarity microservices and event driven architecture
Familiarity with AWS big data services: S3, Redshift, Glue, EC2, Lambda, SageMaker

Apply to Compass Group today!

Click here to Learn More about the Compass Story

Compass Group is an equal opportunity employer. At Compass, we are committed to treating all Applicants and Associates fairly based on their abilities, achievements, and experience without regard to race, national origin, sex, age, disability, veteran status, sexual orientation, gender identity, or any other classification protected by law.

Req ID: 413680

Compass Corporate

HUNTER VANDUSEN

SALARIED EXEMPT",3.4,"Compass Group
3.4","Chicago, IL",10000+ Employees,1941,Company - Public,Catering & Food Service Contractors,"Restaurants, Bars & Food Services",$10+ billion (USD)
Sr. Data Engineer,"$90K-$158K
(Glassdoor Est.)","The Opportunity:

As a Senior Data Engineer, you will maintain a holistic view of the Vivid Seats data architecture with an understanding of how it relates to the systems that depend upon it. Youll partner with engineering teams to create data models and assist in designing our transactional data stores. This includes designing and building data systems and automated processes for our underlying cloud infrastructure and deployment pipelines. Youll mature operational stability of the data platform through best practices, automation and monitoring while staying up to date on new and emerging technologies, planning accordingly to incorporate valuable concepts to enhance our data schema and capabilities.

To be successful, youll need:
Expert knowledge of a relational database platform such as MySQL, Postgres, Oracle or SQL Server
Experience in either modeling transaction or data warehousing with an interest in learning both methodologies
ETL pipeline and tooling experience
Coding and scripting experience using Java, Python or Bash
Proficiency in working in a Linux environment
Cloud experience with either GCP, AWS or Azure and experience running data platforms within a cloud environment
A willingness to participating in an on-call rotation
Additional Experience of Interest:
Experience with configuration as code tools such as Ansible, Terraform etc.
Experience with containerization such as Docker
Experience with continuous integration, testing, and deployment using tools such as Jenkins
What We Offer:

Vivid Seats is the largest independent online ticket marketplace, sending tens of millions of fans to live events. Experiences Matter - which is why we continue to grow year over year. Working at Vivid Seats puts you front and center at the opportunity to scale our best in class platform that allows our fans to sit closer and experience more.

At Vivid Seats, you will have the opportunity to work with the flexibility and speed of a startup; while operating at massive, profitable scale. We keep our teams lean, allowing each employee direct accountability of creating a positive ticket buying experience. We are relentless and move quickly to release new features and content to our applications. Good ideas are heard and implemented, and hard work rewarded. Being a part of our team means having the ability to drive impact and own the innovation that connects our tens of millions of unique monthly users to the memorable experiences that only live events create.

We are passionate about creating memorable experiences for our fans and the best in class experience for our employees. Vivid Seats offers competitive compensation levels, individual and team-based bonus opportunities, 401K matching, a generous benefits package and Flex PTO policy plus a variety of workplace perks.

Location:

111 N Canal Suite #800
Chicago, IL 60606

This position will start remotely.",2.8,"Vivid Seats
2.8","Chicago, IL",201 to 500 Employees,2001,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable
Lead Computational Scientist,-1,"Lead Computational Scientist
If you are a Lead Computational Scientist with experience, please read on!

What You Will Be Doing
Design MEMS devices and characterize the electrical, mechanical, and thermal performance
Extend and enhance the automated infrastructure for MEMS design, data collection and analysis
Design, run, and analyze experiments to understand device physics, materials and fabrication
Interface with local and overseas vendors
Work in cross-functional Engineering teams, including Circuits, Systems, and Packaging
Drive and/or support other projects as needed

What You Need for this Position
PhD in Mechanical Engineering, Electrical Engineering, Physics or equivalent
Experience designing and conducting lab experiments preferred
RF measurement experience preferred
Proficient coder. MATLAB and measurement automation experience preferred.
Printed circuit board design experience and oscillator fundamentals preferred
Finite Element Simulation experience preferred
Desired Characteristics & Attributes:
Strong organizational skills
Excellent critical thinking, ability to design experiments, and interpret results
Clear and concise scientific communication
Ability to work well with others in a collaborative fast-paced team environment
So, if you are a Lead Computational Scientist with experience, please apply today!
Applicants must be authorized to work in the U.S.

CyberCoders, Inc is proud to be an Equal Opportunity Employer
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",4.2,"CyberCoders
4.2","Chicago, IL",201 to 500 Employees,1999,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Data Science Lead Consultant,"$96K-$152K
(Glassdoor Est.)","Where good people build rewarding careers.
Think that working in the insurance field can’t be exciting, rewarding and challenging? Think again. You’ll help us reinvent protection and retirement to improve customers’ lives. We’ll help you make an impact with our training and mentoring offerings. Here, you’ll have the opportunity to expand and apply your skills in ways you never thought possible. And you’ll have fun doing it. Join a company of individuals with hopes, plans and passions, all using and developing our talents for good, at work and in life. Job Description
Allstate is seeking to hire a Data Science Lead Consultant to join our Innovation team at our downtown Chicago location. Allstate’s Innovation Team is at the forefront of change and growth within the company, driving the creation of standalone businesses or reinvention of existing ones. Innovation projects typically include cross-functional team members within Business Strategy, Product, Technology, Design, and Go to Market functions, who use data-driven prototypes and testing to achieve desired business outcomes. The team is seeking to augment its analytics capabilities further by growing a small team of predictive analytics researchers and data engineers with a Senior Data Scientist position. Past projects in the team have included the development of a new consumer “digital footprint” technology , announced at CES 2019, and new approaches to risk prediction for traditional insurance products.

The Data Science Lead Consultant will develop advanced predictive models and exploratory data analyses that will unveil key data insights leveraging both structured and unstructured data. This role will work closely with Data Engineering and the business team to determine what data insights need to be derived and the problem statement that should guide the analysis in order to solve business problems. This individual will be a key communicator of analytical results and insights to various stakeholders across and outside the company. This will require an advanced understanding of which data visualizations and techniques will be most effective in communicating insights to the business team. The Data Science Lead Consultant will be required to drive all analytics efforts supporting the product development lifecycle. Job Qualifications
Bachelor’s degree in a quantitative or technical field such as mathematics, statistics, computer science, or engineering with 8 or more years of experience in a data science and/or predictive analytics role OR -
A Masters or Ph.D. degree in a relevant discipline with 3 or more years of experience in a data science and/or predictive analytics role (Masters or Ph.D. strongly preferred).
Ability to independently develop advanced statistical and machine learning models using a variety of techniques (e.g. GLM, Neural Networks, Tree-based learning methods).
Comfortable bringing new ideas to the team and assessing their benefits over currently used methodologies.
Ability to identify the appropriate modeling technique given a problem statement based on the availability, variety, and quality of data.
Ability to identify and define a problem statement given a business problem.
Expert level knowledge in one or more languages commonly used in data analytics (Python, R, Java, Scala, etc.). Python / R proficiency is strongly preferred.
Expert level knowledge in SQL and database management, both relational and big-data platforms.
Experience visualizing complex data insights using ggplot2 in R or seaborn/matplotlib in Python.
Experience in managing, validating, and manipulating large, complex datasets.
Strong ability to communicate complex analyses and concepts to non-technical audiences within and outside of the organization.
Comfortable performing independent research to support analytics decisions as part of the product lifecycle.
Past experience in insurance industry and other related risk prediction efforts highly desirable.
The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.

Good Work. Good Life. Good Hands®.

As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.

Learn more about life at Allstate. Connect with us on Twitter , Facebook , Instagram and LinkedIn or watch a video .

Allstate generally does not sponsor individuals for employment-based visas for this position.

Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.

For jobs in San Francisco, please click “ here ” for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click “ here ” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.

To view the “EEO is the Law” poster click “ here ”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs

To view the FMLA poster, click “ here ”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.

It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.",3.4,"Allstate
3.4","Chicago, IL",10000+ Employees,1931,Company - Public,Insurance Agencies & Brokerages,Insurance,$10+ billion (USD)
BHJOB15656_15057 – Data Engineer,-1,"The recruitment team at Myticas Consulting Consulting is looking for an experienced Data Engineer who would be interested in a contract to hire opportunity within the Elmhurst, Illinois region.

Plenty of perks and benefits included upon hire.

Must be an American Citizen

Requirements:

5+ years of experience working with enterprise data platforms, building and managing data lakes and using big data technologies
2+ years of experience with Spark using Python/Scala. Experience with Spark streaming, building real time data pipelines is preferred
2+ years of experience working with AWS platform. Experience with solutioning on AWS infrastructure using services like AWS S3, Lambda, EMR, Redshift (or Snowflake)
Experience with automating and orchestrating jobs on a big data platform using Oozie, Airflow, Jenkins or something similar
Good understanding and experience working with various products in the Big data ecosystem like Hive, HDFS, Presto, NoSQL databases like Cassandra, DynamoDB
Experience with setting up and using Kafka for real time streaming is a big plus
Has to be a team player and open to working with newer technologies as well as supporting legacy systems
Prior experience with working in a SQL server based environment and using SSIS, SSRS, TSQL is a plus.
Prior experience with traditional ETL tools like Talend Open Studio, Pentaho or something similar is a plus

Job is also known as: Data Engineer

INDMY",5.0,"Myticas Consulting
5.0","Chicago, IL",1 to 50 Employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable
Building Scientist,"$52K-$110K
(Glassdoor Est.)","Position Description

Collaborates with a multidisciplinary team in the development of fundamental building science, building-to-grid integration, and urban science. Innovates in the development and deployment of physics-based and data analytic tools and technologies for building systems, whole buildings, energy systems, and urban systems. Communicates impactful research outcomes through internal reports, peer-reviewed publications, and conference presentations.

The candidate is expected to have a strong engineering background with demonstrated experience in building science and building energy modeling, especially in uncertainty quantification.

Position Requirements
PhD in architecture, architectural engineering, or mechanical engineering. Research experience in building science and building energy modeling. Postdoctoral or industry experience required.
Experience with building energy modeling using EnergyPlus and/or OpenStudio
Knowledge of conventional and emerging building modeling tools and techniques.
Knowledge of fundamental building sciences.
Experience with building energy modeling tools other than EnergyPlus/OpenStudio
Experience with uncertainty quantification of system models
Experience in working with multidisciplinary research teams.
Experience with modern scientific computing methods for large scale simulations on high performance computing infrastructure for building energy modeling and uncertainty quantification.
Experience in establishing research collaborations
Excellent oral and written communication skills.
Ability to think strategically and work independently.
Experience supervising research work
Experience with developing machine learning and data-analytic tools.
Knowledge of relevant DOE Office funding mechanisms and strategic outlook.
A successful candidate must have the ability to model Argonne’s Core Values: Impact, Safety, Respect, Integrity, and Teamwork
As an equal employment opportunity and affirmative action employer, and in accordance with our core values of impact, safety, respect, integrity and teamwork, Argonne National Laboratory is committed to a diverse and inclusive workplace that fosters collaborative scientific discovery and innovation. In support of this commitment, Argonne encourages minorities, women, veterans and individuals with disabilities to apply for employment. Argonne considers all qualified applicants for employment without regard to age, ancestry, citizenship status, color, disability, gender, gender identity, genetic information, marital status, national origin, pregnancy, race, religion, sexual orientation, veteran status or any other characteristic protected by law.

Argonne employees, and certain guest researchers and contractors, are subject to particular restrictions related to participation in Foreign Government Talent Recruitment Programs, as defined and detailed in United States Department of Energy Order 486.1. You will be asked to disclose any such participation in the application phase for review by Argonne’s Legal Department.
Back to top",4.5,"Argonne National Laboratory
4.5","Lemont, IL",1001 to 5000 Employees,1946,Nonprofit Organization,Federal Agencies,Government,Unknown / Non-Applicable
Sr. Scientist III,"$69K-$138K
(Glassdoor Est.)","Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 103,000 colleagues serve people in more than 160 countries.

Senior Scientist III

Diagnostic testing is a compass, providing information that helps in the prevention, diagnosis and treatment of a range of health conditions.

Abbotts life-changing tests and diagnostic tools give you accurate, timely information to better manage your health. Were empowering smarter medical and economic decision making to help transform the way people manage their health at all stages of life. Every day, more than 10 million tests are run on Abbotts diagnostics instruments, providing lab results for millions of people.

Position Overview:
Conceives, plans, designs, and conducts advanced independent research.
Investigates and develops new procedures.
Direction provided by project goals and experimental design.
May act as project leader, lead scientist, or independent reviewer.
Provides technical direction and feedback to others.
Interacts with other groups and shares information; participates in team
Position Responsibilities:
Defines project goals and is responsible for timely project completion.
Responsible for own Redbook documentation, and for the accuracy, quality, and timeliness of experimental results.
Summarizes data and analyzes results, independently formulates conclusions, and determines future experiments.
Actively participates in routine maintenance, lab safety; may assume roles of responsibility, such as training or document control.


Position Accountabilities
Responsible for implementing and maintaining the effectiveness of the quality system.
Understands and consistently follows documented procedures.
Determines priorities for experiments.
Applies quantitative methods: analyzes data, evaluates results, forms
conclusions, and provides/implements process or document improvements.
Independently designs and executes a series of experiments to test hypotheses related to project outcomes.
Applies advance scientific knowledge to projects.
Utilizes DOE where appropriate.
May assist in the design of experiments for others.
Identifies technical alternatives from literature review.
Applies basic computer skills (includes word processing, spreadsheets, instrumentation-related and Abbott network systems).
Produces reports and documents utilizing advanced writing skills.
Utilizes multiple analytical instruments; trains others in their operation.
Recognizes and resolves technical problems.
Education/ Skills/ Experience:
Knowledge of regulations and standards affecting IVDs and Biologics.
Ph.D. in a life or physical science with 2+ years research or industrial Or B.S./M.S. degree with research experience sufficient to demonstrate
Prepares results of projects internally and may present externally.
Reviews, evaluates, and critiques presentations for others.
Presents complex technical data to large and diverse groups.
Trains others on the theoretical and practical basis of techniques, processes and assays.
Participates in project planning, updates, and process improvements.
May generate new product ideas consistent with division strategy.
Prepares and aligns goals with manager's goals.
May coach lower-level scientists (e.g., presentation skills, negotiation skills, decision-making, and contingency planning).
Influences decision-making through negotiation, addressing conflict, and by
building (productive) working relationships across functional areas.
WHAT WE OFFER

At Abbott, you can have a good job that can grow into a great career. We offer:
Training and career development, with on-boarding programs for new employees and tuition assistance
Financial security through competitive compensation, incentives and retirement plans
Health care and well-being programs including medical, dental, vision, wellness and occupational health programs
Paid time off
401(k) retirement savings with a generous company match
The stability of a company with a record of strong financial performance and history of being actively involved in local communities
Learn more about our benefits that add real value to your life to help you live fully: www.abbottbenefits.com

Follow your career aspirations to Abbott for diverse opportunities with a company that provides the growth and strength to build your future. Abbott is an Equal Opportunity Employer, committed to employee diversity.

Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.",3.6,"Abbott Laboratories
3.6","Des Plaines, IL",10000+ Employees,1888,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
Lead Software Data Engineer - Full Stack,"$93K-$175K
(Glassdoor Est.)","Discover. A brighter future.

With Discover, you’ll have the chance to make a difference at one of the world’s leading digital banking and payments companies. From Day 1, you’ll do meaningful work you’re passionate about, with the support and resources you need for success. We value what makes each employee unique and provide a collaborative, team-based culture that gives everyone an opportunity to shine. Be the reason millions of people find a brighter financial future, while building the future you want, here at Discover.

Job Description


Develops and maintains full stack solutions to fit business needs. Full stack solutions require one or more of the following: front-end (user interfaces), back-end (APIs), database and DevOps development. Works directly with business partners to understand business requirements. Works independently or with own team to innovate on and advocate for best practices within the team. Designs complex solutions and leads them from inception to production within the agile team.

Responsible for working with data asset-related technology that has been approved by the architecture organization to move, transform, and validate data between systems, both internal to Discover Financial Services and with external data sources that provide value to Discover Financial Services. Responsible for writing extract, transform, and load (ETL) scripts, data maps, or integration programs to capture data from source systems and to transform it and load it into a destination system to enable data mining, business intelligence (BI) capabilities for the organization. Translates business functional detailed design requirements into technical solutions through the design, development, integration, and testing (unit and system) of ETL solutions.

The Lead position also participates in data solution design, strategy, including resolving strategic data integration issues, such as data quality and stewardship, real time or event-based data integration, and crafting a vision for data integration working with the architecture organization. The Lead position leads the technical design, development, integration, and testing efforts for ETL to create quality solutions that meet the business requirements. Other responsibilities include: mentoring other Data Engineers, preparing detailed and creating technical design plans.

What You’ll Do
Develops and maintains complex front-ends with a focus on user experience
Develops and maintains backend systems
Works with key stakeholders to design complex solutions and lead from inception top production
Creates and maintains DevOps processes, application infrastructure, and utilizes cloud services (including database systems and models)
Innovates on and advocates for best practices and improved team processes; mentors junior team members
Supports live systems to ensure business continuity
Lead data technology strategy, including resolving strategic data integration issues, such as data quality and stewardship, real time, event-based data integration, and crafting a universal vision for data integration, plan and document succession planning within scope of responsibility
Design, develop, test, and implement data-driven solutions to meet business requirements
Perform the technical design, development, integration, and testing efforts for data using various development languages and tools to create quality solutions that meet the business requirements
Lead code review sessions & create technical design plans/STTs
Optimize the performance of ETL processes and scripts by working with other technical staff as needed and document data solution and processes
Qualifications You’ll Need

Skills Required
Bachelor’s degree in information technology
6+ years of experience in Computer Science, Information Technology, or related experience
In lieu of degree, 8+ years of experience in computer science, information technology or related field
Skills Desired
6 or more years of work experience in BI lifecycle, from strategy to ETL to report implementation
Experience in an Agile-based environment
Big Data stacks/ecosystem including Kafka, Python, Spark, NoSQL
Expertise in the concepts, technology, and practices of building data solutions
Expertise with open-source, ETL scripting and processes and related tools
Expertise with the design and development of ETL data integration solutions
Expertise with relational databases and experience with Cloud-based technologies
Expertise in enabling business intelligence solutions through data integration
Demonstrated experience with integration technologies and how to leverage them into data mapping between systems
Demonstrated experience with transforming business needs into data design and solutions
Extensive experience with writing and performance-tuning complex SQL queries
Experience in agile process and technology
Experience with Ab Initio or other ETL tools and components
Experience with the following database and Cloud-based technologies:
Snowflake
Teradata technologies or similar
Python, Spark
Knowledge with AWS, Snowflake and other Cloud-related technologies is a plus
Strong team player with willingness to collaborate
Strong analytical and problem solving skills
Strong capability to execute tasks with quality
Strong communication and decision-making skills #LI-BG1
What are you waiting for? Apply today!

The same way we treat our employees is how we treat all applicants – with respect. Discover Financial Services is an equal opportunity employer (EEO is the law). We thrive on diversity & inclusion. You will be treated fairly throughout our recruiting process and without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status in consideration for a career at Discover.",3.9,"Discover
3.9","Riverwoods, IL",10000+ Employees,1985,Company - Public,Financial Transaction Processing,Finance,$5 to $10 billion (USD)
"Lead Data Engineer - VC funded, going IPO, 100% remote",-1,"One of my high growth venture capital backed clients is looking to hire roughly 30 remote engineers in the Midwest. They are on the coast and looking to build a remote team moving forward. They are series c funded – over $125M in VC dollars invested and trending towards IPO months.

The product is data driven. Drives revenue for clients. They now have 750+ clients. You will be working on a mobile engineering platform to drive revenue globally

I am looking for a Lead Data Engineer. This is a the first hire in this role. It's newly created.

A little background on leadership:

Co Founders – their previous company was acquired by one of the top social medium platforms about 5 yrs ago. This time they want to IPO.

CTO – was the first tech hire at a previous company that grew to 4000 employees. At a data driven product company. And the final interview round will be with the CTO and VP of Engineering.

Core tech stack React/Reduct, webpack, babel, etc on the front end. Python/Java, microservices coupled w/ Kinesis, AirFlow, MySql, Postgres, and Redis. They don’t care if you don’t have heavy exp with languages. It’s just a tool you can learn from their side. Great engineers can pick up anything.

Lots of machine learning opportunities. Interesting frontend/UI work. Lots of infrastructure challenges. I’m hiring for software ( front and back ), data, machine learning and devops engineers.

Strong base salary. Full benefits. Equity for the IPO.

Feel free to reach out: https://www.linkedin.com/in/lou-russo-2ba5006/

Job Type: Full-time

Pay: $89,943.00 - $182,711.00 per year

Benefits:
401(k)
Dental insurance
Flexible schedule
Health insurance
Paid time off
Vision insurance
Schedule:
Monday to Friday",-1,Relentless Talent,"Chicago, IL",-1,-1,-1,-1,-1,-1
GCP Data engineer with Dataproc + Big Table,"$65K-$115K
(Glassdoor Est.)","Position: GCP Data engineer with Dataproc + Big Table

Location: Anywhere in US

Â

Please note:

Ex- Google PSO Experience and Ex Google Highly Preferred

Dataproc + Big Table Experience is must

Â

Certifications:

GCP Cloud Certification is Must

Google Cloud Certified Professional Data Engineer

Google Cloud Certified Professional Cloud Architect

Â

Technical Skills:

* Experience with private, hybrid or public cloud technology

* Possess Strong Cloud Implementation Experience in Cloud

architecture/design, compute/storage services.

* Understand multi-Cloud/multi-zone based designs.

* Compute: Docker Apps, Lambda/ serverless, UserData customization

* Preferred: Cluster/HA based parallel design/multi-region approach

* Cloud automation: Ansible, YAML, CloudFormation

* Containers: Docker; Preferred: Container orchestration - Mesosphere,

Kubernetes, ECS

* Familiarity with functional operations of server, storage, and

network functions.

* Experience migrating Windows or Linux

* Virtualization experience (VMware, Xen, HyperV)

* Databases understanding: Oracle, DB2,MySql; Preferred: NoSql DB,

MongoDB, Cassandra, DynamoDB

* Program Management experience from Planning to execution

* Having experience of Managing teams of moderate size

* Strong communications skill and multiple stakeholder's management

* Experience in implementing cloud solutions.

Â

Responsibilities:

* Working with GCP team for various GCP Cloud programs including

Certifications, Partner engineering, Marketplace and other Cloud platform

solutions.

* Educating GCP / ISVs customers on best practices

* Stakeholders management / Communication: Google, ISVs, Project

Teams

* Program Management and Execution

* Managing the teams on different projects

* Reporting and Project Communications

* Advocating the customer's perspective during product and

architecture planning.

* Create and maintain a library of reusable container images

* Awareness of Business P&L and Goals aligned to technology and

revenue

Â

Â

Â

Â",4.7,"Sharpedge Solutions Inc
4.7","Naperville, IL",Unknown,-1,Company - Private,Publishing,Media,Less than $1 million (USD)
Machine Learning/Data Engineer (Senior),-1,"Fractal's Overview:
Fractal Analytics is a strategic AI partner to Fortune 500 companies with a vision to power every human decision in the enterprise. Fractal is building a world where individual choices, freedom, and diversity are the greatest assets; an ecosystem where human imagination is at the heart of every decision. Where no possibility is written off, only challenged to get better. We believe that a true Fractalite is the one who empowers imagination with intelligence. Fractal has been featured as a Great Place to Work by The Economic Times in partnership with the Great Place to Work® Institute and recognized as a 'Cool Vendor' and a 'Vendor to Watch' by Gartner.
Data engineering services required:
Build data products and processes alongside the core engineering and technology team
Collaborate with senior data scientists to curate, wrangle, and prepare data for use in their advanced analytical models
Integrate data from a variety of sources, assuring that they adhere to data quality and accessibility standards
Modify and improve data engineering processes to handle ever larger, more complex, and more types of data sources and pipelines
Use Hadoop architecture and HDFS commands to design and optimize data queries at scale
Evaluate and experiment with novel data engineering tools and advises information technology leads and partners about new capabilities to determine optimal solutions for particular technical problems or designated use cases
Big data engineering skills:
Expertise in Python with an emphasis on machine learning, API development, and big data
Hands on experience with Spark, Pandas, Numpy, and Scikit-learn
Experience in designing mission-critical highly available enterprise applications
Deep understanding of the latest data science and data engineering methods and processes to develop impactful and reusable patterns and abstractions from enterprise-level data assets
Hands-on experience in all phases of data modeling from conceptualization to database optimization
Demonstrated ability to perform the engineering necessary to acquire, ingest, cleanse, integrate, and structure massive volumes of data from multiple sources and systems into enterprise analytics platforms
Proven ability to design and optimize queries to build scalable, modular, efficient data pipelines
Ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets
Proven experience delivering production-ready data engineering solutions, including requirements definition, architecture selection, prototype development, debugging, unit-testing, deployment, support, and maintenance
Ability to operate with a variety of data engineering tools and technologies; vendor agnostic candidates preferred.
Domain and industry knowledge:
Strong collaboration and communication skills to work within and across technology teams and business units
Demonstrates the curiosity, interpersonal abilities, and organizational skills necessary to serve as a consulting partner, includes the ability to uncover, understand, and assess the needs of various business stakeholders
Experience with problem discovery, solution design, and insight delivery that involves frequent interaction, education, engagement, and evangelism with senior executives
Ideal candidate will have extensive experience with the creation and delivery of advanced analytics solutions for healthcare payers or insurance companies, including anomaly detection, provider optimization, studies of sources of fraud, waste, and abuse, and analysis of clinical and economic outcomes of treatment and wellness programs involving medical or pharmacy claims data, electronic medical record data, or other health data
Experience with healthcare providers, pharma, or life sciences is a plus",-1,Fractal.ai,"Chicago, IL",-1,-1,-1,-1,-1,-1
Data Engineer Solutions Lead,-1,"Your Talent. Our Vision. At Anthem, Inc., it’s a powerful combination, and the foundation upon which we’re creating greater access to care for our members, greater value for our customers, and greater health for our communities. Join us and together we will drive the future of health care.

This is an exceptional opportunity to do innovative work that means more to you and those we serve at one of America's leading health benefits companies and a Fortune Top 50 Company.

Data Science Solutions Lead is responsible for design and development of analytic models, applications and supporting tools, which enable Data Scientists to create algorithms/models in a big data ecosystem.

Primary duties may include but are not limited to:
Lead the design and implementation of Machine Learning/Data Science model operationalization and related system integration
Lead the design, implementation and delivery of an insights data pipeline supporting analytic products across the organization.
Design and integrate data from different sources.
Forms analytics platform components and/or processing components required to provide a business solution.
Engage with business stakeholders to design and own end-to-end solutions to empower data driven decision making.
Leverage data, technology and quantitative methods to form products that inject analytics and insights into daily workflow of teams.
Defines application scope and objectives, including impact to interfaces.
Ensures appropriate data testing is completed and meets test plan requirements.
Coordinates integration actions to ensure successful implementation.
Mentors Data Science Sol Consultants/Sr. Lead analytical projects and pilots for upgrades or enhancements.
Lead analytical projects and pilots for upgrades or enhancements
Requires BA/BS in Computer Science, Mathematics, or related disciplines; 5-7 years’ experience in predictive analytics and experience with software such as Hadoop technologies; 5-7 years Teradata experience and complex SQL, or equivalent; or any combination of education and experience which would provide an equivalent background. Experience in the healthcare sector preferred. Experience with deployment techniques within an agile development methodology. Strong knowledge of BTEQ and multi database preferred.
Requires BA/BS in Computer Science, Mathematics, or related disciplines.
An ideal candidate will have significant experience in at least one area: Data Architecture, Real-Time Applications, or BI Tools.
5+ years’ experience in leveraging at least 4 of the following technologies – HDFS, Hive, Sqoop, Impala, Spark, distributed processing concepts, Hbase, MongoDB, J2EE/Spring, AWS, Node.js
Solid understanding and experience using at least one of the following programming languages — Java, Python, R, Scala.
5+ years’ experience in one of the following areas:
Database Strategy, Data Modeling, Data Pipelines and ETL Architecture
API & messaging architectures
BI development/design
Experience in public cloud environment and container technologies is preferred
Experience in Healthcare industry is preferred
Strong relational database SQL skills; including optimization techniques, with knowledge of NoSQL concepts
Solid experience with unix and shell scripting
Experience in defining project solution approach leveraging agile methodologies working with Product Owners and Scrum Masters.
Experience with source code management and application deployment techniques within an agile development methodology
Knowledge of the following Machine Learning Algorithms - Classification, Regression, Clustering, Dimensionality Reduction, Model Selection, Feature Extraction
Anthem, Inc. is ranked as one of America’s Most Admired Companies among health insurers by Fortune magazine and is a 2018 DiversityInc magazine Top 50 Company for Diversity. To learn more about our company and apply, please visit us at careers.antheminc.com. An Equal Opportunity Employer/Disability/Veteran.",4.0,"Anthem Health Plans of Virginia
4.0","Chicago, IL",1001 to 5000 Employees,1935,Subsidiary or Business Segment,Insurance Carriers,Insurance,$1 to $2 billion (USD)
Clinical Lab Scientist-MICROBIOLOGY-SIGN ON BONUS,"$21-$34 Per Hour
(Glassdoor Est.)","$2000.00 SIGN ON BONUS
(Bonus program parameters apply)

Edward-Elmhurst Health includes three hospitals — Edward Hospital, Elmhurst Hospital, and Linden Oaks Behavioral Health — and an extensive ambulatory care network that provides comprehensive healthcare to residents of the west and southwest suburbs of Chicago.

Edward-Elmhurst Health provides comprehensive healthcare at more than 60 locations in the suburbs of Chicago. Our success has always been — and always will be — driven by our most talented, reliable, compassionate and skilled people, who genuinely believe in delivering top quality care to our patients and their families. At Edward-Elmhurst Health, you will also experience a vibrant culture and an atmosphere of nurturing support and leadership.

Be DRIVEN to join our over 8,000 employees, 1,700 staff physicians and 1,800 volunteers who want to provide safe, seamless and personalized care every day for our patients, our families and our communities.

Job Summary: Performs various clinical laboratory tests in one or more sections of the Laboratory in order to obtain data for use in diagnosis and treatment of disease.

Hours: Full-time 5pm-1:30am; Includes weekend/holiday rotation

Required:
Associate's degree or higher in Medical Technology or Clinical Laboratory Science
Ability to accurately collect and analyze test results, and to perceive similarities and differences in color
Registration with the American Society of Clinical Pathology (ASCP), National Credentialing Agency (NCA) or equivalent
Preferred:
Bachelor’s Degree
Microbiology experience
*Benefits offered by Edward-Elmhurst Health include:
Medical, dental, and vision
401K
Tuition reimbursement
Paid time off
Fitness center membership
Plus many other Employee Perks",-1,Edward Hospital,"Elmhurst, IL",1001 to 5000 Employees,-1,Hospital,Health Care Services & Hospitals,Health Care,$500 million to $1 billion (USD)
Postdoctoral Appointee - Building Scientist,"$55K-$85K
(Glassdoor Est.)","Position Description

Collaborates with a multidisciplinary team in the development of fundamental building science, building-to-grid integration, and urban science. Innovates in the development and deployment of physics-based and data analytic tools and technologies for building systems, whole buildings, energy systems, and urban systems. Communicates impactful research outcomes through internal reports, peer-reviewed publications, and conference presentations.

The candidate is expected to have a strong engineering background with demonstrated experience in building science and building energy modeling, especially in uncertainty quantification.

Position Requirements
PhD in architecture, architectural engineering, or mechanical engineering. Research experience in building science and building energy modeling.
Experience with building energy modeling using EnergyPlus and/or OpenStudio
Knowledge of conventional and emerging building modeling tools and techniques.
Knowledge of fundamental building sciences.
Experience with building energy modeling tools other than EnergyPlus/OpenStudio
Experience with uncertainty quantification of system models
Experience in working with multidisciplinary research teams.
Experience with modern scientific computing methods for large scale simulations on high performance computing infrastructure for building energy modeling and uncertainty quantification.
Experience in establishing research collaborations
Excellent oral and written communication skills.
Ability to think strategically and work independently.
Experience supervising research work
Experience with developing machine learning and data-analytic tools.
Knowledge of relevant DOE Office funding mechanisms and strategic outlook
A successful candidate must have the ability to model Argonne’s Core Values: Impact, Safety, Respect, Integrity, and Teamwork.
As an equal employment opportunity and affirmative action employer, and in accordance with our core values of impact, safety, respect, integrity and teamwork, Argonne National Laboratory is committed to a diverse and inclusive workplace that fosters collaborative scientific discovery and innovation. In support of this commitment, Argonne encourages minorities, women, veterans and individuals with disabilities to apply for employment. Argonne considers all qualified applicants for employment without regard to age, ancestry, citizenship status, color, disability, gender, gender identity, genetic information, marital status, national origin, pregnancy, race, religion, sexual orientation, veteran status or any other characteristic protected by law.

Argonne employees, and certain guest researchers and contractors, are subject to particular restrictions related to participation in Foreign Government Talent Recruitment Programs, as defined and detailed in United States Department of Energy Order 486.1. You will be asked to disclose any such participation in the application phase for review by Argonne’s Legal Department.",4.5,"Argonne National Laboratory
4.5","Lemont, IL",1001 to 5000 Employees,1946,Nonprofit Organization,Federal Agencies,Government,Unknown / Non-Applicable
"Education Research Scientist/Analyst, AD-1730-00","$56K-$79K
(Glassdoor Est.)","This position is located in the U.S. Department of Education. Candidates selected for this position will serve as a Research Scientist/Analyst in the Institute of Education Sciences (IES).

Basic Requirements: A. Degree that included or was supplemented by at least 24 semester hours of coursework in a field related to the work of the position to be filled (as presented in the description of duties), of which at least one course was in research methods and at least two courses were in statistics. OR B. Combination of education and experience - (including at least 24 semester hours in a field related to the work of the position to be filled, including at least one course in research methods and two courses in statistics, plus appropriate experience or additional education). The experience must have demonstrated (1) a thorough knowledge of the principles underlying the work of this series, and (2) understanding, both theoretical and practical, of the methods and techniques applied in performing work in this series.

The incumbent serves as an Education Research Scientist/Analyst in the Institute of Education Sciences (IES), U.S Department of Education. Incumbents will engage in one or more of the following: (1) develop plans for agency support of education research, evaluation, and statistics; (2) oversee research, evaluation, and statistics activities and programs carried out or funded by the agency; (3) conduct scientific reviews of research, evaluation, and statistics plans and products; (4) analyze data and synthesize information from education research and related areas; (5) prepare written products to convey research-based knowledge and information to a variety of audiences; (6) conduct evaluations of agency activities; (7) engage in dissemination and outreach activities, such as publishing scholarly work and attending scientific conferences; (8) monitor research grants or manage the scientific peer review of research grant competitions; and (9) consult with, or advise staff. SELECTIONS MAY ONLY BE MADE AFTER 30 DAYS OF THE OPENING DATE OF THIS ANNOUNCEMENT.

EDUCATION RESEARCH SCIENTIST/ANALYST requires a doctoral degree or equivalent experience in an appropriate field, and at least five years of experience pertinent to the needs of IES. Education Research Scientist requires demonstration of strong research skills and knowledge in an area of specialization. SPECIALIZED EXPERIENCE: Education Research Scientist must have at least 5 years of research experience in education-related fields (e.g., cognitive, developmental, educational, or social psychology, economics, education, statistics, postsecondary education); experience publishing in scientific peer-reviewed journals and reviewing for such journals.",3.0,"Institute of Education Sciences
3.0","Chicago, IL",51 to 200 Employees,-1,Government,Federal Agencies,Government,Less than $1 million (USD)
Senior Applied Data Engineer,"$90K-$162K
(Glassdoor Est.)","What we do

At Civis, we take a science-first approach to solving problems. With a blend of proprietary technology and statistical advisory services, we help public and private sector organizations find, understand and connect with the people they care about, so they can stop guessing and start using mathematical proof to guide decisions. We know others use “data science” and “analytics” as buzzwords, but at Civis we don’t stand for fluff, and we will always deliver scalable products and technologies — not PowerPoints — to drive your business forward. Learn more about Civis at www.civisanalytics.com.

Our mission

To democratize data science so organizations can stop guessing and make decisions based on numbers and scientific fact.

What we are looking for

Senior Applied Data Engineers are experts in creating elegant, maintainable, and extensible data pipelines and database architectures. They partner with Civis's Applied Data Science consultants -- the Applied Data Engineers make the data clean and available, and the Applied Data Scientists analyze and present the data to clients.

As a Senior Applied Data Engineer, you will be the go-to person for questions about how to handle new datasets. You will help scope and plan what we need to accomplish when starting data work with a new client. You will build maintainable and extensible ETL solutions for diverse data sources. You will advise Applied Data Scientists, mentor junior Applied Data Engineers, and be directly responsible for building some of Civis's most complex client-oriented data pipelines.

Civis Analytics values autonomy, and you will be trusted and expected to use your expertise to solve both technical and non-technical problems to create data solutions for Civis's clients.

**This is a temporary, full-time, salaried position with benefits slated to end Dec. 31, 2020. There is a possibility of extension if the business requires it.**

Due to the uncertainty of COVID-19, all Civis offices are closed and all employees are remote for the foreseeable future. This is being closely monitored as things change and it’s likely our offices will reopen. Because of this uncertainty, we want to ensure candidates are open to relocating to one of our offices in the future, but other locations may be negotiable.

Responsibilities
Ingest data using connectors built by our Engineering team and build new data connectors as required
Collaborate with clients and client-facing teams to define user requirements and database design specifications for our clients’ needs
Transform data based on business requirements
Apply data validation and/or software testing techniques to ensure data processes and pipelines are working properly
Create pipelines that deliver data error-free and on-time with features such as logging, fault tolerance, notifications, and scalability
Document and train others on data pipelines
Serve as a technical resource in resolving issues related to data pipelines
Work closely with client-facing teams
Mentor junior members of the Applied Data Engineering team
Project manage data pipeline construction and maintenance work
Minimum Requirements
Bachelor’s degree in an analytical subject (statistics, math, economics, physics, engineering, business, political or social science, computer science, etc)
5+ years of experience with database and ETL pipeline design
Experience leading data and/or software projects
Proficiency in Python and SQL
Ability to work as part of a cross-functional team to solve problems and build solutions
Strong communication and teamwork skills
Eagerness to constantly learn and teach others
Preferred Qualifications
Experience working on data pipelines in support of data analytics or data science applications
Significant experience with Python and SQL
Experience with software development practices including unit testing, version control, code review, and Agile development
Experience with technical project management
Mentorship and training experience
Familiarity with data and database technologies such as Redshift, Spark, S3, postgres, HDFS, etc., and with issues related to distributed systems.
Who we are

At Civis, we have opportunities for applicants who are newcomers, seasoned professionals, and anywhere in between. Our teams are energized by complex challenges and value diversity of thought. Opportunities to stand out and inspire happen daily and we trust and encourage you to act on your ideas – no matter how big they are. We offer you the tools and community you need to do your best work. Each of us is committed to holding ourselves accountable for results, challenging the status quo and finding new ways to grow our company and each other.

Why join our team?
The opportunity to be part of a growing tech startup focused on solving interesting and meaningful problems, invested in internal promotion, and committed to fostering a diverse, equal and inclusive workplace.
Competitive benefits, including unlimited PTO, 401K match with immediate vesting, health, dental, and vision benefits, paid parental leave, breastfeeding support including breastmilk shipping services for traveling moms, flexible work from home policy, commuter benefits, wellness initiatives including weekly group meditations, monthly on-site massage therapy, and pet insurance.
Civis Analytics embraces the individuality of our employees and we celebrate each other's differences. Our products, services, and culture benefit from and thrive on the unique perspectives brought by each person in our community. We're proud to be an equal opportunity workplace, and we are committed to equal employment opportunity regardless of race, age, sex, color, ancestry, religion, national origin, sexual orientation, gender identity, citizenship, marital status, disability, or Veteran status. If you have a disability or special need that requires accommodation, please contact internalrecruiting@civisanalytics.com

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States.

EEO IS THE LAW

EEO Supplement

Pay Transparency",3.2,"Civis Analytics
3.2","Chicago, IL",51 to 200 Employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,$25 to $50 million (USD)
Big Data Engineer,"$59K-$103K
(Glassdoor Est.)","Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get. Leading edge technology in an industry that's improving the lives of millions. Here, innovation isn't about another gadget, it's about making health care data available wherever and whenever people need it, safely and reliably. There's no room for error. Join us and start doing your life's best work.(sm) Youll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary Responsibilities: Design, code, test, document, and maintain high-quality and scalable Big Data solutionsResearch, evaluate, and deploy new tools, frameworks and patterns to build sustainable Big Data platformIdentify gaps and opportunities for improvement of existing solutionsDefine and develop APIs for integration with various data sources in the enterpriseAnalyze and define customer requirementsAssist in defining product technical architectureMake accurate development effort estimates to assist management in project and resource planningCreate prototypes, proof-of-concepts & design and code reviews Collaborate with management, quality assurance, architecture, and other development teamsWrite technical documentation and participate in production supportKeep skills up to date through ongoing self-directed training The ideal candidate will be a self-starter who can learn things quickly who is enthusiastic, active, and eager to learn. Youll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.",3.4,"UnitedHealth Group
3.4","Downers Grove, IL",10000+ Employees,1977,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
"Associate Data Engineer, Zoro",-1,"Company Summary:
Zoro.com is an eCommerce company that sells business supplies, equipment, and tools—but we’re much more than just a website. We’re a team of people who win and lose together (we prefer winning!). Since 2011, Zoro has been working hard to make it easy for our customers to purchase everything they need to make their businesses go. Zoro currently offers over 3 million products, fast and free shipping, no-hassle returns, and exceptional customer service. We’ve grown quickly in a short time, recently surpassing 400 team members and reaching annual revenue of over $500 million. Add to that our award-winning culture—we were named a Great Place to Work for 2019-20, among other accolades—and we think Zoro is a pretty amazing place to work and grow.
Primary Function:
Imagine what you could help us achieve as an Associate Data Engineer!
The Associate Data Engineer will work under the guidance of other data professionals and collaborate with various IT groups, business partners and external service providers to design, develop, operationalize and support critical components of our cloud-native data platform, the “Zoro Data Platform (ZDP)”.
Duties and Responsibilities:
Participate in Requirements Gathering: work with key business partner groups (e.g. Product Mgt) and other Data Engineering personnel to understand department-level data requirements for ZDP
Design Data Pipelines: work with other Data Engineering personnel to design new data pipelines for flowing data from various internal and external sources into the ZDP using standard and other pre-established frameworks and interfaces
Build Data Pipelines: leverage standard toolset and ZDP-specific data frameworks to develop ETL/ELT code to move data from various internal and external sources into the ZDP
Support Data Quality Program: work with Data QA Engineer to identify automated QA checks and associated monitoring & alerting to ensure ZDP maintains consistently high quality data
Support Operations: triage alerts channeled to you and remediate as necessary
Technical Documentation: leverage templates provided and create clear, simple and comprehensive documentation for your development
Key contributor to defining, implementing, enhancing and supporting:
Data Services
Data Dictionary
Tool Standards
Best Practices
Data Lineage
User Training
Skills & Responsibilities:
Competent programmer with focus on ELT/ ETL design/development using Python
Intermediate-level proficiency in SQL with demonstrable expertise in analytical data management tasks using SQL
Familiarity with Cloud environment development & operations (e.g. AWS, GCP)
Preference for candidates with prior working knowledge in:
Google Cloud Platform (GCP) and associated services; e.g. BigQuery, GCS, Cloud Composer, Dataproc, Dataflow, Dataprep, Cloud Pub/Sub, Data Catalog, Datalab other
Other important Zoro tools: Apache Airflow (scheduler), Bitbucket and git (version control), Stackdriver (ops monitoring), Opsgenie (alert notification), Docker
Real-time data replication/streaming tools
Data Modeling
Excellent verbal and written communications
Strong team player
Success Criteria
Strong analytical thinking and problem solving skills
Superior communication and business-technical interaction skills
Positive, “get it done” attitude with a high degree of ownership and responsibility
Ability to work with a high level of autonomy on critical tasks within an agile framework
To qualify, you must possess the following skills:
Bachelor’s degree in computer science, management information systems, or a related discipline
2+ years hands-on ETL/ELT design/development experience or Masters degree on a related field
Key resource on team(s) / projects that have delivered successful analytics platforms / products

Final note: We share a commitment to our Zoro values – Win & Lose Together (We prefer winning!), Take Ownership, We Are Transparent, and Aspire to be Customer-Obsessed. Everything we do at Zoro is centered around delighting our customers. It's a natural extension of our company culture and how we care for each other. We believe when we act in ways that are consistent with these values, we can solve any technical challenge that lies ahead of us. As a Zoro employee, you can expect to work with smart, energetic people, learn something every day, and be valued for your perspective.

Zoro is an Equal Opportunity Workplace and an Affirmative Action Employer.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.",2.0,"Zoro Tools
2.0","Buffalo Grove, IL",Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD)
Cloud Data Engineer,-1,"Projects the candidate will be working on:
This role is for a Cloud Data Engineer that will join a team responsible for developing a growing cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on a major cloud platform such as Azure..
Team and Team size:
Will be part of team
Agile Team with a size of 6 to 7 members
Top Responsibilities:
This role is for a Cloud Data Engineer that will join a team responsible for developing a growing cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on a major cloud platform such as Azure.
The candidate should be comfortable working with both HDFS based and relational databases/datastore, including any aspect of administration or support required to maintain them.
The candidate should have some familiarity with Data Streaming (Apache Kafka).
Required Experience & Qualifications:
Data Engineering experience - 3 years
Cloud platform experience - 1 years
Version Control (Git) - 1 years
Strong foundation in SQL
General Programing Experience
Preferred Experience & Qualifications:
Experience in Big Data or Streaming Ecosystems (Apache Spark, Hadoop, Kafka)
Experience with Docker & Kubernetes
Experience with Golang, Python, Scala
Experience building RESTful APIs
Interview Process:
a. How many rounds? 2 or 3
b. Video vs. phone? Phone",4.0,"Horizontal
4.0","Schaumburg, IL",501 to 1000 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Clinical Lab Scientist-Generalist,"$21-$34 Per Hour
(Glassdoor Est.)","Edward-Elmhurst Health includes three hospitals — Edward Hospital, Elmhurst Hospital, and Linden Oaks Behavioral Health — and an extensive ambulatory care network that provides comprehensive healthcare to residents of the west and southwest suburbs of Chicago. Edward-Elmhurst Health provides comprehensive healthcare at more than 60 locations in the suburbs of Chicago. Our success has always been — and always will be — driven by our most talented, reliable, compassionate and skilled people, who genuinely believe in delivering top quality care to our patients and their families. At Edward-Elmhurst Health, you will also experience a vibrant culture and an atmosphere of nurturing support and leadership.

Be DRIVEN to join our over 8,000 employees, 1,700 staff physicians and 1,800 volunteers who want to provide safe, seamless and personalized care every day for our patients, our families and our communities.

Job Summary: Performs various clinical laboratory tests in one or more sections of the Laboratory in order to obtain data for use in diagnosis and treatment of disease.

Hours: Full-time 6am -2:30pm various shifts during the week; Includes weekend and holiday rotations

Required:
Associate's degree in Medical Technology or Clinical Laboratory Science
Ability to accurately collect and analyze test results, and to perceive similarities and differences in color
Registration with the American Society of Clinical Pathology (ASCP), National Credentialing Agency (NCA) or equivalent
Preferred:
Bachelor’s Degree
*Benefits offered by Edward-Elmhurst Health include:
Medical, dental, and vision
401K
Tuition reimbursement
Paid time off
Fitness center membership
Plus many other Employee Perks",-1,Edward Hospital,"Naperville, IL",1001 to 5000 Employees,-1,Hospital,Health Care Services & Hospitals,Health Care,$500 million to $1 billion (USD)
RD2 Data Engineering Specialist / RD3 Data Engineer,"$82K-$108K
(Glassdoor Est.)","Position Description

The X-ray Science Division (XSD) of Argonne National Laboratory enables world-class research using x-rays by developing cutting edge X-ray instrumentation and techniques, and pursuing research in the physical, chemical, environmental, and materials sciences. To accomplish this mission, XSD fully operates 43 beamlines and is a partner in the operation of three more beamlines at the Advanced Photon Source (APS). We are currently seeking to fill an Data Engineering Specialist position.

Today, the APS collects approximately 10 PB of raw experimental data per year from approximately 100 sophisticated instruments performing work in a variety of scientific domains. Over the coming decade, the APS anticipates this annual data volume will increase by multiple orders-of-magnitude. This is an exciting opportunity to be at the forefront of solving data and computing solutions needed to answer pressing scientific questions that face the nation today.

The Data Engineering Specialist will be a part of a team developing the strategic direction for facility-wide data architectures and engage in hands-on activities related to the design, development, maintenance, and support of data management solutions for scientific instruments at the APS. The position works independently and collaboratively with staff, scientists, and external collaborators to deliver solutions, and may have project leadership responsibilities. Work may involve the development of computational techniques and software development for scientific data management, processing, and visualization, and utilize high-performance computing platforms.

Position Requirements

Knowledge, Skills, and Experience:
Knowledge and experience with scientific software development in Python or C++, and the ability to work under common Linux command shells.
Knowledge and experience with object-oriented programming and design patterns.
Knowledge and experience with software project management techniques such as revision control, build tools, and issue tracking.
A foundation in computer science, computational/data science, mathematics, physics or a related field.
Strong analytical and problem-solving skills.
Ability to think independently and innovatively to develop exceptional technical solutions.
Strong verbal and written communication skills, and a proven ability to write research reports and publications.
Strong organizational skills and attention to detail.
Ability to work independently and as part of a team, including the ability to interact well with external collaborators and represent the organization as a prime contact.
RD2 Requirements: Bachelor’s Degree and 5+ years of experience; Master’s and 3+ years; Doctorate and 0 years, or equivalent.
RD3 Requirements: Bachelor’s Degree and 8+ years of experience; Master’s and 5+ years; or Doctorate and 4+ years; or equivalent.

As an equal employment opportunity and affirmative action employer, and in accordance with our core values of impact, safety, respect, integrity and teamwork, Argonne National Laboratory is committed to a diverse and inclusive workplace that fosters collaborative scientific discovery and innovation. In support of this commitment, Argonne encourages minorities, women, veterans and individuals with disabilities to apply for employment. Argonne considers all qualified applicants for employment without regard to age, ancestry, citizenship status, color, disability, gender, gender identity, genetic information, marital status, national origin, pregnancy, race, religion, sexual orientation, veteran status or any other characteristic protected by law.

Argonne employees, and certain guest researchers and contractors, are subject to particular restrictions related to participation in Foreign Government Talent Recruitment Programs, as defined and detailed in United States Department of Energy Order 486.1. You will be asked to disclose any such participation in the application phase for review by Argonne’s Legal Department.
Back to top",4.5,"Argonne National Laboratory
4.5","Lemont, IL",1001 to 5000 Employees,1946,Nonprofit Organization,Federal Agencies,Government,Unknown / Non-Applicable
Senior Data Engineer,"$71K-$128K
(Glassdoor Est.)","The Senior Data Engineer will work within the data and the analytics team and partner with multiple businesses and various engineering teams (Platform, Security) to build high quality data pipelines. This individual will be responsible to integrate data from a variety of data sources utilizing cloud-based data structures (AWS) and determine/enhance existing data sources between internal and external stakeholders.
The things that you will tackle:
Solve complex data problems to deliver insights to help our businesses achieve their goals
Advise, consult and coach other data and analytic professionals on data standards and practices
Develop, implement and optimize streaming, data lake and analytics big data solutions
Create and execute testing including unit, integration and end-to-end tests of data pipelines
Foster a culture of sharing, re-use, design for scale stability and operational efficiency of data and analytical solutions
Adapt and learn new technologies in a quickly changing field
Create data products for analytics and engineering team members to improve their productivity
Recommend and implement best tools to ensure optimized data performance
Design, develop, optimize and maintain data architecture and pipelines that adhere to HIMSS principles and business goals
Lead evaluation, implementation and deployment of emerging tools & process for analytic data engineering to improve our productivity as a team

Bachelor’s degree in computer science or related field.
Minimum of five (5) years of application development and implementation experience.
Experience with SQL, Big Data, ETL programming and development within

Our talent anywhere philosophy allows employees the flexibility to work virtually on an as-needed or permanent basis.
Competitive, comprehensive healthcare coverage.
Generous paid time off, including time off to volunteer!
401K with employer match and profit sharing.
Be Well! Lifestyle reimbursement program.
Tuition reimbursement and professional development programs.
Are you a Changemaker?
We’ll do amazing things for healthcare.
HIMSS is an Equal Opportunity Employer: M/F/Vets/Disabled",3.1,"HIMSS
3.1","Chicago, IL",201 to 500 Employees,1961,Nonprofit Organization,Health Care Services & Hospitals,Health Care,$50 to $100 million (USD)
Sr. Data Engineer (Consulting),"$81K-$145K
(Glassdoor Est.)","At West Monroe, our people are our business.
We pride ourselves on bringing a different mindset to consulting—and that takes a different approach: highly collaborative, flexible, and tenacious.
Our people-first, highly collaborative culture is core to our identity. It’s something we care about, and something we strive to enrich and preserve. No hierarchies. No silos. No egos. Just smart ideas, and the drive to make an impact for our clients.
Every day our clients rely on us to help them tackle their greatest challenges, by strategically deploying technology through a business-focused and industry-specific lens. We bring together both the right knowledge and the right approach, so that they can capitalize on opportunities and deliver real results. That takes the right team. And that’s where you come in.
Ready for the next step on your career journey?

West Monroe is seeking an experienced Business Intelligence (BI) Senior Consultant to join our emerging Advanced Analytics Practice in the Chicago office developing technology solutions for our clients in the data warehousing and BI space. This is an excellent opportunity to work within our Information Management team with Fortune 250 clients developing BI strategy and roadmaps, implementing new customer facing reporting and analytics platforms, while gaining exposure to a variety of industries including healthcare, insurance, manufacturing, E&U, and professional services.  Candidates will need to demonstrate in-depth understanding and prior experience in Microsoft SQL Server Integration Services, ETL development, and reporting solutions.

Responsibilities:Work closely with our clients as part of a development team to evaluate requirements and develop business intelligence and data warehousing solutionsDesign and develop data warehouse database schemasDesign and develop extract, transform, and load (ETL) mappings, procedures, and schedules Coordinate activities with data source application owners to ensure integration and data integrityDesign and develop reports, dashboards, KPIs, and data extracts
Qualifications:Minimum 4+ years of hands on professional development experienceStrong technical experience in ETL tools (Informatica, IBM DataStage, or Microsoft Integration Services), database platforms (Oracle or SQL Server), and reporting tool (IBM Cognos, SAP Business Objects, Microsoft Reporting Services, or Microstrategy) Experience with the Microsoft SQL Server platform (version 2008 or later) is requiredGood knowledge of standard concepts, best practices, and procedures within a data warehousing and business intelligence environmentExcellent organizational and communication skills to work in a fast-paced environment and manage and prioritize multiple tasks simultaneouslyAbility to work well in a team of 2 – 5 consultantsAbility to travel 50% nationally Ready to get started? Join our team and make an impact.

Sr. Data Engineer (Consulting)

222 W Adams St, 11th Floor
Chicago, Illinois, 60606
United States
At West Monroe, our people are our business.

We pride ourselves on bringing a different mindset to consulting—and that takes a different approach: highly collaborative, flexible, and tenacious.

Our people-first, highly collaborative culture is core to our identity. It’s something we care about, and something we strive to enrich and preserve. No hierarchies. No silos. No egos. Just smart ideas, and the drive to make an impact for our clients.

Every day our clients rely on us to help them tackle their greatest challenges, by strategically deploying technology through a business-focused and industry-specific lens. We bring together both the right knowledge and the right approach, so that they can capitalize on opportunities and deliver real results. That takes the right team. And that’s where you come in.

Ready for the next step on your career journey?

West Monroe is seeking an experienced Business Intelligence (BI) Senior Consultant to join our emerging Advanced Analytics Practice in the Chicago office developing technology solutions for our clients in the data warehousing and BI space. This is an excellent opportunity to work within our Information Management team with Fortune 250 clients developing BI strategy and roadmaps, implementing new customer facing reporting and analytics platforms, while gaining exposure to a variety of industries including healthcare, insurance, manufacturing, E&U, and professional services.  Candidates will need to demonstrate in-depth understanding and prior experience in Microsoft SQL Server Integration Services, ETL development, and reporting solutions.
Responsibilities:
Work closely with our clients as part of a development team to evaluate requirements and develop business intelligence and data warehousing solutions
Design and develop data warehouse database schemas
Design and develop extract, transform, and load (ETL) mappings, procedures, and schedules
Coordinate activities with data source application owners to ensure integration and data integrity
Design and develop reports, dashboards, KPIs, and data extracts

Qualifications:
Minimum 4+ years of hands on professional development experience
Strong technical experience in ETL tools (Informatica, IBM DataStage, or Microsoft Integration Services), database platforms (Oracle or SQL Server), and reporting tool (IBM Cognos, SAP Business Objects, Microsoft Reporting Services, or Microstrategy)
Experience with the Microsoft SQL Server platform (version 2008 or later) is required
Good knowledge of standard concepts, best practices, and procedures within a data warehousing and business intelligence environment
Excellent organizational and communication skills to work in a fast-paced environment and manage and prioritize multiple tasks simultaneously
Ability to work well in a team of 2 – 5 consultants
Ability to travel 50% nationally
Ready to get started? Join our team and make an impact.

.

West Monroe Partners is an Equal Employment Opportunity Employer -
We believe in treating each employee and applicant for employment fairly and with dignity. We base our employment decisions on merit, experience, and potential, without regard to race, color, national origin, sex, sexual orientation, gender identity, marital status, age, religion, disability, veteran status, or any other characteristic prohibited by federal, state or local law.",4.2,"West Monroe Partners
4.2","Chicago, IL",1001 to 5000 Employees,2002,Company - Private,Consulting,Business Services,$100 to $500 million (USD)
Advanced Data Engineer,"$60K-$115K
(Glassdoor Est.)","Position Summary

The Advanced Data Engineer is a key position within the Data Management
team, responsible for the design, development, test and implementation of
best-in-class ETL/Data Processing solutions for the organization. This is an
advanced role that will be engaged in all phases of the Data Enablement
lifecycle, and will be called upon to mentor less experienced team members as
necessary. Successful candidate will have a proven track record demonstrating
in-depth technical and business knowledge.
Key Accountabilities
Design, develop and maintain SSIS ETL packages
using SSIS and MS SQL Server 2016 or higher.
Support/enhance/create ETL packages to address
AML ETL business requirements, ensuring all related ETL processes meets
best-in-class standards offering high performance. Responsible to address all
ETL defects related to AML data loads.
Required to work in other areas of Data
Warehousing ETL efforts as needed.
Primary resource for AML ETL Production Support,
address all Audit Related questions with respect to AML ETL processes.
Create/Enhance technical documentation and
ensuring all documentation is up to date.
Serves as resource to internal and third-party
team members on escalated issues and analyzing and designing specifications for
less experienced team members
Pursues self-development and effective
relationships with others by sharing resources, information, and knowledge with
coworkers and customers. Seeks opportunities to deliver continuous process
improvement
Bachelor’s degree with 7 experience or Master’s degree with 5 years’ experience in Computer Science, Engineering, Math, or other quantitative field.
7 years’ experience in Data Engineering - designing, implementing data persistence, data processing and MS SQL Server DW Solutions.
Experience in designing and building complete ETL/SSIS processes moving and transforming data for ODS, Staging, Data Warehousing and Data Marts.
Proficient in T-SQL development (complex queries, stored procedures and user defined functions) and performance tuning.
Experience with dynamic package configurations, error handling, checkpoints, auditing and balancing using SSIS and T-SQL Stored Procedures.
Support and maintain the existing ETL processes (SSIS) and SQL Server Data Warehouse for operational and analytical applications.
Strong understanding of DW concepts including 3NF and Dimensional data models.
Experience with processing semi structured and unstructured files using SSIS ETL tool with custom C# coding.
Perform peer reviews and take ownership of the ETL processes to ensure quality of data in data warehouse and downstream data marts.
Experience with building CICD pipelines for SSIS ETL packages using Visual Studio and Azure DevOps is a plus.
Experience with source control repository system such as TFS or GIT is preferred.
Efficiently work in Agile environment. Familiarity with tracking tools such as JIRA is a plus.
Experience with running python programs using SSIS and visual studio is a plus.
Experience working on Banking and Financial domain is preferred.
Proven ability to work within a team environment and interacting with data professionals and business data SME’s throughout the organization
Desire to work in a fast growing environment with strong time management ability
Demonstrates strong analytical and problem solving skills.
Must be self-directed and have excellent initiative and organization skills.
Proven track record of meeting commitments with the highest standards of ethics and integrity.
Founded in 1991 with the idea to be the alternative to the big banks, Wintrust has since grown into a financial services company with more than $36 billion in assets, headquartered in Rosemont, Illinois. Through our multiple companies and divisions, we provide traditional community banking and commercial banking services, wealth management solutions, commercial and life insurance premium financing, mortgage origination, and short-term accounts receivable financing and certain administrative services, such as data processing of payrolls, billing, and treasury management services. We provide community-oriented personal and business banking services to customers located in the greater Chicagoland area, northwest Indiana, and southern Wisconsin through more than 175 community bank locations.

We provide an engaging, dynamic work environment, an excellent compensation package including 401k, employee stock purchase plan, medical/dental, life insurance and more!

Wintrust Financial Corporation, including community banking and financial services subsidiaries, is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, citizenship status, sex, sexual orientation, gender identity and expressions, genetic information, marital status, age, disability, or status as a covered veteran. We request applicants refrain from disclosing current or historical compensation information during the recruitment process; any disclosed detail will not be taken into account as applicants are considered for employment.",4.0,"Wintrust Financial
4.0","Rosemont, IL",1001 to 5000 Employees,1991,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD)
Senior Data Engineer,"$79K-$147K
(Glassdoor Est.)","Numerator is looking for a Senior Data Engineer who is a Big Data enthusiast and has a passion for working with an interesting robust set of data. This person will work in our platform to help ensure that our data quality is flawless. As a company, we have millions of new data points every day that come into our system. You will be working with a passionate team of engineers to solve challenging problems and ensure that we can deliver the best data to our customers, on-time. You will be using the latest cloud data warehouse technologies to build robust and reliable data pipelines.

Duties/Responsibilities Include
Develop expertise in the different upstream data stores and systems across Numerator
Design, develop and maintain data integration pipelines for Numerators growing data sets and product offerings
Collaborate with product and engineering teams to take requirements from prototype to production
Build data validation testing frameworks to ensure high data quality and integrity
Write and maintain documentation on data pipelines and schemas
Requirements
Bachelors degree in Computer Science or related field of study required; Masters degree preferred
5 + years of experience in the data warehouse space
Knowledge of software engineering best practices across the development lifecycle, coding standards, code reviews, source management, build processes, testing, and operations
Knowledge of and experience implementing data security and governance best practices
Expert in SQL, including advanced analytical queries, window functions, CTEs and query optimization
Advanced proficiency in Python (data structures, algorithms, object oriented programming, using APIs)Experience administering a cloud data warehouse (Redshift, Snowflake, Vertica)
Experience with a data pipeline scheduling framework (Airflow)
Experience with schema design and dimensional data modeling
Exceptional candidates will have
Amazon Web Services (EC2, DMS, RDS) experience
Terraform and/or ansible (or similar) for infrastructure deployment
Airflow -- Experience building and monitoring DAGs, developing custom operators and using script templating solutions
Experience supporting production systems and developing on-call/incident management playbooks
Ability to work with team members located in multiple geographies and time zones.
Curious and interested in learning about the latest in data warehouse technology Interest and willingness to mentor junior team members
What we offer you
An inclusive and collaborative company culture - we work in an open environment while working together to get things done, and adapt to the changing needs as they come.
An opportunity to have an impact in a technologically data driven company.
Ownership over platforms and environments of an industry leading product.
Market competitive total compensation package.
Volunteer time off and charitable donation matching.
Strong support for career growth, including mentorship programs, leadership training, access to conferences and employee resource groups.
Regular hackathons to build your own projects and Engineering Lunch and Learns.
Great benefits package including health/vision/dental, unlimited PTO, 401k matching, travel reimbursement and more.
If this sounds like something you would like to be part of, we’d love for you to apply! Don't worry if you think that you don't meet all the qualifications here. The tools, technology, and methodologies we use are constantly changing and we value talent and interest over specific experience.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.",4.1,"Numerator
4.1","Chicago, IL",1001 to 5000 Employees,2004,Company - Private,IT Services,Information Technology,$100 to $500 million (USD)
Senior Pharmaceutical Development Scientist,"$18K-$82K
(Glassdoor Est.)","Company Description
Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.
In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.
In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description
With supervision as required, proficiently performs all assigned chemistry techniques. Demonstrates a good understanding of scientific principals and their cause and effect on scientific outcomes. Practice of GMP/GLP is routine. Once appropriately trained, this individual may be designated as a notebook reviewer. Authors and may review others protocols, reports, specifications and test methods. Presents results at team meetings with interpretation. Acts as a coach to junior staff.
Proficiently performs all assigned laboratory techniques.
Independently develops analytical methods on a variety of analytical techniques and instrumentation.
Independently performs method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience in operating and troubleshooting the following instrumentation:
Ultra-High Performance Liquid Chromatography
Differential Scanning Calorimetry (DSC)
Size Exclusion Chromatography
Multi Angle Light Scattering (MALS)
Fourier Transform Infrared Spectroscopy (FTIR)
Asymmetrical Field- Flow Fractionation (AFFF)
Dynamic Light Scattering (DLS)
Tutors and trains others on troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Designated notebook reviewer.
Generates, analyzes and presents scientific data at team meetings. Explains cause and effect relationships and may propose additional experiments to
prove/disprove hypotheses. Has a general understanding of the depth and breadth of drug development and can contribute to the scientific discussion during project team meetings.
Understand regulatory guidelines and can author protocols, reports and analytical test methods.
Generate and analyze scientific data and handle OOS's (Out of Specification) with little difficulty.
Has a good understanding of different plant manufacturing processes and can plan bench studies that will translate into a manufacturing process while solving related compounding, solubility, etc. problems.
Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development experience. Preferred education background in Analytical Chemistry, Pharmaceutics or similar discipline, however, extensive experience with analytical chemistry may be substituted for education.
Significant experience with the drug development process
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Strong analytical background
Liquid formulation experience is desirable
Product development experience in the pharmaceutical industry
Ability to meet deadlines
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information
Position is full-time, Mon-Fri 8:00am-5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",3.4,"Eurofins
3.4","Lake Forest, IL",10000+ Employees,1987,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (USD)
Senior Data Engineer,"$85K-$155K
(Glassdoor Est.)","Senior Data Engineer - Chicago, IL


Smarter Thinking. Real Results. Technology consulting has been our story for over 14 years. Companies from all industries partner with us for our innovative mindset to help them digitally transform to create market advantages, become resilient, and prepare for whats next. With us, the possible becomes actual.

We provide strategic and innovative consulting services focused on digital experiences, engineering, automation, data and analytics, and salesforce solutions. Saggezza consultants work as part of a global team, and throughout their tenure, have the opportunity to work on a variety of different projects across various clients and industries. We are chartered to do one thing, and one thing only to bring enabling technology to our clients that allow them to move their business forward.

We are currently looking to hire a Senior Data Engineer to join our team.

Each project will be different, but youll always be responsible for:
Working across multiple clients and industries to add value and strategic insights within data & analytics.
Providing proficiency in analyzing data and formulating insights/conclusions.
Building, developing and maintaining reporting systems that support key business decisions.
Helping clients reach solutions by utilizing data management & operations, data quality & governance, cloud transformation, self-service analytics & visualization, and data intelligence.
Working hands-on with SQL/SQL server & Python to deliver analytics to clients.
Examining and reporting results to stakeholders in leadership, technology, marketing, sales, and product teams.
From a cultural perspective, we look for individuals who possess the following qualities that will contribute to our success and the success of our clients:
Entrepreneurial spirit: We seek individuals who enjoy contributing to the growth of an organization and who show commitment to the success of their team.
Problem-solving skills: Individuals at our company have well-honed analytical skills coupled with business acumen to structure problems, deliver solutions, and communicate insights.
Drive: Our team sets ambitious goals and seeks energetic professionals, enjoy a fast pace environment, and thrive in taking on responsibility.
What Youll Definitely Need
A Bachelor's in Computer Science, Information Technology, Mathematics, Engineering or an equivalent field.
7+ years of practical hands-on experience working within data modeling, data extraction, data manipulation, and data warehousing concepts.
Minimum of 2+ years of practical hands-on experience working with SQL/SQL Server and Python for analytics and data science purposes.
Strong understanding of data modeling and entity-relationship diagrams
Experience writing complex SQL queries, including but not limited to stored procedures, functions, views, and triggers.
Knowledge of Indexes and how they can be used to enhance query performance.
Proficiency in modern data tools and cloud technologies would be advantageous, including but not limited to Spark, Hadoop, Tableau, AWS, Azure, Kafka, GCP & IBM Cloud.
Analytical mindset and business acumen. Self-motivated, individual contributor.
Great communication and data-oriented personality with strong problem-solving skills.
What We'd Love to See
Experience with analytic modeling in a scripting language (Python, R, etc.).
an understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc (Depending on specific project requirements).
Cloud certification, or any certification related to database or BI Tools.
Dont tick all the boxes? Dont worry about it: we still want to hear from you if you think youre the right person for the job.

Why Join Our Team?
Diverse culture, experiences, and skills.
Our nurturing and supportive environment fosters collaboration across the entire organization.
We are not hierarchical but operate as a flat surface where every opinion matters, ideas are cultivated and innovation is encouraged.
At Saggezza, we are fortunate to have a strong mentorship program that provides every one of our employees the ability to thrive professionally and personally.
We are only as good as our people. Saggezza, Italian for wisdom, is rooted from the perspective that knowledge is power. We create thought-leaders who are constantly exposed and trained in different technologies in the ever-evolving world of software development.
We welcome innovators with entrepreneurial spirits to grow with our team.
Consulting Magazine - Fastest Growing Firms 2019
Built-In Top Places to Work in Chicago 2020
Best and Brightest Companies in the Nation 2019 and 2020, Best and Brightest Companies in Milwaukee 2020 and Best and Brightest Companies in Chicago 2020
Saggezza is an Equal Employment Opportunity Employer: We believe in treating each employee and applicant for employment fairly and with dignity. We base our employment decisions on merit, experience, and potential, without regard to race, color, national origin, sex, sexual orientation, gender identity, marital status, age, religion, disability, veteran status, or any other characteristic prohibited by federal, state or local law.

Powered by JazzHR",4.2,"Saggezza
4.2","Chicago, IL",501 to 1000 Employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable
Senior Data Engineer,"$89K-$157K
(Glassdoor Est.)","Zurich is
currently looking for a Senior Data Engineer to work out of our North American
Headquarters in Schaumburg, IL.

This
position will be part of an Enterprise Data Initiative Team that will be
responsible for leveraging the value of the data assets throughout the
organization and will facilitate the development/implementation of the desired
end-state data environment. The
Enterprise Data Team will also be responsible for improving the organization's
decision-making capabilities by providing high quality, transparent data.

The
talented Senior Data Engineer will have experience working with very large data
sets and knowledge of building programs/mappings that leverage Hadoop and Cloud
technology platform(s) and Data warehouses (MPP) platforms. The Engineer will
also have significant knowledge of Big Data technologies and tools with the
ability to share ideas among a collaborative team.

In this
role, she/he will participate on core teams identifying and validating data
scenarios within the Enterprise. The candidate will need to demonstrate the
ability to develop actionable plans, recognize opportunities and be able to
report out on on-going progress. This role will require technical documentation
abilities and team coordination skills.

Client Internally Focused - The job’s
core deliverables rely on delivering service to internal clients, usually at
the line manager or employee level. May involve sharing subject matter
expertise to others in the organization or supporting others in their efforts
to deliver on our promise.

Basic Qualifications:
Bachelors Degree in Computer Science or Mathematics/Statistics and 6 or
more years of experience in the Data Engineering area
OR
High School Diploma or Equivalent and 8 or more years of experience in
the Data Engineering area
OR
Zurich Certified Insurance Apprentice including an Associate Degree in
Computer Science or Mathematics/Statistics and 6 or more years of experience in
the Data Engineering area
AND
5 or more of experience in Enterprise Data Engineering
Experience in scripting languages
Experience with data transformation and aggregation tools
Experience in data analysis, data interrogation or data profiling
Preferred Qualifications:
Experience with Cloud platforms and technologies,
like Azure, AWS, Databricks
Experience in scripting languages including Shell, Perl, Python, R, Java
Experience with replication tools, like Attunity
Experience with Big Data tools including Storm, Hive, Spark, Map Reduce,
Kafka, Flume, Tex, Pig, Oozi
Experience with ETL technologies; strong SQL and stored procedure skills
Experience with Dev/Ops
Strong verbal and written communication skills
Ability to work independently and interact effectively as part of a team
Insurance industry experience
Imagine working for a company that truly cares
about their employees, customers, stakeholders, and communities they serve.

Imagine working for a values-driven organization
that has the ambition and desire to be the best global insurance provider in
the world.

Zurich is that place where 55,000 employees across
200 countries and territories are all focused on helping people and helping
companies protect what is truly most important to them. We are a values-driven
organization that takes pride in the work that we do every day and we have the
ambition to be the best global insurer in the world.

EOE Disability / Veterans

Zurich does
not accept unsolicited resumes from search firms or employment agencies. Any
unsolicited resume will become the property of Zurich American Insurance. If you are a preferred vendor, please use our
Recruiting Agency Portal for resume submission.",3.2,"Zurich North America
3.2","Schaumburg, IL",10000+ Employees,1912,Company - Public,Insurance Carriers,Insurance,$500 million to $1 billion (USD)
Senior Data Engineer,"$104K-$187K
(Glassdoor Est.)","Senior Data Engineer at Belvedere Trading

Belvedere is looking for someone that is passionate about data and can help take our analytical capabilities to the next level. You will be instrumental in ensuring the availability, breadth, and reliability of data that uses to continuously make better technical and trading decisions. You will have the opportunity to actively take part in key decisions as we continue to advance our analytical capabilities. Our Data Engineers are responsible for data services including ETL pipeline implementation, data warehouse architecture, data quality automation, and integration.

You will help solve some of the hardest problems in a team environment, incrementally adapt to change in technologies, and business requirements. You will work on our platform to help ensure that our data quality is flawless. You will get the chance to work with a passionate team of engineers to solve challenging problems and ensure that we can deliver the best data to our traders that drive business insight.

What you’ll do
Design, build, maintain, and enhance analytical data models/structures in support of Belvedere’s analytical needs
Establish and ensure reliable flow and integration of data from internally and externally sourced data
Ensure reliable availability, integrity, and quality of data through automation
Partner with multiple stakeholders to deliver end-to-end analytics solutions
Collaborate with multiple cross-functional engineering teams to identify and address data gaps or inconsistencies
Determine reporting needs and integrate with business intelligence visualization tools
Research, evaluate, and recommend technical solutions for data collection, processing, and reporting
Create custom tooling, as necessary, to simplify the efforts of both the Business Intelligence team and end-users
What you’ll need
Experience designing and developing big data warehouses and ETL pipelines
Solid understanding and background building data structures and leveraging data stores optimized for analytical purposes
Proficiency and relevant experience with ETL and stream processing toolsets
Proficiency with one or more programming language(s) (ex. Python, C#, C++, Java/JavaScript, R)
Demonstrated ability to navigate and integrate data across multiple data platforms including RDBMS, NoSQL, and Time Series
Proven ability to research and implement innovative technologies and frameworks incrementally
Experience with Tick Data Store a plus (Kdb, OneTick, HDF5)
Excellent verbal and written communication, analytical, and problem-solving skills
Experience in Financial Services or Proprietary trading preferred
Education: Bachelor’s degree in Computer Science, Information Systems, Engineering, or related field.
Who we are

Belvedere Trading is a leading proprietary trading firm proudly headquartered in downtown Chicago. Our traders work hard to provide liquidity to the market through their market-making activities and are the masters of a diverse set of commodities, interest rates, exchange-traded funds (ETF), and equity index options. You name it, we trade it. This would not be possible without the dedicated efforts of our technology teams who utilize and perfect our innovative technology solutions.

Our Stance

Belvedere is an Equal Opportunity Employer and is committed to providing a non-discriminatory employment environment for its employees. Discrimination against employees and applicants due to race, color, religion, sex, national origin, disability, age, military, and veteran status is prohibited. Belvedere encourages initiatives to increase diversity and provide equal opportunity to all applicants and employees. Belvedere is committed to providing a positive environment in which team members are treated with respect, dignity, and courtesy. Our firm believes in a dynamic culture of inclusion and diversity, where people thrive on individual and organizational characteristics, values, experiences, and backgrounds.

Please note that Belvedere Trading does not accept unsolicited resumes from search firms or employment agencies. Any unsolicited resumes will become the property of Team Belvedere. No phone calls, please.
Job Status: Full-Time

Sponsorship: Not available for this position
Work Schedule: Regular and reliable on-site attendance during business hours

Amount of Travel Required: None

Through our efforts to provide a safe environment for you and our team members, all interviews for this position will be conducted virtually via phone or video. We will continue to actively hire and onboard new team members virtually through the remainder of the year unless otherwise noted. Any questions regarding the virtual recruiting process, please reach out to recruiting@belvederetrading.com.",3.5,"Belvedere Trading
3.5","Chicago, IL",201 to 500 Employees,2002,Company - Private,Venture Capital & Private Equity,Finance,Unknown / Non-Applicable
Sr. Data Engineer,"$58K-$110K
(Glassdoor Est.)","The Sr. Data Engineer is a hands-on role responsible for building and maintaining big data pipelines to support advanced analytics and data science solutions. The sr. data engineer identifies and deeply understands valuable internal and external data and collaborates closely with data scientists to wrangle data for the design, development, and deployment of new solutions that support CGI’s strategic business priorities.

Requirements:
Bachelor’s degree in computer science or related quantitative field of study
4+ years of hands-on professional data engineering experience
Experience building and optimizing data pipelines, datasets, and architectures
Strong experience working with Python, Pandas, and Spark
Highly skilled in manipulating big data using HDFS/Hadoop ecosystem tools
Strong knowledge of distributed computing and performance optimization
Familiarity with modern machine learning techniques
Exceptional problem solving and analytical thinking and skills
Teamwork and collaboration
Strong communication skills
Excellent organizational skills
Natural sense of urgency, teamwork, and collaboration reflected in daily work ethic
Proficient in Microsoft Office
Preferred Requirements:
Master’s degree in computer science or related quantitative field of study
2+ years of professional experience delivering engineering for advanced analytics or data science solutions
Agile methodologies
Data visualization tools, including Qlik
Responsibilities:
Develop and maintain optimal data pipelines into the advanced analytics platform, including design of data flows, procedures, and schedules
Collaborate with data scientists to prepare data for model development
Understand and contribute to the models and machine learning methods developed and deployed
Collaborate with stakeholders and advanced analytics business partners to understand business needs and translate requirements into scalable data engineering solutions
Collaborate with sr. data architect on the enhancement of the advanced analytics platform
Collaborate with data visualization and reporting application developers to ensure the sustainability of production applications and reports
Update and modify data pipelines to ensure ongoing quality for production solutions, including the identification, design, and implementation of improvements in processing of data
Provide leadership to third-party contractors
Protect Chamberlain’s reputation by keeping information confidential
Maintain professional and technical knowledge by attending educational workshops, professional publications, establishing personal networks, and participating in professional societies.
Contribute to the team effort by accomplishing related results and participating on projects as needed
The Sr. Data Engineer role offers a competitive base salary and excellent benefits including medical, dental, vision, 401(k) with company match, and more! We're an organization who values its human capital and provides support to assist its employees succeed.
Chamberlain Group is proud to be an Equal Opportunity Employer. You will be considered for this position based upon your experience and education, without regard to race, color, religion, sex, national origin, age, sexual orientation, ancestry; marital, disabled or veteran status. We are committed to creating and maintaining a workforce environment that is free from any form of discriminations or harassment. Chamberlain Group conducts background checks and drug screens for candidates who receive employment offers.",3.2,"Chamberlain Group Inc
3.2","Oak Brook, IL",1001 to 5000 Employees,1954,Company - Private,Consumer Products Manufacturing,Manufacturing,Unknown / Non-Applicable
Big Data Machine Learning Engineer,"$57K-$103K
(Glassdoor Est.)","Title: Big Data Machine Learning Engineer@ Chicago, IL
Terms of Hire: Full Time.
Salary: $Open+ Benefits.

The candidate can also work from any of these locations:
Chicago, IL, US
Cleveland,OH,US
Washington,DC,US
Job description

ABOUT THE JOB

The Decision Sciences team is part of the Enterprise Payments and Analytics organization. Its mission is to lead Client’s journey to become an innovative, data driven enterprise by building advanced analytics solutions for solving business problems. Our experienced team of AI/ML and Data Science practitioners focuses on engaging, enabling, and empowering decision-makers across the enterprise by developing, managing and supporting advanced analytics products and scalable digital solutions, such as real time and on demand predictive models and prescriptive analytics, and continuously researching, specifying, and deploying next-generation analytics capabilities. We are an internal consulting and services organization that works directly with users across the firm, including Lines of Businesses and partners in Enterprise Strategy, Marketing, Data Analytics, and Enterprise Architecture, to facilitate the development of innovative solutions that help Client compete and win with analytics.

The Big Data ML Engineer fills a critical data, analytics, technology support, and innovation role for the business analytics and advanced analytics functions within the organization. The Engineer is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organization’s enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS

The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use cases—primarily focused around open source technologies including cloud infrastructures. This individual evaluates short/long-term business needs required to support Client business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on Client Enterprise systems. Under the guidance of the Group’s Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on Client data assets for business decision management solutions. The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions. The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions. The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organization’s AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.

REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
What are the 3-4 non-negotiable requirements on this position?
1. Experience in open source technologies (Python, Hadoop, Spark, etc.) 2. Experience in Cloud environment, Google Cloud platform preferred 3. Machine learning expertise
What are the nice-to-have skills?
Finance/banking background
You Will Enjoy:
An opportunity to be a part of a great culture, an awesome team, a challenging work environment, and some fun along the way!
Apply today to learn more and be part of our Growth story.
All applications will be kept strictly confidential and once shortlisted, our team will be in touch with you for further discussions.

Department: Scout
This is a full time position",3.3,"Cedent Consulting
3.3","Chicago, IL",1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD)
Senior Data Engineer,"$71K-$126K
(Glassdoor Est.)","WW is looking for candidates to help change people’s lives. We are a global wellness technology company inspiring millions of people to adopt healthy habits for real life. We do this through engaging digital experiences, face-to-face workshops and sustainable programs that encourage people to move more, shift their mindset and eat healthier while enjoying the foods they love. By drawing on over five decades of experience and expertise in behavioral science, we build communities in order to deliver wellness for all.

To learn more about WW and jobs with a purpose, visit ww.com.

Position: Senior Data Engineer (Remote)

Location:New York City

Experience: 6-10 years

Reporting to: Director, Data Engineering

Job Description


At WW, we are re-imagining engineering in and around our data infrastructure, architecture, pipeline, flow and security. We are building a modern data lake fed by batch and streaming pipelines creating incremental value from our data. We are implementing a data catalog, glossary and dictionary solution to make our data search and discoverable propelling data democratization, enhancing data quality and data security. We are reimagining and replacing old data pipelines with modern architecture and technologies. It’s an exciting time for WW Data Org and Data Engineering is driving the excitement.

If you would like to be part of this exciting journey, help building our modern data engineering solutions and set yourself up for an impressive learning and career growth potential, we have an opportunity for you. If you feel passionate and excited to design and build data engineering solutions on Google Cloud Platform (GCP), we shall talk.

Roles and Responsibilities
Lead design, development, implementation and support of end-to-end data pipeline for centralized data lake on cloud
Design and implement streaming data analytics platform using moder cloud based and open source technologies and Python/JavaScript/Scala programing language
Build data catalog, data dictionary and make data searchable for our stakeholders and users
Work with various Google Cloud Platform (GCP) technologies, Kafka, Airflow, Metadata Management tool, Data Quality (DQ) tool, Cloud-Native Microservice architecture, CI/CD, Dev/Ops and much more
Design and implement data security, access control (including fine-grained) and compliance solutions to safeguard our data
Work with high volume (100s of TB), high velocity (real-time stream), high complexity (heterogeneous) data from hundreds of sources e.g. social media, click stream, e-commerce etc.
Mentor and guide junior team members, if hired at a senior position
Effectively communicate data governance initiatives and values to stakeholders
Experience & Skill Set
If you have done similar works as above for 4 years or more, have some of the skillsets from below list and feel passionate and excited doing it again at WW, you have the right experience and skill sets. Let us talk
Experienced of architecting and implementing modern data platform (data lake or data warehouse) with batch and streaming data ingestion and processing on GCP or AWS cloud
Solid understanding of fundamental architecture and working principle of relational database, NoSQL database, massively parallel processing (MPP) database, distributed processing framework (MapReduce/Spark etc.), pub/sub messaging/streaming platform (e.g. Kafka, Google Pub/Sub, Kinesis)
Experienced in SQL query, data manipulation language (DML) and data definition language (DDL) including hands-on experience of managing database tables and views
Experienced of building Data App or Data Pipeline using Java/Python/Scala/Go programing language(s)
Experienced and willing to lead and manage work for junior data engineers on the team
Possess excellent work ethic, positive attitude to work and good verbal communication
Can effectively document, present and pursue solution design and idea to stakeholders / teams
Excellent work ethic, positive attitude to work and good verbal communication
We hire only the best people. Here are the benefits to being top-notch:
Competitive compensation and profit-sharing plan
A 401K plan to help you plan for your future, plus company match
Health care coverage starting on your first day
Tuition reimbursement and online courses to help you reach your career aspirations
Commuter benefits
Yearly well-being allowance for your physical, financial, social and emotional well-being
Free WW membership for you plus 3 free WW memberships for your friends and 3 for your family
Free fruit, snacks and coffee to get you through your day
Summer Fridays, happy hours, and company outings
Robust employee referral bonuses
Developmental opportunities and assignments to grow your career",3.3,"WW International
3.3","Chicago, IL",10000+ Employees,1961,Company - Public,"Health, Beauty, & Fitness",Consumer Services,$1 to $2 billion (USD)
Data Engineer - Data Strategy Senior Consultant,"$87K-$152K
(Glassdoor Est.)","Job Description
If you are passionate about making a difference in the work you do, being recognized for your talent and expertise in solving complex and challenging analytical/data problems while contributing to the success of key strategic initiatives, consider growing your career with a Fortune 5 healthcare leader!

As a member of the Analytic Development organization you will be responsible for the design, development and delivery of analytic solutions. You will collaborate with business partners from product development and management, operations, finance, and marketing to demonstrate value of CVS Caremark products and services. You will enable data-driven strategic decision-making and identify opportunities for existing product improvement and new product development. Your experience will include translating business needs into analytic questions, using SAS and SQL to access data and develop Tableau dashboards. In this exciting role, you will design and conduct rigorous analyses of pharmacy claims, medical claims and other data translating your analytic findings for appropriate business and customer audiences.

Required Qualifications
0-2 years of experience in an educational/professional setting in the following areas:

. Data analysis, cleansing, transformation, advanced analytics etc.
. Collaboration with key internal and external stakeholders such as Hospitals, Administrators and Business Stakeholders in gathering and analyzing needs and understanding reporting requirements;
Designing and implementing robust analytic and reporting solutions to support identified needs;
Accessing data, design summary data layers and manipulate large datasets to support planned analyses, using SAS, SQL and similar tools;
Assessing existing available data, identifying data gaps, and collaborating with business partners to develop approaches to close data gaps;
Testing and validation of summary data layers and reporting tools to ensure the results match the expected outcome;
Constructing and delivering reports of analytic findings in a variety of formats (reports, PPT etc.), including visualization of data and findings.

Preferred Qualifications
Capability to build dynamic dashboards using Tableau;
Experience communicating complex technical subjects to technical and non-technical audiences, such as but not limited to training analytic and business users on how to use data layers and reporting tools, including development of documentation and training materials;
Capability in managing complex projects related to healthcare analytics
Independent, curious, eager to tackle a wide variety of problems and able to quickly develop knowledge and understanding of new domains and underlying data sources.
Excellent written and oral communication skills.
Experience developing, testing, documenting and maintaining standardized outcome metrics meeting diverse business needs.
Experience developing, implementing, testing, and maintaining methodologies for standardized and repeatable reporting for internal and external audiences.
Ability to interact with and influence decision-making by non-analytical business audiences.
Experience in test-and-learn analytic concepts as applied to patient communications in a healthcare or related setting.
Working knowledge of statistical methods.
Good understanding and experience with predictive analytics and descriptive analytics.

Education
Bachelor's degree is required.
Advanced degree in a qualitative field preferred.

Business Overview
At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.",2.9,"CVS Health
2.9","Northbrook, IL",10000+ Employees,1963,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
Azure Data Modeler,-1,"Great opportunity to show off your passion for data, reporting, analytics and data warehousing. Our client's BI team may have the perfect fit for you!

We are looking for a self-motivated Data modeler/Engineer to join our business intelligence team.

This individual will be responsible for developing and maintaining business intelligence, data warehousing and data engineering solutions for Enterprise data This individual will also create and maintain detailed business requirements, outlining data problems, opportunities and solutions.

Responsibilities Include:
Responsible for designing relational and non-relational data stores on Azure.
Responsible for designing and developing solutions in Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, SQL Data Warehouse, HDInsight.
Gather and process raw data at scale that meet functional / non-functional business requirements (including writing scripts, REST API calls, SQL Queries, etc.)
Responsible for developing data set processes for data modeling, mining and production.
Responsible for building new Data Lake in Azure, expanding and optimizing our data platform and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
Responsible for supporting our Software Developers, Data Analysts and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Develop complex SQL queries in TIBCO Data Virtualization tool.
Qualifications:
3+ Years of experience architecting and building Data Lake, Azure Big Data architecture, Enterprise Analytics Solutions, and optimizing ' big data' data pipelines, architectures and data sets.
Bachelor’s Degree in Computer Science, Information Systems, or related field
Advanced hands-on SQL, USQL, Python, C#, Java, pySpark (2+ of these) knowledge and experience working with relational databases for data querying and retrieval.
Experience with Design and Architecture of Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure ML, SQL Data Warehouse, HDInsight.
Experience with building processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience working with cross-functional teams in a dynamic environment.
Experience building Big data pipeline with Java and/or Python a plus.
Strong SQL skills on multiple platform
Data Modeling tools (e.g. Erwin, Visio) knowledge a plus.
Experience with SAP HANA a plus.
Experience with Talend a plus.
_Brooksource provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws_

Job Types: Full-time, Contract

Pay: $45.00 - $50.00 per hour

Benefits:
Dental Insurance
Health Insurance
Paid Time Off
Vision Insurance
Schedule:
8 Hour Shift
Day shift
Monday to Friday
Experience:
Azure Big Data architecture: 3 years (Required)
Architecting and Building Data Lake: 3 years (Required)
Developing complex SQL Queries: 3 years (Required)
Enterprise Analytics Solutions: 3 years (Required)
Full Time Opportunity:
Yes
Work Location:
One location
Benefit Conditions:
Waiting period may apply
Work Remotely:
Temporarily due to COVID-19",4.5,"Brooksource
4.5","Northfield, IL",501 to 1000 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Senior Data Science Consultant,-1,"Senior Data Science Consultant
Healthcare
Chicago, IL
$135,000 - $155,000 + Benefits + Bonus

Are you passionate about joining one of America's most famous organizations in the healthcare/ pharmaceutical space? A leading healthcare company is looking for an experienced Senior Data Science Consultant who is technically strong in R, SQL, Python, and Tableau, to advise in implementing solutions through an analytical lens to drive business growth.

THE ROLE:

As Senior Data Science Consultant, you will be partnering with Data Scientists and mentoring junior team members in implementing and framing solutions for making certain treatment programs more efficient. You will be responsible for:

Navigating huge and complex claims data
Performing advanced analytics using Python, R, SQL, and Tableau
Consulting with internal clients to identify opportunities for which you can implement data science
Acting as analytics product owner translating business needs into analytics actions and projects

YOUR SKILLS AND EXPERIENCE:

Strong understanding of managed healthcare space
Proven commercial experience in working with claims data at a large company
Proficient in R, Hadoop, Python, SQL, and Tableau
Proficient in mathematical analysis methods, machine learning, statistical analysis, and predictive modeling
Strong understanding of advanced analytical tools and languages needed to analyze large sets of complex and messy data from multiple sources
Proven experience in strategy consulting, as well as managing or leading teams
Bachelor's degree and Master's in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline; PhD preferred

BENEFITS:

As Senior Data Science Consultant you can expect to earn up to $155,000 (depending on your experience) plus great benefits and of course, great healthcare!

HOW TO APPLY:

Please register your interest by sending your resume to George Little via the Apply link on this page.

KEYWORDS:

Healthcare, pharmaceutical, data science, advanced analytics, consultant, consulting, advisor, Python, R, Hadoop, Tableau, SQL, machine learning, predictive models, predictive analysis, statistics, claims data, engineering, project management, product owner, strategy",4.2,"Harnham
4.2","Chicago, IL",51 to 200 Employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Big Data Machine Learning Engineer,-1,"Title: Big Data Machine Learning Engineer@ Chicago, IL
Terms of Hire: Full Time.
Salary: $Open+ Benefits.

The candidate can also work from any of these locations:
Chicago, IL, US
Cleveland,OH,US
Washington,DC,US
Job description

ABOUT THE JOB

The Decision Sciences team is part of the Enterprise Payments and Analytics organization. Its mission is to lead Client’s journey to become an innovative, data driven enterprise by building advanced analytics solutions for solving business problems. Our experienced team of AI/ML and Data Science practitioners focuses on engaging, enabling, and empowering decision-makers across the enterprise by developing, managing and supporting advanced analytics products and scalable digital solutions, such as real time and on demand predictive models and prescriptive analytics, and continuously researching, specifying, and deploying next-generation analytics capabilities. We are an internal consulting and services organization that works directly with users across the firm, including Lines of Businesses and partners in Enterprise Strategy, Marketing, Data Analytics, and Enterprise Architecture, to facilitate the development of innovative solutions that help Client compete and win with analytics.

The Big Data ML Engineer fills a critical data, analytics, technology support, and innovation role for the business analytics and advanced analytics functions within the organization. The Engineer is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organization’s enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS

The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use cases—primarily focused around open source technologies including cloud infrastructures. This individual evaluates short/long-term business needs required to support Client business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on Client Enterprise systems. Under the guidance of the Group’s Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on Client data assets for business decision management solutions. The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions. The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions. The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organization’s AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.

REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
What are the 3-4 non-negotiable requirements on this position?
1. Experience in open source technologies (Python, Hadoop, Spark, etc.) 2. Experience in Cloud environment, Google Cloud platform preferred 3. Machine learning expertise
What are the nice-to-have skills?
Finance/banking background
You Will Enjoy:
An opportunity to be a part of a great culture, an awesome team, a challenging work environment, and some fun along the way!
Apply today to learn more and be part of our Growth story.
All applications will be kept strictly confidential and once shortlisted, our team will be in touch with you for further discussions.",-1,CEDENT,"Chicago, IL",1 to 50 Employees,-1,Contract,Computer Hardware & Software,Information Technology,Less than $1 million (USD)
Big Data Machine Learning Engineer,-1,"Thusa is looking for Big Data Machine Learning Engineerto join the team. The ideal candidate is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organizations enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS
The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use casesprimarily focused around open source technologies including cloud infrastructures.
This individual evaluates short/long-term business needs required to support key business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on the Enterprise systems.
Under the guidance of the Groups Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on key data assets for business decision management solutions.
The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions.
The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions.
The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organizations AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.
REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
Thusa is dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock. dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock.

Our employees enjoy a work culture that promotes company priorities.

We treat our employees like family while providing on-going support for growth. We are not only looking for people who can do the job, we are also looking for our future leaders.

Powered by JazzHR",-1,Thusa Solutions,"Chicago, IL",-1,-1,-1,-1,-1,-1
Kafka Data Engineer (remote),"$62K-$114K
(Glassdoor Est.)","Summary
We exist to help people achieve financial clarity. At Thrivent, we believe money is a tool, not a goal. Driven by a higher purpose at our core, we are committed to providing financial advice, investments, insurance, banking and generosity programs to help people make the most of all they’ve been given.

At our heart, we are a membership-owned fraternal organization, as well as a holistic financial services organization, dedicated to serving the unique needs of our clients. We focus on their goals and priorities, guiding them toward financial choices that will help them live the life they want today—and tomorrow.

Join our newly created Data Office as the full-time Kafka Data Engineer! We are hiring for both a mid-level and a senior level Engineer. Bring your expertise in implementing modern data architectures and Data Streaming. We have a data streaming platform to enable frictionless data flow from business systems and 3rd party sources using publish/subscribe model. This role will require experience with hybrid platforms, cloud migration, publishing, development with newer technologies such as Spring Boot, KSQL/Stream Processing, data connectors such as Kafka, performance tuning, data quality and data visualization knowledge. You and will report to the Director of Information Delivery.
Job Description


Job Duties and Responsibilities
Partner on the design, deployment, and persistence of our new streaming platform unifies the data across organization, using Confluent Kafka.
As the senior level Engineer, you will be leading a group of engineers.
Design, Develop, Release & Support containerized microservices (OpenShift / Spring Boot) to transform and enrich topic data.
Lead reusable design and patterns for services and data processes within the platform.
Partner on setting standards, implementing tools, and creating documentation for self-serve data pipeline services supporting core engineering and professional services use cases.
Work with existing engineering teams to become data producers and consumers to and from Confluent Kafka.
Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.
Apply business knowledge and experience to effectively advise others on technology as an enabler.
Lead efforts to analyze IT industry and market trends and determine potential impacts.
Develop concepts and constructs necessary to create technology-enabled business systems.
Influence technology direction.
Provides thought leadership and execution to large complex efforts.
Utilize breadth of technical understanding and dive deep when necessary.
Consult on and manage initiatives to ensure alignment across multiple business and IT areas.
Proactively mitigate risks across multiple assets, information domains, technologies & platforms.
Provide leadership, mentoring and technical guidance to others to drive initiatives.
Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.
Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.
Act as a change agent to continuously improve and move the organization forward.
Accountable to provide leadership to successfully deliver the right results on initiatives in a timely and effective manner.
Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.
Ability to work within a diverse team of skillsets and experience levels to deliver results.
Required Job Qualifications
Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field.
5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years of lead experience.
Strong experience with event streaming such as (Kafka or Amazon Kinesis).
Experience with SQL and NoSQL databases (PostgreSQL, MongoDB, etc).
Proficient delivering services within AWS.
Experience with Confluent Kafka, penShift / SpringBoot is preferred.
Demonstrated ability to develop containerized microservices (Docker with Kubernetes) is preferred.
The ability to communicate cross-functionally, derive requirements and architect shared datasets; ability to synthesize, simplify and explain complex problems to different types of audiences.
Desire to show ownership of problems you identify and proven ability to empower others to get more done.
Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color, sex, gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state, or federal law. This policy applies to all employees and job applicants.

Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation, please let us know by sending an email to human.resources@thrivent.com or call 800-847-4836 and request Human Resources.",3.5,"Thrivent
3.5","Chicago, IL",5001 to 10000 Employees,1902,Nonprofit Organization,Insurance Carriers,Insurance,$5 to $10 billion (USD)
Director of AI Product Management - Office of Data Science,"$68K-$121K
(Glassdoor Est.)","Advance your career at Liberty Mutual Insurance - A Fortune 100 Company!

Help bring Liberty Mutual into the future by advocating on behalf of all data scientists across the enterprise. The Director of AI Product Management will be a key member of the Office of Data Science Product Team. As the Director of AI Product Management you will advocate for DS efforts across the enterprise by acting as Product Owner over a team of ML engineers, helping to identify, measure and socialize DS initiatives and partnering with technology, business and the data science community (DSPRG) to promote collaboration and reuse. Liberty Mutual aspires to be the data science leader within the insurance industry and you will play a key role in partnering across the organization to make this happen.

Roles and Responsibilities:
Strategic Vision
Partner with the ODS Science team to engage the enterprise and identify top business opportunities for ML application (e.g. CV, NLP, Aerial Imagery, and Trusted AI).
Measure the value of data science at Liberty and communicate it to the enterprise.
Customer / Collaboration
Foster relationships across the LM enterprise. Promote and build excitement for data science.
Act as a change agent across the organization by influencing and driving strategic direction and investments in AI.
Collaborate with and influence key stakeholders and customers to embrace a product mindset and drive business outcomes.
Partner with the business, tech and data science leaders to jointly drive forward efforts to enhance DS/AI collaboration.
Model Deployment
Act as the product owner for a ML Engineering squad tasked with deploying models delivering ~$100M (and growing) in value to the enterprise.
Manages the existing program, onboards new customers and socialize the value of the portfolio
Vendor
Support DS and ML vendor engagements and purchasing decisions as the organization makes build vs buy vs research decisions
Key traits we are looking for:
Data Science Passion - you have a passion for making things better through data science.
Leadership - You are a passionate leader who can bring the enterprise together, gain cross team alignment and deliver results.
Customer Empathy - ability to try on the experiences of customers and stakeholders - especially those with conflicting viewpoints.
Problem solving - you can solve difficult problems efficiently with appropriate methodologies
Integrity - you build and maintain trust with your colleagues, stakeholders, partners, and leaders
Drive - you work smart and hard to succeed
Communication Skills - you can communicate to a wide variety of audiences adapting your technique as appropriate in a strategic manner
Qualifications:

A minimum of three years recent experience in a DS or technology product role with a proven track record of providing leadership on complex / challenging technical product delivery.
Demonstrated ability to think broadly across multiple good viewpoints
Knowledge of DS applications, DS infrastructure needs, and organizational challenges & obstacles as it relates to vetting, prototyping and scaling DS solutions
Excellent communication, analytical, interpersonal, organizational and team building skills, business judgement, and proven expertise in directing the efforts of agile teams
Experience of strongly influencing product strategy at a senior level and leading organizational change
Ability to continuously prioritize development based on business value and product strategy
Ability to create and foster consensus from the whole business for a coherent product vision
Ability to estimate ROI of complex projects

Benefits:
We value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits
Overview:
At Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.
We're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.",3.5,"Liberty Mutual Insurance
3.5","Warrenville, IL",10000+ Employees,1912,Company - Private,Insurance Carriers,Insurance,$10+ billion (USD)
Sr. Data Engineer,"$75K-$140K
(Glassdoor Est.)","At Echo we are committed to help our Associates grow their career. Apply today and grow with Echo!
-
-",3.5,"Echo Global Logistics
3.5","Chicago, IL",1001 to 5000 Employees,2005,Company - Public,Transportation Management,Transportation & Logistics,$2 to $5 billion (USD)
Senior Data Engineer,-1,"Are you interested in building the future of healthcare and transforming the patient experience? Are you hopeful about what data and medical research can do to improve medicine? We’re looking for a Senior Data Engineer to ensure PatientIQ remains on the forefront of using data to drive positive healthcare outcomes.

As a core member of the Analytics department, you will be in a dynamic environment that is actively building the future versions of our automated data science platform - Analytics Autopilot. In addition, our team often works cross-functionally with the Engineering, Product, and Sales departments as PatientIQ scales its business. Your work will involve coming up with new software features, defining metrics, streamlining existing data processes, and mentoring other team members. We heavily value diligence, curiosity, and initiative, as those are key to unlocking the value of PatientIQ's data for our users and our decision-making. Your work will be impactful across the entire organization.

Role Responsibilities
Design, develop, and maintain ETL infrastructure to support the ingestion of external data sources
Work on a cross-functional team to design, develop, and maintain PatientIQ's internal reporting infrastructure
Understand data requirements and implement solutions for data science applications
Perform unit and integration testing
Mentor junior team members
Help scale PatientIQ's data strategy as the platform and business grows
Requirements

Ideal Qualifications
Experience designing, building, and maintaining ETL infrastructure in a production setting
BS/MS in Computer Science, Engineering, Mathematics, or related field
Proficient in Python or another object oriented programming language
Deep knowledge of SQL and at least one database technology
Experience with software development lifecycle processes and using version control systems (git), either from prior data engineering work or in a more traditional software engineering setting
Highly self-motivated with strong analytical problem-solving skills and attention to detail
Nice to Haves
Experience with workflow management systems such as luigi or airflow
Experience in machine learning and/or business intelligence
Experience with cloud technologies such as AWS, Google Cloud Platform, or Azure
Experience with ETL tools like Apache Kafka, Logstash, Segment, Informatica
Experience with automated machine learning technologies such as Amazon SageMaker or Google Cloud AutoML
Experience with cloud data warehouse platforms such as Snowflake, Qubole, etc.
Experience working in Healthcare, Finance or another regulated industry
Benefits
Great Benefits - top-notch health, dental and vision insurance. Additional perks available including 401K.
We are Mission Driven - our team is motivated to solve complex problems, drive medicine forward, and ultimately improve patient outcomes.
True Idea Meritocracy - great ideas win out. We encourage all team members to challenge the status quo because our mission demands this.
Flexible Time Off - we trust you to take the time you need when you feel it is appropriate, given your workload and responsibilities. No need to track it or save up.
World-Class Team - we’re at the top of our industry because of our employees. They’re the best investment we can make, and we never forget that.
Fast Growing - we are building the largest platform for healthcare providers, industry partners, researchers, and others to collaborate on the mission to improve patient outcomes.",-1,PatientIQ,"Chicago, IL",-1,-1,-1,-1,-1,-1
Big Data Architect,-1,"Our Client is a leader in data-driven marketing, named as one of the top 20 data integrators to watch and grow with. Our Client delivers insight and results to their customer with marketing expertise, technical and analytic capabilities, and a relentless focus on the customer. Business model based on driving lasting customer relationships and incremental brand revenue through integrated systems, online and offline CRM, real time predictive modeling, and data management.

The Big Data Architects primary responsibilities are to create and develop solution designs to integrate and ingest data from various resources, supporting Clientss internal big data ecosystem.

They will be responsible for defining the big data architectural blueprint under the supervision and collaboration with the Technology Solutions Director. The Architect will work closely with data engineers, cloud engineers, and data scientists to design and implement optimum solutions using best practices. They are responsible to ensure the data ecosystem is built to be highly scalable, responsive, and available.

The Big Data Architect oversees the implementation of data solutions by working with Clients onshore and offshore engineering teams to create ETL, batch, real-time, and automated processes. As part of the core Technology Solutions team the right candidate will heavily contribute to the teams coding and programming standards and ensure other team members are following the guidelines and standards.

Responsibilities:


Take ownership of data solutions from design and architecture perspective for projects in presales phase as well as on-going projects

Select and integrate any Big Data tools and frameworks required to provide requested capabilities. Can oversee the implementation by team members of said solutions

Design and implement ETL and automated processes

Monitor performance and advise of any necessary improvements and changes

Management of EMR clusters, Glue Jobs, Athena Tables, S3 data lakes; with all included services

Provide technical support to members of TS and SA team, as well as project support across client engagements

Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value

Stays current with relevant technology in order to maintain and/or improve functionality for authored applications

Assume other responsibilities as requested/required

Acts as a subject matter expert for systems worked on

Ensures Clients data solutions are using the latest versions and code base

Actively listen to and work with end users to gather feedback and input, and make suggestions and solutions based on said feedback

Requirements

Required Experience:
(7 years of relevant experience) or (5 years of relevant experience and an advanced degree in Computer Science/IT or related field)

Keen understanding of distributed computing principles
• Proficiency with Big Data frameworks such as Hadoop, Spark, MapReduce, HDFS.

Proven experience ingesting data from multiple data sources such as REST API, SFTP flat files, Streaming data etc.

Proven experience with Big Data querying tools such as Athena/Presto, Pig, Hive, and Impala

Proven experience with NoSQL databases, such as HBase, Cassandra, Redshift, DynamoDB

Proven experience with various ETL techniques and frameworks, such as Flume, Glue Jobs, Step Functions

Proven experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O

Proven experience with AWS Lambda and leveraging it in various solutions such as Glue, Step Functions, CloudWatch, S3 Events, etc.

Strong experience with using Python scripts & libraries

Experience desired with Database Warehousing Design Concepts; Dimensional.
• Modeling, Star/Snowflake Schemas, ETL/ELT, Data Marts, Analytic Playgrounds, Reporting techniques

Experience working with Agile software development methodologies, namely Scrum

Proven experience with team collaboration, release management, system and performance monitoring

Ability to work well with people from many different disciplines and varying degrees of technical experience

Excellent analytical, problem resolution, organization and time management skills

Ability to handle multiple tasks at a time
• Demonstrated ability to have successfully completed multiple, complex technical projects and create high-level design and architecture of the solution, including class, sequence and deployment infrastructure diagrams

Prior experience with application delivery using an Onshore/Offshore model
• Experience with gathering end user requirements and writing technical documentation

Keyword: Hadoop, Spark, MapReduce, HDFS, REST, API, SFTP, Athena, Pig, Hive, Impala, NoSQL, HBase, Cassandra, Reddrift, DynamoDB

Benefits


We do have a full benefit package of medical/dental/vision insurance, disability, life, 401k employer match along with profit sharing and bonus. Optional benefits is AFLAC plans and FSA for medical or childcare.

Vacation, 5 Sick Days and 2 personal days with a total of about 30 days off within a year depending on when holidays fall. Included in that is the close of the office between Christmas and New Years.",-1,DSMHConsulting,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"Candidate Responsibilities

Develop implementation patterns leveraging AWS technologies to support Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solution Data Designs, Models, Pipelines
Prototype New Solutions Technical guidance to data designers and
developers Solution Implementation Reviews Open to Chicago, IL as well.

Typical Day

Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solutions with Platform, Business, and Application teams

Requirements


Education Requirements:

B.S. in Computer Science, Information Systems, or related major or
equivalent IS / business experience. 10+ years experience designing,
implementing data persistance and processing solutions AWS
Certifications

Technical Skills

AWS Cloud Based Technologies for Data Processing and Persistance
(DynamoDB, S3, Aurora, Kinesis, SQS,SNS, Lambda, Fargate, Glue) Ability
to design and communicate solutions to meet business and technical
requirements Demonstrated Data Architecture and Design
for Big Data, Analytics, and applications

Soft Skills

Written and Verbal Communication Able to produce architecture and design artifacts in Visio and Office 365",-1,DSMHConsulting,"Chicago, IL",-1,-1,-1,-1,-1,-1
Staff Big Data Engineer,"$95K-$171K
(Glassdoor Est.)","Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry. Our technology handles hundreds of thousands of transactions per second; collects tens of billions of events each day; and evaluates thousands of data-points in real-time all while responding in just a few milliseconds.

We are looking for an experienced Big Data Engineer to join our Data Engineering team. This position will be the Senior technical resource driving architecture for the integration of large 3rd party partner integrations with companies like Facebook, Google and Twitter to name a few. The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. This position will require the ability to own and lead data initiatives on a cross-functional team.The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. You should be able to not take yourself too seriously as well. And most of all, you will enjoy working with great people who are changing the entire industry.

What you'll do:
Migrate existing data pipelines from on-prem regional data centers to AWS and GCP.
Architect a new modern event driven architecture with both batching and streaming
Adjust existing pipelines to fit the AWS processing model such as integration with S3, migrate to open source version of hadoop, adjustments to security model, etc...
Working on Big Data technologies such as Hadoop, MapReduce, Kafka, and/or Spark in columnar databases
Architect, design, code and maintain components for aggregating tens of billions of daily transactions
Lead the entire software lifecycle including hands-on development, code reviews, testing, deployment, and documentation for streaming and batch ETL's and RESTful API's
Partner and work closely with the QA Engineers to develop automated tests
Participate in training and mentoring of junior team members
You should apply if you have most of this:

(We have flexibility in this role to consider more, or marginally lesser, experience than requested below)
8+ years of experience designing and building data-intensive applications
5+ years architecting systems in a big data ecosystem using MapReduce, Spark, MPP Data Warehouses, and sql/nosql databases.
5+ years recent hands-on experience with object oriented languages (Java, Scala, Python)
5+ years Hands on experience building production level systems in a cloud environment (AWS or GCP)
Excellent interpersonal and communication skills in English
Proven experience leading the design and execution of event driven architectures for distributed systems
Experience designing systems for performance, scalability, and reliability
In-depth understanding of object oriented programming concepts
Low level working knowledge of collections, multi-threading, JVM memory model, etc.
Solid understanding of database fundamentals and SQL
Understanding the full software development life cycle, agile development and continuous integration
Ability to clearly communicate with team-members in a cross-matrix environment
What puts you over the top:
Built systems in a containerized environment with familiarity in Docker, ECS, Kubernetes
Exposure to Data Warehousing solutions like Snowflake and BigQuery
Prior ad tech experience
About Integral Ad Science

Integral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 18 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit integralads.com.

Equal Opportunity Employer:

IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.

California Applicant Pre-Collection Notice:

We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.

To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN

Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.",3.5,"Integral Ad Science
3.5","Chicago, IL",501 to 1000 Employees,2009,Company - Private,Internet,Information Technology,$100 to $500 million (USD)
Sr. Data Engineer,-1,"About Us:

Convr is a growing startup in the InsureTech space. Our d3 Underwriting Platform helps underwriters make better decisions more efficiently. As we continue to grow we are looking for leaders to help us scale not only our platform but our organization. This is an exciting role that will allow you to mentor, lead, and innovate.

The Role:

THIS POSITION WILL BE IN OUR SCHAUMBURG, IL OFFICE. WE CANNOT OFFER OUT OF STATE OPPORTUNITIES AT THIS TIME. As a Sr. Data Engineer, you will work closely with technical leadership and product managers to lead a team delivering the best solutions for our customers. You will develop a deep understanding of the people, technologies, and practices of your team(s), and apply your expertise to scale our teams and platform. You will innovate and push our technology further. You will teach and mentor our engineers to be more efficient, write quality code, and leverage best practices.

Your Responsibilities:
Be a high performer that produces production quality code that gets value to our customers
Enables scalability within our applications and services
Owns parts of our systems and innovates to create defensible depth in our products
Mentors our engineers to help further their technical skills
Technical Skills Demonstrated:
7+ Years in creating a production application / services
1+ Years as a team lead on a sprint team
1+ Years in Python
4+ Years with micro-services architecture
Understanding of data modeling and various data lake solutions
Built out data platforms that support multiple data sources
Worked on systems with high number of users (1000s - 1Ms)
ML and AI Experience
Owned Code all the way to production before
Experience with DevOps
Things that will help you succeed:
Passion for delivering value to customers
Enjoys solving complex data problems
Can evangelize Agile / Scrum framework to deliver this value
Quality is everything to you
Ownership! Takes ownership and responsibility for all things Convr
Test 1st Mindset
Education:

Bachelors Degree",-1,Convr,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Pharmaceutical Development Scientist,-1,"Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description

With supervision as required, proficiently performs all assigned chemistry techniques. Demonstrates a good understanding of scientific principals and their cause and effect on scientific outcomes. Practice of GMP/GLP is routine. Once appropriately trained, this individual may be designated as a notebook reviewer. Authors and may review others protocols, reports, specifications and test methods. Presents results at team meetings with interpretation. Acts as a coach to junior staff.
Proficiently performs all assigned laboratory techniques.
Independently develops analytical methods on a variety of analytical techniques and instrumentation.
Independently performs method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience in operating and troubleshooting the following instrumentation:
Ultra-High Performance Liquid Chromatography
Differential Scanning Calorimetry (DSC)
Size Exclusion Chromatography
Multi Angle Light Scattering (MALS)
Fourier Transform Infrared Spectroscopy (FTIR)
Asymmetrical Field- Flow Fractionation (AFFF)
Dynamic Light Scattering (DLS)
Tutors and trains others on troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Designated notebook reviewer.
Generates, analyzes and presents scientific data at team meetings. Explains cause and effect relationships and may propose additional experiments to
prove/disprove hypotheses. Has a general understanding of the depth and breadth of drug development and can contribute to the scientific discussion during project team meetings.
Understand regulatory guidelines and can author protocols, reports and analytical test methods.
Generate and analyze scientific data and handle OOS’s (Out of Specification) with little difficulty.
Has a good understanding of different plant manufacturing processes and can plan bench studies that will translate into a manufacturing process while solving related compounding, solubility, etc. problems.
Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development experience. Preferred education background in Analytical Chemistry, Pharmaceutics or similar discipline, however, extensive experience with analytical chemistry may be substituted for education.
Significant experience with the drug development process
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Strong analytical background
Liquid formulation experience is desirable
Product development experience in the pharmaceutical industry
Ability to meet deadlines
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information

Position is full-time, Mon-Fri 8:00am-5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",-1,Eurofins USA PSS Insourcing Solutions,"Lake Forest, IL",-1,-1,-1,-1,-1,-1
Senior Pharmaceutical Development Scientist,-1,"Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description

With supervision as required, proficiently performs all assigned chemistry techniques. Demonstrates a good understanding of scientific principals and their cause and effect on scientific outcomes. Practice of GMP/GLP is routine. Once appropriately trained, this individual may be designated as a notebook reviewer. Authors and may review others protocols, reports, specifications and test methods. Presents results at team meetings with interpretation. Acts as a coach to junior staff.
Proficiently performs all assigned laboratory techniques.
Independently develops analytical methods on a variety of analytical techniques and instrumentation.
Independently performs method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience in operating and troubleshooting the following instrumentation:
Ultra-High Performance Liquid Chromatography
Differential Scanning Calorimetry (DSC)
Size Exclusion Chromatography
Multi Angle Light Scattering (MALS)
Fourier Transform Infrared Spectroscopy (FTIR)
Asymmetrical Field- Flow Fractionation (AFFF)
Dynamic Light Scattering (DLS)
Tutors and trains others on troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Designated notebook reviewer.
Generates, analyzes and presents scientific data at team meetings. Explains cause and effect relationships and may propose additional experiments to
prove/disprove hypotheses. Has a general understanding of the depth and breadth of drug development and can contribute to the scientific discussion during project team meetings.
Understand regulatory guidelines and can author protocols, reports and analytical test methods.
Generate and analyze scientific data and handle OOS’s (Out of Specification) with little difficulty.
Has a good understanding of different plant manufacturing processes and can plan bench studies that will translate into a manufacturing process while solving related compounding, solubility, etc. problems.
Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development experience. Preferred education background in Analytical Chemistry, Pharmaceutics or similar discipline, however, extensive experience with analytical chemistry may be substituted for education.
Significant experience with the drug development process
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Strong analytical background
Liquid formulation experience is desirable
Product development experience in the pharmaceutical industry
Ability to meet deadlines
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information

Position is full-time, Mon-Fri 8:00am-5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",-1,Eurofins USA PSS Insourcing Solutions,"Lake Forest, IL",-1,-1,-1,-1,-1,-1
Senior Pharmaceutical Development Scientist,-1,"Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description

With supervision as required, proficiently performs all assigned chemistry techniques. Demonstrates a good understanding of scientific principals and their cause and effect on scientific outcomes. Practice of GMP/GLP is routine. Once appropriately trained, this individual may be designated as a notebook reviewer. Authors and may review others protocols, reports, specifications and test methods. Presents results at team meetings with interpretation. Acts as a coach to junior staff.
Proficiently performs all assigned laboratory techniques.
Independently develops analytical methods on a variety of analytical techniques and instrumentation.
Independently performs method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience in operating and troubleshooting the following instrumentation:
Ultra-High Performance Liquid Chromatography
Differential Scanning Calorimetry (DSC)
Size Exclusion Chromatography
Multi Angle Light Scattering (MALS)
Fourier Transform Infrared Spectroscopy (FTIR)
Asymmetrical Field- Flow Fractionation (AFFF)
Dynamic Light Scattering (DLS)
Tutors and trains others on troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Designated notebook reviewer.
Generates, analyzes and presents scientific data at team meetings. Explains cause and effect relationships and may propose additional experiments to
prove/disprove hypotheses. Has a general understanding of the depth and breadth of drug development and can contribute to the scientific discussion during project team meetings.
Understand regulatory guidelines and can author protocols, reports and analytical test methods.
Generate and analyze scientific data and handle OOS’s (Out of Specification) with little difficulty.
Has a good understanding of different plant manufacturing processes and can plan bench studies that will translate into a manufacturing process while solving related compounding, solubility, etc. problems.
Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development experience. Preferred education background in Analytical Chemistry, Pharmaceutics or similar discipline, however, extensive experience with analytical chemistry may be substituted for education.
Significant experience with the drug development process
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Strong analytical background
Liquid formulation experience is desirable
Product development experience in the pharmaceutical industry
Ability to meet deadlines
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information

Position is full-time, Mon-Fri 8:00am-5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",-1,Eurofins USA PSS Insourcing Solutions,"Lake Forest, IL",-1,-1,-1,-1,-1,-1
Senior Pharmaceutical Development Scientist,"$27-$49 Per Hour
(Glassdoor Est.)","Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description

With supervision as required, proficiently performs all assigned chemistry techniques. Demonstrates a good understanding of scientific principals and their cause and effect on scientific outcomes. Practice of GMP/GLP is routine. Once appropriately trained, this individual may be designated as a notebook reviewer. Authors and may review others protocols, reports, specifications and test methods. Presents results at team meetings with interpretation. Acts as a coach to junior staff.
Proficiently performs all assigned laboratory techniques.
Independently develops analytical methods on a variety of analytical techniques and instrumentation.
Independently performs method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience in operating and troubleshooting the following instrumentation:
Ultra-High Performance Liquid Chromatography
Differential Scanning Calorimetry (DSC)
Size Exclusion Chromatography
Multi Angle Light Scattering (MALS)
Fourier Transform Infrared Spectroscopy (FTIR)
Asymmetrical Field- Flow Fractionation (AFFF)
Dynamic Light Scattering (DLS)
Tutors and trains others on troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Designated notebook reviewer.
Generates, analyzes and presents scientific data at team meetings. Explains cause and effect relationships and may propose additional experiments to
prove/disprove hypotheses. Has a general understanding of the depth and breadth of drug development and can contribute to the scientific discussion during project team meetings.
Understand regulatory guidelines and can author protocols, reports and analytical test methods.
Generate and analyze scientific data and handle OOS’s (Out of Specification) with little difficulty.
Has a good understanding of different plant manufacturing processes and can plan bench studies that will translate into a manufacturing process while solving related compounding, solubility, etc. problems.
Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development experience. Preferred education background in Analytical Chemistry, Pharmaceutics or similar discipline, however, extensive experience with analytical chemistry may be substituted for education.
Significant experience with the drug development process
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Strong analytical background
Liquid formulation experience is desirable
Product development experience in the pharmaceutical industry
Ability to meet deadlines
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information

Position is full-time, Mon-Fri 8:00am-5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",3.5,Eurofins USA PSS Insourcing Solutions,"Lake Forest, IL",10000+ Employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10 to $25 million (USD)
Lead Big Data Engineer,"$100K-$169K
(Glassdoor Est.)","Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the worlds large accumulation of health-related information, or guide health and lifestyle choices, or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) The ideal candidate will be a self-starter who can learn things quickly, who is enthusiastic, active, and eager to learn. Youll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary Responsibilities: Design, code, test, document, and maintain high-quality and scalable Big Data solutionsDesign, develop and implement rules enginesResearch, evaluate, and deploy new tools, frameworks and patterns to build sustainable Big Data platformIdentify gaps and opportunities for improvement of existing solutionsDefine and develop APIs for integration with various data sources in the enterpriseAnalyze and define customer requirementsAssist in defining product technical architecture Make accurate development effort estimates to assist management in project and resource planning Create prototypes, proof-of-concepts & design and code reviews Collaborate with management, quality assurance, architecture, and other development teamsWrite technical documentation and participate in production support Keep skills up to date through ongoing self-directed training Youll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.",3.4,"UnitedHealth Group
3.4","Downers Grove, IL",10000+ Employees,1977,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
"Senior Software Engineer, Data Platform",-1,"About Us

Mastery Logistics Systems is building the worlds first lovable Transportation Management System, or TMS.

Our customers large transportation companies and shippers who need those companies have struggled with systems that are outdated or inadequate. As shippers or transportation service providers, our customers have in the past been forced to use multiple systems to manage dedicated fleet operations, outsourced or insourced trans management, one way trucking, truckload brokerage, LTL, and Intermodal, or to sub-optimize one or more of those functions by attempting to fit it into a TMS that is adequate at another function.

Mastermind TMS allows our customers to bring all of these functions into a single platform, providing flexibility, visibility, control, and efficiency. Todays unprecedented global supply chain upheavals underscore how important the transportation industry is. We are building a system to allow this industry to work faster, smarter and more efficiently.

The challenges in this industry are big and exciting! We are tackling everything from fast and efficient data input to ingesting large amounts of data and applying AI to looking at blockchain to securely digitize paperwork. If you are passionate about humanizing an industry, automating in innovative ways, building for quality and scale, helping make people's lives easier and touching every part of our economy then this is the place for you.

Mastery Logistics Systems is committed to continuing to build an incredible company. We are a masterful mosaic of incredible people. We are specialists and experienced in our respective fields. We are dedicated to continuous improvement both professionally and personally. We are a collective group of really good people. We have different interests, backgrounds & talents and we work together to create really cool stuff! We believe in diversity of thought and are mindful and inclusive. We have deep respect for each other and work diligently at adding the right people to our teams.

At this moment we are all working from home and doing our part to combat the Covid 19 virus. We are creatively building our new work habits. We are respectful of each others time and personal life. We have flexible schedules but share in the mission that we are building and need to get it done. We offer an excellent suite of benefits. We are dedicated to finding new ways to add perks as we live and work from home.

Our team has the domain knowledge and connections to make an impact, and were looking for experienced and thoughtful people to who thrive on creating and building great products. We want people who have a true passion for servicing and taking care of our customers. We need people who are flexible problem solvers, thrive on collaboration and consistently know how to communicate their solutions well. We are small and nimble which is evident in how quickly we could pivot to our new reality. Each member of the team can make a tremendous impact both technically and culturally. While a start-up, we are well-funded, have an initial paying customer with which to test and launch, and are founded by top experts and veterans in the logistics industry.

Join us youll love it lets build a masterpiece!

About the Role

The transportation industry has no shortage of complex problems requiring creative, data-intensive solutions in order to effectively and efficiently automate operations at scale. In this role, you will be expected to work autonomously and contribute to several high impact projects including building services providing near real-time analytical insights to Masterys customers.

Responsibilities
Closely collaborate with fellow Engineers, Data Scientists, and Product Managers and interact with stakeholders across the organization to build real-time data products
Design, build, and deploy microservices that provide real-time, analytical insights to some of North Americas largest freight brokerages
Support Masterys Data Science team by establishing best practices, developing tools, and building infrastructure that makes the work of Data Analysts and Data Scientists more robust, reliable, and easy to implement
Write clean, maintainable, and well-tested code
Engage in the full development life-cycle including architectural design and testing
Be a force-multiplier on the velocity and quality of your team
Stay current on software engineering trends & tools, and be practical but open-minded in applying them
Maintain a high bar for quality and performance of your product with vigorous attention to detail and automated testing
Continuously improve how we design, build, and ship software as a highly functional team
Requirements
3+ years of practical experience in data-intensive software development, including designing, building, deploying, and maintaining data applications
Expertise in data-focused development, including experience with a variety of database, data warehouse, distributed processing, and machine learning technologies
Minimum of two years of industry experience building production software with Python
Experience with Kafka or similar event streaming systems
Expertise with SQL and RDBMS
Excellent written and verbal communication skills
Adept at interacting with technical and non-technical audiences
Experience working with real-time, distributed systems
Strong sense of responsibility with a bias towards action
Experience working with RESTful APIs
Comfortable self-directing and prioritizing your own work
Ability to understand complicated problems and craft into simple solutions that can be maintained by the rest of the team
Experience leading technical projects
Ability to train and mentor junior engineer
Experience with NoSQL technologies, preferred
Experience with GraphQL, preferred
Experience in logistics industry, preferred
Benefits

Mastery takes great pride in providing our employees a robust and highly competitive benefit package. Our benefits include Medical, Dental and Vision insurance covering 90% of premium costs. Company paid life insurance for 1x salary. Legal, AD&D, Additional Life and other employee assistance benefits. We have a 401k savings plan with a 4% match. We provide opportunities for professional growth and development. We fully support our work from home initiative as we do our part to combat the Covid 19 crisis. We have a manage your life and schedule Paid Time Off program. We are fully devoted to finding creative perks and benefits since we cannot currently enjoy our cool office culture. Our philanthropic partner is St. Jude Childrens Research Hospital.

We are an equal opportunity employer and actively seek a diverse community of professionals. Veterans, Women, non-binary, people of color, LGBTQIA, we welcome all to apply!",-1,"Mastery Logistics Systems, Inc.","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Azure Data Modeler,-1,"Great opportunity to show off your passion for data, reporting, analytics and data warehousing. Our client's BI team may have the perfect fit for you!

We are looking for a self-motivated Data modeler/Engineer to join our business intelligence team.

This individual will be responsible for developing and maintaining business intelligence, data warehousing and data engineering solutions for Enterprise data This individual will also create and maintain detailed business requirements, outlining data problems, opportunities and solutions.

Responsibilities Include:
Responsible for designing relational and non-relational data stores on Azure.
Responsible for designing and developing solutions in Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, SQL Data Warehouse, HDInsight.
Gather and process raw data at scale that meet functional / non-functional business requirements (including writing scripts, REST API calls, SQL Queries, etc.)
Responsible for developing data set processes for data modeling, mining and production.
Responsible for building new Data Lake in Azure, expanding and optimizing our data platform and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
Responsible for supporting our Software Developers, Data Analysts and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Develop complex SQL queries in TIBCO Data Virtualization tool.
Qualifications:
3+ Years of experience architecting and building Data Lake, Azure Big Data architecture, Enterprise Analytics Solutions, and optimizing ' big data' data pipelines, architectures and data sets.
Bachelor’s Degree in Computer Science, Information Systems, or related field
Advanced hands-on SQL, USQL, Python, C#, Java, pySpark (2+ of these) knowledge and experience working with relational databases for data querying and retrieval.
Experience with Design and Architecture of Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure ML, SQL Data Warehouse, HDInsight.
Experience with building processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience working with cross-functional teams in a dynamic environment.
Experience building Big data pipeline with Java and/or Python a plus.
Strong SQL skills on multiple platform
Data Modeling tools (e.g. Erwin, Visio) knowledge a plus.
Experience with SAP HANA a plus.
Experience with Talend a plus.
_Brooksource provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws_

Job Types: Full-time, Contract

Pay: $45.00 - $50.00 per hour

Benefits:
Dental Insurance
Health Insurance
Paid Time Off
Vision Insurance
Schedule:
8 Hour Shift
Day shift
Monday to Friday
Experience:
Azure Big Data architecture: 3 years (Required)
Architecting and Building Data Lake: 3 years (Required)
Developing complex SQL Queries: 3 years (Required)
Enterprise Analytics Solutions: 3 years (Required)
Full Time Opportunity:
Yes
Work Location:
One location
Benefit Conditions:
Waiting period may apply
Work Remotely:
Temporarily due to COVID-19",4.5,"Brooksource
4.5","Northfield, IL",501 to 1000 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Senior Data Science Consultant,-1,"Senior Data Science Consultant
Healthcare
Chicago, IL
$135,000 - $155,000 + Benefits + Bonus

Are you passionate about joining one of America's most famous organizations in the healthcare/ pharmaceutical space? A leading healthcare company is looking for an experienced Senior Data Science Consultant who is technically strong in R, SQL, Python, and Tableau, to advise in implementing solutions through an analytical lens to drive business growth.

THE ROLE:

As Senior Data Science Consultant, you will be partnering with Data Scientists and mentoring junior team members in implementing and framing solutions for making certain treatment programs more efficient. You will be responsible for:

Navigating huge and complex claims data
Performing advanced analytics using Python, R, SQL, and Tableau
Consulting with internal clients to identify opportunities for which you can implement data science
Acting as analytics product owner translating business needs into analytics actions and projects

YOUR SKILLS AND EXPERIENCE:

Strong understanding of managed healthcare space
Proven commercial experience in working with claims data at a large company
Proficient in R, Hadoop, Python, SQL, and Tableau
Proficient in mathematical analysis methods, machine learning, statistical analysis, and predictive modeling
Strong understanding of advanced analytical tools and languages needed to analyze large sets of complex and messy data from multiple sources
Proven experience in strategy consulting, as well as managing or leading teams
Bachelor's degree and Master's in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline; PhD preferred

BENEFITS:

As Senior Data Science Consultant you can expect to earn up to $155,000 (depending on your experience) plus great benefits and of course, great healthcare!

HOW TO APPLY:

Please register your interest by sending your resume to George Little via the Apply link on this page.

KEYWORDS:

Healthcare, pharmaceutical, data science, advanced analytics, consultant, consulting, advisor, Python, R, Hadoop, Tableau, SQL, machine learning, predictive models, predictive analysis, statistics, claims data, engineering, project management, product owner, strategy",4.2,"Harnham
4.2","Chicago, IL",51 to 200 Employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Big Data Machine Learning Engineer,-1,"Title: Big Data Machine Learning Engineer@ Chicago, IL
Terms of Hire: Full Time.
Salary: $Open+ Benefits.

The candidate can also work from any of these locations:
Chicago, IL, US
Cleveland,OH,US
Washington,DC,US
Job description

ABOUT THE JOB

The Decision Sciences team is part of the Enterprise Payments and Analytics organization. Its mission is to lead Client’s journey to become an innovative, data driven enterprise by building advanced analytics solutions for solving business problems. Our experienced team of AI/ML and Data Science practitioners focuses on engaging, enabling, and empowering decision-makers across the enterprise by developing, managing and supporting advanced analytics products and scalable digital solutions, such as real time and on demand predictive models and prescriptive analytics, and continuously researching, specifying, and deploying next-generation analytics capabilities. We are an internal consulting and services organization that works directly with users across the firm, including Lines of Businesses and partners in Enterprise Strategy, Marketing, Data Analytics, and Enterprise Architecture, to facilitate the development of innovative solutions that help Client compete and win with analytics.

The Big Data ML Engineer fills a critical data, analytics, technology support, and innovation role for the business analytics and advanced analytics functions within the organization. The Engineer is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organization’s enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS

The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use cases—primarily focused around open source technologies including cloud infrastructures. This individual evaluates short/long-term business needs required to support Client business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on Client Enterprise systems. Under the guidance of the Group’s Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on Client data assets for business decision management solutions. The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions. The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions. The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organization’s AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.

REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
What are the 3-4 non-negotiable requirements on this position?
1. Experience in open source technologies (Python, Hadoop, Spark, etc.) 2. Experience in Cloud environment, Google Cloud platform preferred 3. Machine learning expertise
What are the nice-to-have skills?
Finance/banking background
You Will Enjoy:
An opportunity to be a part of a great culture, an awesome team, a challenging work environment, and some fun along the way!
Apply today to learn more and be part of our Growth story.
All applications will be kept strictly confidential and once shortlisted, our team will be in touch with you for further discussions.",-1,CEDENT,"Chicago, IL",1 to 50 Employees,-1,Contract,Computer Hardware & Software,Information Technology,Less than $1 million (USD)
Big Data Machine Learning Engineer,-1,"Thusa is looking for Big Data Machine Learning Engineerto join the team. The ideal candidate is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organizations enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS
The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use casesprimarily focused around open source technologies including cloud infrastructures.
This individual evaluates short/long-term business needs required to support key business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on the Enterprise systems.
Under the guidance of the Groups Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on key data assets for business decision management solutions.
The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions.
The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions.
The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organizations AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.
REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
Thusa is dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock. dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock.

Our employees enjoy a work culture that promotes company priorities.

We treat our employees like family while providing on-going support for growth. We are not only looking for people who can do the job, we are also looking for our future leaders.

Powered by JazzHR",-1,Thusa Solutions,"Chicago, IL",-1,-1,-1,-1,-1,-1
Kafka Data Engineer (remote),"$62K-$114K
(Glassdoor Est.)","Summary
We exist to help people achieve financial clarity. At Thrivent, we believe money is a tool, not a goal. Driven by a higher purpose at our core, we are committed to providing financial advice, investments, insurance, banking and generosity programs to help people make the most of all they’ve been given.

At our heart, we are a membership-owned fraternal organization, as well as a holistic financial services organization, dedicated to serving the unique needs of our clients. We focus on their goals and priorities, guiding them toward financial choices that will help them live the life they want today—and tomorrow.

Join our newly created Data Office as the full-time Kafka Data Engineer! We are hiring for both a mid-level and a senior level Engineer. Bring your expertise in implementing modern data architectures and Data Streaming. We have a data streaming platform to enable frictionless data flow from business systems and 3rd party sources using publish/subscribe model. This role will require experience with hybrid platforms, cloud migration, publishing, development with newer technologies such as Spring Boot, KSQL/Stream Processing, data connectors such as Kafka, performance tuning, data quality and data visualization knowledge. You and will report to the Director of Information Delivery.
Job Description


Job Duties and Responsibilities
Partner on the design, deployment, and persistence of our new streaming platform unifies the data across organization, using Confluent Kafka.
As the senior level Engineer, you will be leading a group of engineers.
Design, Develop, Release & Support containerized microservices (OpenShift / Spring Boot) to transform and enrich topic data.
Lead reusable design and patterns for services and data processes within the platform.
Partner on setting standards, implementing tools, and creating documentation for self-serve data pipeline services supporting core engineering and professional services use cases.
Work with existing engineering teams to become data producers and consumers to and from Confluent Kafka.
Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.
Apply business knowledge and experience to effectively advise others on technology as an enabler.
Lead efforts to analyze IT industry and market trends and determine potential impacts.
Develop concepts and constructs necessary to create technology-enabled business systems.
Influence technology direction.
Provides thought leadership and execution to large complex efforts.
Utilize breadth of technical understanding and dive deep when necessary.
Consult on and manage initiatives to ensure alignment across multiple business and IT areas.
Proactively mitigate risks across multiple assets, information domains, technologies & platforms.
Provide leadership, mentoring and technical guidance to others to drive initiatives.
Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.
Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.
Act as a change agent to continuously improve and move the organization forward.
Accountable to provide leadership to successfully deliver the right results on initiatives in a timely and effective manner.
Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.
Ability to work within a diverse team of skillsets and experience levels to deliver results.
Required Job Qualifications
Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field.
5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years of lead experience.
Strong experience with event streaming such as (Kafka or Amazon Kinesis).
Experience with SQL and NoSQL databases (PostgreSQL, MongoDB, etc).
Proficient delivering services within AWS.
Experience with Confluent Kafka, penShift / SpringBoot is preferred.
Demonstrated ability to develop containerized microservices (Docker with Kubernetes) is preferred.
The ability to communicate cross-functionally, derive requirements and architect shared datasets; ability to synthesize, simplify and explain complex problems to different types of audiences.
Desire to show ownership of problems you identify and proven ability to empower others to get more done.
Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color, sex, gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state, or federal law. This policy applies to all employees and job applicants.

Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation, please let us know by sending an email to human.resources@thrivent.com or call 800-847-4836 and request Human Resources.",3.5,"Thrivent
3.5","Chicago, IL",5001 to 10000 Employees,1902,Nonprofit Organization,Insurance Carriers,Insurance,$5 to $10 billion (USD)
Director of AI Product Management - Office of Data Science,"$68K-$121K
(Glassdoor Est.)","Advance your career at Liberty Mutual Insurance - A Fortune 100 Company!

Help bring Liberty Mutual into the future by advocating on behalf of all data scientists across the enterprise. The Director of AI Product Management will be a key member of the Office of Data Science Product Team. As the Director of AI Product Management you will advocate for DS efforts across the enterprise by acting as Product Owner over a team of ML engineers, helping to identify, measure and socialize DS initiatives and partnering with technology, business and the data science community (DSPRG) to promote collaboration and reuse. Liberty Mutual aspires to be the data science leader within the insurance industry and you will play a key role in partnering across the organization to make this happen.

Roles and Responsibilities:
Strategic Vision
Partner with the ODS Science team to engage the enterprise and identify top business opportunities for ML application (e.g. CV, NLP, Aerial Imagery, and Trusted AI).
Measure the value of data science at Liberty and communicate it to the enterprise.
Customer / Collaboration
Foster relationships across the LM enterprise. Promote and build excitement for data science.
Act as a change agent across the organization by influencing and driving strategic direction and investments in AI.
Collaborate with and influence key stakeholders and customers to embrace a product mindset and drive business outcomes.
Partner with the business, tech and data science leaders to jointly drive forward efforts to enhance DS/AI collaboration.
Model Deployment
Act as the product owner for a ML Engineering squad tasked with deploying models delivering ~$100M (and growing) in value to the enterprise.
Manages the existing program, onboards new customers and socialize the value of the portfolio
Vendor
Support DS and ML vendor engagements and purchasing decisions as the organization makes build vs buy vs research decisions
Key traits we are looking for:
Data Science Passion - you have a passion for making things better through data science.
Leadership - You are a passionate leader who can bring the enterprise together, gain cross team alignment and deliver results.
Customer Empathy - ability to try on the experiences of customers and stakeholders - especially those with conflicting viewpoints.
Problem solving - you can solve difficult problems efficiently with appropriate methodologies
Integrity - you build and maintain trust with your colleagues, stakeholders, partners, and leaders
Drive - you work smart and hard to succeed
Communication Skills - you can communicate to a wide variety of audiences adapting your technique as appropriate in a strategic manner
Qualifications:

A minimum of three years recent experience in a DS or technology product role with a proven track record of providing leadership on complex / challenging technical product delivery.
Demonstrated ability to think broadly across multiple good viewpoints
Knowledge of DS applications, DS infrastructure needs, and organizational challenges & obstacles as it relates to vetting, prototyping and scaling DS solutions
Excellent communication, analytical, interpersonal, organizational and team building skills, business judgement, and proven expertise in directing the efforts of agile teams
Experience of strongly influencing product strategy at a senior level and leading organizational change
Ability to continuously prioritize development based on business value and product strategy
Ability to create and foster consensus from the whole business for a coherent product vision
Ability to estimate ROI of complex projects

Benefits:
We value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits
Overview:
At Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.
We're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.",3.5,"Liberty Mutual Insurance
3.5","Warrenville, IL",10000+ Employees,1912,Company - Private,Insurance Carriers,Insurance,$10+ billion (USD)
Sr. Data Engineer,"$75K-$140K
(Glassdoor Est.)","At Echo we are committed to help our Associates grow their career. Apply today and grow with Echo!
-
-",3.5,"Echo Global Logistics
3.5","Chicago, IL",1001 to 5000 Employees,2005,Company - Public,Transportation Management,Transportation & Logistics,$2 to $5 billion (USD)
Senior Data Engineer,-1,"Are you interested in building the future of healthcare and transforming the patient experience? Are you hopeful about what data and medical research can do to improve medicine? We’re looking for a Senior Data Engineer to ensure PatientIQ remains on the forefront of using data to drive positive healthcare outcomes.

As a core member of the Analytics department, you will be in a dynamic environment that is actively building the future versions of our automated data science platform - Analytics Autopilot. In addition, our team often works cross-functionally with the Engineering, Product, and Sales departments as PatientIQ scales its business. Your work will involve coming up with new software features, defining metrics, streamlining existing data processes, and mentoring other team members. We heavily value diligence, curiosity, and initiative, as those are key to unlocking the value of PatientIQ's data for our users and our decision-making. Your work will be impactful across the entire organization.

Role Responsibilities
Design, develop, and maintain ETL infrastructure to support the ingestion of external data sources
Work on a cross-functional team to design, develop, and maintain PatientIQ's internal reporting infrastructure
Understand data requirements and implement solutions for data science applications
Perform unit and integration testing
Mentor junior team members
Help scale PatientIQ's data strategy as the platform and business grows
Requirements

Ideal Qualifications
Experience designing, building, and maintaining ETL infrastructure in a production setting
BS/MS in Computer Science, Engineering, Mathematics, or related field
Proficient in Python or another object oriented programming language
Deep knowledge of SQL and at least one database technology
Experience with software development lifecycle processes and using version control systems (git), either from prior data engineering work or in a more traditional software engineering setting
Highly self-motivated with strong analytical problem-solving skills and attention to detail
Nice to Haves
Experience with workflow management systems such as luigi or airflow
Experience in machine learning and/or business intelligence
Experience with cloud technologies such as AWS, Google Cloud Platform, or Azure
Experience with ETL tools like Apache Kafka, Logstash, Segment, Informatica
Experience with automated machine learning technologies such as Amazon SageMaker or Google Cloud AutoML
Experience with cloud data warehouse platforms such as Snowflake, Qubole, etc.
Experience working in Healthcare, Finance or another regulated industry
Benefits
Great Benefits - top-notch health, dental and vision insurance. Additional perks available including 401K.
We are Mission Driven - our team is motivated to solve complex problems, drive medicine forward, and ultimately improve patient outcomes.
True Idea Meritocracy - great ideas win out. We encourage all team members to challenge the status quo because our mission demands this.
Flexible Time Off - we trust you to take the time you need when you feel it is appropriate, given your workload and responsibilities. No need to track it or save up.
World-Class Team - we’re at the top of our industry because of our employees. They’re the best investment we can make, and we never forget that.
Fast Growing - we are building the largest platform for healthcare providers, industry partners, researchers, and others to collaborate on the mission to improve patient outcomes.",-1,PatientIQ,"Chicago, IL",-1,-1,-1,-1,-1,-1
Big Data Architect,-1,"Our Client is a leader in data-driven marketing, named as one of the top 20 data integrators to watch and grow with. Our Client delivers insight and results to their customer with marketing expertise, technical and analytic capabilities, and a relentless focus on the customer. Business model based on driving lasting customer relationships and incremental brand revenue through integrated systems, online and offline CRM, real time predictive modeling, and data management.

The Big Data Architects primary responsibilities are to create and develop solution designs to integrate and ingest data from various resources, supporting Clientss internal big data ecosystem.

They will be responsible for defining the big data architectural blueprint under the supervision and collaboration with the Technology Solutions Director. The Architect will work closely with data engineers, cloud engineers, and data scientists to design and implement optimum solutions using best practices. They are responsible to ensure the data ecosystem is built to be highly scalable, responsive, and available.

The Big Data Architect oversees the implementation of data solutions by working with Clients onshore and offshore engineering teams to create ETL, batch, real-time, and automated processes. As part of the core Technology Solutions team the right candidate will heavily contribute to the teams coding and programming standards and ensure other team members are following the guidelines and standards.

Responsibilities:


Take ownership of data solutions from design and architecture perspective for projects in presales phase as well as on-going projects

Select and integrate any Big Data tools and frameworks required to provide requested capabilities. Can oversee the implementation by team members of said solutions

Design and implement ETL and automated processes

Monitor performance and advise of any necessary improvements and changes

Management of EMR clusters, Glue Jobs, Athena Tables, S3 data lakes; with all included services

Provide technical support to members of TS and SA team, as well as project support across client engagements

Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value

Stays current with relevant technology in order to maintain and/or improve functionality for authored applications

Assume other responsibilities as requested/required

Acts as a subject matter expert for systems worked on

Ensures Clients data solutions are using the latest versions and code base

Actively listen to and work with end users to gather feedback and input, and make suggestions and solutions based on said feedback

Requirements

Required Experience:
(7 years of relevant experience) or (5 years of relevant experience and an advanced degree in Computer Science/IT or related field)

Keen understanding of distributed computing principles
• Proficiency with Big Data frameworks such as Hadoop, Spark, MapReduce, HDFS.

Proven experience ingesting data from multiple data sources such as REST API, SFTP flat files, Streaming data etc.

Proven experience with Big Data querying tools such as Athena/Presto, Pig, Hive, and Impala

Proven experience with NoSQL databases, such as HBase, Cassandra, Redshift, DynamoDB

Proven experience with various ETL techniques and frameworks, such as Flume, Glue Jobs, Step Functions

Proven experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O

Proven experience with AWS Lambda and leveraging it in various solutions such as Glue, Step Functions, CloudWatch, S3 Events, etc.

Strong experience with using Python scripts & libraries

Experience desired with Database Warehousing Design Concepts; Dimensional.
• Modeling, Star/Snowflake Schemas, ETL/ELT, Data Marts, Analytic Playgrounds, Reporting techniques

Experience working with Agile software development methodologies, namely Scrum

Proven experience with team collaboration, release management, system and performance monitoring

Ability to work well with people from many different disciplines and varying degrees of technical experience

Excellent analytical, problem resolution, organization and time management skills

Ability to handle multiple tasks at a time
• Demonstrated ability to have successfully completed multiple, complex technical projects and create high-level design and architecture of the solution, including class, sequence and deployment infrastructure diagrams

Prior experience with application delivery using an Onshore/Offshore model
• Experience with gathering end user requirements and writing technical documentation

Keyword: Hadoop, Spark, MapReduce, HDFS, REST, API, SFTP, Athena, Pig, Hive, Impala, NoSQL, HBase, Cassandra, Reddrift, DynamoDB

Benefits


We do have a full benefit package of medical/dental/vision insurance, disability, life, 401k employer match along with profit sharing and bonus. Optional benefits is AFLAC plans and FSA for medical or childcare.

Vacation, 5 Sick Days and 2 personal days with a total of about 30 days off within a year depending on when holidays fall. Included in that is the close of the office between Christmas and New Years.",-1,DSMHConsulting,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"Candidate Responsibilities

Develop implementation patterns leveraging AWS technologies to support Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solution Data Designs, Models, Pipelines
Prototype New Solutions Technical guidance to data designers and
developers Solution Implementation Reviews Open to Chicago, IL as well.

Typical Day

Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solutions with Platform, Business, and Application teams

Requirements


Education Requirements:

B.S. in Computer Science, Information Systems, or related major or
equivalent IS / business experience. 10+ years experience designing,
implementing data persistance and processing solutions AWS
Certifications

Technical Skills

AWS Cloud Based Technologies for Data Processing and Persistance
(DynamoDB, S3, Aurora, Kinesis, SQS,SNS, Lambda, Fargate, Glue) Ability
to design and communicate solutions to meet business and technical
requirements Demonstrated Data Architecture and Design
for Big Data, Analytics, and applications

Soft Skills

Written and Verbal Communication Able to produce architecture and design artifacts in Visio and Office 365",-1,DSMHConsulting,"Chicago, IL",-1,-1,-1,-1,-1,-1
Staff Big Data Engineer,"$95K-$171K
(Glassdoor Est.)","Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry. Our technology handles hundreds of thousands of transactions per second; collects tens of billions of events each day; and evaluates thousands of data-points in real-time all while responding in just a few milliseconds.

We are looking for an experienced Big Data Engineer to join our Data Engineering team. This position will be the Senior technical resource driving architecture for the integration of large 3rd party partner integrations with companies like Facebook, Google and Twitter to name a few. The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. This position will require the ability to own and lead data initiatives on a cross-functional team.The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. You should be able to not take yourself too seriously as well. And most of all, you will enjoy working with great people who are changing the entire industry.

What you'll do:
Migrate existing data pipelines from on-prem regional data centers to AWS and GCP.
Architect a new modern event driven architecture with both batching and streaming
Adjust existing pipelines to fit the AWS processing model such as integration with S3, migrate to open source version of hadoop, adjustments to security model, etc...
Working on Big Data technologies such as Hadoop, MapReduce, Kafka, and/or Spark in columnar databases
Architect, design, code and maintain components for aggregating tens of billions of daily transactions
Lead the entire software lifecycle including hands-on development, code reviews, testing, deployment, and documentation for streaming and batch ETL's and RESTful API's
Partner and work closely with the QA Engineers to develop automated tests
Participate in training and mentoring of junior team members
You should apply if you have most of this:

(We have flexibility in this role to consider more, or marginally lesser, experience than requested below)
8+ years of experience designing and building data-intensive applications
5+ years architecting systems in a big data ecosystem using MapReduce, Spark, MPP Data Warehouses, and sql/nosql databases.
5+ years recent hands-on experience with object oriented languages (Java, Scala, Python)
5+ years Hands on experience building production level systems in a cloud environment (AWS or GCP)
Excellent interpersonal and communication skills in English
Proven experience leading the design and execution of event driven architectures for distributed systems
Experience designing systems for performance, scalability, and reliability
In-depth understanding of object oriented programming concepts
Low level working knowledge of collections, multi-threading, JVM memory model, etc.
Solid understanding of database fundamentals and SQL
Understanding the full software development life cycle, agile development and continuous integration
Ability to clearly communicate with team-members in a cross-matrix environment
What puts you over the top:
Built systems in a containerized environment with familiarity in Docker, ECS, Kubernetes
Exposure to Data Warehousing solutions like Snowflake and BigQuery
Prior ad tech experience
About Integral Ad Science

Integral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 18 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit integralads.com.

Equal Opportunity Employer:

IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.

California Applicant Pre-Collection Notice:

We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.

To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN

Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.",3.5,"Integral Ad Science
3.5","Chicago, IL",501 to 1000 Employees,2009,Company - Private,Internet,Information Technology,$100 to $500 million (USD)
Sr. Data Engineer,-1,"About Us:

Convr is a growing startup in the InsureTech space. Our d3 Underwriting Platform helps underwriters make better decisions more efficiently. As we continue to grow we are looking for leaders to help us scale not only our platform but our organization. This is an exciting role that will allow you to mentor, lead, and innovate.

The Role:

THIS POSITION WILL BE IN OUR SCHAUMBURG, IL OFFICE. WE CANNOT OFFER OUT OF STATE OPPORTUNITIES AT THIS TIME. As a Sr. Data Engineer, you will work closely with technical leadership and product managers to lead a team delivering the best solutions for our customers. You will develop a deep understanding of the people, technologies, and practices of your team(s), and apply your expertise to scale our teams and platform. You will innovate and push our technology further. You will teach and mentor our engineers to be more efficient, write quality code, and leverage best practices.

Your Responsibilities:
Be a high performer that produces production quality code that gets value to our customers
Enables scalability within our applications and services
Owns parts of our systems and innovates to create defensible depth in our products
Mentors our engineers to help further their technical skills
Technical Skills Demonstrated:
7+ Years in creating a production application / services
1+ Years as a team lead on a sprint team
1+ Years in Python
4+ Years with micro-services architecture
Understanding of data modeling and various data lake solutions
Built out data platforms that support multiple data sources
Worked on systems with high number of users (1000s - 1Ms)
ML and AI Experience
Owned Code all the way to production before
Experience with DevOps
Things that will help you succeed:
Passion for delivering value to customers
Enjoys solving complex data problems
Can evangelize Agile / Scrum framework to deliver this value
Quality is everything to you
Ownership! Takes ownership and responsibility for all things Convr
Test 1st Mindset
Education:

Bachelors Degree",-1,Convr,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Pharmaceutical Development Scientist,-1,"Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description

With supervision as required, proficiently performs all assigned chemistry techniques. Demonstrates a good understanding of scientific principals and their cause and effect on scientific outcomes. Practice of GMP/GLP is routine. Once appropriately trained, this individual may be designated as a notebook reviewer. Authors and may review others protocols, reports, specifications and test methods. Presents results at team meetings with interpretation. Acts as a coach to junior staff.
Proficiently performs all assigned laboratory techniques.
Independently develops analytical methods on a variety of analytical techniques and instrumentation.
Independently performs method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience in operating and troubleshooting the following instrumentation:
Ultra-High Performance Liquid Chromatography
Differential Scanning Calorimetry (DSC)
Size Exclusion Chromatography
Multi Angle Light Scattering (MALS)
Fourier Transform Infrared Spectroscopy (FTIR)
Asymmetrical Field- Flow Fractionation (AFFF)
Dynamic Light Scattering (DLS)
Tutors and trains others on troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Designated notebook reviewer.
Generates, analyzes and presents scientific data at team meetings. Explains cause and effect relationships and may propose additional experiments to
prove/disprove hypotheses. Has a general understanding of the depth and breadth of drug development and can contribute to the scientific discussion during project team meetings.
Understand regulatory guidelines and can author protocols, reports and analytical test methods.
Generate and analyze scientific data and handle OOS’s (Out of Specification) with little difficulty.
Has a good understanding of different plant manufacturing processes and can plan bench studies that will translate into a manufacturing process while solving related compounding, solubility, etc. problems.
Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development experience. Preferred education background in Analytical Chemistry, Pharmaceutics or similar discipline, however, extensive experience with analytical chemistry may be substituted for education.
Significant experience with the drug development process
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Strong analytical background
Liquid formulation experience is desirable
Product development experience in the pharmaceutical industry
Ability to meet deadlines
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information

Position is full-time, Mon-Fri 8:00am-5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",-1,Eurofins USA PSS Insourcing Solutions,"Lake Forest, IL",-1,-1,-1,-1,-1,-1
Senior Clinical Scientist - Clinical Trial Mgmt and Medical Monitoring exp required,"$27-$49 Per Hour
(Glassdoor Est.)","Job Overview:


Senior Clinical Scientist - Oncology

Clinical Trial Mgmt and Medical Monitoring experience is required

Remote in the USA or Canada

Why settle for one thing when you can have everything?

Covance gives you the best two-for-one opportunity for career growth. Who doesnt want twice the perks? Working at Covanceone of the largest FSP CROsand partnering with one sponsor with a dedicated therapeutic focus. You can have it all!

As a Covance employee dedicated to an FSP project, you will bring your specialized discipline to a core team working directly with one sponsor. Whether your specialization is in clinical monitoring, clinical project management, data management, biometrics or pharmacovigilance, Covance has an FSP opportunity to match your area of expertise.

You will enjoy the best of both worldsall the benefits that come along with Covances Energizing Purpose, Exceptional People and Extraordinary Potential combined with working exclusively with one sponsor and this also comes with the benefit of bringing your strong therapeutic experience to allow your expertise to shine through.

Covances FSP model is flexible and scalable. Our teams are collaborative and proactive a great place for you to continue honing your therapeutic skills and growing and excelling in new and exciting research.

Covances reach is global extending to 60+ countries making us one of the largest FSP CROs. No matter where you are located on the globe, we have an FSP opportunity for you.

In this role, the selected candidate may lead or support a study or studies, depending on size/complexity. If lead, accountable for the clinical/scientific execution of the protocol.

As lead, will be responsible for the following:
Clinical point of contact for scientific issues/questions for internal and external stakeholders (e.g., IRB, sites)
Responsible for trial design and endpoint development in collaboration with CD
Leads the Medical Monitoring (MM) team in performing MM activities, including development of the Medical Monitoring Plan (MMP) and review of SAE reports
Sets up/supports SAC, DMC, adjudication committees
Protocols/amendments collaborates with medical writer, participates in governance committee review
Authors protocol clarification letters
Contributor to study specific documents (e.g., SMP)
Reviews/updates informed consent
Provides scientific input to SM for data management activities (e.g., EDC, DRP, CRFs)
Monitors data issues requiring clinical input
Monitors central lab reports and other external data for safety and critical values
Prepares scientific slides, attends and presents protocol information at Investigator Meeting
Scientific lead on Clinical Trial Team (CTT)
Reviews specs, initiates allocation (randomization) request form and approval schedule in allocation schedule generation system
Coordinates planning of lab, bio specimens and imaging specifications
Co- authors newsletters with SM
Participates in Database lock activities
Collaboratively plans CSRs, CTDs/WMAs with medical writing
Supports publications/presentations as needed
Reconciles and review all protocol deviation classifications in SPECTRUM
Assesses and prepares protocol deviation list for CSR
Collaborates with medical writing to develop trial results communication for investigators
Provides scientific assessment for Operational Reviews
Supports SM/MW activities as needed to achieve CTT deliverables.
Provides clinical specifications to SM to support interactions with external vendors (e.g., IVRS, ePRO)
May act as mentor to other CSs
Education/Qualifications:

Degree in Life Sciences or significant experience in clinical development (>14 years)
BS/BA with 7+ yrs clinical research experience
MS/PhD with 5+ years clinical research experience
Experience:

Minimum 2 years pharmaceutical and clinical drug development experience in a Clinical Scientist role as a lead required.
Proven ability to effectively manage multiple complex studies
Medical monitoring experience required
TA-specific experience in Oncology
Excellent Excel and PP skills required
Excellent written and oral communication skills",3.5,"Covance
3.5","Chicago, IL",10000+ Employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10 to $25 million (USD)
Senior Data Engineer,-1,"Projects the candidate will be working on:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
Team and Team size:
Will be part of team
Will be part of Agile team with minimum 7 members
Top Responsibilities:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
The ideal candidate will be very comfortable creating subscriptions to stream real-time data using CDC tools such as IBM Infosphere Data Replication and streaming data to Kafka.
The candidate should be comfortable working with AS400, Oracle and MSSQL server databases, including any aspect of administration or support required to maintain them.
Required Experience & Qualifications:
Data engineering experience - 7 years
Cloud platform experience - 1 year
Version Control (Git or equivalent) - 1 years
Preferred Experience & Qualifications:
Change Data Capture Tools (IBM CDC, Attunity or equivalent) 3 years
Version Control (Git or equivalent) 1 year
Scripting (Linux/Unix Shell scripting or equivalent) 5 years
Interview Process:
a. How many rounds? 2 or 3
b. Video vs. phone? Phone
c. How technical will the interviews be? Very detailed Technical",4.0,"Horizontal
4.0","Schaumburg, IL",501 to 1000 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Sr Data Engineer,"$59K-$116K
(Glassdoor Est.)","Position Role/Tile: Sr Data Engineer
Location: Schaumburg, IL.

Job description:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.

Is this person a sole contributor or part of a team?
Will be part of team
If so, please describe the team? (Name of team, size of team, etc.)
Will be part of Agile team with minimum 7 members
What are the top 5-10 responsibilities for this position? (Please be detailed as to what the candidate is expected to do or complete on a daily basis)
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting. The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
The ideal candidate will be very comfortable creating subscriptions to stream real-time data using CDC tools such as IBM Infosphere Data Replication and streaming data to Kafka.
The candidate should be comfortable working with AS400, Oracle and MSSQL server databases, including any aspect of administration or support required to maintain them.
What software tools/skills are needed to perform these daily responsibilities?
Required Experience & Qualifications:
Data engineering experience - 7 years
Cloud platform experience - 1 year
Version Control (Git or equivalent) - 1 years
Preferred Experience & Qualifications:
Change Data Capture Tools (IBM CDC, Attunity or equivalent) 3 years
Version Control (Git or equivalent) 1 year
Scripting (Linux/Unix Shell scripting or equivalent) 5 years
Central Business Solutions, Inc,
37600 Central Ct.
Suite #214
Newark, CA 94560",3.0,"Central Business Solutions, Inc
3.0","Schaumburg, IL",51 to 200 Employees,-1,Company - Private,Consulting,Business Services,$5 to $10 million (USD)
Lead Big Data Engineer,"$100K-$169K
(Glassdoor Est.)","Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the worlds large accumulation of health-related information, or guide health and lifestyle choices, or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) The ideal candidate will be a self-starter who can learn things quickly, who is enthusiastic, active, and eager to learn. Youll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary Responsibilities: Design, code, test, document, and maintain high-quality and scalable Big Data solutionsDesign, develop and implement rules enginesResearch, evaluate, and deploy new tools, frameworks and patterns to build sustainable Big Data platformIdentify gaps and opportunities for improvement of existing solutionsDefine and develop APIs for integration with various data sources in the enterpriseAnalyze and define customer requirementsAssist in defining product technical architecture Make accurate development effort estimates to assist management in project and resource planning Create prototypes, proof-of-concepts & design and code reviews Collaborate with management, quality assurance, architecture, and other development teamsWrite technical documentation and participate in production support Keep skills up to date through ongoing self-directed training Youll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.",3.4,"UnitedHealth Group
3.4","Downers Grove, IL",10000+ Employees,1977,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
"Senior Software Engineer, Data Platform",-1,"About Us

Mastery Logistics Systems is building the worlds first lovable Transportation Management System, or TMS.

Our customers large transportation companies and shippers who need those companies have struggled with systems that are outdated or inadequate. As shippers or transportation service providers, our customers have in the past been forced to use multiple systems to manage dedicated fleet operations, outsourced or insourced trans management, one way trucking, truckload brokerage, LTL, and Intermodal, or to sub-optimize one or more of those functions by attempting to fit it into a TMS that is adequate at another function.

Mastermind TMS allows our customers to bring all of these functions into a single platform, providing flexibility, visibility, control, and efficiency. Todays unprecedented global supply chain upheavals underscore how important the transportation industry is. We are building a system to allow this industry to work faster, smarter and more efficiently.

The challenges in this industry are big and exciting! We are tackling everything from fast and efficient data input to ingesting large amounts of data and applying AI to looking at blockchain to securely digitize paperwork. If you are passionate about humanizing an industry, automating in innovative ways, building for quality and scale, helping make people's lives easier and touching every part of our economy then this is the place for you.

Mastery Logistics Systems is committed to continuing to build an incredible company. We are a masterful mosaic of incredible people. We are specialists and experienced in our respective fields. We are dedicated to continuous improvement both professionally and personally. We are a collective group of really good people. We have different interests, backgrounds & talents and we work together to create really cool stuff! We believe in diversity of thought and are mindful and inclusive. We have deep respect for each other and work diligently at adding the right people to our teams.

At this moment we are all working from home and doing our part to combat the Covid 19 virus. We are creatively building our new work habits. We are respectful of each others time and personal life. We have flexible schedules but share in the mission that we are building and need to get it done. We offer an excellent suite of benefits. We are dedicated to finding new ways to add perks as we live and work from home.

Our team has the domain knowledge and connections to make an impact, and were looking for experienced and thoughtful people to who thrive on creating and building great products. We want people who have a true passion for servicing and taking care of our customers. We need people who are flexible problem solvers, thrive on collaboration and consistently know how to communicate their solutions well. We are small and nimble which is evident in how quickly we could pivot to our new reality. Each member of the team can make a tremendous impact both technically and culturally. While a start-up, we are well-funded, have an initial paying customer with which to test and launch, and are founded by top experts and veterans in the logistics industry.

Join us youll love it lets build a masterpiece!

About the Role

The transportation industry has no shortage of complex problems requiring creative, data-intensive solutions in order to effectively and efficiently automate operations at scale. In this role, you will be expected to work autonomously and contribute to several high impact projects including building services providing near real-time analytical insights to Masterys customers.

Responsibilities
Closely collaborate with fellow Engineers, Data Scientists, and Product Managers and interact with stakeholders across the organization to build real-time data products
Design, build, and deploy microservices that provide real-time, analytical insights to some of North Americas largest freight brokerages
Support Masterys Data Science team by establishing best practices, developing tools, and building infrastructure that makes the work of Data Analysts and Data Scientists more robust, reliable, and easy to implement
Write clean, maintainable, and well-tested code
Engage in the full development life-cycle including architectural design and testing
Be a force-multiplier on the velocity and quality of your team
Stay current on software engineering trends & tools, and be practical but open-minded in applying them
Maintain a high bar for quality and performance of your product with vigorous attention to detail and automated testing
Continuously improve how we design, build, and ship software as a highly functional team
Requirements
3+ years of practical experience in data-intensive software development, including designing, building, deploying, and maintaining data applications
Expertise in data-focused development, including experience with a variety of database, data warehouse, distributed processing, and machine learning technologies
Minimum of two years of industry experience building production software with Python
Experience with Kafka or similar event streaming systems
Expertise with SQL and RDBMS
Excellent written and verbal communication skills
Adept at interacting with technical and non-technical audiences
Experience working with real-time, distributed systems
Strong sense of responsibility with a bias towards action
Experience working with RESTful APIs
Comfortable self-directing and prioritizing your own work
Ability to understand complicated problems and craft into simple solutions that can be maintained by the rest of the team
Experience leading technical projects
Ability to train and mentor junior engineer
Experience with NoSQL technologies, preferred
Experience with GraphQL, preferred
Experience in logistics industry, preferred
Benefits

Mastery takes great pride in providing our employees a robust and highly competitive benefit package. Our benefits include Medical, Dental and Vision insurance covering 90% of premium costs. Company paid life insurance for 1x salary. Legal, AD&D, Additional Life and other employee assistance benefits. We have a 401k savings plan with a 4% match. We provide opportunities for professional growth and development. We fully support our work from home initiative as we do our part to combat the Covid 19 crisis. We have a manage your life and schedule Paid Time Off program. We are fully devoted to finding creative perks and benefits since we cannot currently enjoy our cool office culture. Our philanthropic partner is St. Jude Childrens Research Hospital.

We are an equal opportunity employer and actively seek a diverse community of professionals. Veterans, Women, non-binary, people of color, LGBTQIA, we welcome all to apply!",-1,"Mastery Logistics Systems, Inc.","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Azure Data Modeler,-1,"Great opportunity to show off your passion for data, reporting, analytics and data warehousing. Our client's BI team may have the perfect fit for you!

We are looking for a self-motivated Data modeler/Engineer to join our business intelligence team.

This individual will be responsible for developing and maintaining business intelligence, data warehousing and data engineering solutions for Enterprise data This individual will also create and maintain detailed business requirements, outlining data problems, opportunities and solutions.

Responsibilities Include:
Responsible for designing relational and non-relational data stores on Azure.
Responsible for designing and developing solutions in Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, SQL Data Warehouse, HDInsight.
Gather and process raw data at scale that meet functional / non-functional business requirements (including writing scripts, REST API calls, SQL Queries, etc.)
Responsible for developing data set processes for data modeling, mining and production.
Responsible for building new Data Lake in Azure, expanding and optimizing our data platform and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
Responsible for supporting our Software Developers, Data Analysts and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Develop complex SQL queries in TIBCO Data Virtualization tool.
Qualifications:
3+ Years of experience architecting and building Data Lake, Azure Big Data architecture, Enterprise Analytics Solutions, and optimizing ' big data' data pipelines, architectures and data sets.
Bachelor’s Degree in Computer Science, Information Systems, or related field
Advanced hands-on SQL, USQL, Python, C#, Java, pySpark (2+ of these) knowledge and experience working with relational databases for data querying and retrieval.
Experience with Design and Architecture of Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure ML, SQL Data Warehouse, HDInsight.
Experience with building processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience working with cross-functional teams in a dynamic environment.
Experience building Big data pipeline with Java and/or Python a plus.
Strong SQL skills on multiple platform
Data Modeling tools (e.g. Erwin, Visio) knowledge a plus.
Experience with SAP HANA a plus.
Experience with Talend a plus.
_Brooksource provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws_

Job Types: Full-time, Contract

Pay: $45.00 - $50.00 per hour

Benefits:
Dental Insurance
Health Insurance
Paid Time Off
Vision Insurance
Schedule:
8 Hour Shift
Day shift
Monday to Friday
Experience:
Azure Big Data architecture: 3 years (Required)
Architecting and Building Data Lake: 3 years (Required)
Developing complex SQL Queries: 3 years (Required)
Enterprise Analytics Solutions: 3 years (Required)
Full Time Opportunity:
Yes
Work Location:
One location
Benefit Conditions:
Waiting period may apply
Work Remotely:
Temporarily due to COVID-19",4.5,"Brooksource
4.5","Northfield, IL",501 to 1000 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Senior Data Science Consultant,-1,"Senior Data Science Consultant
Healthcare
Chicago, IL
$135,000 - $155,000 + Benefits + Bonus

Are you passionate about joining one of America's most famous organizations in the healthcare/ pharmaceutical space? A leading healthcare company is looking for an experienced Senior Data Science Consultant who is technically strong in R, SQL, Python, and Tableau, to advise in implementing solutions through an analytical lens to drive business growth.

THE ROLE:

As Senior Data Science Consultant, you will be partnering with Data Scientists and mentoring junior team members in implementing and framing solutions for making certain treatment programs more efficient. You will be responsible for:

Navigating huge and complex claims data
Performing advanced analytics using Python, R, SQL, and Tableau
Consulting with internal clients to identify opportunities for which you can implement data science
Acting as analytics product owner translating business needs into analytics actions and projects

YOUR SKILLS AND EXPERIENCE:

Strong understanding of managed healthcare space
Proven commercial experience in working with claims data at a large company
Proficient in R, Hadoop, Python, SQL, and Tableau
Proficient in mathematical analysis methods, machine learning, statistical analysis, and predictive modeling
Strong understanding of advanced analytical tools and languages needed to analyze large sets of complex and messy data from multiple sources
Proven experience in strategy consulting, as well as managing or leading teams
Bachelor's degree and Master's in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline; PhD preferred

BENEFITS:

As Senior Data Science Consultant you can expect to earn up to $155,000 (depending on your experience) plus great benefits and of course, great healthcare!

HOW TO APPLY:

Please register your interest by sending your resume to George Little via the Apply link on this page.

KEYWORDS:

Healthcare, pharmaceutical, data science, advanced analytics, consultant, consulting, advisor, Python, R, Hadoop, Tableau, SQL, machine learning, predictive models, predictive analysis, statistics, claims data, engineering, project management, product owner, strategy",4.2,"Harnham
4.2","Chicago, IL",51 to 200 Employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Big Data Machine Learning Engineer,-1,"Title: Big Data Machine Learning Engineer@ Chicago, IL
Terms of Hire: Full Time.
Salary: $Open+ Benefits.

The candidate can also work from any of these locations:
Chicago, IL, US
Cleveland,OH,US
Washington,DC,US
Job description

ABOUT THE JOB

The Decision Sciences team is part of the Enterprise Payments and Analytics organization. Its mission is to lead Client’s journey to become an innovative, data driven enterprise by building advanced analytics solutions for solving business problems. Our experienced team of AI/ML and Data Science practitioners focuses on engaging, enabling, and empowering decision-makers across the enterprise by developing, managing and supporting advanced analytics products and scalable digital solutions, such as real time and on demand predictive models and prescriptive analytics, and continuously researching, specifying, and deploying next-generation analytics capabilities. We are an internal consulting and services organization that works directly with users across the firm, including Lines of Businesses and partners in Enterprise Strategy, Marketing, Data Analytics, and Enterprise Architecture, to facilitate the development of innovative solutions that help Client compete and win with analytics.

The Big Data ML Engineer fills a critical data, analytics, technology support, and innovation role for the business analytics and advanced analytics functions within the organization. The Engineer is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organization’s enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS

The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use cases—primarily focused around open source technologies including cloud infrastructures. This individual evaluates short/long-term business needs required to support Client business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on Client Enterprise systems. Under the guidance of the Group’s Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on Client data assets for business decision management solutions. The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions. The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions. The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organization’s AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.

REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
What are the 3-4 non-negotiable requirements on this position?
1. Experience in open source technologies (Python, Hadoop, Spark, etc.) 2. Experience in Cloud environment, Google Cloud platform preferred 3. Machine learning expertise
What are the nice-to-have skills?
Finance/banking background
You Will Enjoy:
An opportunity to be a part of a great culture, an awesome team, a challenging work environment, and some fun along the way!
Apply today to learn more and be part of our Growth story.
All applications will be kept strictly confidential and once shortlisted, our team will be in touch with you for further discussions.",-1,CEDENT,"Chicago, IL",1 to 50 Employees,-1,Contract,Computer Hardware & Software,Information Technology,Less than $1 million (USD)
Big Data Machine Learning Engineer,-1,"Thusa is looking for Big Data Machine Learning Engineerto join the team. The ideal candidate is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organizations enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS
The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use casesprimarily focused around open source technologies including cloud infrastructures.
This individual evaluates short/long-term business needs required to support key business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on the Enterprise systems.
Under the guidance of the Groups Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on key data assets for business decision management solutions.
The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions.
The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions.
The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organizations AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.
REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
Thusa is dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock. dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock.

Our employees enjoy a work culture that promotes company priorities.

We treat our employees like family while providing on-going support for growth. We are not only looking for people who can do the job, we are also looking for our future leaders.

Powered by JazzHR",-1,Thusa Solutions,"Chicago, IL",-1,-1,-1,-1,-1,-1
Kafka Data Engineer (remote),"$62K-$114K
(Glassdoor Est.)","Summary
We exist to help people achieve financial clarity. At Thrivent, we believe money is a tool, not a goal. Driven by a higher purpose at our core, we are committed to providing financial advice, investments, insurance, banking and generosity programs to help people make the most of all they’ve been given.

At our heart, we are a membership-owned fraternal organization, as well as a holistic financial services organization, dedicated to serving the unique needs of our clients. We focus on their goals and priorities, guiding them toward financial choices that will help them live the life they want today—and tomorrow.

Join our newly created Data Office as the full-time Kafka Data Engineer! We are hiring for both a mid-level and a senior level Engineer. Bring your expertise in implementing modern data architectures and Data Streaming. We have a data streaming platform to enable frictionless data flow from business systems and 3rd party sources using publish/subscribe model. This role will require experience with hybrid platforms, cloud migration, publishing, development with newer technologies such as Spring Boot, KSQL/Stream Processing, data connectors such as Kafka, performance tuning, data quality and data visualization knowledge. You and will report to the Director of Information Delivery.
Job Description


Job Duties and Responsibilities
Partner on the design, deployment, and persistence of our new streaming platform unifies the data across organization, using Confluent Kafka.
As the senior level Engineer, you will be leading a group of engineers.
Design, Develop, Release & Support containerized microservices (OpenShift / Spring Boot) to transform and enrich topic data.
Lead reusable design and patterns for services and data processes within the platform.
Partner on setting standards, implementing tools, and creating documentation for self-serve data pipeline services supporting core engineering and professional services use cases.
Work with existing engineering teams to become data producers and consumers to and from Confluent Kafka.
Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.
Apply business knowledge and experience to effectively advise others on technology as an enabler.
Lead efforts to analyze IT industry and market trends and determine potential impacts.
Develop concepts and constructs necessary to create technology-enabled business systems.
Influence technology direction.
Provides thought leadership and execution to large complex efforts.
Utilize breadth of technical understanding and dive deep when necessary.
Consult on and manage initiatives to ensure alignment across multiple business and IT areas.
Proactively mitigate risks across multiple assets, information domains, technologies & platforms.
Provide leadership, mentoring and technical guidance to others to drive initiatives.
Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.
Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.
Act as a change agent to continuously improve and move the organization forward.
Accountable to provide leadership to successfully deliver the right results on initiatives in a timely and effective manner.
Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.
Ability to work within a diverse team of skillsets and experience levels to deliver results.
Required Job Qualifications
Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field.
5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years of lead experience.
Strong experience with event streaming such as (Kafka or Amazon Kinesis).
Experience with SQL and NoSQL databases (PostgreSQL, MongoDB, etc).
Proficient delivering services within AWS.
Experience with Confluent Kafka, penShift / SpringBoot is preferred.
Demonstrated ability to develop containerized microservices (Docker with Kubernetes) is preferred.
The ability to communicate cross-functionally, derive requirements and architect shared datasets; ability to synthesize, simplify and explain complex problems to different types of audiences.
Desire to show ownership of problems you identify and proven ability to empower others to get more done.
Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color, sex, gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state, or federal law. This policy applies to all employees and job applicants.

Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation, please let us know by sending an email to human.resources@thrivent.com or call 800-847-4836 and request Human Resources.",3.5,"Thrivent
3.5","Chicago, IL",5001 to 10000 Employees,1902,Nonprofit Organization,Insurance Carriers,Insurance,$5 to $10 billion (USD)
Director of AI Product Management - Office of Data Science,"$68K-$121K
(Glassdoor Est.)","Advance your career at Liberty Mutual Insurance - A Fortune 100 Company!

Help bring Liberty Mutual into the future by advocating on behalf of all data scientists across the enterprise. The Director of AI Product Management will be a key member of the Office of Data Science Product Team. As the Director of AI Product Management you will advocate for DS efforts across the enterprise by acting as Product Owner over a team of ML engineers, helping to identify, measure and socialize DS initiatives and partnering with technology, business and the data science community (DSPRG) to promote collaboration and reuse. Liberty Mutual aspires to be the data science leader within the insurance industry and you will play a key role in partnering across the organization to make this happen.

Roles and Responsibilities:
Strategic Vision
Partner with the ODS Science team to engage the enterprise and identify top business opportunities for ML application (e.g. CV, NLP, Aerial Imagery, and Trusted AI).
Measure the value of data science at Liberty and communicate it to the enterprise.
Customer / Collaboration
Foster relationships across the LM enterprise. Promote and build excitement for data science.
Act as a change agent across the organization by influencing and driving strategic direction and investments in AI.
Collaborate with and influence key stakeholders and customers to embrace a product mindset and drive business outcomes.
Partner with the business, tech and data science leaders to jointly drive forward efforts to enhance DS/AI collaboration.
Model Deployment
Act as the product owner for a ML Engineering squad tasked with deploying models delivering ~$100M (and growing) in value to the enterprise.
Manages the existing program, onboards new customers and socialize the value of the portfolio
Vendor
Support DS and ML vendor engagements and purchasing decisions as the organization makes build vs buy vs research decisions
Key traits we are looking for:
Data Science Passion - you have a passion for making things better through data science.
Leadership - You are a passionate leader who can bring the enterprise together, gain cross team alignment and deliver results.
Customer Empathy - ability to try on the experiences of customers and stakeholders - especially those with conflicting viewpoints.
Problem solving - you can solve difficult problems efficiently with appropriate methodologies
Integrity - you build and maintain trust with your colleagues, stakeholders, partners, and leaders
Drive - you work smart and hard to succeed
Communication Skills - you can communicate to a wide variety of audiences adapting your technique as appropriate in a strategic manner
Qualifications:

A minimum of three years recent experience in a DS or technology product role with a proven track record of providing leadership on complex / challenging technical product delivery.
Demonstrated ability to think broadly across multiple good viewpoints
Knowledge of DS applications, DS infrastructure needs, and organizational challenges & obstacles as it relates to vetting, prototyping and scaling DS solutions
Excellent communication, analytical, interpersonal, organizational and team building skills, business judgement, and proven expertise in directing the efforts of agile teams
Experience of strongly influencing product strategy at a senior level and leading organizational change
Ability to continuously prioritize development based on business value and product strategy
Ability to create and foster consensus from the whole business for a coherent product vision
Ability to estimate ROI of complex projects

Benefits:
We value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits
Overview:
At Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.
We're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.",3.5,"Liberty Mutual Insurance
3.5","Warrenville, IL",10000+ Employees,1912,Company - Private,Insurance Carriers,Insurance,$10+ billion (USD)
Sr. Data Engineer,"$75K-$140K
(Glassdoor Est.)","At Echo we are committed to help our Associates grow their career. Apply today and grow with Echo!
-
-",3.5,"Echo Global Logistics
3.5","Chicago, IL",1001 to 5000 Employees,2005,Company - Public,Transportation Management,Transportation & Logistics,$2 to $5 billion (USD)
Senior Data Engineer,-1,"Are you interested in building the future of healthcare and transforming the patient experience? Are you hopeful about what data and medical research can do to improve medicine? We’re looking for a Senior Data Engineer to ensure PatientIQ remains on the forefront of using data to drive positive healthcare outcomes.

As a core member of the Analytics department, you will be in a dynamic environment that is actively building the future versions of our automated data science platform - Analytics Autopilot. In addition, our team often works cross-functionally with the Engineering, Product, and Sales departments as PatientIQ scales its business. Your work will involve coming up with new software features, defining metrics, streamlining existing data processes, and mentoring other team members. We heavily value diligence, curiosity, and initiative, as those are key to unlocking the value of PatientIQ's data for our users and our decision-making. Your work will be impactful across the entire organization.

Role Responsibilities
Design, develop, and maintain ETL infrastructure to support the ingestion of external data sources
Work on a cross-functional team to design, develop, and maintain PatientIQ's internal reporting infrastructure
Understand data requirements and implement solutions for data science applications
Perform unit and integration testing
Mentor junior team members
Help scale PatientIQ's data strategy as the platform and business grows
Requirements

Ideal Qualifications
Experience designing, building, and maintaining ETL infrastructure in a production setting
BS/MS in Computer Science, Engineering, Mathematics, or related field
Proficient in Python or another object oriented programming language
Deep knowledge of SQL and at least one database technology
Experience with software development lifecycle processes and using version control systems (git), either from prior data engineering work or in a more traditional software engineering setting
Highly self-motivated with strong analytical problem-solving skills and attention to detail
Nice to Haves
Experience with workflow management systems such as luigi or airflow
Experience in machine learning and/or business intelligence
Experience with cloud technologies such as AWS, Google Cloud Platform, or Azure
Experience with ETL tools like Apache Kafka, Logstash, Segment, Informatica
Experience with automated machine learning technologies such as Amazon SageMaker or Google Cloud AutoML
Experience with cloud data warehouse platforms such as Snowflake, Qubole, etc.
Experience working in Healthcare, Finance or another regulated industry
Benefits
Great Benefits - top-notch health, dental and vision insurance. Additional perks available including 401K.
We are Mission Driven - our team is motivated to solve complex problems, drive medicine forward, and ultimately improve patient outcomes.
True Idea Meritocracy - great ideas win out. We encourage all team members to challenge the status quo because our mission demands this.
Flexible Time Off - we trust you to take the time you need when you feel it is appropriate, given your workload and responsibilities. No need to track it or save up.
World-Class Team - we’re at the top of our industry because of our employees. They’re the best investment we can make, and we never forget that.
Fast Growing - we are building the largest platform for healthcare providers, industry partners, researchers, and others to collaborate on the mission to improve patient outcomes.",-1,PatientIQ,"Chicago, IL",-1,-1,-1,-1,-1,-1
Big Data Architect,-1,"Our Client is a leader in data-driven marketing, named as one of the top 20 data integrators to watch and grow with. Our Client delivers insight and results to their customer with marketing expertise, technical and analytic capabilities, and a relentless focus on the customer. Business model based on driving lasting customer relationships and incremental brand revenue through integrated systems, online and offline CRM, real time predictive modeling, and data management.

The Big Data Architects primary responsibilities are to create and develop solution designs to integrate and ingest data from various resources, supporting Clientss internal big data ecosystem.

They will be responsible for defining the big data architectural blueprint under the supervision and collaboration with the Technology Solutions Director. The Architect will work closely with data engineers, cloud engineers, and data scientists to design and implement optimum solutions using best practices. They are responsible to ensure the data ecosystem is built to be highly scalable, responsive, and available.

The Big Data Architect oversees the implementation of data solutions by working with Clients onshore and offshore engineering teams to create ETL, batch, real-time, and automated processes. As part of the core Technology Solutions team the right candidate will heavily contribute to the teams coding and programming standards and ensure other team members are following the guidelines and standards.

Responsibilities:


Take ownership of data solutions from design and architecture perspective for projects in presales phase as well as on-going projects

Select and integrate any Big Data tools and frameworks required to provide requested capabilities. Can oversee the implementation by team members of said solutions

Design and implement ETL and automated processes

Monitor performance and advise of any necessary improvements and changes

Management of EMR clusters, Glue Jobs, Athena Tables, S3 data lakes; with all included services

Provide technical support to members of TS and SA team, as well as project support across client engagements

Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value

Stays current with relevant technology in order to maintain and/or improve functionality for authored applications

Assume other responsibilities as requested/required

Acts as a subject matter expert for systems worked on

Ensures Clients data solutions are using the latest versions and code base

Actively listen to and work with end users to gather feedback and input, and make suggestions and solutions based on said feedback

Requirements

Required Experience:
(7 years of relevant experience) or (5 years of relevant experience and an advanced degree in Computer Science/IT or related field)

Keen understanding of distributed computing principles
• Proficiency with Big Data frameworks such as Hadoop, Spark, MapReduce, HDFS.

Proven experience ingesting data from multiple data sources such as REST API, SFTP flat files, Streaming data etc.

Proven experience with Big Data querying tools such as Athena/Presto, Pig, Hive, and Impala

Proven experience with NoSQL databases, such as HBase, Cassandra, Redshift, DynamoDB

Proven experience with various ETL techniques and frameworks, such as Flume, Glue Jobs, Step Functions

Proven experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O

Proven experience with AWS Lambda and leveraging it in various solutions such as Glue, Step Functions, CloudWatch, S3 Events, etc.

Strong experience with using Python scripts & libraries

Experience desired with Database Warehousing Design Concepts; Dimensional.
• Modeling, Star/Snowflake Schemas, ETL/ELT, Data Marts, Analytic Playgrounds, Reporting techniques

Experience working with Agile software development methodologies, namely Scrum

Proven experience with team collaboration, release management, system and performance monitoring

Ability to work well with people from many different disciplines and varying degrees of technical experience

Excellent analytical, problem resolution, organization and time management skills

Ability to handle multiple tasks at a time
• Demonstrated ability to have successfully completed multiple, complex technical projects and create high-level design and architecture of the solution, including class, sequence and deployment infrastructure diagrams

Prior experience with application delivery using an Onshore/Offshore model
• Experience with gathering end user requirements and writing technical documentation

Keyword: Hadoop, Spark, MapReduce, HDFS, REST, API, SFTP, Athena, Pig, Hive, Impala, NoSQL, HBase, Cassandra, Reddrift, DynamoDB

Benefits


We do have a full benefit package of medical/dental/vision insurance, disability, life, 401k employer match along with profit sharing and bonus. Optional benefits is AFLAC plans and FSA for medical or childcare.

Vacation, 5 Sick Days and 2 personal days with a total of about 30 days off within a year depending on when holidays fall. Included in that is the close of the office between Christmas and New Years.",-1,DSMHConsulting,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"Candidate Responsibilities

Develop implementation patterns leveraging AWS technologies to support Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solution Data Designs, Models, Pipelines
Prototype New Solutions Technical guidance to data designers and
developers Solution Implementation Reviews Open to Chicago, IL as well.

Typical Day

Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solutions with Platform, Business, and Application teams

Requirements


Education Requirements:

B.S. in Computer Science, Information Systems, or related major or
equivalent IS / business experience. 10+ years experience designing,
implementing data persistance and processing solutions AWS
Certifications

Technical Skills

AWS Cloud Based Technologies for Data Processing and Persistance
(DynamoDB, S3, Aurora, Kinesis, SQS,SNS, Lambda, Fargate, Glue) Ability
to design and communicate solutions to meet business and technical
requirements Demonstrated Data Architecture and Design
for Big Data, Analytics, and applications

Soft Skills

Written and Verbal Communication Able to produce architecture and design artifacts in Visio and Office 365",-1,DSMHConsulting,"Chicago, IL",-1,-1,-1,-1,-1,-1
Staff Big Data Engineer,"$95K-$171K
(Glassdoor Est.)","Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry. Our technology handles hundreds of thousands of transactions per second; collects tens of billions of events each day; and evaluates thousands of data-points in real-time all while responding in just a few milliseconds.

We are looking for an experienced Big Data Engineer to join our Data Engineering team. This position will be the Senior technical resource driving architecture for the integration of large 3rd party partner integrations with companies like Facebook, Google and Twitter to name a few. The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. This position will require the ability to own and lead data initiatives on a cross-functional team.The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. You should be able to not take yourself too seriously as well. And most of all, you will enjoy working with great people who are changing the entire industry.

What you'll do:
Migrate existing data pipelines from on-prem regional data centers to AWS and GCP.
Architect a new modern event driven architecture with both batching and streaming
Adjust existing pipelines to fit the AWS processing model such as integration with S3, migrate to open source version of hadoop, adjustments to security model, etc...
Working on Big Data technologies such as Hadoop, MapReduce, Kafka, and/or Spark in columnar databases
Architect, design, code and maintain components for aggregating tens of billions of daily transactions
Lead the entire software lifecycle including hands-on development, code reviews, testing, deployment, and documentation for streaming and batch ETL's and RESTful API's
Partner and work closely with the QA Engineers to develop automated tests
Participate in training and mentoring of junior team members
You should apply if you have most of this:

(We have flexibility in this role to consider more, or marginally lesser, experience than requested below)
8+ years of experience designing and building data-intensive applications
5+ years architecting systems in a big data ecosystem using MapReduce, Spark, MPP Data Warehouses, and sql/nosql databases.
5+ years recent hands-on experience with object oriented languages (Java, Scala, Python)
5+ years Hands on experience building production level systems in a cloud environment (AWS or GCP)
Excellent interpersonal and communication skills in English
Proven experience leading the design and execution of event driven architectures for distributed systems
Experience designing systems for performance, scalability, and reliability
In-depth understanding of object oriented programming concepts
Low level working knowledge of collections, multi-threading, JVM memory model, etc.
Solid understanding of database fundamentals and SQL
Understanding the full software development life cycle, agile development and continuous integration
Ability to clearly communicate with team-members in a cross-matrix environment
What puts you over the top:
Built systems in a containerized environment with familiarity in Docker, ECS, Kubernetes
Exposure to Data Warehousing solutions like Snowflake and BigQuery
Prior ad tech experience
About Integral Ad Science

Integral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 18 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit integralads.com.

Equal Opportunity Employer:

IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.

California Applicant Pre-Collection Notice:

We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.

To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN

Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.",3.5,"Integral Ad Science
3.5","Chicago, IL",501 to 1000 Employees,2009,Company - Private,Internet,Information Technology,$100 to $500 million (USD)
Sr. Data Engineer,-1,"About Us:

Convr is a growing startup in the InsureTech space. Our d3 Underwriting Platform helps underwriters make better decisions more efficiently. As we continue to grow we are looking for leaders to help us scale not only our platform but our organization. This is an exciting role that will allow you to mentor, lead, and innovate.

The Role:

THIS POSITION WILL BE IN OUR SCHAUMBURG, IL OFFICE. WE CANNOT OFFER OUT OF STATE OPPORTUNITIES AT THIS TIME. As a Sr. Data Engineer, you will work closely with technical leadership and product managers to lead a team delivering the best solutions for our customers. You will develop a deep understanding of the people, technologies, and practices of your team(s), and apply your expertise to scale our teams and platform. You will innovate and push our technology further. You will teach and mentor our engineers to be more efficient, write quality code, and leverage best practices.

Your Responsibilities:
Be a high performer that produces production quality code that gets value to our customers
Enables scalability within our applications and services
Owns parts of our systems and innovates to create defensible depth in our products
Mentors our engineers to help further their technical skills
Technical Skills Demonstrated:
7+ Years in creating a production application / services
1+ Years as a team lead on a sprint team
1+ Years in Python
4+ Years with micro-services architecture
Understanding of data modeling and various data lake solutions
Built out data platforms that support multiple data sources
Worked on systems with high number of users (1000s - 1Ms)
ML and AI Experience
Owned Code all the way to production before
Experience with DevOps
Things that will help you succeed:
Passion for delivering value to customers
Enjoys solving complex data problems
Can evangelize Agile / Scrum framework to deliver this value
Quality is everything to you
Ownership! Takes ownership and responsibility for all things Convr
Test 1st Mindset
Education:

Bachelors Degree",-1,Convr,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Pharmaceutical Development Scientist,-1,"Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description

With supervision as required, proficiently performs all assigned chemistry techniques. Demonstrates a good understanding of scientific principals and their cause and effect on scientific outcomes. Practice of GMP/GLP is routine. Once appropriately trained, this individual may be designated as a notebook reviewer. Authors and may review others protocols, reports, specifications and test methods. Presents results at team meetings with interpretation. Acts as a coach to junior staff.
Proficiently performs all assigned laboratory techniques.
Independently develops analytical methods on a variety of analytical techniques and instrumentation.
Independently performs method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience in operating and troubleshooting the following instrumentation:
Ultra-High Performance Liquid Chromatography
Differential Scanning Calorimetry (DSC)
Size Exclusion Chromatography
Multi Angle Light Scattering (MALS)
Fourier Transform Infrared Spectroscopy (FTIR)
Asymmetrical Field- Flow Fractionation (AFFF)
Dynamic Light Scattering (DLS)
Tutors and trains others on troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Designated notebook reviewer.
Generates, analyzes and presents scientific data at team meetings. Explains cause and effect relationships and may propose additional experiments to
prove/disprove hypotheses. Has a general understanding of the depth and breadth of drug development and can contribute to the scientific discussion during project team meetings.
Understand regulatory guidelines and can author protocols, reports and analytical test methods.
Generate and analyze scientific data and handle OOS’s (Out of Specification) with little difficulty.
Has a good understanding of different plant manufacturing processes and can plan bench studies that will translate into a manufacturing process while solving related compounding, solubility, etc. problems.
Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development experience. Preferred education background in Analytical Chemistry, Pharmaceutics or similar discipline, however, extensive experience with analytical chemistry may be substituted for education.
Significant experience with the drug development process
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Strong analytical background
Liquid formulation experience is desirable
Product development experience in the pharmaceutical industry
Ability to meet deadlines
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information

Position is full-time, Mon-Fri 8:00am-5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",-1,Eurofins USA PSS Insourcing Solutions,"Lake Forest, IL",-1,-1,-1,-1,-1,-1
Senior Clinical Scientist - Clinical Trial Mgmt and Medical Monitoring exp required,"$27-$49 Per Hour
(Glassdoor Est.)","Job Overview:


Senior Clinical Scientist - Oncology

Clinical Trial Mgmt and Medical Monitoring experience is required

Remote in the USA or Canada

Why settle for one thing when you can have everything?

Covance gives you the best two-for-one opportunity for career growth. Who doesnt want twice the perks? Working at Covanceone of the largest FSP CROsand partnering with one sponsor with a dedicated therapeutic focus. You can have it all!

As a Covance employee dedicated to an FSP project, you will bring your specialized discipline to a core team working directly with one sponsor. Whether your specialization is in clinical monitoring, clinical project management, data management, biometrics or pharmacovigilance, Covance has an FSP opportunity to match your area of expertise.

You will enjoy the best of both worldsall the benefits that come along with Covances Energizing Purpose, Exceptional People and Extraordinary Potential combined with working exclusively with one sponsor and this also comes with the benefit of bringing your strong therapeutic experience to allow your expertise to shine through.

Covances FSP model is flexible and scalable. Our teams are collaborative and proactive a great place for you to continue honing your therapeutic skills and growing and excelling in new and exciting research.

Covances reach is global extending to 60+ countries making us one of the largest FSP CROs. No matter where you are located on the globe, we have an FSP opportunity for you.

In this role, the selected candidate may lead or support a study or studies, depending on size/complexity. If lead, accountable for the clinical/scientific execution of the protocol.

As lead, will be responsible for the following:
Clinical point of contact for scientific issues/questions for internal and external stakeholders (e.g., IRB, sites)
Responsible for trial design and endpoint development in collaboration with CD
Leads the Medical Monitoring (MM) team in performing MM activities, including development of the Medical Monitoring Plan (MMP) and review of SAE reports
Sets up/supports SAC, DMC, adjudication committees
Protocols/amendments collaborates with medical writer, participates in governance committee review
Authors protocol clarification letters
Contributor to study specific documents (e.g., SMP)
Reviews/updates informed consent
Provides scientific input to SM for data management activities (e.g., EDC, DRP, CRFs)
Monitors data issues requiring clinical input
Monitors central lab reports and other external data for safety and critical values
Prepares scientific slides, attends and presents protocol information at Investigator Meeting
Scientific lead on Clinical Trial Team (CTT)
Reviews specs, initiates allocation (randomization) request form and approval schedule in allocation schedule generation system
Coordinates planning of lab, bio specimens and imaging specifications
Co- authors newsletters with SM
Participates in Database lock activities
Collaboratively plans CSRs, CTDs/WMAs with medical writing
Supports publications/presentations as needed
Reconciles and review all protocol deviation classifications in SPECTRUM
Assesses and prepares protocol deviation list for CSR
Collaborates with medical writing to develop trial results communication for investigators
Provides scientific assessment for Operational Reviews
Supports SM/MW activities as needed to achieve CTT deliverables.
Provides clinical specifications to SM to support interactions with external vendors (e.g., IVRS, ePRO)
May act as mentor to other CSs
Education/Qualifications:

Degree in Life Sciences or significant experience in clinical development (>14 years)
BS/BA with 7+ yrs clinical research experience
MS/PhD with 5+ years clinical research experience
Experience:

Minimum 2 years pharmaceutical and clinical drug development experience in a Clinical Scientist role as a lead required.
Proven ability to effectively manage multiple complex studies
Medical monitoring experience required
TA-specific experience in Oncology
Excellent Excel and PP skills required
Excellent written and oral communication skills",3.5,"Covance
3.5","Chicago, IL",10000+ Employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10 to $25 million (USD)
Senior Data Engineer,-1,"Projects the candidate will be working on:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
Team and Team size:
Will be part of team
Will be part of Agile team with minimum 7 members
Top Responsibilities:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
The ideal candidate will be very comfortable creating subscriptions to stream real-time data using CDC tools such as IBM Infosphere Data Replication and streaming data to Kafka.
The candidate should be comfortable working with AS400, Oracle and MSSQL server databases, including any aspect of administration or support required to maintain them.
Required Experience & Qualifications:
Data engineering experience - 7 years
Cloud platform experience - 1 year
Version Control (Git or equivalent) - 1 years
Preferred Experience & Qualifications:
Change Data Capture Tools (IBM CDC, Attunity or equivalent) 3 years
Version Control (Git or equivalent) 1 year
Scripting (Linux/Unix Shell scripting or equivalent) 5 years
Interview Process:
a. How many rounds? 2 or 3
b. Video vs. phone? Phone
c. How technical will the interviews be? Very detailed Technical",4.0,"Horizontal
4.0","Schaumburg, IL",501 to 1000 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Sr Data Engineer,"$59K-$116K
(Glassdoor Est.)","Position Role/Tile: Sr Data Engineer
Location: Schaumburg, IL.

Job description:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.

Is this person a sole contributor or part of a team?
Will be part of team
If so, please describe the team? (Name of team, size of team, etc.)
Will be part of Agile team with minimum 7 members
What are the top 5-10 responsibilities for this position? (Please be detailed as to what the candidate is expected to do or complete on a daily basis)
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting. The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
The ideal candidate will be very comfortable creating subscriptions to stream real-time data using CDC tools such as IBM Infosphere Data Replication and streaming data to Kafka.
The candidate should be comfortable working with AS400, Oracle and MSSQL server databases, including any aspect of administration or support required to maintain them.
What software tools/skills are needed to perform these daily responsibilities?
Required Experience & Qualifications:
Data engineering experience - 7 years
Cloud platform experience - 1 year
Version Control (Git or equivalent) - 1 years
Preferred Experience & Qualifications:
Change Data Capture Tools (IBM CDC, Attunity or equivalent) 3 years
Version Control (Git or equivalent) 1 year
Scripting (Linux/Unix Shell scripting or equivalent) 5 years
Central Business Solutions, Inc,
37600 Central Ct.
Suite #214
Newark, CA 94560",3.0,"Central Business Solutions, Inc
3.0","Schaumburg, IL",51 to 200 Employees,-1,Company - Private,Consulting,Business Services,$5 to $10 million (USD)
Lead Big Data Engineer,"$100K-$169K
(Glassdoor Est.)","Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the worlds large accumulation of health-related information, or guide health and lifestyle choices, or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) The ideal candidate will be a self-starter who can learn things quickly, who is enthusiastic, active, and eager to learn. Youll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary Responsibilities: Design, code, test, document, and maintain high-quality and scalable Big Data solutionsDesign, develop and implement rules enginesResearch, evaluate, and deploy new tools, frameworks and patterns to build sustainable Big Data platformIdentify gaps and opportunities for improvement of existing solutionsDefine and develop APIs for integration with various data sources in the enterpriseAnalyze and define customer requirementsAssist in defining product technical architecture Make accurate development effort estimates to assist management in project and resource planning Create prototypes, proof-of-concepts & design and code reviews Collaborate with management, quality assurance, architecture, and other development teamsWrite technical documentation and participate in production support Keep skills up to date through ongoing self-directed training Youll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.",3.4,"UnitedHealth Group
3.4","Downers Grove, IL",10000+ Employees,1977,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
"Senior Software Engineer, Data Platform",-1,"About Us

Mastery Logistics Systems is building the worlds first lovable Transportation Management System, or TMS.

Our customers large transportation companies and shippers who need those companies have struggled with systems that are outdated or inadequate. As shippers or transportation service providers, our customers have in the past been forced to use multiple systems to manage dedicated fleet operations, outsourced or insourced trans management, one way trucking, truckload brokerage, LTL, and Intermodal, or to sub-optimize one or more of those functions by attempting to fit it into a TMS that is adequate at another function.

Mastermind TMS allows our customers to bring all of these functions into a single platform, providing flexibility, visibility, control, and efficiency. Todays unprecedented global supply chain upheavals underscore how important the transportation industry is. We are building a system to allow this industry to work faster, smarter and more efficiently.

The challenges in this industry are big and exciting! We are tackling everything from fast and efficient data input to ingesting large amounts of data and applying AI to looking at blockchain to securely digitize paperwork. If you are passionate about humanizing an industry, automating in innovative ways, building for quality and scale, helping make people's lives easier and touching every part of our economy then this is the place for you.

Mastery Logistics Systems is committed to continuing to build an incredible company. We are a masterful mosaic of incredible people. We are specialists and experienced in our respective fields. We are dedicated to continuous improvement both professionally and personally. We are a collective group of really good people. We have different interests, backgrounds & talents and we work together to create really cool stuff! We believe in diversity of thought and are mindful and inclusive. We have deep respect for each other and work diligently at adding the right people to our teams.

At this moment we are all working from home and doing our part to combat the Covid 19 virus. We are creatively building our new work habits. We are respectful of each others time and personal life. We have flexible schedules but share in the mission that we are building and need to get it done. We offer an excellent suite of benefits. We are dedicated to finding new ways to add perks as we live and work from home.

Our team has the domain knowledge and connections to make an impact, and were looking for experienced and thoughtful people to who thrive on creating and building great products. We want people who have a true passion for servicing and taking care of our customers. We need people who are flexible problem solvers, thrive on collaboration and consistently know how to communicate their solutions well. We are small and nimble which is evident in how quickly we could pivot to our new reality. Each member of the team can make a tremendous impact both technically and culturally. While a start-up, we are well-funded, have an initial paying customer with which to test and launch, and are founded by top experts and veterans in the logistics industry.

Join us youll love it lets build a masterpiece!

About the Role

The transportation industry has no shortage of complex problems requiring creative, data-intensive solutions in order to effectively and efficiently automate operations at scale. In this role, you will be expected to work autonomously and contribute to several high impact projects including building services providing near real-time analytical insights to Masterys customers.

Responsibilities
Closely collaborate with fellow Engineers, Data Scientists, and Product Managers and interact with stakeholders across the organization to build real-time data products
Design, build, and deploy microservices that provide real-time, analytical insights to some of North Americas largest freight brokerages
Support Masterys Data Science team by establishing best practices, developing tools, and building infrastructure that makes the work of Data Analysts and Data Scientists more robust, reliable, and easy to implement
Write clean, maintainable, and well-tested code
Engage in the full development life-cycle including architectural design and testing
Be a force-multiplier on the velocity and quality of your team
Stay current on software engineering trends & tools, and be practical but open-minded in applying them
Maintain a high bar for quality and performance of your product with vigorous attention to detail and automated testing
Continuously improve how we design, build, and ship software as a highly functional team
Requirements
3+ years of practical experience in data-intensive software development, including designing, building, deploying, and maintaining data applications
Expertise in data-focused development, including experience with a variety of database, data warehouse, distributed processing, and machine learning technologies
Minimum of two years of industry experience building production software with Python
Experience with Kafka or similar event streaming systems
Expertise with SQL and RDBMS
Excellent written and verbal communication skills
Adept at interacting with technical and non-technical audiences
Experience working with real-time, distributed systems
Strong sense of responsibility with a bias towards action
Experience working with RESTful APIs
Comfortable self-directing and prioritizing your own work
Ability to understand complicated problems and craft into simple solutions that can be maintained by the rest of the team
Experience leading technical projects
Ability to train and mentor junior engineer
Experience with NoSQL technologies, preferred
Experience with GraphQL, preferred
Experience in logistics industry, preferred
Benefits

Mastery takes great pride in providing our employees a robust and highly competitive benefit package. Our benefits include Medical, Dental and Vision insurance covering 90% of premium costs. Company paid life insurance for 1x salary. Legal, AD&D, Additional Life and other employee assistance benefits. We have a 401k savings plan with a 4% match. We provide opportunities for professional growth and development. We fully support our work from home initiative as we do our part to combat the Covid 19 crisis. We have a manage your life and schedule Paid Time Off program. We are fully devoted to finding creative perks and benefits since we cannot currently enjoy our cool office culture. Our philanthropic partner is St. Jude Childrens Research Hospital.

We are an equal opportunity employer and actively seek a diverse community of professionals. Veterans, Women, non-binary, people of color, LGBTQIA, we welcome all to apply!",-1,"Mastery Logistics Systems, Inc.","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Azure Data Modeler,-1,"Great opportunity to show off your passion for data, reporting, analytics and data warehousing. Our client's BI team may have the perfect fit for you!

We are looking for a self-motivated Data modeler/Engineer to join our business intelligence team.

This individual will be responsible for developing and maintaining business intelligence, data warehousing and data engineering solutions for Enterprise data This individual will also create and maintain detailed business requirements, outlining data problems, opportunities and solutions.

Responsibilities Include:
Responsible for designing relational and non-relational data stores on Azure.
Responsible for designing and developing solutions in Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, SQL Data Warehouse, HDInsight.
Gather and process raw data at scale that meet functional / non-functional business requirements (including writing scripts, REST API calls, SQL Queries, etc.)
Responsible for developing data set processes for data modeling, mining and production.
Responsible for building new Data Lake in Azure, expanding and optimizing our data platform and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
Responsible for supporting our Software Developers, Data Analysts and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Develop complex SQL queries in TIBCO Data Virtualization tool.
Qualifications:
3+ Years of experience architecting and building Data Lake, Azure Big Data architecture, Enterprise Analytics Solutions, and optimizing ' big data' data pipelines, architectures and data sets.
Bachelor’s Degree in Computer Science, Information Systems, or related field
Advanced hands-on SQL, USQL, Python, C#, Java, pySpark (2+ of these) knowledge and experience working with relational databases for data querying and retrieval.
Experience with Design and Architecture of Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure ML, SQL Data Warehouse, HDInsight.
Experience with building processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience working with cross-functional teams in a dynamic environment.
Experience building Big data pipeline with Java and/or Python a plus.
Strong SQL skills on multiple platform
Data Modeling tools (e.g. Erwin, Visio) knowledge a plus.
Experience with SAP HANA a plus.
Experience with Talend a plus.
_Brooksource provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws_

Job Types: Full-time, Contract

Pay: $45.00 - $50.00 per hour

Benefits:
Dental Insurance
Health Insurance
Paid Time Off
Vision Insurance
Schedule:
8 Hour Shift
Day shift
Monday to Friday
Experience:
Azure Big Data architecture: 3 years (Required)
Architecting and Building Data Lake: 3 years (Required)
Developing complex SQL Queries: 3 years (Required)
Enterprise Analytics Solutions: 3 years (Required)
Full Time Opportunity:
Yes
Work Location:
One location
Benefit Conditions:
Waiting period may apply
Work Remotely:
Temporarily due to COVID-19",4.5,"Brooksource
4.5","Northfield, IL",501 to 1000 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Senior Data Science Consultant,-1,"Senior Data Science Consultant
Healthcare
Chicago, IL
$135,000 - $155,000 + Benefits + Bonus

Are you passionate about joining one of America's most famous organizations in the healthcare/ pharmaceutical space? A leading healthcare company is looking for an experienced Senior Data Science Consultant who is technically strong in R, SQL, Python, and Tableau, to advise in implementing solutions through an analytical lens to drive business growth.

THE ROLE:

As Senior Data Science Consultant, you will be partnering with Data Scientists and mentoring junior team members in implementing and framing solutions for making certain treatment programs more efficient. You will be responsible for:

Navigating huge and complex claims data
Performing advanced analytics using Python, R, SQL, and Tableau
Consulting with internal clients to identify opportunities for which you can implement data science
Acting as analytics product owner translating business needs into analytics actions and projects

YOUR SKILLS AND EXPERIENCE:

Strong understanding of managed healthcare space
Proven commercial experience in working with claims data at a large company
Proficient in R, Hadoop, Python, SQL, and Tableau
Proficient in mathematical analysis methods, machine learning, statistical analysis, and predictive modeling
Strong understanding of advanced analytical tools and languages needed to analyze large sets of complex and messy data from multiple sources
Proven experience in strategy consulting, as well as managing or leading teams
Bachelor's degree and Master's in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline; PhD preferred

BENEFITS:

As Senior Data Science Consultant you can expect to earn up to $155,000 (depending on your experience) plus great benefits and of course, great healthcare!

HOW TO APPLY:

Please register your interest by sending your resume to George Little via the Apply link on this page.

KEYWORDS:

Healthcare, pharmaceutical, data science, advanced analytics, consultant, consulting, advisor, Python, R, Hadoop, Tableau, SQL, machine learning, predictive models, predictive analysis, statistics, claims data, engineering, project management, product owner, strategy",4.2,"Harnham
4.2","Chicago, IL",51 to 200 Employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Big Data Machine Learning Engineer,-1,"Title: Big Data Machine Learning Engineer@ Chicago, IL
Terms of Hire: Full Time.
Salary: $Open+ Benefits.

The candidate can also work from any of these locations:
Chicago, IL, US
Cleveland,OH,US
Washington,DC,US
Job description

ABOUT THE JOB

The Decision Sciences team is part of the Enterprise Payments and Analytics organization. Its mission is to lead Client’s journey to become an innovative, data driven enterprise by building advanced analytics solutions for solving business problems. Our experienced team of AI/ML and Data Science practitioners focuses on engaging, enabling, and empowering decision-makers across the enterprise by developing, managing and supporting advanced analytics products and scalable digital solutions, such as real time and on demand predictive models and prescriptive analytics, and continuously researching, specifying, and deploying next-generation analytics capabilities. We are an internal consulting and services organization that works directly with users across the firm, including Lines of Businesses and partners in Enterprise Strategy, Marketing, Data Analytics, and Enterprise Architecture, to facilitate the development of innovative solutions that help Client compete and win with analytics.

The Big Data ML Engineer fills a critical data, analytics, technology support, and innovation role for the business analytics and advanced analytics functions within the organization. The Engineer is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organization’s enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS

The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use cases—primarily focused around open source technologies including cloud infrastructures. This individual evaluates short/long-term business needs required to support Client business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on Client Enterprise systems. Under the guidance of the Group’s Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on Client data assets for business decision management solutions. The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions. The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions. The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organization’s AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.

REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
What are the 3-4 non-negotiable requirements on this position?
1. Experience in open source technologies (Python, Hadoop, Spark, etc.) 2. Experience in Cloud environment, Google Cloud platform preferred 3. Machine learning expertise
What are the nice-to-have skills?
Finance/banking background
You Will Enjoy:
An opportunity to be a part of a great culture, an awesome team, a challenging work environment, and some fun along the way!
Apply today to learn more and be part of our Growth story.
All applications will be kept strictly confidential and once shortlisted, our team will be in touch with you for further discussions.",-1,CEDENT,"Chicago, IL",1 to 50 Employees,-1,Contract,Computer Hardware & Software,Information Technology,Less than $1 million (USD)
Big Data Machine Learning Engineer,-1,"Thusa is looking for Big Data Machine Learning Engineerto join the team. The ideal candidate is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organizations enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS
The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use casesprimarily focused around open source technologies including cloud infrastructures.
This individual evaluates short/long-term business needs required to support key business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on the Enterprise systems.
Under the guidance of the Groups Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on key data assets for business decision management solutions.
The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions.
The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions.
The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organizations AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.
REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
Thusa is dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock. dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock.

Our employees enjoy a work culture that promotes company priorities.

We treat our employees like family while providing on-going support for growth. We are not only looking for people who can do the job, we are also looking for our future leaders.

Powered by JazzHR",-1,Thusa Solutions,"Chicago, IL",-1,-1,-1,-1,-1,-1
Kafka Data Engineer (remote),"$62K-$114K
(Glassdoor Est.)","Summary
We exist to help people achieve financial clarity. At Thrivent, we believe money is a tool, not a goal. Driven by a higher purpose at our core, we are committed to providing financial advice, investments, insurance, banking and generosity programs to help people make the most of all they’ve been given.

At our heart, we are a membership-owned fraternal organization, as well as a holistic financial services organization, dedicated to serving the unique needs of our clients. We focus on their goals and priorities, guiding them toward financial choices that will help them live the life they want today—and tomorrow.

Join our newly created Data Office as the full-time Kafka Data Engineer! We are hiring for both a mid-level and a senior level Engineer. Bring your expertise in implementing modern data architectures and Data Streaming. We have a data streaming platform to enable frictionless data flow from business systems and 3rd party sources using publish/subscribe model. This role will require experience with hybrid platforms, cloud migration, publishing, development with newer technologies such as Spring Boot, KSQL/Stream Processing, data connectors such as Kafka, performance tuning, data quality and data visualization knowledge. You and will report to the Director of Information Delivery.
Job Description


Job Duties and Responsibilities
Partner on the design, deployment, and persistence of our new streaming platform unifies the data across organization, using Confluent Kafka.
As the senior level Engineer, you will be leading a group of engineers.
Design, Develop, Release & Support containerized microservices (OpenShift / Spring Boot) to transform and enrich topic data.
Lead reusable design and patterns for services and data processes within the platform.
Partner on setting standards, implementing tools, and creating documentation for self-serve data pipeline services supporting core engineering and professional services use cases.
Work with existing engineering teams to become data producers and consumers to and from Confluent Kafka.
Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.
Apply business knowledge and experience to effectively advise others on technology as an enabler.
Lead efforts to analyze IT industry and market trends and determine potential impacts.
Develop concepts and constructs necessary to create technology-enabled business systems.
Influence technology direction.
Provides thought leadership and execution to large complex efforts.
Utilize breadth of technical understanding and dive deep when necessary.
Consult on and manage initiatives to ensure alignment across multiple business and IT areas.
Proactively mitigate risks across multiple assets, information domains, technologies & platforms.
Provide leadership, mentoring and technical guidance to others to drive initiatives.
Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.
Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.
Act as a change agent to continuously improve and move the organization forward.
Accountable to provide leadership to successfully deliver the right results on initiatives in a timely and effective manner.
Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.
Ability to work within a diverse team of skillsets and experience levels to deliver results.
Required Job Qualifications
Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field.
5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years of lead experience.
Strong experience with event streaming such as (Kafka or Amazon Kinesis).
Experience with SQL and NoSQL databases (PostgreSQL, MongoDB, etc).
Proficient delivering services within AWS.
Experience with Confluent Kafka, penShift / SpringBoot is preferred.
Demonstrated ability to develop containerized microservices (Docker with Kubernetes) is preferred.
The ability to communicate cross-functionally, derive requirements and architect shared datasets; ability to synthesize, simplify and explain complex problems to different types of audiences.
Desire to show ownership of problems you identify and proven ability to empower others to get more done.
Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color, sex, gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state, or federal law. This policy applies to all employees and job applicants.

Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation, please let us know by sending an email to human.resources@thrivent.com or call 800-847-4836 and request Human Resources.",3.5,"Thrivent
3.5","Chicago, IL",5001 to 10000 Employees,1902,Nonprofit Organization,Insurance Carriers,Insurance,$5 to $10 billion (USD)
Director of AI Product Management - Office of Data Science,"$68K-$121K
(Glassdoor Est.)","Advance your career at Liberty Mutual Insurance - A Fortune 100 Company!

Help bring Liberty Mutual into the future by advocating on behalf of all data scientists across the enterprise. The Director of AI Product Management will be a key member of the Office of Data Science Product Team. As the Director of AI Product Management you will advocate for DS efforts across the enterprise by acting as Product Owner over a team of ML engineers, helping to identify, measure and socialize DS initiatives and partnering with technology, business and the data science community (DSPRG) to promote collaboration and reuse. Liberty Mutual aspires to be the data science leader within the insurance industry and you will play a key role in partnering across the organization to make this happen.

Roles and Responsibilities:
Strategic Vision
Partner with the ODS Science team to engage the enterprise and identify top business opportunities for ML application (e.g. CV, NLP, Aerial Imagery, and Trusted AI).
Measure the value of data science at Liberty and communicate it to the enterprise.
Customer / Collaboration
Foster relationships across the LM enterprise. Promote and build excitement for data science.
Act as a change agent across the organization by influencing and driving strategic direction and investments in AI.
Collaborate with and influence key stakeholders and customers to embrace a product mindset and drive business outcomes.
Partner with the business, tech and data science leaders to jointly drive forward efforts to enhance DS/AI collaboration.
Model Deployment
Act as the product owner for a ML Engineering squad tasked with deploying models delivering ~$100M (and growing) in value to the enterprise.
Manages the existing program, onboards new customers and socialize the value of the portfolio
Vendor
Support DS and ML vendor engagements and purchasing decisions as the organization makes build vs buy vs research decisions
Key traits we are looking for:
Data Science Passion - you have a passion for making things better through data science.
Leadership - You are a passionate leader who can bring the enterprise together, gain cross team alignment and deliver results.
Customer Empathy - ability to try on the experiences of customers and stakeholders - especially those with conflicting viewpoints.
Problem solving - you can solve difficult problems efficiently with appropriate methodologies
Integrity - you build and maintain trust with your colleagues, stakeholders, partners, and leaders
Drive - you work smart and hard to succeed
Communication Skills - you can communicate to a wide variety of audiences adapting your technique as appropriate in a strategic manner
Qualifications:

A minimum of three years recent experience in a DS or technology product role with a proven track record of providing leadership on complex / challenging technical product delivery.
Demonstrated ability to think broadly across multiple good viewpoints
Knowledge of DS applications, DS infrastructure needs, and organizational challenges & obstacles as it relates to vetting, prototyping and scaling DS solutions
Excellent communication, analytical, interpersonal, organizational and team building skills, business judgement, and proven expertise in directing the efforts of agile teams
Experience of strongly influencing product strategy at a senior level and leading organizational change
Ability to continuously prioritize development based on business value and product strategy
Ability to create and foster consensus from the whole business for a coherent product vision
Ability to estimate ROI of complex projects

Benefits:
We value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits
Overview:
At Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.
We're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.",3.5,"Liberty Mutual Insurance
3.5","Warrenville, IL",10000+ Employees,1912,Company - Private,Insurance Carriers,Insurance,$10+ billion (USD)
Sr. Data Engineer,"$75K-$140K
(Glassdoor Est.)","At Echo we are committed to help our Associates grow their career. Apply today and grow with Echo!
-
-",3.5,"Echo Global Logistics
3.5","Chicago, IL",1001 to 5000 Employees,2005,Company - Public,Transportation Management,Transportation & Logistics,$2 to $5 billion (USD)
Senior Data Engineer,-1,"Are you interested in building the future of healthcare and transforming the patient experience? Are you hopeful about what data and medical research can do to improve medicine? We’re looking for a Senior Data Engineer to ensure PatientIQ remains on the forefront of using data to drive positive healthcare outcomes.

As a core member of the Analytics department, you will be in a dynamic environment that is actively building the future versions of our automated data science platform - Analytics Autopilot. In addition, our team often works cross-functionally with the Engineering, Product, and Sales departments as PatientIQ scales its business. Your work will involve coming up with new software features, defining metrics, streamlining existing data processes, and mentoring other team members. We heavily value diligence, curiosity, and initiative, as those are key to unlocking the value of PatientIQ's data for our users and our decision-making. Your work will be impactful across the entire organization.

Role Responsibilities
Design, develop, and maintain ETL infrastructure to support the ingestion of external data sources
Work on a cross-functional team to design, develop, and maintain PatientIQ's internal reporting infrastructure
Understand data requirements and implement solutions for data science applications
Perform unit and integration testing
Mentor junior team members
Help scale PatientIQ's data strategy as the platform and business grows
Requirements

Ideal Qualifications
Experience designing, building, and maintaining ETL infrastructure in a production setting
BS/MS in Computer Science, Engineering, Mathematics, or related field
Proficient in Python or another object oriented programming language
Deep knowledge of SQL and at least one database technology
Experience with software development lifecycle processes and using version control systems (git), either from prior data engineering work or in a more traditional software engineering setting
Highly self-motivated with strong analytical problem-solving skills and attention to detail
Nice to Haves
Experience with workflow management systems such as luigi or airflow
Experience in machine learning and/or business intelligence
Experience with cloud technologies such as AWS, Google Cloud Platform, or Azure
Experience with ETL tools like Apache Kafka, Logstash, Segment, Informatica
Experience with automated machine learning technologies such as Amazon SageMaker or Google Cloud AutoML
Experience with cloud data warehouse platforms such as Snowflake, Qubole, etc.
Experience working in Healthcare, Finance or another regulated industry
Benefits
Great Benefits - top-notch health, dental and vision insurance. Additional perks available including 401K.
We are Mission Driven - our team is motivated to solve complex problems, drive medicine forward, and ultimately improve patient outcomes.
True Idea Meritocracy - great ideas win out. We encourage all team members to challenge the status quo because our mission demands this.
Flexible Time Off - we trust you to take the time you need when you feel it is appropriate, given your workload and responsibilities. No need to track it or save up.
World-Class Team - we’re at the top of our industry because of our employees. They’re the best investment we can make, and we never forget that.
Fast Growing - we are building the largest platform for healthcare providers, industry partners, researchers, and others to collaborate on the mission to improve patient outcomes.",-1,PatientIQ,"Chicago, IL",-1,-1,-1,-1,-1,-1
Big Data Architect,-1,"Our Client is a leader in data-driven marketing, named as one of the top 20 data integrators to watch and grow with. Our Client delivers insight and results to their customer with marketing expertise, technical and analytic capabilities, and a relentless focus on the customer. Business model based on driving lasting customer relationships and incremental brand revenue through integrated systems, online and offline CRM, real time predictive modeling, and data management.

The Big Data Architects primary responsibilities are to create and develop solution designs to integrate and ingest data from various resources, supporting Clientss internal big data ecosystem.

They will be responsible for defining the big data architectural blueprint under the supervision and collaboration with the Technology Solutions Director. The Architect will work closely with data engineers, cloud engineers, and data scientists to design and implement optimum solutions using best practices. They are responsible to ensure the data ecosystem is built to be highly scalable, responsive, and available.

The Big Data Architect oversees the implementation of data solutions by working with Clients onshore and offshore engineering teams to create ETL, batch, real-time, and automated processes. As part of the core Technology Solutions team the right candidate will heavily contribute to the teams coding and programming standards and ensure other team members are following the guidelines and standards.

Responsibilities:


Take ownership of data solutions from design and architecture perspective for projects in presales phase as well as on-going projects

Select and integrate any Big Data tools and frameworks required to provide requested capabilities. Can oversee the implementation by team members of said solutions

Design and implement ETL and automated processes

Monitor performance and advise of any necessary improvements and changes

Management of EMR clusters, Glue Jobs, Athena Tables, S3 data lakes; with all included services

Provide technical support to members of TS and SA team, as well as project support across client engagements

Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value

Stays current with relevant technology in order to maintain and/or improve functionality for authored applications

Assume other responsibilities as requested/required

Acts as a subject matter expert for systems worked on

Ensures Clients data solutions are using the latest versions and code base

Actively listen to and work with end users to gather feedback and input, and make suggestions and solutions based on said feedback

Requirements

Required Experience:
(7 years of relevant experience) or (5 years of relevant experience and an advanced degree in Computer Science/IT or related field)

Keen understanding of distributed computing principles
• Proficiency with Big Data frameworks such as Hadoop, Spark, MapReduce, HDFS.

Proven experience ingesting data from multiple data sources such as REST API, SFTP flat files, Streaming data etc.

Proven experience with Big Data querying tools such as Athena/Presto, Pig, Hive, and Impala

Proven experience with NoSQL databases, such as HBase, Cassandra, Redshift, DynamoDB

Proven experience with various ETL techniques and frameworks, such as Flume, Glue Jobs, Step Functions

Proven experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O

Proven experience with AWS Lambda and leveraging it in various solutions such as Glue, Step Functions, CloudWatch, S3 Events, etc.

Strong experience with using Python scripts & libraries

Experience desired with Database Warehousing Design Concepts; Dimensional.
• Modeling, Star/Snowflake Schemas, ETL/ELT, Data Marts, Analytic Playgrounds, Reporting techniques

Experience working with Agile software development methodologies, namely Scrum

Proven experience with team collaboration, release management, system and performance monitoring

Ability to work well with people from many different disciplines and varying degrees of technical experience

Excellent analytical, problem resolution, organization and time management skills

Ability to handle multiple tasks at a time
• Demonstrated ability to have successfully completed multiple, complex technical projects and create high-level design and architecture of the solution, including class, sequence and deployment infrastructure diagrams

Prior experience with application delivery using an Onshore/Offshore model
• Experience with gathering end user requirements and writing technical documentation

Keyword: Hadoop, Spark, MapReduce, HDFS, REST, API, SFTP, Athena, Pig, Hive, Impala, NoSQL, HBase, Cassandra, Reddrift, DynamoDB

Benefits


We do have a full benefit package of medical/dental/vision insurance, disability, life, 401k employer match along with profit sharing and bonus. Optional benefits is AFLAC plans and FSA for medical or childcare.

Vacation, 5 Sick Days and 2 personal days with a total of about 30 days off within a year depending on when holidays fall. Included in that is the close of the office between Christmas and New Years.",-1,DSMHConsulting,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"Candidate Responsibilities

Develop implementation patterns leveraging AWS technologies to support Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solution Data Designs, Models, Pipelines
Prototype New Solutions Technical guidance to data designers and
developers Solution Implementation Reviews Open to Chicago, IL as well.

Typical Day

Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solutions with Platform, Business, and Application teams

Requirements


Education Requirements:

B.S. in Computer Science, Information Systems, or related major or
equivalent IS / business experience. 10+ years experience designing,
implementing data persistance and processing solutions AWS
Certifications

Technical Skills

AWS Cloud Based Technologies for Data Processing and Persistance
(DynamoDB, S3, Aurora, Kinesis, SQS,SNS, Lambda, Fargate, Glue) Ability
to design and communicate solutions to meet business and technical
requirements Demonstrated Data Architecture and Design
for Big Data, Analytics, and applications

Soft Skills

Written and Verbal Communication Able to produce architecture and design artifacts in Visio and Office 365",-1,DSMHConsulting,"Chicago, IL",-1,-1,-1,-1,-1,-1
Staff Big Data Engineer,"$95K-$171K
(Glassdoor Est.)","Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry. Our technology handles hundreds of thousands of transactions per second; collects tens of billions of events each day; and evaluates thousands of data-points in real-time all while responding in just a few milliseconds.

We are looking for an experienced Big Data Engineer to join our Data Engineering team. This position will be the Senior technical resource driving architecture for the integration of large 3rd party partner integrations with companies like Facebook, Google and Twitter to name a few. The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. This position will require the ability to own and lead data initiatives on a cross-functional team.The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. You should be able to not take yourself too seriously as well. And most of all, you will enjoy working with great people who are changing the entire industry.

What you'll do:
Migrate existing data pipelines from on-prem regional data centers to AWS and GCP.
Architect a new modern event driven architecture with both batching and streaming
Adjust existing pipelines to fit the AWS processing model such as integration with S3, migrate to open source version of hadoop, adjustments to security model, etc...
Working on Big Data technologies such as Hadoop, MapReduce, Kafka, and/or Spark in columnar databases
Architect, design, code and maintain components for aggregating tens of billions of daily transactions
Lead the entire software lifecycle including hands-on development, code reviews, testing, deployment, and documentation for streaming and batch ETL's and RESTful API's
Partner and work closely with the QA Engineers to develop automated tests
Participate in training and mentoring of junior team members
You should apply if you have most of this:

(We have flexibility in this role to consider more, or marginally lesser, experience than requested below)
8+ years of experience designing and building data-intensive applications
5+ years architecting systems in a big data ecosystem using MapReduce, Spark, MPP Data Warehouses, and sql/nosql databases.
5+ years recent hands-on experience with object oriented languages (Java, Scala, Python)
5+ years Hands on experience building production level systems in a cloud environment (AWS or GCP)
Excellent interpersonal and communication skills in English
Proven experience leading the design and execution of event driven architectures for distributed systems
Experience designing systems for performance, scalability, and reliability
In-depth understanding of object oriented programming concepts
Low level working knowledge of collections, multi-threading, JVM memory model, etc.
Solid understanding of database fundamentals and SQL
Understanding the full software development life cycle, agile development and continuous integration
Ability to clearly communicate with team-members in a cross-matrix environment
What puts you over the top:
Built systems in a containerized environment with familiarity in Docker, ECS, Kubernetes
Exposure to Data Warehousing solutions like Snowflake and BigQuery
Prior ad tech experience
About Integral Ad Science

Integral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 18 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit integralads.com.

Equal Opportunity Employer:

IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.

California Applicant Pre-Collection Notice:

We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.

To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN

Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.",3.5,"Integral Ad Science
3.5","Chicago, IL",501 to 1000 Employees,2009,Company - Private,Internet,Information Technology,$100 to $500 million (USD)
Sr. Data Engineer,-1,"About Us:

Convr is a growing startup in the InsureTech space. Our d3 Underwriting Platform helps underwriters make better decisions more efficiently. As we continue to grow we are looking for leaders to help us scale not only our platform but our organization. This is an exciting role that will allow you to mentor, lead, and innovate.

The Role:

THIS POSITION WILL BE IN OUR SCHAUMBURG, IL OFFICE. WE CANNOT OFFER OUT OF STATE OPPORTUNITIES AT THIS TIME. As a Sr. Data Engineer, you will work closely with technical leadership and product managers to lead a team delivering the best solutions for our customers. You will develop a deep understanding of the people, technologies, and practices of your team(s), and apply your expertise to scale our teams and platform. You will innovate and push our technology further. You will teach and mentor our engineers to be more efficient, write quality code, and leverage best practices.

Your Responsibilities:
Be a high performer that produces production quality code that gets value to our customers
Enables scalability within our applications and services
Owns parts of our systems and innovates to create defensible depth in our products
Mentors our engineers to help further their technical skills
Technical Skills Demonstrated:
7+ Years in creating a production application / services
1+ Years as a team lead on a sprint team
1+ Years in Python
4+ Years with micro-services architecture
Understanding of data modeling and various data lake solutions
Built out data platforms that support multiple data sources
Worked on systems with high number of users (1000s - 1Ms)
ML and AI Experience
Owned Code all the way to production before
Experience with DevOps
Things that will help you succeed:
Passion for delivering value to customers
Enjoys solving complex data problems
Can evangelize Agile / Scrum framework to deliver this value
Quality is everything to you
Ownership! Takes ownership and responsibility for all things Convr
Test 1st Mindset
Education:

Bachelors Degree",-1,Convr,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Pharmaceutical Development Scientist,-1,"Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description

With supervision as required, proficiently performs all assigned chemistry techniques. Demonstrates a good understanding of scientific principals and their cause and effect on scientific outcomes. Practice of GMP/GLP is routine. Once appropriately trained, this individual may be designated as a notebook reviewer. Authors and may review others protocols, reports, specifications and test methods. Presents results at team meetings with interpretation. Acts as a coach to junior staff.
Proficiently performs all assigned laboratory techniques.
Independently develops analytical methods on a variety of analytical techniques and instrumentation.
Independently performs method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience in operating and troubleshooting the following instrumentation:
Ultra-High Performance Liquid Chromatography
Differential Scanning Calorimetry (DSC)
Size Exclusion Chromatography
Multi Angle Light Scattering (MALS)
Fourier Transform Infrared Spectroscopy (FTIR)
Asymmetrical Field- Flow Fractionation (AFFF)
Dynamic Light Scattering (DLS)
Tutors and trains others on troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Designated notebook reviewer.
Generates, analyzes and presents scientific data at team meetings. Explains cause and effect relationships and may propose additional experiments to
prove/disprove hypotheses. Has a general understanding of the depth and breadth of drug development and can contribute to the scientific discussion during project team meetings.
Understand regulatory guidelines and can author protocols, reports and analytical test methods.
Generate and analyze scientific data and handle OOS’s (Out of Specification) with little difficulty.
Has a good understanding of different plant manufacturing processes and can plan bench studies that will translate into a manufacturing process while solving related compounding, solubility, etc. problems.
Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development experience. Preferred education background in Analytical Chemistry, Pharmaceutics or similar discipline, however, extensive experience with analytical chemistry may be substituted for education.
Significant experience with the drug development process
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Strong analytical background
Liquid formulation experience is desirable
Product development experience in the pharmaceutical industry
Ability to meet deadlines
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information

Position is full-time, Mon-Fri 8:00am-5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",-1,Eurofins USA PSS Insourcing Solutions,"Lake Forest, IL",-1,-1,-1,-1,-1,-1
Senior Clinical Scientist - Clinical Trial Mgmt and Medical Monitoring exp required,"$27-$49 Per Hour
(Glassdoor Est.)","Job Overview:


Senior Clinical Scientist - Oncology

Clinical Trial Mgmt and Medical Monitoring experience is required

Remote in the USA or Canada

Why settle for one thing when you can have everything?

Covance gives you the best two-for-one opportunity for career growth. Who doesnt want twice the perks? Working at Covanceone of the largest FSP CROsand partnering with one sponsor with a dedicated therapeutic focus. You can have it all!

As a Covance employee dedicated to an FSP project, you will bring your specialized discipline to a core team working directly with one sponsor. Whether your specialization is in clinical monitoring, clinical project management, data management, biometrics or pharmacovigilance, Covance has an FSP opportunity to match your area of expertise.

You will enjoy the best of both worldsall the benefits that come along with Covances Energizing Purpose, Exceptional People and Extraordinary Potential combined with working exclusively with one sponsor and this also comes with the benefit of bringing your strong therapeutic experience to allow your expertise to shine through.

Covances FSP model is flexible and scalable. Our teams are collaborative and proactive a great place for you to continue honing your therapeutic skills and growing and excelling in new and exciting research.

Covances reach is global extending to 60+ countries making us one of the largest FSP CROs. No matter where you are located on the globe, we have an FSP opportunity for you.

In this role, the selected candidate may lead or support a study or studies, depending on size/complexity. If lead, accountable for the clinical/scientific execution of the protocol.

As lead, will be responsible for the following:
Clinical point of contact for scientific issues/questions for internal and external stakeholders (e.g., IRB, sites)
Responsible for trial design and endpoint development in collaboration with CD
Leads the Medical Monitoring (MM) team in performing MM activities, including development of the Medical Monitoring Plan (MMP) and review of SAE reports
Sets up/supports SAC, DMC, adjudication committees
Protocols/amendments collaborates with medical writer, participates in governance committee review
Authors protocol clarification letters
Contributor to study specific documents (e.g., SMP)
Reviews/updates informed consent
Provides scientific input to SM for data management activities (e.g., EDC, DRP, CRFs)
Monitors data issues requiring clinical input
Monitors central lab reports and other external data for safety and critical values
Prepares scientific slides, attends and presents protocol information at Investigator Meeting
Scientific lead on Clinical Trial Team (CTT)
Reviews specs, initiates allocation (randomization) request form and approval schedule in allocation schedule generation system
Coordinates planning of lab, bio specimens and imaging specifications
Co- authors newsletters with SM
Participates in Database lock activities
Collaboratively plans CSRs, CTDs/WMAs with medical writing
Supports publications/presentations as needed
Reconciles and review all protocol deviation classifications in SPECTRUM
Assesses and prepares protocol deviation list for CSR
Collaborates with medical writing to develop trial results communication for investigators
Provides scientific assessment for Operational Reviews
Supports SM/MW activities as needed to achieve CTT deliverables.
Provides clinical specifications to SM to support interactions with external vendors (e.g., IVRS, ePRO)
May act as mentor to other CSs
Education/Qualifications:

Degree in Life Sciences or significant experience in clinical development (>14 years)
BS/BA with 7+ yrs clinical research experience
MS/PhD with 5+ years clinical research experience
Experience:

Minimum 2 years pharmaceutical and clinical drug development experience in a Clinical Scientist role as a lead required.
Proven ability to effectively manage multiple complex studies
Medical monitoring experience required
TA-specific experience in Oncology
Excellent Excel and PP skills required
Excellent written and oral communication skills",3.5,"Covance
3.5","Chicago, IL",10000+ Employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10 to $25 million (USD)
Senior Data Engineer,-1,"Projects the candidate will be working on:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
Team and Team size:
Will be part of team
Will be part of Agile team with minimum 7 members
Top Responsibilities:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
The ideal candidate will be very comfortable creating subscriptions to stream real-time data using CDC tools such as IBM Infosphere Data Replication and streaming data to Kafka.
The candidate should be comfortable working with AS400, Oracle and MSSQL server databases, including any aspect of administration or support required to maintain them.
Required Experience & Qualifications:
Data engineering experience - 7 years
Cloud platform experience - 1 year
Version Control (Git or equivalent) - 1 years
Preferred Experience & Qualifications:
Change Data Capture Tools (IBM CDC, Attunity or equivalent) 3 years
Version Control (Git or equivalent) 1 year
Scripting (Linux/Unix Shell scripting or equivalent) 5 years
Interview Process:
a. How many rounds? 2 or 3
b. Video vs. phone? Phone
c. How technical will the interviews be? Very detailed Technical",4.0,"Horizontal
4.0","Schaumburg, IL",501 to 1000 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Sr Data Engineer,"$59K-$116K
(Glassdoor Est.)","Position Role/Tile: Sr Data Engineer
Location: Schaumburg, IL.

Job description:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.

Is this person a sole contributor or part of a team?
Will be part of team
If so, please describe the team? (Name of team, size of team, etc.)
Will be part of Agile team with minimum 7 members
What are the top 5-10 responsibilities for this position? (Please be detailed as to what the candidate is expected to do or complete on a daily basis)
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting. The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
The ideal candidate will be very comfortable creating subscriptions to stream real-time data using CDC tools such as IBM Infosphere Data Replication and streaming data to Kafka.
The candidate should be comfortable working with AS400, Oracle and MSSQL server databases, including any aspect of administration or support required to maintain them.
What software tools/skills are needed to perform these daily responsibilities?
Required Experience & Qualifications:
Data engineering experience - 7 years
Cloud platform experience - 1 year
Version Control (Git or equivalent) - 1 years
Preferred Experience & Qualifications:
Change Data Capture Tools (IBM CDC, Attunity or equivalent) 3 years
Version Control (Git or equivalent) 1 year
Scripting (Linux/Unix Shell scripting or equivalent) 5 years
Central Business Solutions, Inc,
37600 Central Ct.
Suite #214
Newark, CA 94560",3.0,"Central Business Solutions, Inc
3.0","Schaumburg, IL",51 to 200 Employees,-1,Company - Private,Consulting,Business Services,$5 to $10 million (USD)
Lead Big Data Engineer,"$100K-$169K
(Glassdoor Est.)","Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the worlds large accumulation of health-related information, or guide health and lifestyle choices, or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) The ideal candidate will be a self-starter who can learn things quickly, who is enthusiastic, active, and eager to learn. Youll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary Responsibilities: Design, code, test, document, and maintain high-quality and scalable Big Data solutionsDesign, develop and implement rules enginesResearch, evaluate, and deploy new tools, frameworks and patterns to build sustainable Big Data platformIdentify gaps and opportunities for improvement of existing solutionsDefine and develop APIs for integration with various data sources in the enterpriseAnalyze and define customer requirementsAssist in defining product technical architecture Make accurate development effort estimates to assist management in project and resource planning Create prototypes, proof-of-concepts & design and code reviews Collaborate with management, quality assurance, architecture, and other development teamsWrite technical documentation and participate in production support Keep skills up to date through ongoing self-directed training Youll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.",3.4,"UnitedHealth Group
3.4","Downers Grove, IL",10000+ Employees,1977,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
"Senior Software Engineer, Data Platform",-1,"About Us

Mastery Logistics Systems is building the worlds first lovable Transportation Management System, or TMS.

Our customers large transportation companies and shippers who need those companies have struggled with systems that are outdated or inadequate. As shippers or transportation service providers, our customers have in the past been forced to use multiple systems to manage dedicated fleet operations, outsourced or insourced trans management, one way trucking, truckload brokerage, LTL, and Intermodal, or to sub-optimize one or more of those functions by attempting to fit it into a TMS that is adequate at another function.

Mastermind TMS allows our customers to bring all of these functions into a single platform, providing flexibility, visibility, control, and efficiency. Todays unprecedented global supply chain upheavals underscore how important the transportation industry is. We are building a system to allow this industry to work faster, smarter and more efficiently.

The challenges in this industry are big and exciting! We are tackling everything from fast and efficient data input to ingesting large amounts of data and applying AI to looking at blockchain to securely digitize paperwork. If you are passionate about humanizing an industry, automating in innovative ways, building for quality and scale, helping make people's lives easier and touching every part of our economy then this is the place for you.

Mastery Logistics Systems is committed to continuing to build an incredible company. We are a masterful mosaic of incredible people. We are specialists and experienced in our respective fields. We are dedicated to continuous improvement both professionally and personally. We are a collective group of really good people. We have different interests, backgrounds & talents and we work together to create really cool stuff! We believe in diversity of thought and are mindful and inclusive. We have deep respect for each other and work diligently at adding the right people to our teams.

At this moment we are all working from home and doing our part to combat the Covid 19 virus. We are creatively building our new work habits. We are respectful of each others time and personal life. We have flexible schedules but share in the mission that we are building and need to get it done. We offer an excellent suite of benefits. We are dedicated to finding new ways to add perks as we live and work from home.

Our team has the domain knowledge and connections to make an impact, and were looking for experienced and thoughtful people to who thrive on creating and building great products. We want people who have a true passion for servicing and taking care of our customers. We need people who are flexible problem solvers, thrive on collaboration and consistently know how to communicate their solutions well. We are small and nimble which is evident in how quickly we could pivot to our new reality. Each member of the team can make a tremendous impact both technically and culturally. While a start-up, we are well-funded, have an initial paying customer with which to test and launch, and are founded by top experts and veterans in the logistics industry.

Join us youll love it lets build a masterpiece!

About the Role

The transportation industry has no shortage of complex problems requiring creative, data-intensive solutions in order to effectively and efficiently automate operations at scale. In this role, you will be expected to work autonomously and contribute to several high impact projects including building services providing near real-time analytical insights to Masterys customers.

Responsibilities
Closely collaborate with fellow Engineers, Data Scientists, and Product Managers and interact with stakeholders across the organization to build real-time data products
Design, build, and deploy microservices that provide real-time, analytical insights to some of North Americas largest freight brokerages
Support Masterys Data Science team by establishing best practices, developing tools, and building infrastructure that makes the work of Data Analysts and Data Scientists more robust, reliable, and easy to implement
Write clean, maintainable, and well-tested code
Engage in the full development life-cycle including architectural design and testing
Be a force-multiplier on the velocity and quality of your team
Stay current on software engineering trends & tools, and be practical but open-minded in applying them
Maintain a high bar for quality and performance of your product with vigorous attention to detail and automated testing
Continuously improve how we design, build, and ship software as a highly functional team
Requirements
3+ years of practical experience in data-intensive software development, including designing, building, deploying, and maintaining data applications
Expertise in data-focused development, including experience with a variety of database, data warehouse, distributed processing, and machine learning technologies
Minimum of two years of industry experience building production software with Python
Experience with Kafka or similar event streaming systems
Expertise with SQL and RDBMS
Excellent written and verbal communication skills
Adept at interacting with technical and non-technical audiences
Experience working with real-time, distributed systems
Strong sense of responsibility with a bias towards action
Experience working with RESTful APIs
Comfortable self-directing and prioritizing your own work
Ability to understand complicated problems and craft into simple solutions that can be maintained by the rest of the team
Experience leading technical projects
Ability to train and mentor junior engineer
Experience with NoSQL technologies, preferred
Experience with GraphQL, preferred
Experience in logistics industry, preferred
Benefits

Mastery takes great pride in providing our employees a robust and highly competitive benefit package. Our benefits include Medical, Dental and Vision insurance covering 90% of premium costs. Company paid life insurance for 1x salary. Legal, AD&D, Additional Life and other employee assistance benefits. We have a 401k savings plan with a 4% match. We provide opportunities for professional growth and development. We fully support our work from home initiative as we do our part to combat the Covid 19 crisis. We have a manage your life and schedule Paid Time Off program. We are fully devoted to finding creative perks and benefits since we cannot currently enjoy our cool office culture. Our philanthropic partner is St. Jude Childrens Research Hospital.

We are an equal opportunity employer and actively seek a diverse community of professionals. Veterans, Women, non-binary, people of color, LGBTQIA, we welcome all to apply!",-1,"Mastery Logistics Systems, Inc.","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Azure Data Modeler,-1,"Great opportunity to show off your passion for data, reporting, analytics and data warehousing. Our client's BI team may have the perfect fit for you!

We are looking for a self-motivated Data modeler/Engineer to join our business intelligence team.

This individual will be responsible for developing and maintaining business intelligence, data warehousing and data engineering solutions for Enterprise data This individual will also create and maintain detailed business requirements, outlining data problems, opportunities and solutions.

Responsibilities Include:
Responsible for designing relational and non-relational data stores on Azure.
Responsible for designing and developing solutions in Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, SQL Data Warehouse, HDInsight.
Gather and process raw data at scale that meet functional / non-functional business requirements (including writing scripts, REST API calls, SQL Queries, etc.)
Responsible for developing data set processes for data modeling, mining and production.
Responsible for building new Data Lake in Azure, expanding and optimizing our data platform and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
Responsible for supporting our Software Developers, Data Analysts and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Develop complex SQL queries in TIBCO Data Virtualization tool.
Qualifications:
3+ Years of experience architecting and building Data Lake, Azure Big Data architecture, Enterprise Analytics Solutions, and optimizing ' big data' data pipelines, architectures and data sets.
Bachelor’s Degree in Computer Science, Information Systems, or related field
Advanced hands-on SQL, USQL, Python, C#, Java, pySpark (2+ of these) knowledge and experience working with relational databases for data querying and retrieval.
Experience with Design and Architecture of Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure ML, SQL Data Warehouse, HDInsight.
Experience with building processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience working with cross-functional teams in a dynamic environment.
Experience building Big data pipeline with Java and/or Python a plus.
Strong SQL skills on multiple platform
Data Modeling tools (e.g. Erwin, Visio) knowledge a plus.
Experience with SAP HANA a plus.
Experience with Talend a plus.
_Brooksource provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws_

Job Types: Full-time, Contract

Pay: $45.00 - $50.00 per hour

Benefits:
Dental Insurance
Health Insurance
Paid Time Off
Vision Insurance
Schedule:
8 Hour Shift
Day shift
Monday to Friday
Experience:
Azure Big Data architecture: 3 years (Required)
Architecting and Building Data Lake: 3 years (Required)
Developing complex SQL Queries: 3 years (Required)
Enterprise Analytics Solutions: 3 years (Required)
Full Time Opportunity:
Yes
Work Location:
One location
Benefit Conditions:
Waiting period may apply
Work Remotely:
Temporarily due to COVID-19",4.5,"Brooksource
4.5","Northfield, IL",501 to 1000 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Senior Data Science Consultant,-1,"Senior Data Science Consultant
Healthcare
Chicago, IL
$135,000 - $155,000 + Benefits + Bonus

Are you passionate about joining one of America's most famous organizations in the healthcare/ pharmaceutical space? A leading healthcare company is looking for an experienced Senior Data Science Consultant who is technically strong in R, SQL, Python, and Tableau, to advise in implementing solutions through an analytical lens to drive business growth.

THE ROLE:

As Senior Data Science Consultant, you will be partnering with Data Scientists and mentoring junior team members in implementing and framing solutions for making certain treatment programs more efficient. You will be responsible for:

Navigating huge and complex claims data
Performing advanced analytics using Python, R, SQL, and Tableau
Consulting with internal clients to identify opportunities for which you can implement data science
Acting as analytics product owner translating business needs into analytics actions and projects

YOUR SKILLS AND EXPERIENCE:

Strong understanding of managed healthcare space
Proven commercial experience in working with claims data at a large company
Proficient in R, Hadoop, Python, SQL, and Tableau
Proficient in mathematical analysis methods, machine learning, statistical analysis, and predictive modeling
Strong understanding of advanced analytical tools and languages needed to analyze large sets of complex and messy data from multiple sources
Proven experience in strategy consulting, as well as managing or leading teams
Bachelor's degree and Master's in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline; PhD preferred

BENEFITS:

As Senior Data Science Consultant you can expect to earn up to $155,000 (depending on your experience) plus great benefits and of course, great healthcare!

HOW TO APPLY:

Please register your interest by sending your resume to George Little via the Apply link on this page.

KEYWORDS:

Healthcare, pharmaceutical, data science, advanced analytics, consultant, consulting, advisor, Python, R, Hadoop, Tableau, SQL, machine learning, predictive models, predictive analysis, statistics, claims data, engineering, project management, product owner, strategy",4.2,"Harnham
4.2","Chicago, IL",51 to 200 Employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Big Data Machine Learning Engineer,-1,"Title: Big Data Machine Learning Engineer@ Chicago, IL
Terms of Hire: Full Time.
Salary: $Open+ Benefits.

The candidate can also work from any of these locations:
Chicago, IL, US
Cleveland,OH,US
Washington,DC,US
Job description

ABOUT THE JOB

The Decision Sciences team is part of the Enterprise Payments and Analytics organization. Its mission is to lead Client’s journey to become an innovative, data driven enterprise by building advanced analytics solutions for solving business problems. Our experienced team of AI/ML and Data Science practitioners focuses on engaging, enabling, and empowering decision-makers across the enterprise by developing, managing and supporting advanced analytics products and scalable digital solutions, such as real time and on demand predictive models and prescriptive analytics, and continuously researching, specifying, and deploying next-generation analytics capabilities. We are an internal consulting and services organization that works directly with users across the firm, including Lines of Businesses and partners in Enterprise Strategy, Marketing, Data Analytics, and Enterprise Architecture, to facilitate the development of innovative solutions that help Client compete and win with analytics.

The Big Data ML Engineer fills a critical data, analytics, technology support, and innovation role for the business analytics and advanced analytics functions within the organization. The Engineer is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organization’s enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS

The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use cases—primarily focused around open source technologies including cloud infrastructures. This individual evaluates short/long-term business needs required to support Client business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on Client Enterprise systems. Under the guidance of the Group’s Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on Client data assets for business decision management solutions. The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions. The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions. The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organization’s AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.

REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
What are the 3-4 non-negotiable requirements on this position?
1. Experience in open source technologies (Python, Hadoop, Spark, etc.) 2. Experience in Cloud environment, Google Cloud platform preferred 3. Machine learning expertise
What are the nice-to-have skills?
Finance/banking background
You Will Enjoy:
An opportunity to be a part of a great culture, an awesome team, a challenging work environment, and some fun along the way!
Apply today to learn more and be part of our Growth story.
All applications will be kept strictly confidential and once shortlisted, our team will be in touch with you for further discussions.",-1,CEDENT,"Chicago, IL",1 to 50 Employees,-1,Contract,Computer Hardware & Software,Information Technology,Less than $1 million (USD)
Big Data Machine Learning Engineer,-1,"Thusa is looking for Big Data Machine Learning Engineerto join the team. The ideal candidate is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organizations enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS
The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use casesprimarily focused around open source technologies including cloud infrastructures.
This individual evaluates short/long-term business needs required to support key business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on the Enterprise systems.
Under the guidance of the Groups Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on key data assets for business decision management solutions.
The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions.
The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions.
The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organizations AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.
REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
Thusa is dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock. dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock.

Our employees enjoy a work culture that promotes company priorities.

We treat our employees like family while providing on-going support for growth. We are not only looking for people who can do the job, we are also looking for our future leaders.

Powered by JazzHR",-1,Thusa Solutions,"Chicago, IL",-1,-1,-1,-1,-1,-1
Kafka Data Engineer (remote),"$62K-$114K
(Glassdoor Est.)","Summary
We exist to help people achieve financial clarity. At Thrivent, we believe money is a tool, not a goal. Driven by a higher purpose at our core, we are committed to providing financial advice, investments, insurance, banking and generosity programs to help people make the most of all they’ve been given.

At our heart, we are a membership-owned fraternal organization, as well as a holistic financial services organization, dedicated to serving the unique needs of our clients. We focus on their goals and priorities, guiding them toward financial choices that will help them live the life they want today—and tomorrow.

Join our newly created Data Office as the full-time Kafka Data Engineer! We are hiring for both a mid-level and a senior level Engineer. Bring your expertise in implementing modern data architectures and Data Streaming. We have a data streaming platform to enable frictionless data flow from business systems and 3rd party sources using publish/subscribe model. This role will require experience with hybrid platforms, cloud migration, publishing, development with newer technologies such as Spring Boot, KSQL/Stream Processing, data connectors such as Kafka, performance tuning, data quality and data visualization knowledge. You and will report to the Director of Information Delivery.
Job Description


Job Duties and Responsibilities
Partner on the design, deployment, and persistence of our new streaming platform unifies the data across organization, using Confluent Kafka.
As the senior level Engineer, you will be leading a group of engineers.
Design, Develop, Release & Support containerized microservices (OpenShift / Spring Boot) to transform and enrich topic data.
Lead reusable design and patterns for services and data processes within the platform.
Partner on setting standards, implementing tools, and creating documentation for self-serve data pipeline services supporting core engineering and professional services use cases.
Work with existing engineering teams to become data producers and consumers to and from Confluent Kafka.
Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.
Apply business knowledge and experience to effectively advise others on technology as an enabler.
Lead efforts to analyze IT industry and market trends and determine potential impacts.
Develop concepts and constructs necessary to create technology-enabled business systems.
Influence technology direction.
Provides thought leadership and execution to large complex efforts.
Utilize breadth of technical understanding and dive deep when necessary.
Consult on and manage initiatives to ensure alignment across multiple business and IT areas.
Proactively mitigate risks across multiple assets, information domains, technologies & platforms.
Provide leadership, mentoring and technical guidance to others to drive initiatives.
Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.
Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.
Act as a change agent to continuously improve and move the organization forward.
Accountable to provide leadership to successfully deliver the right results on initiatives in a timely and effective manner.
Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.
Ability to work within a diverse team of skillsets and experience levels to deliver results.
Required Job Qualifications
Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field.
5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years of lead experience.
Strong experience with event streaming such as (Kafka or Amazon Kinesis).
Experience with SQL and NoSQL databases (PostgreSQL, MongoDB, etc).
Proficient delivering services within AWS.
Experience with Confluent Kafka, penShift / SpringBoot is preferred.
Demonstrated ability to develop containerized microservices (Docker with Kubernetes) is preferred.
The ability to communicate cross-functionally, derive requirements and architect shared datasets; ability to synthesize, simplify and explain complex problems to different types of audiences.
Desire to show ownership of problems you identify and proven ability to empower others to get more done.
Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color, sex, gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state, or federal law. This policy applies to all employees and job applicants.

Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation, please let us know by sending an email to human.resources@thrivent.com or call 800-847-4836 and request Human Resources.",3.5,"Thrivent
3.5","Chicago, IL",5001 to 10000 Employees,1902,Nonprofit Organization,Insurance Carriers,Insurance,$5 to $10 billion (USD)
Director of AI Product Management - Office of Data Science,"$68K-$121K
(Glassdoor Est.)","Advance your career at Liberty Mutual Insurance - A Fortune 100 Company!

Help bring Liberty Mutual into the future by advocating on behalf of all data scientists across the enterprise. The Director of AI Product Management will be a key member of the Office of Data Science Product Team. As the Director of AI Product Management you will advocate for DS efforts across the enterprise by acting as Product Owner over a team of ML engineers, helping to identify, measure and socialize DS initiatives and partnering with technology, business and the data science community (DSPRG) to promote collaboration and reuse. Liberty Mutual aspires to be the data science leader within the insurance industry and you will play a key role in partnering across the organization to make this happen.

Roles and Responsibilities:
Strategic Vision
Partner with the ODS Science team to engage the enterprise and identify top business opportunities for ML application (e.g. CV, NLP, Aerial Imagery, and Trusted AI).
Measure the value of data science at Liberty and communicate it to the enterprise.
Customer / Collaboration
Foster relationships across the LM enterprise. Promote and build excitement for data science.
Act as a change agent across the organization by influencing and driving strategic direction and investments in AI.
Collaborate with and influence key stakeholders and customers to embrace a product mindset and drive business outcomes.
Partner with the business, tech and data science leaders to jointly drive forward efforts to enhance DS/AI collaboration.
Model Deployment
Act as the product owner for a ML Engineering squad tasked with deploying models delivering ~$100M (and growing) in value to the enterprise.
Manages the existing program, onboards new customers and socialize the value of the portfolio
Vendor
Support DS and ML vendor engagements and purchasing decisions as the organization makes build vs buy vs research decisions
Key traits we are looking for:
Data Science Passion - you have a passion for making things better through data science.
Leadership - You are a passionate leader who can bring the enterprise together, gain cross team alignment and deliver results.
Customer Empathy - ability to try on the experiences of customers and stakeholders - especially those with conflicting viewpoints.
Problem solving - you can solve difficult problems efficiently with appropriate methodologies
Integrity - you build and maintain trust with your colleagues, stakeholders, partners, and leaders
Drive - you work smart and hard to succeed
Communication Skills - you can communicate to a wide variety of audiences adapting your technique as appropriate in a strategic manner
Qualifications:

A minimum of three years recent experience in a DS or technology product role with a proven track record of providing leadership on complex / challenging technical product delivery.
Demonstrated ability to think broadly across multiple good viewpoints
Knowledge of DS applications, DS infrastructure needs, and organizational challenges & obstacles as it relates to vetting, prototyping and scaling DS solutions
Excellent communication, analytical, interpersonal, organizational and team building skills, business judgement, and proven expertise in directing the efforts of agile teams
Experience of strongly influencing product strategy at a senior level and leading organizational change
Ability to continuously prioritize development based on business value and product strategy
Ability to create and foster consensus from the whole business for a coherent product vision
Ability to estimate ROI of complex projects

Benefits:
We value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits
Overview:
At Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.
We're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.",3.5,"Liberty Mutual Insurance
3.5","Warrenville, IL",10000+ Employees,1912,Company - Private,Insurance Carriers,Insurance,$10+ billion (USD)
Sr. Data Engineer,"$75K-$140K
(Glassdoor Est.)","At Echo we are committed to help our Associates grow their career. Apply today and grow with Echo!
-
-",3.5,"Echo Global Logistics
3.5","Chicago, IL",1001 to 5000 Employees,2005,Company - Public,Transportation Management,Transportation & Logistics,$2 to $5 billion (USD)
Senior Data Engineer,-1,"Are you interested in building the future of healthcare and transforming the patient experience? Are you hopeful about what data and medical research can do to improve medicine? We’re looking for a Senior Data Engineer to ensure PatientIQ remains on the forefront of using data to drive positive healthcare outcomes.

As a core member of the Analytics department, you will be in a dynamic environment that is actively building the future versions of our automated data science platform - Analytics Autopilot. In addition, our team often works cross-functionally with the Engineering, Product, and Sales departments as PatientIQ scales its business. Your work will involve coming up with new software features, defining metrics, streamlining existing data processes, and mentoring other team members. We heavily value diligence, curiosity, and initiative, as those are key to unlocking the value of PatientIQ's data for our users and our decision-making. Your work will be impactful across the entire organization.

Role Responsibilities
Design, develop, and maintain ETL infrastructure to support the ingestion of external data sources
Work on a cross-functional team to design, develop, and maintain PatientIQ's internal reporting infrastructure
Understand data requirements and implement solutions for data science applications
Perform unit and integration testing
Mentor junior team members
Help scale PatientIQ's data strategy as the platform and business grows
Requirements

Ideal Qualifications
Experience designing, building, and maintaining ETL infrastructure in a production setting
BS/MS in Computer Science, Engineering, Mathematics, or related field
Proficient in Python or another object oriented programming language
Deep knowledge of SQL and at least one database technology
Experience with software development lifecycle processes and using version control systems (git), either from prior data engineering work or in a more traditional software engineering setting
Highly self-motivated with strong analytical problem-solving skills and attention to detail
Nice to Haves
Experience with workflow management systems such as luigi or airflow
Experience in machine learning and/or business intelligence
Experience with cloud technologies such as AWS, Google Cloud Platform, or Azure
Experience with ETL tools like Apache Kafka, Logstash, Segment, Informatica
Experience with automated machine learning technologies such as Amazon SageMaker or Google Cloud AutoML
Experience with cloud data warehouse platforms such as Snowflake, Qubole, etc.
Experience working in Healthcare, Finance or another regulated industry
Benefits
Great Benefits - top-notch health, dental and vision insurance. Additional perks available including 401K.
We are Mission Driven - our team is motivated to solve complex problems, drive medicine forward, and ultimately improve patient outcomes.
True Idea Meritocracy - great ideas win out. We encourage all team members to challenge the status quo because our mission demands this.
Flexible Time Off - we trust you to take the time you need when you feel it is appropriate, given your workload and responsibilities. No need to track it or save up.
World-Class Team - we’re at the top of our industry because of our employees. They’re the best investment we can make, and we never forget that.
Fast Growing - we are building the largest platform for healthcare providers, industry partners, researchers, and others to collaborate on the mission to improve patient outcomes.",-1,PatientIQ,"Chicago, IL",-1,-1,-1,-1,-1,-1
Big Data Architect,-1,"Our Client is a leader in data-driven marketing, named as one of the top 20 data integrators to watch and grow with. Our Client delivers insight and results to their customer with marketing expertise, technical and analytic capabilities, and a relentless focus on the customer. Business model based on driving lasting customer relationships and incremental brand revenue through integrated systems, online and offline CRM, real time predictive modeling, and data management.

The Big Data Architects primary responsibilities are to create and develop solution designs to integrate and ingest data from various resources, supporting Clientss internal big data ecosystem.

They will be responsible for defining the big data architectural blueprint under the supervision and collaboration with the Technology Solutions Director. The Architect will work closely with data engineers, cloud engineers, and data scientists to design and implement optimum solutions using best practices. They are responsible to ensure the data ecosystem is built to be highly scalable, responsive, and available.

The Big Data Architect oversees the implementation of data solutions by working with Clients onshore and offshore engineering teams to create ETL, batch, real-time, and automated processes. As part of the core Technology Solutions team the right candidate will heavily contribute to the teams coding and programming standards and ensure other team members are following the guidelines and standards.

Responsibilities:


Take ownership of data solutions from design and architecture perspective for projects in presales phase as well as on-going projects

Select and integrate any Big Data tools and frameworks required to provide requested capabilities. Can oversee the implementation by team members of said solutions

Design and implement ETL and automated processes

Monitor performance and advise of any necessary improvements and changes

Management of EMR clusters, Glue Jobs, Athena Tables, S3 data lakes; with all included services

Provide technical support to members of TS and SA team, as well as project support across client engagements

Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value

Stays current with relevant technology in order to maintain and/or improve functionality for authored applications

Assume other responsibilities as requested/required

Acts as a subject matter expert for systems worked on

Ensures Clients data solutions are using the latest versions and code base

Actively listen to and work with end users to gather feedback and input, and make suggestions and solutions based on said feedback

Requirements

Required Experience:
(7 years of relevant experience) or (5 years of relevant experience and an advanced degree in Computer Science/IT or related field)

Keen understanding of distributed computing principles
• Proficiency with Big Data frameworks such as Hadoop, Spark, MapReduce, HDFS.

Proven experience ingesting data from multiple data sources such as REST API, SFTP flat files, Streaming data etc.

Proven experience with Big Data querying tools such as Athena/Presto, Pig, Hive, and Impala

Proven experience with NoSQL databases, such as HBase, Cassandra, Redshift, DynamoDB

Proven experience with various ETL techniques and frameworks, such as Flume, Glue Jobs, Step Functions

Proven experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O

Proven experience with AWS Lambda and leveraging it in various solutions such as Glue, Step Functions, CloudWatch, S3 Events, etc.

Strong experience with using Python scripts & libraries

Experience desired with Database Warehousing Design Concepts; Dimensional.
• Modeling, Star/Snowflake Schemas, ETL/ELT, Data Marts, Analytic Playgrounds, Reporting techniques

Experience working with Agile software development methodologies, namely Scrum

Proven experience with team collaboration, release management, system and performance monitoring

Ability to work well with people from many different disciplines and varying degrees of technical experience

Excellent analytical, problem resolution, organization and time management skills

Ability to handle multiple tasks at a time
• Demonstrated ability to have successfully completed multiple, complex technical projects and create high-level design and architecture of the solution, including class, sequence and deployment infrastructure diagrams

Prior experience with application delivery using an Onshore/Offshore model
• Experience with gathering end user requirements and writing technical documentation

Keyword: Hadoop, Spark, MapReduce, HDFS, REST, API, SFTP, Athena, Pig, Hive, Impala, NoSQL, HBase, Cassandra, Reddrift, DynamoDB

Benefits


We do have a full benefit package of medical/dental/vision insurance, disability, life, 401k employer match along with profit sharing and bonus. Optional benefits is AFLAC plans and FSA for medical or childcare.

Vacation, 5 Sick Days and 2 personal days with a total of about 30 days off within a year depending on when holidays fall. Included in that is the close of the office between Christmas and New Years.",-1,DSMHConsulting,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"Candidate Responsibilities

Develop implementation patterns leveraging AWS technologies to support Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solution Data Designs, Models, Pipelines
Prototype New Solutions Technical guidance to data designers and
developers Solution Implementation Reviews Open to Chicago, IL as well.

Typical Day

Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solutions with Platform, Business, and Application teams

Requirements


Education Requirements:

B.S. in Computer Science, Information Systems, or related major or
equivalent IS / business experience. 10+ years experience designing,
implementing data persistance and processing solutions AWS
Certifications

Technical Skills

AWS Cloud Based Technologies for Data Processing and Persistance
(DynamoDB, S3, Aurora, Kinesis, SQS,SNS, Lambda, Fargate, Glue) Ability
to design and communicate solutions to meet business and technical
requirements Demonstrated Data Architecture and Design
for Big Data, Analytics, and applications

Soft Skills

Written and Verbal Communication Able to produce architecture and design artifacts in Visio and Office 365",-1,DSMHConsulting,"Chicago, IL",-1,-1,-1,-1,-1,-1
Staff Big Data Engineer,"$95K-$171K
(Glassdoor Est.)","Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry. Our technology handles hundreds of thousands of transactions per second; collects tens of billions of events each day; and evaluates thousands of data-points in real-time all while responding in just a few milliseconds.

We are looking for an experienced Big Data Engineer to join our Data Engineering team. This position will be the Senior technical resource driving architecture for the integration of large 3rd party partner integrations with companies like Facebook, Google and Twitter to name a few. The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. This position will require the ability to own and lead data initiatives on a cross-functional team.The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. You should be able to not take yourself too seriously as well. And most of all, you will enjoy working with great people who are changing the entire industry.

What you'll do:
Migrate existing data pipelines from on-prem regional data centers to AWS and GCP.
Architect a new modern event driven architecture with both batching and streaming
Adjust existing pipelines to fit the AWS processing model such as integration with S3, migrate to open source version of hadoop, adjustments to security model, etc...
Working on Big Data technologies such as Hadoop, MapReduce, Kafka, and/or Spark in columnar databases
Architect, design, code and maintain components for aggregating tens of billions of daily transactions
Lead the entire software lifecycle including hands-on development, code reviews, testing, deployment, and documentation for streaming and batch ETL's and RESTful API's
Partner and work closely with the QA Engineers to develop automated tests
Participate in training and mentoring of junior team members
You should apply if you have most of this:

(We have flexibility in this role to consider more, or marginally lesser, experience than requested below)
8+ years of experience designing and building data-intensive applications
5+ years architecting systems in a big data ecosystem using MapReduce, Spark, MPP Data Warehouses, and sql/nosql databases.
5+ years recent hands-on experience with object oriented languages (Java, Scala, Python)
5+ years Hands on experience building production level systems in a cloud environment (AWS or GCP)
Excellent interpersonal and communication skills in English
Proven experience leading the design and execution of event driven architectures for distributed systems
Experience designing systems for performance, scalability, and reliability
In-depth understanding of object oriented programming concepts
Low level working knowledge of collections, multi-threading, JVM memory model, etc.
Solid understanding of database fundamentals and SQL
Understanding the full software development life cycle, agile development and continuous integration
Ability to clearly communicate with team-members in a cross-matrix environment
What puts you over the top:
Built systems in a containerized environment with familiarity in Docker, ECS, Kubernetes
Exposure to Data Warehousing solutions like Snowflake and BigQuery
Prior ad tech experience
About Integral Ad Science

Integral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 18 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit integralads.com.

Equal Opportunity Employer:

IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.

California Applicant Pre-Collection Notice:

We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.

To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN

Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.",3.5,"Integral Ad Science
3.5","Chicago, IL",501 to 1000 Employees,2009,Company - Private,Internet,Information Technology,$100 to $500 million (USD)
Sr. Data Engineer,-1,"About Us:

Convr is a growing startup in the InsureTech space. Our d3 Underwriting Platform helps underwriters make better decisions more efficiently. As we continue to grow we are looking for leaders to help us scale not only our platform but our organization. This is an exciting role that will allow you to mentor, lead, and innovate.

The Role:

THIS POSITION WILL BE IN OUR SCHAUMBURG, IL OFFICE. WE CANNOT OFFER OUT OF STATE OPPORTUNITIES AT THIS TIME. As a Sr. Data Engineer, you will work closely with technical leadership and product managers to lead a team delivering the best solutions for our customers. You will develop a deep understanding of the people, technologies, and practices of your team(s), and apply your expertise to scale our teams and platform. You will innovate and push our technology further. You will teach and mentor our engineers to be more efficient, write quality code, and leverage best practices.

Your Responsibilities:
Be a high performer that produces production quality code that gets value to our customers
Enables scalability within our applications and services
Owns parts of our systems and innovates to create defensible depth in our products
Mentors our engineers to help further their technical skills
Technical Skills Demonstrated:
7+ Years in creating a production application / services
1+ Years as a team lead on a sprint team
1+ Years in Python
4+ Years with micro-services architecture
Understanding of data modeling and various data lake solutions
Built out data platforms that support multiple data sources
Worked on systems with high number of users (1000s - 1Ms)
ML and AI Experience
Owned Code all the way to production before
Experience with DevOps
Things that will help you succeed:
Passion for delivering value to customers
Enjoys solving complex data problems
Can evangelize Agile / Scrum framework to deliver this value
Quality is everything to you
Ownership! Takes ownership and responsibility for all things Convr
Test 1st Mindset
Education:

Bachelors Degree",-1,Convr,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Pharmaceutical Development Scientist,-1,"Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description

With supervision as required, proficiently performs all assigned chemistry techniques. Demonstrates a good understanding of scientific principals and their cause and effect on scientific outcomes. Practice of GMP/GLP is routine. Once appropriately trained, this individual may be designated as a notebook reviewer. Authors and may review others protocols, reports, specifications and test methods. Presents results at team meetings with interpretation. Acts as a coach to junior staff.
Proficiently performs all assigned laboratory techniques.
Independently develops analytical methods on a variety of analytical techniques and instrumentation.
Independently performs method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience in operating and troubleshooting the following instrumentation:
Ultra-High Performance Liquid Chromatography
Differential Scanning Calorimetry (DSC)
Size Exclusion Chromatography
Multi Angle Light Scattering (MALS)
Fourier Transform Infrared Spectroscopy (FTIR)
Asymmetrical Field- Flow Fractionation (AFFF)
Dynamic Light Scattering (DLS)
Tutors and trains others on troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Designated notebook reviewer.
Generates, analyzes and presents scientific data at team meetings. Explains cause and effect relationships and may propose additional experiments to
prove/disprove hypotheses. Has a general understanding of the depth and breadth of drug development and can contribute to the scientific discussion during project team meetings.
Understand regulatory guidelines and can author protocols, reports and analytical test methods.
Generate and analyze scientific data and handle OOS’s (Out of Specification) with little difficulty.
Has a good understanding of different plant manufacturing processes and can plan bench studies that will translate into a manufacturing process while solving related compounding, solubility, etc. problems.
Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development experience. Preferred education background in Analytical Chemistry, Pharmaceutics or similar discipline, however, extensive experience with analytical chemistry may be substituted for education.
Significant experience with the drug development process
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Strong analytical background
Liquid formulation experience is desirable
Product development experience in the pharmaceutical industry
Ability to meet deadlines
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information

Position is full-time, Mon-Fri 8:00am-5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",-1,Eurofins USA PSS Insourcing Solutions,"Lake Forest, IL",-1,-1,-1,-1,-1,-1
Senior Clinical Scientist - Clinical Trial Mgmt and Medical Monitoring exp required,"$27-$49 Per Hour
(Glassdoor Est.)","Job Overview:


Senior Clinical Scientist - Oncology

Clinical Trial Mgmt and Medical Monitoring experience is required

Remote in the USA or Canada

Why settle for one thing when you can have everything?

Covance gives you the best two-for-one opportunity for career growth. Who doesnt want twice the perks? Working at Covanceone of the largest FSP CROsand partnering with one sponsor with a dedicated therapeutic focus. You can have it all!

As a Covance employee dedicated to an FSP project, you will bring your specialized discipline to a core team working directly with one sponsor. Whether your specialization is in clinical monitoring, clinical project management, data management, biometrics or pharmacovigilance, Covance has an FSP opportunity to match your area of expertise.

You will enjoy the best of both worldsall the benefits that come along with Covances Energizing Purpose, Exceptional People and Extraordinary Potential combined with working exclusively with one sponsor and this also comes with the benefit of bringing your strong therapeutic experience to allow your expertise to shine through.

Covances FSP model is flexible and scalable. Our teams are collaborative and proactive a great place for you to continue honing your therapeutic skills and growing and excelling in new and exciting research.

Covances reach is global extending to 60+ countries making us one of the largest FSP CROs. No matter where you are located on the globe, we have an FSP opportunity for you.

In this role, the selected candidate may lead or support a study or studies, depending on size/complexity. If lead, accountable for the clinical/scientific execution of the protocol.

As lead, will be responsible for the following:
Clinical point of contact for scientific issues/questions for internal and external stakeholders (e.g., IRB, sites)
Responsible for trial design and endpoint development in collaboration with CD
Leads the Medical Monitoring (MM) team in performing MM activities, including development of the Medical Monitoring Plan (MMP) and review of SAE reports
Sets up/supports SAC, DMC, adjudication committees
Protocols/amendments collaborates with medical writer, participates in governance committee review
Authors protocol clarification letters
Contributor to study specific documents (e.g., SMP)
Reviews/updates informed consent
Provides scientific input to SM for data management activities (e.g., EDC, DRP, CRFs)
Monitors data issues requiring clinical input
Monitors central lab reports and other external data for safety and critical values
Prepares scientific slides, attends and presents protocol information at Investigator Meeting
Scientific lead on Clinical Trial Team (CTT)
Reviews specs, initiates allocation (randomization) request form and approval schedule in allocation schedule generation system
Coordinates planning of lab, bio specimens and imaging specifications
Co- authors newsletters with SM
Participates in Database lock activities
Collaboratively plans CSRs, CTDs/WMAs with medical writing
Supports publications/presentations as needed
Reconciles and review all protocol deviation classifications in SPECTRUM
Assesses and prepares protocol deviation list for CSR
Collaborates with medical writing to develop trial results communication for investigators
Provides scientific assessment for Operational Reviews
Supports SM/MW activities as needed to achieve CTT deliverables.
Provides clinical specifications to SM to support interactions with external vendors (e.g., IVRS, ePRO)
May act as mentor to other CSs
Education/Qualifications:

Degree in Life Sciences or significant experience in clinical development (>14 years)
BS/BA with 7+ yrs clinical research experience
MS/PhD with 5+ years clinical research experience
Experience:

Minimum 2 years pharmaceutical and clinical drug development experience in a Clinical Scientist role as a lead required.
Proven ability to effectively manage multiple complex studies
Medical monitoring experience required
TA-specific experience in Oncology
Excellent Excel and PP skills required
Excellent written and oral communication skills",3.5,"Covance
3.5","Chicago, IL",10000+ Employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10 to $25 million (USD)
Senior Data Engineer,-1,"Projects the candidate will be working on:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
Team and Team size:
Will be part of team
Will be part of Agile team with minimum 7 members
Top Responsibilities:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
The ideal candidate will be very comfortable creating subscriptions to stream real-time data using CDC tools such as IBM Infosphere Data Replication and streaming data to Kafka.
The candidate should be comfortable working with AS400, Oracle and MSSQL server databases, including any aspect of administration or support required to maintain them.
Required Experience & Qualifications:
Data engineering experience - 7 years
Cloud platform experience - 1 year
Version Control (Git or equivalent) - 1 years
Preferred Experience & Qualifications:
Change Data Capture Tools (IBM CDC, Attunity or equivalent) 3 years
Version Control (Git or equivalent) 1 year
Scripting (Linux/Unix Shell scripting or equivalent) 5 years
Interview Process:
a. How many rounds? 2 or 3
b. Video vs. phone? Phone
c. How technical will the interviews be? Very detailed Technical",4.0,"Horizontal
4.0","Schaumburg, IL",501 to 1000 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Sr Data Engineer,"$59K-$116K
(Glassdoor Est.)","Position Role/Tile: Sr Data Engineer
Location: Schaumburg, IL.

Job description:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.

Is this person a sole contributor or part of a team?
Will be part of team
If so, please describe the team? (Name of team, size of team, etc.)
Will be part of Agile team with minimum 7 members
What are the top 5-10 responsibilities for this position? (Please be detailed as to what the candidate is expected to do or complete on a daily basis)
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting. The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
The ideal candidate will be very comfortable creating subscriptions to stream real-time data using CDC tools such as IBM Infosphere Data Replication and streaming data to Kafka.
The candidate should be comfortable working with AS400, Oracle and MSSQL server databases, including any aspect of administration or support required to maintain them.
What software tools/skills are needed to perform these daily responsibilities?
Required Experience & Qualifications:
Data engineering experience - 7 years
Cloud platform experience - 1 year
Version Control (Git or equivalent) - 1 years
Preferred Experience & Qualifications:
Change Data Capture Tools (IBM CDC, Attunity or equivalent) 3 years
Version Control (Git or equivalent) 1 year
Scripting (Linux/Unix Shell scripting or equivalent) 5 years
Central Business Solutions, Inc,
37600 Central Ct.
Suite #214
Newark, CA 94560",3.0,"Central Business Solutions, Inc
3.0","Schaumburg, IL",51 to 200 Employees,-1,Company - Private,Consulting,Business Services,$5 to $10 million (USD)
Lead Big Data Engineer,"$100K-$169K
(Glassdoor Est.)","Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the worlds large accumulation of health-related information, or guide health and lifestyle choices, or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) The ideal candidate will be a self-starter who can learn things quickly, who is enthusiastic, active, and eager to learn. Youll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary Responsibilities: Design, code, test, document, and maintain high-quality and scalable Big Data solutionsDesign, develop and implement rules enginesResearch, evaluate, and deploy new tools, frameworks and patterns to build sustainable Big Data platformIdentify gaps and opportunities for improvement of existing solutionsDefine and develop APIs for integration with various data sources in the enterpriseAnalyze and define customer requirementsAssist in defining product technical architecture Make accurate development effort estimates to assist management in project and resource planning Create prototypes, proof-of-concepts & design and code reviews Collaborate with management, quality assurance, architecture, and other development teamsWrite technical documentation and participate in production support Keep skills up to date through ongoing self-directed training Youll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.",3.4,"UnitedHealth Group
3.4","Downers Grove, IL",10000+ Employees,1977,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
"Senior Software Engineer, Data Platform",-1,"About Us

Mastery Logistics Systems is building the worlds first lovable Transportation Management System, or TMS.

Our customers large transportation companies and shippers who need those companies have struggled with systems that are outdated or inadequate. As shippers or transportation service providers, our customers have in the past been forced to use multiple systems to manage dedicated fleet operations, outsourced or insourced trans management, one way trucking, truckload brokerage, LTL, and Intermodal, or to sub-optimize one or more of those functions by attempting to fit it into a TMS that is adequate at another function.

Mastermind TMS allows our customers to bring all of these functions into a single platform, providing flexibility, visibility, control, and efficiency. Todays unprecedented global supply chain upheavals underscore how important the transportation industry is. We are building a system to allow this industry to work faster, smarter and more efficiently.

The challenges in this industry are big and exciting! We are tackling everything from fast and efficient data input to ingesting large amounts of data and applying AI to looking at blockchain to securely digitize paperwork. If you are passionate about humanizing an industry, automating in innovative ways, building for quality and scale, helping make people's lives easier and touching every part of our economy then this is the place for you.

Mastery Logistics Systems is committed to continuing to build an incredible company. We are a masterful mosaic of incredible people. We are specialists and experienced in our respective fields. We are dedicated to continuous improvement both professionally and personally. We are a collective group of really good people. We have different interests, backgrounds & talents and we work together to create really cool stuff! We believe in diversity of thought and are mindful and inclusive. We have deep respect for each other and work diligently at adding the right people to our teams.

At this moment we are all working from home and doing our part to combat the Covid 19 virus. We are creatively building our new work habits. We are respectful of each others time and personal life. We have flexible schedules but share in the mission that we are building and need to get it done. We offer an excellent suite of benefits. We are dedicated to finding new ways to add perks as we live and work from home.

Our team has the domain knowledge and connections to make an impact, and were looking for experienced and thoughtful people to who thrive on creating and building great products. We want people who have a true passion for servicing and taking care of our customers. We need people who are flexible problem solvers, thrive on collaboration and consistently know how to communicate their solutions well. We are small and nimble which is evident in how quickly we could pivot to our new reality. Each member of the team can make a tremendous impact both technically and culturally. While a start-up, we are well-funded, have an initial paying customer with which to test and launch, and are founded by top experts and veterans in the logistics industry.

Join us youll love it lets build a masterpiece!

About the Role

The transportation industry has no shortage of complex problems requiring creative, data-intensive solutions in order to effectively and efficiently automate operations at scale. In this role, you will be expected to work autonomously and contribute to several high impact projects including building services providing near real-time analytical insights to Masterys customers.

Responsibilities
Closely collaborate with fellow Engineers, Data Scientists, and Product Managers and interact with stakeholders across the organization to build real-time data products
Design, build, and deploy microservices that provide real-time, analytical insights to some of North Americas largest freight brokerages
Support Masterys Data Science team by establishing best practices, developing tools, and building infrastructure that makes the work of Data Analysts and Data Scientists more robust, reliable, and easy to implement
Write clean, maintainable, and well-tested code
Engage in the full development life-cycle including architectural design and testing
Be a force-multiplier on the velocity and quality of your team
Stay current on software engineering trends & tools, and be practical but open-minded in applying them
Maintain a high bar for quality and performance of your product with vigorous attention to detail and automated testing
Continuously improve how we design, build, and ship software as a highly functional team
Requirements
3+ years of practical experience in data-intensive software development, including designing, building, deploying, and maintaining data applications
Expertise in data-focused development, including experience with a variety of database, data warehouse, distributed processing, and machine learning technologies
Minimum of two years of industry experience building production software with Python
Experience with Kafka or similar event streaming systems
Expertise with SQL and RDBMS
Excellent written and verbal communication skills
Adept at interacting with technical and non-technical audiences
Experience working with real-time, distributed systems
Strong sense of responsibility with a bias towards action
Experience working with RESTful APIs
Comfortable self-directing and prioritizing your own work
Ability to understand complicated problems and craft into simple solutions that can be maintained by the rest of the team
Experience leading technical projects
Ability to train and mentor junior engineer
Experience with NoSQL technologies, preferred
Experience with GraphQL, preferred
Experience in logistics industry, preferred
Benefits

Mastery takes great pride in providing our employees a robust and highly competitive benefit package. Our benefits include Medical, Dental and Vision insurance covering 90% of premium costs. Company paid life insurance for 1x salary. Legal, AD&D, Additional Life and other employee assistance benefits. We have a 401k savings plan with a 4% match. We provide opportunities for professional growth and development. We fully support our work from home initiative as we do our part to combat the Covid 19 crisis. We have a manage your life and schedule Paid Time Off program. We are fully devoted to finding creative perks and benefits since we cannot currently enjoy our cool office culture. Our philanthropic partner is St. Jude Childrens Research Hospital.

We are an equal opportunity employer and actively seek a diverse community of professionals. Veterans, Women, non-binary, people of color, LGBTQIA, we welcome all to apply!",-1,"Mastery Logistics Systems, Inc.","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
Azure Data Modeler,-1,"Great opportunity to show off your passion for data, reporting, analytics and data warehousing. Our client's BI team may have the perfect fit for you!

We are looking for a self-motivated Data modeler/Engineer to join our business intelligence team.

This individual will be responsible for developing and maintaining business intelligence, data warehousing and data engineering solutions for Enterprise data This individual will also create and maintain detailed business requirements, outlining data problems, opportunities and solutions.

Responsibilities Include:
Responsible for designing relational and non-relational data stores on Azure.
Responsible for designing and developing solutions in Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, SQL Data Warehouse, HDInsight.
Gather and process raw data at scale that meet functional / non-functional business requirements (including writing scripts, REST API calls, SQL Queries, etc.)
Responsible for developing data set processes for data modeling, mining and production.
Responsible for building new Data Lake in Azure, expanding and optimizing our data platform and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
Responsible for supporting our Software Developers, Data Analysts and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Develop complex SQL queries in TIBCO Data Virtualization tool.
Qualifications:
3+ Years of experience architecting and building Data Lake, Azure Big Data architecture, Enterprise Analytics Solutions, and optimizing ' big data' data pipelines, architectures and data sets.
Bachelor’s Degree in Computer Science, Information Systems, or related field
Advanced hands-on SQL, USQL, Python, C#, Java, pySpark (2+ of these) knowledge and experience working with relational databases for data querying and retrieval.
Experience with Design and Architecture of Azure big data frameworks/tools: Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure ML, SQL Data Warehouse, HDInsight.
Experience with building processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience working with cross-functional teams in a dynamic environment.
Experience building Big data pipeline with Java and/or Python a plus.
Strong SQL skills on multiple platform
Data Modeling tools (e.g. Erwin, Visio) knowledge a plus.
Experience with SAP HANA a plus.
Experience with Talend a plus.
_Brooksource provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws_

Job Types: Full-time, Contract

Pay: $45.00 - $50.00 per hour

Benefits:
Dental Insurance
Health Insurance
Paid Time Off
Vision Insurance
Schedule:
8 Hour Shift
Day shift
Monday to Friday
Experience:
Azure Big Data architecture: 3 years (Required)
Architecting and Building Data Lake: 3 years (Required)
Developing complex SQL Queries: 3 years (Required)
Enterprise Analytics Solutions: 3 years (Required)
Full Time Opportunity:
Yes
Work Location:
One location
Benefit Conditions:
Waiting period may apply
Work Remotely:
Temporarily due to COVID-19",4.5,"Brooksource
4.5","Northfield, IL",501 to 1000 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Senior Data Science Consultant,-1,"Senior Data Science Consultant
Healthcare
Chicago, IL
$135,000 - $155,000 + Benefits + Bonus

Are you passionate about joining one of America's most famous organizations in the healthcare/ pharmaceutical space? A leading healthcare company is looking for an experienced Senior Data Science Consultant who is technically strong in R, SQL, Python, and Tableau, to advise in implementing solutions through an analytical lens to drive business growth.

THE ROLE:

As Senior Data Science Consultant, you will be partnering with Data Scientists and mentoring junior team members in implementing and framing solutions for making certain treatment programs more efficient. You will be responsible for:

Navigating huge and complex claims data
Performing advanced analytics using Python, R, SQL, and Tableau
Consulting with internal clients to identify opportunities for which you can implement data science
Acting as analytics product owner translating business needs into analytics actions and projects

YOUR SKILLS AND EXPERIENCE:

Strong understanding of managed healthcare space
Proven commercial experience in working with claims data at a large company
Proficient in R, Hadoop, Python, SQL, and Tableau
Proficient in mathematical analysis methods, machine learning, statistical analysis, and predictive modeling
Strong understanding of advanced analytical tools and languages needed to analyze large sets of complex and messy data from multiple sources
Proven experience in strategy consulting, as well as managing or leading teams
Bachelor's degree and Master's in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline; PhD preferred

BENEFITS:

As Senior Data Science Consultant you can expect to earn up to $155,000 (depending on your experience) plus great benefits and of course, great healthcare!

HOW TO APPLY:

Please register your interest by sending your resume to George Little via the Apply link on this page.

KEYWORDS:

Healthcare, pharmaceutical, data science, advanced analytics, consultant, consulting, advisor, Python, R, Hadoop, Tableau, SQL, machine learning, predictive models, predictive analysis, statistics, claims data, engineering, project management, product owner, strategy",4.2,"Harnham
4.2","Chicago, IL",51 to 200 Employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD)
Big Data Machine Learning Engineer,-1,"Title: Big Data Machine Learning Engineer@ Chicago, IL
Terms of Hire: Full Time.
Salary: $Open+ Benefits.

The candidate can also work from any of these locations:
Chicago, IL, US
Cleveland,OH,US
Washington,DC,US
Job description

ABOUT THE JOB

The Decision Sciences team is part of the Enterprise Payments and Analytics organization. Its mission is to lead Client’s journey to become an innovative, data driven enterprise by building advanced analytics solutions for solving business problems. Our experienced team of AI/ML and Data Science practitioners focuses on engaging, enabling, and empowering decision-makers across the enterprise by developing, managing and supporting advanced analytics products and scalable digital solutions, such as real time and on demand predictive models and prescriptive analytics, and continuously researching, specifying, and deploying next-generation analytics capabilities. We are an internal consulting and services organization that works directly with users across the firm, including Lines of Businesses and partners in Enterprise Strategy, Marketing, Data Analytics, and Enterprise Architecture, to facilitate the development of innovative solutions that help Client compete and win with analytics.

The Big Data ML Engineer fills a critical data, analytics, technology support, and innovation role for the business analytics and advanced analytics functions within the organization. The Engineer is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organization’s enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS

The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use cases—primarily focused around open source technologies including cloud infrastructures. This individual evaluates short/long-term business needs required to support Client business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on Client Enterprise systems. Under the guidance of the Group’s Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on Client data assets for business decision management solutions. The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions. The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions. The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organization’s AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.

REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
What are the 3-4 non-negotiable requirements on this position?
1. Experience in open source technologies (Python, Hadoop, Spark, etc.) 2. Experience in Cloud environment, Google Cloud platform preferred 3. Machine learning expertise
What are the nice-to-have skills?
Finance/banking background
You Will Enjoy:
An opportunity to be a part of a great culture, an awesome team, a challenging work environment, and some fun along the way!
Apply today to learn more and be part of our Growth story.
All applications will be kept strictly confidential and once shortlisted, our team will be in touch with you for further discussions.",-1,CEDENT,"Chicago, IL",1 to 50 Employees,-1,Contract,Computer Hardware & Software,Information Technology,Less than $1 million (USD)
Big Data Machine Learning Engineer,-1,"Thusa is looking for Big Data Machine Learning Engineerto join the team. The ideal candidate is primarily responsible for end-user product development, deployment in production framework, data analytics technical support as well as leveraging best tools and techniques, and end-user training of new emerging analytics open source technologies. S/he is also the primary conduit for identifying, researching, and evaluating new and innovative technologies that enhance the organizations enterprise analytics and advanced analytics capabilities.

ESSENTIAL JOB FUNCTIONS
The ML Engineer works both independently and in collaboration with a cross-functional team of Data scientists and solution system architects to effectively develop, deploy, monitor, manage, and support AI/ML models and advanced analytics technology, data infrastructures, and underlying analytics use casesprimarily focused around open source technologies including cloud infrastructures.
This individual evaluates short/long-term business needs required to support key business goals and priorities and works to ensure Advanced analytics solutions are built and deployed in an effective and efficient manner on the Enterprise systems.
Under the guidance of the Groups Director and in cooperation with partners in decision science, technology, and data the Engineer will coordinate the development of on-premise and cloud-based analytical non-production and production infrastructure and tools providing computational and statistical capabilities to enhance business results and monetize on key data assets for business decision management solutions.
The Engineer will be working closely with data scientists, data mining experts, and business partner supporting the design of experiments and analytics, data sampling and mining, verification of data quality and information integrity, and best practices around the development and deployment of predictive/prescriptive models, DevOps operational systems and practices, and data visualization solutions.
The Engineer has responsibility for advising data scientists, Agile project teams, and solution architects in the integration of analytical models/methods into decision management solutions.
The Engineer will assist peers in best practices and in the selection and integration of appropriate tools to support required analytic products in close coordination with the organizations AI/AutoML analytics, digital intelligence engineers, solution/data architects, data integration developers, and data science community ensuring tight integration of functionality and toolsets.
REQUIRED QUALIFICATIONS
Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required.
Minimum of 8 years of experience in IT and Big data software development is required
Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.
Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,
Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies
Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR
Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins
Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)
Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL
Extensive Experience with R and Python including language-specific and data science-oriented packages required.
Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR
Experience with Linux/Unix required
Exposure to Google Cloud services- GCP or any cloud environment.
Working experience on Apache Airflow
Experience in enterprise scale analytic solutions development and deployment with high performance, scalability, availability & reliability.
Certified Professional Google Data Engineer preferred
Candidate must be a self-starter and creative problem-solver with an innovative and curious mindset.
Must have a working knowledge of advanced technology uses cases in financial services including machine learning, interactive data visualization, cloud computing, and streaming analytics.
Strong communication skills and the ability to interact and collaborate with all levels of the organization.
A broad, enterprise-wide view of the business and varying degrees of appreciation for strategy, processes and capabilities, enabling technologies, and governance
The ability to recognize pain points within the organization, functional interdependencies and cross-silo redundancies. Those issues may exist in role alignment, process gaps and overlaps, and business capability maturity gaps
The ability to apply architectural principles, methods, and tools to business challenges
The ability to create capability portfolios and technical roadmaps addressing gaps
The ability to understand and recognize the economics of technology and the business goals
The ability to perform industry analysis and identify business and technology trends specific to the portfolio
The ability to visualize and create high-level models that can be used in future analysis to extend and mature the business architecture
The ability to assist business case creation and realization by aligning business goals to organizational capabilities
Strong situational analysis and decision-making abilities
Financial and/or Banking background preferred.
Thusa is dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock. dedicated to delivering holistic solutions through our customized qualifying methods in which we make the upfront investment to thoroughly qualify our talent. We take the time to build real relationships with our clients and resources. In addition to that, we go the extra mile to make sure that our workforce is happy, dedicated, and appreciated so that they will always be ready to deliver quality while on your clock.

Our employees enjoy a work culture that promotes company priorities.

We treat our employees like family while providing on-going support for growth. We are not only looking for people who can do the job, we are also looking for our future leaders.

Powered by JazzHR",-1,Thusa Solutions,"Chicago, IL",-1,-1,-1,-1,-1,-1
Kafka Data Engineer (remote),"$62K-$114K
(Glassdoor Est.)","Summary
We exist to help people achieve financial clarity. At Thrivent, we believe money is a tool, not a goal. Driven by a higher purpose at our core, we are committed to providing financial advice, investments, insurance, banking and generosity programs to help people make the most of all they’ve been given.

At our heart, we are a membership-owned fraternal organization, as well as a holistic financial services organization, dedicated to serving the unique needs of our clients. We focus on their goals and priorities, guiding them toward financial choices that will help them live the life they want today—and tomorrow.

Join our newly created Data Office as the full-time Kafka Data Engineer! We are hiring for both a mid-level and a senior level Engineer. Bring your expertise in implementing modern data architectures and Data Streaming. We have a data streaming platform to enable frictionless data flow from business systems and 3rd party sources using publish/subscribe model. This role will require experience with hybrid platforms, cloud migration, publishing, development with newer technologies such as Spring Boot, KSQL/Stream Processing, data connectors such as Kafka, performance tuning, data quality and data visualization knowledge. You and will report to the Director of Information Delivery.
Job Description


Job Duties and Responsibilities
Partner on the design, deployment, and persistence of our new streaming platform unifies the data across organization, using Confluent Kafka.
As the senior level Engineer, you will be leading a group of engineers.
Design, Develop, Release & Support containerized microservices (OpenShift / Spring Boot) to transform and enrich topic data.
Lead reusable design and patterns for services and data processes within the platform.
Partner on setting standards, implementing tools, and creating documentation for self-serve data pipeline services supporting core engineering and professional services use cases.
Work with existing engineering teams to become data producers and consumers to and from Confluent Kafka.
Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.
Apply business knowledge and experience to effectively advise others on technology as an enabler.
Lead efforts to analyze IT industry and market trends and determine potential impacts.
Develop concepts and constructs necessary to create technology-enabled business systems.
Influence technology direction.
Provides thought leadership and execution to large complex efforts.
Utilize breadth of technical understanding and dive deep when necessary.
Consult on and manage initiatives to ensure alignment across multiple business and IT areas.
Proactively mitigate risks across multiple assets, information domains, technologies & platforms.
Provide leadership, mentoring and technical guidance to others to drive initiatives.
Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.
Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.
Act as a change agent to continuously improve and move the organization forward.
Accountable to provide leadership to successfully deliver the right results on initiatives in a timely and effective manner.
Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.
Ability to work within a diverse team of skillsets and experience levels to deliver results.
Required Job Qualifications
Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field.
5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years of lead experience.
Strong experience with event streaming such as (Kafka or Amazon Kinesis).
Experience with SQL and NoSQL databases (PostgreSQL, MongoDB, etc).
Proficient delivering services within AWS.
Experience with Confluent Kafka, penShift / SpringBoot is preferred.
Demonstrated ability to develop containerized microservices (Docker with Kubernetes) is preferred.
The ability to communicate cross-functionally, derive requirements and architect shared datasets; ability to synthesize, simplify and explain complex problems to different types of audiences.
Desire to show ownership of problems you identify and proven ability to empower others to get more done.
Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color, sex, gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state, or federal law. This policy applies to all employees and job applicants.

Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation, please let us know by sending an email to human.resources@thrivent.com or call 800-847-4836 and request Human Resources.",3.5,"Thrivent
3.5","Chicago, IL",5001 to 10000 Employees,1902,Nonprofit Organization,Insurance Carriers,Insurance,$5 to $10 billion (USD)
Director of AI Product Management - Office of Data Science,"$68K-$121K
(Glassdoor Est.)","Advance your career at Liberty Mutual Insurance - A Fortune 100 Company!

Help bring Liberty Mutual into the future by advocating on behalf of all data scientists across the enterprise. The Director of AI Product Management will be a key member of the Office of Data Science Product Team. As the Director of AI Product Management you will advocate for DS efforts across the enterprise by acting as Product Owner over a team of ML engineers, helping to identify, measure and socialize DS initiatives and partnering with technology, business and the data science community (DSPRG) to promote collaboration and reuse. Liberty Mutual aspires to be the data science leader within the insurance industry and you will play a key role in partnering across the organization to make this happen.

Roles and Responsibilities:
Strategic Vision
Partner with the ODS Science team to engage the enterprise and identify top business opportunities for ML application (e.g. CV, NLP, Aerial Imagery, and Trusted AI).
Measure the value of data science at Liberty and communicate it to the enterprise.
Customer / Collaboration
Foster relationships across the LM enterprise. Promote and build excitement for data science.
Act as a change agent across the organization by influencing and driving strategic direction and investments in AI.
Collaborate with and influence key stakeholders and customers to embrace a product mindset and drive business outcomes.
Partner with the business, tech and data science leaders to jointly drive forward efforts to enhance DS/AI collaboration.
Model Deployment
Act as the product owner for a ML Engineering squad tasked with deploying models delivering ~$100M (and growing) in value to the enterprise.
Manages the existing program, onboards new customers and socialize the value of the portfolio
Vendor
Support DS and ML vendor engagements and purchasing decisions as the organization makes build vs buy vs research decisions
Key traits we are looking for:
Data Science Passion - you have a passion for making things better through data science.
Leadership - You are a passionate leader who can bring the enterprise together, gain cross team alignment and deliver results.
Customer Empathy - ability to try on the experiences of customers and stakeholders - especially those with conflicting viewpoints.
Problem solving - you can solve difficult problems efficiently with appropriate methodologies
Integrity - you build and maintain trust with your colleagues, stakeholders, partners, and leaders
Drive - you work smart and hard to succeed
Communication Skills - you can communicate to a wide variety of audiences adapting your technique as appropriate in a strategic manner
Qualifications:

A minimum of three years recent experience in a DS or technology product role with a proven track record of providing leadership on complex / challenging technical product delivery.
Demonstrated ability to think broadly across multiple good viewpoints
Knowledge of DS applications, DS infrastructure needs, and organizational challenges & obstacles as it relates to vetting, prototyping and scaling DS solutions
Excellent communication, analytical, interpersonal, organizational and team building skills, business judgement, and proven expertise in directing the efforts of agile teams
Experience of strongly influencing product strategy at a senior level and leading organizational change
Ability to continuously prioritize development based on business value and product strategy
Ability to create and foster consensus from the whole business for a coherent product vision
Ability to estimate ROI of complex projects

Benefits:
We value your hard work, integrity and commitment to positive change. In return for your service, it's our privilege to offer you benefits and rewards that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits
Overview:
At Liberty Mutual, we give motivated, accomplished professionals the opportunity to help us redefine what insurance means; to work for a global leader with a deep sense of humanity and a focus on improving and protecting everyday lives. We create an inspired, collaborative environment, where people can take ownership of their work; push breakthrough ideas; and feel confident that their contributions will be valued and their growth championed.
We're dedicated to doing the right thing for our employees, because we know that their fulfillment and success leads us to great places. Life. Happiness. Innovation. Impact. Advancement. Whatever their pursuit, talented people find their path at Liberty Mutual.",3.5,"Liberty Mutual Insurance
3.5","Warrenville, IL",10000+ Employees,1912,Company - Private,Insurance Carriers,Insurance,$10+ billion (USD)
Sr. Data Engineer,"$75K-$140K
(Glassdoor Est.)","At Echo we are committed to help our Associates grow their career. Apply today and grow with Echo!
-
-",3.5,"Echo Global Logistics
3.5","Chicago, IL",1001 to 5000 Employees,2005,Company - Public,Transportation Management,Transportation & Logistics,$2 to $5 billion (USD)
Senior Data Engineer,-1,"Are you interested in building the future of healthcare and transforming the patient experience? Are you hopeful about what data and medical research can do to improve medicine? We’re looking for a Senior Data Engineer to ensure PatientIQ remains on the forefront of using data to drive positive healthcare outcomes.

As a core member of the Analytics department, you will be in a dynamic environment that is actively building the future versions of our automated data science platform - Analytics Autopilot. In addition, our team often works cross-functionally with the Engineering, Product, and Sales departments as PatientIQ scales its business. Your work will involve coming up with new software features, defining metrics, streamlining existing data processes, and mentoring other team members. We heavily value diligence, curiosity, and initiative, as those are key to unlocking the value of PatientIQ's data for our users and our decision-making. Your work will be impactful across the entire organization.

Role Responsibilities
Design, develop, and maintain ETL infrastructure to support the ingestion of external data sources
Work on a cross-functional team to design, develop, and maintain PatientIQ's internal reporting infrastructure
Understand data requirements and implement solutions for data science applications
Perform unit and integration testing
Mentor junior team members
Help scale PatientIQ's data strategy as the platform and business grows
Requirements

Ideal Qualifications
Experience designing, building, and maintaining ETL infrastructure in a production setting
BS/MS in Computer Science, Engineering, Mathematics, or related field
Proficient in Python or another object oriented programming language
Deep knowledge of SQL and at least one database technology
Experience with software development lifecycle processes and using version control systems (git), either from prior data engineering work or in a more traditional software engineering setting
Highly self-motivated with strong analytical problem-solving skills and attention to detail
Nice to Haves
Experience with workflow management systems such as luigi or airflow
Experience in machine learning and/or business intelligence
Experience with cloud technologies such as AWS, Google Cloud Platform, or Azure
Experience with ETL tools like Apache Kafka, Logstash, Segment, Informatica
Experience with automated machine learning technologies such as Amazon SageMaker or Google Cloud AutoML
Experience with cloud data warehouse platforms such as Snowflake, Qubole, etc.
Experience working in Healthcare, Finance or another regulated industry
Benefits
Great Benefits - top-notch health, dental and vision insurance. Additional perks available including 401K.
We are Mission Driven - our team is motivated to solve complex problems, drive medicine forward, and ultimately improve patient outcomes.
True Idea Meritocracy - great ideas win out. We encourage all team members to challenge the status quo because our mission demands this.
Flexible Time Off - we trust you to take the time you need when you feel it is appropriate, given your workload and responsibilities. No need to track it or save up.
World-Class Team - we’re at the top of our industry because of our employees. They’re the best investment we can make, and we never forget that.
Fast Growing - we are building the largest platform for healthcare providers, industry partners, researchers, and others to collaborate on the mission to improve patient outcomes.",-1,PatientIQ,"Chicago, IL",-1,-1,-1,-1,-1,-1
Big Data Architect,-1,"Our Client is a leader in data-driven marketing, named as one of the top 20 data integrators to watch and grow with. Our Client delivers insight and results to their customer with marketing expertise, technical and analytic capabilities, and a relentless focus on the customer. Business model based on driving lasting customer relationships and incremental brand revenue through integrated systems, online and offline CRM, real time predictive modeling, and data management.

The Big Data Architects primary responsibilities are to create and develop solution designs to integrate and ingest data from various resources, supporting Clientss internal big data ecosystem.

They will be responsible for defining the big data architectural blueprint under the supervision and collaboration with the Technology Solutions Director. The Architect will work closely with data engineers, cloud engineers, and data scientists to design and implement optimum solutions using best practices. They are responsible to ensure the data ecosystem is built to be highly scalable, responsive, and available.

The Big Data Architect oversees the implementation of data solutions by working with Clients onshore and offshore engineering teams to create ETL, batch, real-time, and automated processes. As part of the core Technology Solutions team the right candidate will heavily contribute to the teams coding and programming standards and ensure other team members are following the guidelines and standards.

Responsibilities:


Take ownership of data solutions from design and architecture perspective for projects in presales phase as well as on-going projects

Select and integrate any Big Data tools and frameworks required to provide requested capabilities. Can oversee the implementation by team members of said solutions

Design and implement ETL and automated processes

Monitor performance and advise of any necessary improvements and changes

Management of EMR clusters, Glue Jobs, Athena Tables, S3 data lakes; with all included services

Provide technical support to members of TS and SA team, as well as project support across client engagements

Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value

Stays current with relevant technology in order to maintain and/or improve functionality for authored applications

Assume other responsibilities as requested/required

Acts as a subject matter expert for systems worked on

Ensures Clients data solutions are using the latest versions and code base

Actively listen to and work with end users to gather feedback and input, and make suggestions and solutions based on said feedback

Requirements

Required Experience:
(7 years of relevant experience) or (5 years of relevant experience and an advanced degree in Computer Science/IT or related field)

Keen understanding of distributed computing principles
• Proficiency with Big Data frameworks such as Hadoop, Spark, MapReduce, HDFS.

Proven experience ingesting data from multiple data sources such as REST API, SFTP flat files, Streaming data etc.

Proven experience with Big Data querying tools such as Athena/Presto, Pig, Hive, and Impala

Proven experience with NoSQL databases, such as HBase, Cassandra, Redshift, DynamoDB

Proven experience with various ETL techniques and frameworks, such as Flume, Glue Jobs, Step Functions

Proven experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O

Proven experience with AWS Lambda and leveraging it in various solutions such as Glue, Step Functions, CloudWatch, S3 Events, etc.

Strong experience with using Python scripts & libraries

Experience desired with Database Warehousing Design Concepts; Dimensional.
• Modeling, Star/Snowflake Schemas, ETL/ELT, Data Marts, Analytic Playgrounds, Reporting techniques

Experience working with Agile software development methodologies, namely Scrum

Proven experience with team collaboration, release management, system and performance monitoring

Ability to work well with people from many different disciplines and varying degrees of technical experience

Excellent analytical, problem resolution, organization and time management skills

Ability to handle multiple tasks at a time
• Demonstrated ability to have successfully completed multiple, complex technical projects and create high-level design and architecture of the solution, including class, sequence and deployment infrastructure diagrams

Prior experience with application delivery using an Onshore/Offshore model
• Experience with gathering end user requirements and writing technical documentation

Keyword: Hadoop, Spark, MapReduce, HDFS, REST, API, SFTP, Athena, Pig, Hive, Impala, NoSQL, HBase, Cassandra, Reddrift, DynamoDB

Benefits


We do have a full benefit package of medical/dental/vision insurance, disability, life, 401k employer match along with profit sharing and bonus. Optional benefits is AFLAC plans and FSA for medical or childcare.

Vacation, 5 Sick Days and 2 personal days with a total of about 30 days off within a year depending on when holidays fall. Included in that is the close of the office between Christmas and New Years.",-1,DSMHConsulting,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"Candidate Responsibilities

Develop implementation patterns leveraging AWS technologies to support Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solution Data Designs, Models, Pipelines
Prototype New Solutions Technical guidance to data designers and
developers Solution Implementation Reviews Open to Chicago, IL as well.

Typical Day

Understand business and technical requirements Develop Conceptual and
Logical Data Solution for data acquisition, data models and pipelines
Review Solutions with Platform, Business, and Application teams

Requirements


Education Requirements:

B.S. in Computer Science, Information Systems, or related major or
equivalent IS / business experience. 10+ years experience designing,
implementing data persistance and processing solutions AWS
Certifications

Technical Skills

AWS Cloud Based Technologies for Data Processing and Persistance
(DynamoDB, S3, Aurora, Kinesis, SQS,SNS, Lambda, Fargate, Glue) Ability
to design and communicate solutions to meet business and technical
requirements Demonstrated Data Architecture and Design
for Big Data, Analytics, and applications

Soft Skills

Written and Verbal Communication Able to produce architecture and design artifacts in Visio and Office 365",-1,DSMHConsulting,"Chicago, IL",-1,-1,-1,-1,-1,-1
Staff Big Data Engineer,"$95K-$171K
(Glassdoor Est.)","Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry. Our technology handles hundreds of thousands of transactions per second; collects tens of billions of events each day; and evaluates thousands of data-points in real-time all while responding in just a few milliseconds.

We are looking for an experienced Big Data Engineer to join our Data Engineering team. This position will be the Senior technical resource driving architecture for the integration of large 3rd party partner integrations with companies like Facebook, Google and Twitter to name a few. The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. This position will require the ability to own and lead data initiatives on a cross-functional team.The ideal candidate is naturally curious, dedicated, detail-oriented with a strong desire to work with awesome people in a highly collaborative environment. You should be able to not take yourself too seriously as well. And most of all, you will enjoy working with great people who are changing the entire industry.

What you'll do:
Migrate existing data pipelines from on-prem regional data centers to AWS and GCP.
Architect a new modern event driven architecture with both batching and streaming
Adjust existing pipelines to fit the AWS processing model such as integration with S3, migrate to open source version of hadoop, adjustments to security model, etc...
Working on Big Data technologies such as Hadoop, MapReduce, Kafka, and/or Spark in columnar databases
Architect, design, code and maintain components for aggregating tens of billions of daily transactions
Lead the entire software lifecycle including hands-on development, code reviews, testing, deployment, and documentation for streaming and batch ETL's and RESTful API's
Partner and work closely with the QA Engineers to develop automated tests
Participate in training and mentoring of junior team members
You should apply if you have most of this:

(We have flexibility in this role to consider more, or marginally lesser, experience than requested below)
8+ years of experience designing and building data-intensive applications
5+ years architecting systems in a big data ecosystem using MapReduce, Spark, MPP Data Warehouses, and sql/nosql databases.
5+ years recent hands-on experience with object oriented languages (Java, Scala, Python)
5+ years Hands on experience building production level systems in a cloud environment (AWS or GCP)
Excellent interpersonal and communication skills in English
Proven experience leading the design and execution of event driven architectures for distributed systems
Experience designing systems for performance, scalability, and reliability
In-depth understanding of object oriented programming concepts
Low level working knowledge of collections, multi-threading, JVM memory model, etc.
Solid understanding of database fundamentals and SQL
Understanding the full software development life cycle, agile development and continuous integration
Ability to clearly communicate with team-members in a cross-matrix environment
What puts you over the top:
Built systems in a containerized environment with familiarity in Docker, ECS, Kubernetes
Exposure to Data Warehousing solutions like Snowflake and BigQuery
Prior ad tech experience
About Integral Ad Science

Integral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 18 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit integralads.com.

Equal Opportunity Employer:

IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.

California Applicant Pre-Collection Notice:

We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.

To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN

Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.",3.5,"Integral Ad Science
3.5","Chicago, IL",501 to 1000 Employees,2009,Company - Private,Internet,Information Technology,$100 to $500 million (USD)
Sr. Data Engineer,-1,"About Us:

Convr is a growing startup in the InsureTech space. Our d3 Underwriting Platform helps underwriters make better decisions more efficiently. As we continue to grow we are looking for leaders to help us scale not only our platform but our organization. This is an exciting role that will allow you to mentor, lead, and innovate.

The Role:

THIS POSITION WILL BE IN OUR SCHAUMBURG, IL OFFICE. WE CANNOT OFFER OUT OF STATE OPPORTUNITIES AT THIS TIME. As a Sr. Data Engineer, you will work closely with technical leadership and product managers to lead a team delivering the best solutions for our customers. You will develop a deep understanding of the people, technologies, and practices of your team(s), and apply your expertise to scale our teams and platform. You will innovate and push our technology further. You will teach and mentor our engineers to be more efficient, write quality code, and leverage best practices.

Your Responsibilities:
Be a high performer that produces production quality code that gets value to our customers
Enables scalability within our applications and services
Owns parts of our systems and innovates to create defensible depth in our products
Mentors our engineers to help further their technical skills
Technical Skills Demonstrated:
7+ Years in creating a production application / services
1+ Years as a team lead on a sprint team
1+ Years in Python
4+ Years with micro-services architecture
Understanding of data modeling and various data lake solutions
Built out data platforms that support multiple data sources
Worked on systems with high number of users (1000s - 1Ms)
ML and AI Experience
Owned Code all the way to production before
Experience with DevOps
Things that will help you succeed:
Passion for delivering value to customers
Enjoys solving complex data problems
Can evangelize Agile / Scrum framework to deliver this value
Quality is everything to you
Ownership! Takes ownership and responsibility for all things Convr
Test 1st Mindset
Education:

Bachelors Degree",-1,Convr,"Schaumburg, IL",-1,-1,-1,-1,-1,-1
Senior Pharmaceutical Development Scientist,-1,"Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate.Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generatedtotal revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

Job Description

With supervision as required, proficiently performs all assigned chemistry techniques. Demonstrates a good understanding of scientific principals and their cause and effect on scientific outcomes. Practice of GMP/GLP is routine. Once appropriately trained, this individual may be designated as a notebook reviewer. Authors and may review others protocols, reports, specifications and test methods. Presents results at team meetings with interpretation. Acts as a coach to junior staff.
Proficiently performs all assigned laboratory techniques.
Independently develops analytical methods on a variety of analytical techniques and instrumentation.
Independently performs method validation by authoring protocols, reports and analytical methods and may review or critique others.
Experience in operating and troubleshooting the following instrumentation:
Ultra-High Performance Liquid Chromatography
Differential Scanning Calorimetry (DSC)
Size Exclusion Chromatography
Multi Angle Light Scattering (MALS)
Fourier Transform Infrared Spectroscopy (FTIR)
Asymmetrical Field- Flow Fractionation (AFFF)
Dynamic Light Scattering (DLS)
Tutors and trains others on troubleshooting analytical methods and instrumentation.
Routine practice of and compliance with GMP/GLP.
Designated notebook reviewer.
Generates, analyzes and presents scientific data at team meetings. Explains cause and effect relationships and may propose additional experiments to
prove/disprove hypotheses. Has a general understanding of the depth and breadth of drug development and can contribute to the scientific discussion during project team meetings.
Understand regulatory guidelines and can author protocols, reports and analytical test methods.
Generate and analyze scientific data and handle OOS’s (Out of Specification) with little difficulty.
Has a good understanding of different plant manufacturing processes and can plan bench studies that will translate into a manufacturing process while solving related compounding, solubility, etc. problems.
Qualifications
B.S. and 5 - 7 years of drug development/tech transfer/manufacturing experience or M.S. or Ph.D. and 2 - 3 years of drug development experience. Preferred education background in Analytical Chemistry, Pharmaceutics or similar discipline, however, extensive experience with analytical chemistry may be substituted for education.
Significant experience with the drug development process
Self-driven and self-motivated
Excellent communication skills
Track record of responsibility for multiple development projects
Strong analytical background
Liquid formulation experience is desirable
Product development experience in the pharmaceutical industry
Ability to meet deadlines
Authorization to work in the United States indefinitely without restriction or sponsorship
Additional Information

Position is full-time, Mon-Fri 8:00am-5:00pm. Candidates currently living within a commutable distance of Lake Forest, IL are encouraged to apply.
Excellent full time benefits including comprehensive medical coverage, dental, and vision options
Life and disability insurance
401(k) with company match
Paid vacation and holidays
Eurofins is a M/F, Disabled, and Veteran Equal Employment Opportunity and Affirmative Action employer.",-1,Eurofins USA PSS Insourcing Solutions,"Lake Forest, IL",-1,-1,-1,-1,-1,-1
Senior Clinical Scientist - Clinical Trial Mgmt and Medical Monitoring exp required,"$27-$49 Per Hour
(Glassdoor Est.)","Job Overview:


Senior Clinical Scientist - Oncology

Clinical Trial Mgmt and Medical Monitoring experience is required

Remote in the USA or Canada

Why settle for one thing when you can have everything?

Covance gives you the best two-for-one opportunity for career growth. Who doesnt want twice the perks? Working at Covanceone of the largest FSP CROsand partnering with one sponsor with a dedicated therapeutic focus. You can have it all!

As a Covance employee dedicated to an FSP project, you will bring your specialized discipline to a core team working directly with one sponsor. Whether your specialization is in clinical monitoring, clinical project management, data management, biometrics or pharmacovigilance, Covance has an FSP opportunity to match your area of expertise.

You will enjoy the best of both worldsall the benefits that come along with Covances Energizing Purpose, Exceptional People and Extraordinary Potential combined with working exclusively with one sponsor and this also comes with the benefit of bringing your strong therapeutic experience to allow your expertise to shine through.

Covances FSP model is flexible and scalable. Our teams are collaborative and proactive a great place for you to continue honing your therapeutic skills and growing and excelling in new and exciting research.

Covances reach is global extending to 60+ countries making us one of the largest FSP CROs. No matter where you are located on the globe, we have an FSP opportunity for you.

In this role, the selected candidate may lead or support a study or studies, depending on size/complexity. If lead, accountable for the clinical/scientific execution of the protocol.

As lead, will be responsible for the following:
Clinical point of contact for scientific issues/questions for internal and external stakeholders (e.g., IRB, sites)
Responsible for trial design and endpoint development in collaboration with CD
Leads the Medical Monitoring (MM) team in performing MM activities, including development of the Medical Monitoring Plan (MMP) and review of SAE reports
Sets up/supports SAC, DMC, adjudication committees
Protocols/amendments collaborates with medical writer, participates in governance committee review
Authors protocol clarification letters
Contributor to study specific documents (e.g., SMP)
Reviews/updates informed consent
Provides scientific input to SM for data management activities (e.g., EDC, DRP, CRFs)
Monitors data issues requiring clinical input
Monitors central lab reports and other external data for safety and critical values
Prepares scientific slides, attends and presents protocol information at Investigator Meeting
Scientific lead on Clinical Trial Team (CTT)
Reviews specs, initiates allocation (randomization) request form and approval schedule in allocation schedule generation system
Coordinates planning of lab, bio specimens and imaging specifications
Co- authors newsletters with SM
Participates in Database lock activities
Collaboratively plans CSRs, CTDs/WMAs with medical writing
Supports publications/presentations as needed
Reconciles and review all protocol deviation classifications in SPECTRUM
Assesses and prepares protocol deviation list for CSR
Collaborates with medical writing to develop trial results communication for investigators
Provides scientific assessment for Operational Reviews
Supports SM/MW activities as needed to achieve CTT deliverables.
Provides clinical specifications to SM to support interactions with external vendors (e.g., IVRS, ePRO)
May act as mentor to other CSs
Education/Qualifications:

Degree in Life Sciences or significant experience in clinical development (>14 years)
BS/BA with 7+ yrs clinical research experience
MS/PhD with 5+ years clinical research experience
Experience:

Minimum 2 years pharmaceutical and clinical drug development experience in a Clinical Scientist role as a lead required.
Proven ability to effectively manage multiple complex studies
Medical monitoring experience required
TA-specific experience in Oncology
Excellent Excel and PP skills required
Excellent written and oral communication skills",3.5,"Covance
3.5","Chicago, IL",10000+ Employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10 to $25 million (USD)
Senior Data Engineer,-1,"Projects the candidate will be working on:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
Team and Team size:
Will be part of team
Will be part of Agile team with minimum 7 members
Top Responsibilities:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
The ideal candidate will be very comfortable creating subscriptions to stream real-time data using CDC tools such as IBM Infosphere Data Replication and streaming data to Kafka.
The candidate should be comfortable working with AS400, Oracle and MSSQL server databases, including any aspect of administration or support required to maintain them.
Required Experience & Qualifications:
Data engineering experience - 7 years
Cloud platform experience - 1 year
Version Control (Git or equivalent) - 1 years
Preferred Experience & Qualifications:
Change Data Capture Tools (IBM CDC, Attunity or equivalent) 3 years
Version Control (Git or equivalent) 1 year
Scripting (Linux/Unix Shell scripting or equivalent) 5 years
Interview Process:
a. How many rounds? 2 or 3
b. Video vs. phone? Phone
c. How technical will the interviews be? Very detailed Technical",4.0,"Horizontal
4.0","Schaumburg, IL",501 to 1000 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD)
Sr Data Engineer,"$59K-$116K
(Glassdoor Est.)","Position Role/Tile: Sr Data Engineer
Location: Schaumburg, IL.

Job description:
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.
The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.

Is this person a sole contributor or part of a team?
Will be part of team
If so, please describe the team? (Name of team, size of team, etc.)
Will be part of Agile team with minimum 7 members
What are the top 5-10 responsibilities for this position? (Please be detailed as to what the candidate is expected to do or complete on a daily basis)
This role is for a Change Data Capture (CDC) Senior Data Engineer that will join a team responsible for streaming data for Cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting. The right candidate will have a solid background in data engineering and should have a few years of experience on AS400, Change Data Capture tools and also working on Cloud platform such as Azure.
The ideal candidate will be very comfortable creating subscriptions to stream real-time data using CDC tools such as IBM Infosphere Data Replication and streaming data to Kafka.
The candidate should be comfortable working with AS400, Oracle and MSSQL server databases, including any aspect of administration or support required to maintain them.
What software tools/skills are needed to perform these daily responsibilities?
Required Experience & Qualifications:
Data engineering experience - 7 years
Cloud platform experience - 1 year
Version Control (Git or equivalent) - 1 years
Preferred Experience & Qualifications:
Change Data Capture Tools (IBM CDC, Attunity or equivalent) 3 years
Version Control (Git or equivalent) 1 year
Scripting (Linux/Unix Shell scripting or equivalent) 5 years
Central Business Solutions, Inc,
37600 Central Ct.
Suite #214
Newark, CA 94560",3.0,"Central Business Solutions, Inc
3.0","Schaumburg, IL",51 to 200 Employees,-1,Company - Private,Consulting,Business Services,$5 to $10 million (USD)
Lead Big Data Engineer,"$100K-$169K
(Glassdoor Est.)","Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the worlds large accumulation of health-related information, or guide health and lifestyle choices, or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) The ideal candidate will be a self-starter who can learn things quickly, who is enthusiastic, active, and eager to learn. Youll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary Responsibilities: Design, code, test, document, and maintain high-quality and scalable Big Data solutionsDesign, develop and implement rules enginesResearch, evaluate, and deploy new tools, frameworks and patterns to build sustainable Big Data platformIdentify gaps and opportunities for improvement of existing solutionsDefine and develop APIs for integration with various data sources in the enterpriseAnalyze and define customer requirementsAssist in defining product technical architecture Make accurate development effort estimates to assist management in project and resource planning Create prototypes, proof-of-concepts & design and code reviews Collaborate with management, quality assurance, architecture, and other development teamsWrite technical documentation and participate in production support Keep skills up to date through ongoing self-directed training Youll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.",3.4,"UnitedHealth Group
3.4","Downers Grove, IL",10000+ Employees,1977,Company - Public,Health Care Services & Hospitals,Health Care,$10+ billion (USD)
"Senior Software Engineer, Data Platform",-1,"About Us

Mastery Logistics Systems is building the worlds first lovable Transportation Management System, or TMS.

Our customers large transportation companies and shippers who need those companies have struggled with systems that are outdated or inadequate. As shippers or transportation service providers, our customers have in the past been forced to use multiple systems to manage dedicated fleet operations, outsourced or insourced trans management, one way trucking, truckload brokerage, LTL, and Intermodal, or to sub-optimize one or more of those functions by attempting to fit it into a TMS that is adequate at another function.

Mastermind TMS allows our customers to bring all of these functions into a single platform, providing flexibility, visibility, control, and efficiency. Todays unprecedented global supply chain upheavals underscore how important the transportation industry is. We are building a system to allow this industry to work faster, smarter and more efficiently.

The challenges in this industry are big and exciting! We are tackling everything from fast and efficient data input to ingesting large amounts of data and applying AI to looking at blockchain to securely digitize paperwork. If you are passionate about humanizing an industry, automating in innovative ways, building for quality and scale, helping make people's lives easier and touching every part of our economy then this is the place for you.

Mastery Logistics Systems is committed to continuing to build an incredible company. We are a masterful mosaic of incredible people. We are specialists and experienced in our respective fields. We are dedicated to continuous improvement both professionally and personally. We are a collective group of really good people. We have different interests, backgrounds & talents and we work together to create really cool stuff! We believe in diversity of thought and are mindful and inclusive. We have deep respect for each other and work diligently at adding the right people to our teams.

At this moment we are all working from home and doing our part to combat the Covid 19 virus. We are creatively building our new work habits. We are respectful of each others time and personal life. We have flexible schedules but share in the mission that we are building and need to get it done. We offer an excellent suite of benefits. We are dedicated to finding new ways to add perks as we live and work from home.

Our team has the domain knowledge and connections to make an impact, and were looking for experienced and thoughtful people to who thrive on creating and building great products. We want people who have a true passion for servicing and taking care of our customers. We need people who are flexible problem solvers, thrive on collaboration and consistently know how to communicate their solutions well. We are small and nimble which is evident in how quickly we could pivot to our new reality. Each member of the team can make a tremendous impact both technically and culturally. While a start-up, we are well-funded, have an initial paying customer with which to test and launch, and are founded by top experts and veterans in the logistics industry.

Join us youll love it lets build a masterpiece!

About the Role

The transportation industry has no shortage of complex problems requiring creative, data-intensive solutions in order to effectively and efficiently automate operations at scale. In this role, you will be expected to work autonomously and contribute to several high impact projects including building services providing near real-time analytical insights to Masterys customers.

Responsibilities
Closely collaborate with fellow Engineers, Data Scientists, and Product Managers and interact with stakeholders across the organization to build real-time data products
Design, build, and deploy microservices that provide real-time, analytical insights to some of North Americas largest freight brokerages
Support Masterys Data Science team by establishing best practices, developing tools, and building infrastructure that makes the work of Data Analysts and Data Scientists more robust, reliable, and easy to implement
Write clean, maintainable, and well-tested code
Engage in the full development life-cycle including architectural design and testing
Be a force-multiplier on the velocity and quality of your team
Stay current on software engineering trends & tools, and be practical but open-minded in applying them
Maintain a high bar for quality and performance of your product with vigorous attention to detail and automated testing
Continuously improve how we design, build, and ship software as a highly functional team
Requirements
3+ years of practical experience in data-intensive software development, including designing, building, deploying, and maintaining data applications
Expertise in data-focused development, including experience with a variety of database, data warehouse, distributed processing, and machine learning technologies
Minimum of two years of industry experience building production software with Python
Experience with Kafka or similar event streaming systems
Expertise with SQL and RDBMS
Excellent written and verbal communication skills
Adept at interacting with technical and non-technical audiences
Experience working with real-time, distributed systems
Strong sense of responsibility with a bias towards action
Experience working with RESTful APIs
Comfortable self-directing and prioritizing your own work
Ability to understand complicated problems and craft into simple solutions that can be maintained by the rest of the team
Experience leading technical projects
Ability to train and mentor junior engineer
Experience with NoSQL technologies, preferred
Experience with GraphQL, preferred
Experience in logistics industry, preferred
Benefits

Mastery takes great pride in providing our employees a robust and highly competitive benefit package. Our benefits include Medical, Dental and Vision insurance covering 90% of premium costs. Company paid life insurance for 1x salary. Legal, AD&D, Additional Life and other employee assistance benefits. We have a 401k savings plan with a 4% match. We provide opportunities for professional growth and development. We fully support our work from home initiative as we do our part to combat the Covid 19 crisis. We have a manage your life and schedule Paid Time Off program. We are fully devoted to finding creative perks and benefits since we cannot currently enjoy our cool office culture. Our philanthropic partner is St. Jude Childrens Research Hospital.

We are an equal opportunity employer and actively seek a diverse community of professionals. Veterans, Women, non-binary, people of color, LGBTQIA, we welcome all to apply!",-1,"Mastery Logistics Systems, Inc.","Chicago, IL",1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD)
